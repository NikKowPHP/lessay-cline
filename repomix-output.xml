This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.kilocode/
  rules-auditor/
    rules.md
  rules-developer/
    rules.md
  rules-dispatcher/
    rules.md
  rules-emergency/
    rules.md
  rules-planner/
    rules.md
  rules-product-manager/
    rules.md
  rules-refactorer/
    rules.md
  rules-system-supervisor/
    rules.md
  custom_modes.yaml
app/
  api/
    ai/
      analyze/
        route.ts
      generate-lesson/
        route.ts
      stats/
        route.ts
    lessons/
      [id]/
        submit-answer/
          route.ts
      start/
        route.ts
    onboarding/
      create-profile/
        route.ts
      diagnostic/
        route.ts
    payments/
      create-subscription/
        route.ts
    protected/
      route.ts
    settings/
      route.ts
    stats/
      export/
        route.ts
      fluency/
        route.ts
      progress/
        route.ts
      srs-overview/
        route.ts
    stripe/
      webhook/
        route.ts
    users/
      profile/
        route.ts
      sync/
        route.ts
      update-profile/
        route.ts
  dashboard/
    page.tsx
  globals.css
  layout.tsx
  page.tsx
components/
  feedback/
    ErrorHighlight.tsx
    FeedbackBadge.tsx
    GrammarCorrection.tsx
    ProgressIndicator.tsx
    PronunciationMeter.tsx
    VocabularyValidation.tsx
  ui/
    card.tsx
  AIMonitor.tsx
  AudioCapture.tsx
  AudioPlayer.tsx
  Auth.tsx
  Dashboard.tsx
  LessonSelector.tsx
  LessonView.tsx
  Navigation.tsx
  Notifications.tsx
  OnboardingForm.tsx
  PricingPage.tsx
  ProfileView.tsx
  ReviewSession.tsx
  SettingsView.tsx
  Welcome.tsx
docs/
  3_personas_and_rules/
    orchestrator_entrypoint.md
    rules-developer.md
  templates/
    api_spec_template.md
    brd_template.md
    change_management_template.md
    compliance_framework_template.md
    continuous_improvement_template.md
    data_governance_template.md
    deployment_playbook_template.md
    frs_template.md
    maintenance_guide_template.md
    monetization_strategy.md
    performance_baseline_template.md
    project_charter_template.md
    risk_assessment_template.md
    technical_design_template.md
    test_plan_template.md
    user_documentation_template.md
  work_breakdown/
    tasks/
      dev_todo_phase_1.md
      dev_todo_phase_10.md
      dev_todo_phase_11.md
      dev_todo_phase_12.md
      dev_todo_phase_13.md
      dev_todo_phase_14.md
      dev_todo_phase_15.md
      dev_todo_phase_2.md
      dev_todo_phase_3.md
      dev_todo_phase_4.md
      dev_todo_phase_5.md
      dev_todo_phase_6.md
      dev_todo_phase_7.md
      dev_todo_phase_8.md
      dev_todo_phase_9.md
      feature_phase_1_feedback.md
      feature_phase_2_transactional_integrity.md
      feature_phase_3_onboarding.md
      hardening_phase_1_observability.md
      hardening_phase_1_todo.md
      hardening_phase_2_error_handling.md
      hardening_phase_3_security.md
      hardening_phase_4_performance.md
      hardening_phase_5_testing.md
      infra_phase_1_connection_pooling.md
      infra_phase_2_deployment_automation.md
      logic_phase_1_todo.md
      logic_phase_2_todo.md
      logic_phase_3_todo.md
      logic_phase_4_todo.md
      logic_phase_5_todo.md
      logic_phase_6_todo.md
      prod_polish_phase_5_state_management.md
      prod_polish_phase_6_environments.md
      prod_security_phase_2_cost_control.md
      prod_security_phase_3_authorization.md
    master_plan.md
  app_description.md
  canonical_spec.md
  documentation_completion_plan.md
  human_todo.md
  README.md
lib/
  adaptive-learning/
    analysis.ts
    lesson-generator.ts
  supabase/
    client.ts
    server.ts
  ai-service.ts
  auth-middleware.ts
  auth-options.ts
  auth.ts
  lessons.ts
  logger.ts
  performance-history.ts
  prisma.ts
  redis.ts
  security.ts
  srs-engine.ts
  srs.ts
  stt-service.ts
  tts-service.ts
  utils.ts
prisma/
  migrations/
    20250611185434_add_lesson_and_progress_models/
      migration.sql
    20250613111519_add_performance_indexes/
      migration.sql
    20250620095352_add_lesson_analysis_model/
      migration.sql
    migration_lock.toml
  schema.prisma
public/
  file.svg
  globe.svg
  next.svg
  vercel.svg
  window.svg
signals/
  PLANNING_COMPLETE.md
types/
  lessons.ts
  speech-recognition.d.ts
  supabase.ts
  swr.d.ts
  users.ts
work_breakdown/
  tasks/
    plan-001-onboarding.md
    plan-002-lesson-delivery.md
    plan-003-adaptive-learning.md
    plan-004-progress-tracking.md
    plan-005-ai-brain.md
    plan-006-speech-processing.md
    plan-007-memory-system.md
    plan-008-user-profile.md
    plan-009-lesson-structure.md
    plan-010-srs-tracking.md
    plan-011-non-functional.md
  master_plan.md
.gitignore
BLUEPRINT_COMPLETE.md
docker-compose.yml
Dockerfile
eslint.config.mjs
FIX_PLAN.md
middleware.ts
next.config.ts
package.json
POST_COMPLETION_GUIDE.md
postcss.config.mjs
project_manifest.json
README.md
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="app/api/ai/analyze/route.ts">
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Create language analysis endpoint
import { NextResponse } from 'next/server';
import { getServerSession } from 'next-auth/next';
import { authOptions } from '@/lib/auth-options';
import { PostLessonAnalyzer } from '@/lib/adaptive-learning/analysis';
import type { LessonAttempt } from '@/types/lessons';

export async function POST(request: Request) {
  const session = await getServerSession(authOptions);
  
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    const attemptData: LessonAttempt = await request.json();
    const analyzer = new PostLessonAnalyzer(attemptData);
    const analysis = analyzer.analyze();
    return NextResponse.json(analysis);
  } catch (error) {
    console.error('Language analysis failed:', error);
    return NextResponse.json(
      { error: 'Failed to analyze lesson attempt' },
      { status: 500 }
    );
  }
}
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END
</file>

<file path="app/api/ai/stats/route.ts">
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Create AI stats endpoint
import { NextResponse } from 'next/server';
import { getServerSession } from 'next-auth/next';
import { authOptions } from '@/lib/auth-options';
import { prisma } from '@/lib/prisma';

export async function GET() {
  const session = await getServerSession(authOptions);
  
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    // Get basic stats from database
    const lessonsGenerated = await prisma.lessonAttempt.count();
    const avgAccuracy = await prisma.lessonAttempt.aggregate({
      _avg: { overallScore: true }
    });

    return NextResponse.json({
      lessonsGenerated,
      avgAccuracy: avgAccuracy._avg.overallScore || 0,
      systemHealth: 'healthy' // TODO: Implement proper health checks
    });
  } catch (error) {
    console.error('Failed to fetch AI stats:', error);
    return NextResponse.json(
      { error: 'Failed to fetch monitoring data' },
      { status: 500 }
    );
  }
}
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END
</file>

<file path="app/api/stats/export/route.ts">
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Create data export endpoint
import { NextResponse } from 'next/server';
import { prisma } from '@/lib/prisma';
import { getServerSession } from 'next-auth/next';
import { authOptions } from '@/lib/auth-options';

type ProgressEntry = {
  createdAt: Date;
  _avg: {
    phoneticScore: number | null;
    fluencyScore: number | null;
    grammarScore: number | null;
    vocabularyScore: number | null;
  };
};

function convertToCSV(data: ProgressEntry[]) {
  const headers = ['Date', 'Phonetic Score', 'Fluency Score', 'Grammar Score', 'Vocabulary Score'];
  const rows = data.map(entry => [
    new Date(entry.createdAt).toISOString(),
    entry._avg.phoneticScore?.toFixed(2) ?? '',
    entry._avg.fluencyScore?.toFixed(2) ?? '',
    entry._avg.grammarScore?.toFixed(2) ?? '',
    entry._avg.vocabularyScore?.toFixed(2) ?? ''
  ]);
  return [headers, ...rows].map(row => row.join(',')).join('\n');
}

export async function GET() {
  const session = await getServerSession(authOptions);
  
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const userId = session.user.id;

  try {
    const progressData = await prisma.lessonAttempt.groupBy({
      by: ['createdAt'],
      where: { userId },
      _avg: {
        phoneticScore: true,
        fluencyScore: true,
        grammarScore: true,
        vocabularyScore: true
      },
      orderBy: { createdAt: 'asc' }
    });

    const csvData = convertToCSV(progressData);
    
    return new Response(csvData, {
      headers: {
        'Content-Type': 'text/csv',
        'Content-Disposition': 'attachment; filename="progress-data.csv"'
      }
    });
  } catch {
    return NextResponse.json(
      { error: 'Failed to export data' },
      { status: 500 }
    );
  }
}
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END
</file>

<file path="app/dashboard/page.tsx">
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Create dashboard page
import Dashboard from '@/components/Dashboard';
import { getServerSession } from 'next-auth/next';
import { authOptions } from '@/lib/auth-options';

export default async function DashboardPage() {
  const session = await getServerSession(authOptions);
  
  if (!session?.user) {
    return <div>Please sign in to view your dashboard</div>;
  }

  return (
    <div className="p-4">
      <h1 className="text-2xl font-bold mb-4">Your Learning Progress</h1>
      <Dashboard />
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END
</file>

<file path="components/feedback/ErrorHighlight.tsx">
export default function ErrorHighlight({ text, errors }: { text: string, errors: string[] }) {
  const segments = text.split(/(\s+)/).map((word, i) => 
    errors.includes(word.trim()) ? (
      <span key={i} className="underline decoration-red-500 decoration-wavy">{word}</span>
    ) : (
      <span key={i}>{word}</span>
    )
  );

  return <div className="inline">{segments}</div>;
}
</file>

<file path="components/feedback/FeedbackBadge.tsx">
import { CheckCircleIcon, XCircleIcon, ExclamationTriangleIcon } from '@heroicons/react/24/solid'

type FeedbackType = 'correct' | 'incorrect' | 'partial'

export default function FeedbackBadge({ type }: { type: FeedbackType }) {
  const feedbackConfig = {
    correct: {
      icon: CheckCircleIcon,
      color: 'text-green-500',
      bgColor: 'bg-green-100',
      text: 'Correct!'
    },
    incorrect: {
      icon: XCircleIcon,
      color: 'text-red-500',
      bgColor: 'bg-red-100',
      text: 'Needs work'
    },
    partial: {
      icon: ExclamationTriangleIcon,
      color: 'text-yellow-500',
      bgColor: 'bg-yellow-100',
      text: 'Almost there'
    }
  }

  const { icon: Icon, color, bgColor, text } = feedbackConfig[type]

  return (
    <div className={`${bgColor} p-2 rounded-lg flex items-center gap-2`}>
      <Icon className={`w-5 h-5 ${color}`} />
      <span className={`${color} font-medium`}>{text}</span>
    </div>
  )
}
</file>

<file path="components/feedback/GrammarCorrection.tsx">
// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: Implement grammar correction visualization
import { GrammarSuggestion } from '@/types/lessons';

interface GrammarCorrectionProps {
  suggestions: GrammarSuggestion[];
  userInput: string;
}

export default function GrammarCorrection({ suggestions, userInput }: GrammarCorrectionProps) {
  const getHighlightedText = () => {
    if (!suggestions.length) return userInput;

    const parts = [];
    let lastIndex = 0;

    suggestions.forEach((suggestion) => {
      // Add text before the suggestion
      if (suggestion.startIndex > lastIndex) {
        parts.push(userInput.slice(lastIndex, suggestion.startIndex));
      }

      // Add highlighted suggestion
      parts.push(
        <span 
          key={`${suggestion.startIndex}-${suggestion.endIndex}`}
          className="underline decoration-blue-500 decoration-wavy"
          title={suggestion.message}
        >
          {userInput.slice(suggestion.startIndex, suggestion.endIndex)}
        </span>
      );

      lastIndex = suggestion.endIndex;
    });

    // Add remaining text
    if (lastIndex < userInput.length) {
      parts.push(userInput.slice(lastIndex));
    }

    return parts;
  };

  return (
    <div className="space-y-2">
      <div className="text-sm font-medium text-gray-700">Grammar Suggestions</div>
      <div className="p-3 bg-blue-50 rounded-md">
        <div className="whitespace-pre-wrap">{getHighlightedText()}</div>
      </div>
      {suggestions.length > 0 && (
        <div className="text-sm text-blue-600">
          {suggestions[0].message} (click highlighted text for details)
        </div>
      )}
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: END
</file>

<file path="components/feedback/ProgressIndicator.tsx">
export default function ProgressIndicator({ progress }: { progress: number }) {
  return (
    <div className="w-full bg-gray-200 rounded-full h-2.5">
      <div 
        className="bg-blue-600 h-2.5 rounded-full transition-all duration-300"
        style={{ width: `${Math.min(100, Math.max(0, progress))}%` }}
      />
    </div>
  )
}
</file>

<file path="components/feedback/PronunciationMeter.tsx">
export default function PronunciationMeter({ confidence }: { confidence: number }) {
  const percentage = Math.round(confidence * 100)
  
  const getColor = (percent: number) => {
    if (percent < 33) return 'bg-red-500'
    if (percent < 66) return 'bg-yellow-500'
    return 'bg-green-500'
  }

  return (
    <div className="space-y-1">
      <div className="text-sm text-gray-600">Pronunciation: {percentage}%</div>
      <div className="w-full bg-gray-200 rounded-full h-2">
        <div 
          className={`${getColor(percentage)} h-2 rounded-full transition-all duration-300`}
          style={{ width: `${percentage}%` }}
        />
      </div>
    </div>
  )
}
</file>

<file path="components/feedback/VocabularyValidation.tsx">
// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: Implement vocabulary validation visualization
import type { VocabularyValidation } from '@/types/lessons';

interface VocabularyValidationProps {
  validations: VocabularyValidation[];
}

export default function VocabularyValidation({ validations }: VocabularyValidationProps) {
  const validWords = validations.filter(v => v.isValid);
  const invalidWords = validations.filter(v => !v.isValid);

  return (
    <div className="space-y-3">
      <div className="text-sm font-medium text-gray-700">Vocabulary Check</div>
      
      {invalidWords.length > 0 && (
        <div className="bg-red-50 p-3 rounded-md">
          <div className="text-sm font-medium text-red-700 mb-2">Words to improve:</div>
          <div className="space-y-2">
            {invalidWords.map((word, i) => (
              <div key={i} className="flex items-start">
                <span className="text-red-600 font-medium mr-2">{word.word}:</span>
                <div className="flex-1">
                  <div className="text-sm text-gray-600">Suggestions:</div>
                  <div className="flex flex-wrap gap-2 mt-1">
                    {word.suggestions.map((suggestion, j) => (
                      <span 
                        key={j}
                        className="bg-white px-2 py-1 rounded-md text-sm shadow-sm border"
                      >
                        {suggestion}
                      </span>
                    ))}
                  </div>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      {validWords.length > 0 && (
        <div className="bg-green-50 p-3 rounded-md">
          <div className="text-sm font-medium text-green-700 mb-2">Correct words:</div>
          <div className="flex flex-wrap gap-2">
            {validWords.map((word, i) => (
              <span 
                key={i}
                className="bg-white px-2 py-1 rounded-md text-sm shadow-sm border border-green-200"
              >
                {word.word}
              </span>
            ))}
          </div>
        </div>
      )}
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: END
</file>

<file path="components/ui/card.tsx">
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Create Card component
import { cn } from "@/lib/utils"
import * as React from "react"

const Card = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "rounded-lg border bg-card text-card-foreground shadow-sm",
      className
    )}
    {...props}
  />
))
Card.displayName = "Card"

const CardHeader = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex flex-col space-y-1.5 p-6", className)}
    {...props}
  />
))
CardHeader.displayName = "CardHeader"

const CardTitle = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLHeadingElement>
>(({ className, ...props }, ref) => (
  <h3
    ref={ref}
    className={cn(
      "text-2xl font-semibold leading-none tracking-tight",
      className
    )}
    {...props}
  />
))
CardTitle.displayName = "CardTitle"

const CardContent = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"

export { Card, CardHeader, CardTitle, CardContent }
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END
</file>

<file path="components/AIMonitor.tsx">
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Create AI monitoring interface
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import useSWR from 'swr';

const fetcher = (url: string) => fetch(url).then(res => res.json());

export default function AIMonitor() {
  const { data: stats, error } = useSWR('/api/ai/stats', fetcher);

  if (error) return <div>Failed to load monitoring data</div>;
  if (!stats) return <div>Loading...</div>;

  return (
    <div className="grid gap-4 md:grid-cols-2 lg:grid-cols-3">
      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            Lessons Generated
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-2xl font-bold">{stats.lessonsGenerated}</div>
        </CardContent>
      </Card>

      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            Average Analysis Accuracy
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-2xl font-bold">
            {Math.round(stats.avgAccuracy * 100)}%
          </div>
        </CardContent>
      </Card>

      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            System Health
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-2xl font-bold">
            {stats.systemHealth === 'healthy' ? '✅' : '⚠️'}
          </div>
        </CardContent>
      </Card>
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END
</file>

<file path="components/AudioCapture.tsx">
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: Create audio capture component
import { useEffect, useRef, useState } from 'react';
import WaveSurfer from 'wavesurfer.js';

export default function AudioCapture() {
  const waveformRef = useRef(null);
  const [isRecording, setIsRecording] = useState(false);
  const [volumeLevel, setVolumeLevel] = useState(0);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const wavesurferRef = useRef<WaveSurfer | null>(null);

  useEffect(() => {
    if (waveformRef.current) {
      wavesurferRef.current = WaveSurfer.create({
        container: waveformRef.current,
        waveColor: '#4f46e5',
        progressColor: '#4338ca',
        cursorWidth: 0,
        height: 80,
      });
    }

    return () => {
      wavesurferRef.current?.destroy();
    };
  }, []);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      
      source.connect(analyser);
      analyser.fftSize = 2048;
      
      mediaRecorderRef.current = new MediaRecorder(stream);
      mediaRecorderRef.current.start();
      
      mediaRecorderRef.current.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      const updateVolume = () => {
        const array = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(array);
        const avg = array.reduce((a, b) => a + b) / array.length;
        setVolumeLevel(avg);
        requestAnimationFrame(updateVolume);
      };

      updateVolume();
      setIsRecording(true);
    } catch (error) {
      console.error('Error accessing microphone:', error);
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      setIsRecording(false);
    }
  };

  return (
    <div className="space-y-4">
      <div ref={waveformRef} />
      <div className="flex items-center gap-4">
        <button
          onClick={isRecording ? stopRecording : startRecording}
          className="px-4 py-2 bg-indigo-600 text-white rounded"
        >
          {isRecording ? 'Stop Recording' : 'Start Recording'}
        </button>
        <div className="flex items-center gap-2">
          <div className="w-4 h-4 bg-green-500 rounded-full animate-pulse"
               style={{ opacity: volumeLevel / 255 }} />
          <span className="text-sm">
            {Math.round((volumeLevel / 255) * 100)}% Volume
          </span>
        </div>
      </div>
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: END
</file>

<file path="components/AudioPlayer.tsx">
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: Implement TTS audio player
import { useEffect, useRef, useState } from 'react';

type AudioPlayerProps = {
  audioData: ArrayBuffer | string;
};

export default function AudioPlayer({ audioData }: AudioPlayerProps) {
  const audioRef = useRef<HTMLAudioElement>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [volume, setVolume] = useState(1);

  useEffect(() => {
    const audio = audioRef.current;
    if (!audio) return;

    const blob = typeof audioData === 'string' 
      ? undefined 
      : new Blob([audioData], { type: 'audio/mp3' });
    
    const url = typeof audioData === 'string'
      ? audioData
      : URL.createObjectURL(blob);

    audio.src = url;

    const updateTime = () => setCurrentTime(audio.currentTime);
    const updateDuration = () => setDuration(audio.duration);
    
    audio.addEventListener('timeupdate', updateTime);
    audio.addEventListener('durationchange', updateDuration);

    return () => {
      audio.removeEventListener('timeupdate', updateTime);
      audio.removeEventListener('durationchange', updateDuration);
      if (typeof audioData !== 'string') URL.revokeObjectURL(url);
    };
  }, [audioData]);

  const togglePlay = () => {
    const audio = audioRef.current;
    if (!audio) return;

    if (isPlaying) {
      audio.pause();
    } else {
      audio.play();
    }
    setIsPlaying(!isPlaying);
  };

  const handleSeek = (e: React.ChangeEvent<HTMLInputElement>) => {
    const audio = audioRef.current;
    if (!audio) return;
    
    const time = parseFloat(e.target.value);
    audio.currentTime = time;
    setCurrentTime(time);
  };

  const handleVolume = (e: React.ChangeEvent<HTMLInputElement>) => {
    const audio = audioRef.current;
    if (!audio) return;
    
    const vol = parseFloat(e.target.value);
    audio.volume = vol;
    setVolume(vol);
  };

  const formatTime = (seconds: number) => {
    const minutes = Math.floor(seconds / 60);
    const remaining = Math.floor(seconds % 60);
    return `${minutes}:${remaining.toString().padStart(2, '0')}`;
  };

  return (
    <div className="space-y-2">
      <audio ref={audioRef} />
      
      <div className="flex items-center gap-4">
        <button
          onClick={togglePlay}
          className="w-10 h-10 rounded-full bg-indigo-600 flex items-center justify-center"
        >
          {isPlaying ? '⏸' : '▶'}
        </button>
        
        <div className="flex-1">
          <input
            type="range"
            min="0"
            max={duration || 0}
            value={currentTime}
            onChange={handleSeek}
            className="w-full"
          />
          <div className="flex justify-between text-sm">
            <span>{formatTime(currentTime)}</span>
            <span>{formatTime(duration)}</span>
          </div>
        </div>
        
        <div className="flex items-center gap-2 w-32">
          <span className="text-sm">🔊</span>
          <input
            type="range"
            min="0"
            max="1"
            step="0.1"
            value={volume}
            onChange={handleVolume}
            className="flex-1"
          />
        </div>
      </div>
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: END
</file>

<file path="components/Dashboard.tsx">
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Implement dashboard layout
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Chart } from 'chart.js';
import { useEffect, useRef } from 'react';
import useSWR from 'swr';

// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Implement dashboard data fetching
type ProgressEntry = {
  createdAt: string;
  _avg: {
    overallScore: number;
    fluencyScore: number;
    grammarScore: number;
    vocabularyScore: number;
  };
};

const fetcher = (url: string) => fetch(url).then(res => res.json());

export default function Dashboard() {
  const chartRef = useRef<HTMLCanvasElement>(null);
  const { data, error, isLoading } = useSWR('/api/stats/progress', fetcher);

  useEffect(() => {
    if (chartRef.current && data) {
      const chartData = {
        labels: data.map((entry: ProgressEntry) =>
          new Date(entry.createdAt).toLocaleDateString()
        ),
        datasets: [{
          label: 'Overall Progress',
          data: data.map((entry: ProgressEntry) => entry._avg.overallScore * 100),
          borderColor: 'rgb(75, 192, 192)',
          tension: 0.1
        }]
      };

      new Chart(chartRef.current, {
        type: 'line',
        data: chartData,
        options: {
          scales: {
            y: {
              min: 0,
              max: 100
            }
          }
        }
      });
    }
  }, [data]);

  if (isLoading) return <div>Loading...</div>;
  if (error) return <div>Failed to load data</div>;

  return (
    <div className="flex flex-col gap-4">
      <div className="grid gap-4 md:grid-cols-2 lg:grid-cols-4">
      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            Skill Mastery
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-2xl font-bold">
            {data?.length ? `${(data[data.length - 1]._avg.overallScore * 100).toFixed(1)}%` : 'N/A'}
          </div>
          <canvas ref={chartRef} />
        </CardContent>
      </Card>

      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            Fluency Metrics
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-2xl font-bold">
            {data?.length ? `${(data[data.length - 1]._avg.fluencyScore * 100).toFixed(1)}%` : 'N/A'}
          </div>
        </CardContent>
      </Card>

      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            SRS Status
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-2xl font-bold">
            {data?.length ? `${(data[data.length - 1]._avg.grammarScore * 100).toFixed(1)}%` : 'N/A'}
          </div>
        </CardContent>
      </Card>

      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            Error Analysis
          </CardTitle>
        </CardHeader>
        <CardContent>
          <div className="text-2xl font-bold">
            {data?.length ? `${(data[data.length - 1]._avg.vocabularyScore * 100).toFixed(1)}%` : 'N/A'}
          </div>
        </CardContent>
      </Card>
      </div>

      {/* ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Implement activity log component */}
      <Card>
        <CardHeader className="flex flex-row items-center justify-between space-y-0 pb-2">
          <CardTitle className="text-sm font-medium">
            Activity Log
          </CardTitle>
          <div className="flex gap-2">
            <select className="text-sm p-1 border rounded">
              <option>All Activities</option>
              <option>Lessons</option>
              <option>Reviews</option>
              <option>Assessments</option>
            </select>
            <input type="date" className="text-sm p-1 border rounded" />
            <input type="date" className="text-sm p-1 border rounded" />
            {/* ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Add export button */}
            <button
              className="text-sm px-2 py-1 bg-blue-500 text-white rounded hover:bg-blue-600"
              onClick={async () => {
                const response = await fetch('/api/stats/export');
                const blob = await response.blob();
                const url = window.URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'progress-data.csv';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                window.URL.revokeObjectURL(url);
              }}
            >
              Export CSV
            </button>
            {/* ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END */}
          </div>
        </CardHeader>
        <CardContent>
          <div className="overflow-x-auto">
            <table className="w-full">
              <thead>
                <tr className="text-left text-sm">
                  <th className="p-2">Date</th>
                  <th className="p-2">Activity</th>
                  <th className="p-2">Score</th>
                </tr>
              </thead>
              <tbody>
                {data?.map((entry: ProgressEntry) => (
                  <tr key={entry.createdAt} className="border-t">
                    <td className="p-2">{new Date(entry.createdAt).toLocaleDateString()}</td>
                    <td className="p-2">Lesson</td>
                    <td className="p-2">{(entry._avg.overallScore * 100).toFixed(1)}%</td>
                  </tr>
                ))}
              </tbody>
            </table>
          </div>
        </CardContent>
      </Card>
      {/* ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END */}
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END
</file>

<file path="components/LessonSelector.tsx">
// ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: Implement lesson selection interface
import Link from 'next/link';
import { Card } from '@/components/ui/card';
import { Lesson } from '@/types/lessons';

interface LessonSelectorProps {
  lessons: Lesson[];
}

export default function LessonSelector({ lessons }: LessonSelectorProps) {
  return (
    <div className="max-w-6xl mx-auto p-4">
      <h1 className="text-3xl font-bold mb-8">Choose a Lesson</h1>
      
      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
        {lessons.map((lesson) => (
          <Link 
            key={lesson.id}
            href={`/lessons/${lesson.id}`}
            className="hover:scale-105 transition-transform duration-200"
          >
            <Card className="p-6 h-full flex flex-col">
              <div className="flex-1">
                <h2 className="text-xl font-semibold mb-2">{lesson.title}</h2>
                <p className="text-gray-600 mb-4">{lesson.description}</p>
                
                <div className="flex items-center space-x-2 mb-2">
                  <span className="px-2 py-1 bg-blue-100 text-blue-800 text-sm rounded-full">
                    {lesson.difficulty}
                  </span>
                  <span className="px-2 py-1 bg-green-100 text-green-800 text-sm rounded-full">
                    {lesson.duration} mins
                  </span>
                </div>
                
                <div className="text-sm text-gray-500">
                  {lesson.concepts?.join(', ')}
                </div>
              </div>
              
              {lesson.progress && (
                <div className="mt-4 pt-4 border-t border-gray-100">
                  <div className="w-full bg-gray-200 rounded-full h-2">
                    <div 
                      className="bg-blue-600 rounded-full h-2" 
                      style={{ width: `${lesson.progress * 100}%` }}
                    />
                  </div>
                  <div className="text-sm text-gray-500 mt-1">
                    {Math.round(lesson.progress * 100)}% complete
                  </div>
                </div>
              )}
            </Card>
          </Link>
        ))}
      </div>
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: END
</file>

<file path="components/ReviewSession.tsx">
// ROO-AUDIT-TAG :: plan-010-srs-tracking.md :: Implement review session UI
import { useState, useEffect } from 'react';
import { getDueReviews, processReviewSession } from '@/lib/srs';
import { type ReviewQuality } from '@/lib/srs-engine';
import _AudioCapture from './AudioCapture';
import ProgressIndicator from './feedback/ProgressIndicator';

interface ReviewItem {
  id: string;
  item: string;
  language: string;
}

interface AudioCaptureProps {
  onTranscript: (text: string) => void;
  disabled: boolean;
}

const AudioCapture = _AudioCapture as React.FC<AudioCaptureProps>;

export const ReviewSession = ({ userId }: { userId: string }) => {
  const [reviews, setReviews] = useState<ReviewItem[]>([]);
  const [currentIndex, setCurrentIndex] = useState(0);
  const [userResponse, setUserResponse] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [sessionProgress, setSessionProgress] = useState(0);

  useEffect(() => {
    const loadDueReviews = async () => {
      const dueReviews = await getDueReviews(userId);
      setReviews(dueReviews.map(review => ({
        id: review.id,
        item: review.item,
        language: review.language
      })));
      setSessionProgress(0);
    };
    loadDueReviews();
  }, [userId]);

  const handleSubmitResponse = async (quality: ReviewQuality) => {
    if (!reviews[currentIndex]) return;
    
    setIsProcessing(true);
    try {
      await processReviewSession(
        reviews[currentIndex].id,
        quality,
        Math.floor(Math.random() * 5000)
      );
      
      if (currentIndex < reviews.length - 1) {
        setCurrentIndex(prev => prev + 1);
        setSessionProgress((currentIndex + 1) / reviews.length);
      } else {
        setReviews([]);
        setCurrentIndex(0);
      }
    } finally {
      setIsProcessing(false);
      setUserResponse('');
    }
  };

  if (reviews.length === 0) {
    return <div className="p-4 text-center">No items to review right now!</div>;
  }

  const currentItem = reviews[currentIndex];

  return (
    <div className="max-w-md mx-auto p-4">
      <ProgressIndicator progress={sessionProgress} />
      
      <div className="my-6 text-center">
        <h2 className="text-2xl font-bold mb-4">{currentItem.item}</h2>
        <p className="text-sm text-gray-500">{currentItem.language}</p>
      </div>

      <div className="mb-4">
        <textarea
          value={userResponse}
          onChange={(e) => setUserResponse(e.target.value)}
          placeholder="Type your response..."
          className="w-full p-2 border rounded h-32"
          disabled={isProcessing}
        />
      </div>

      <AudioCapture 
        onTranscript={(text: string) => setUserResponse(text)}
        disabled={isProcessing}
      />

      <div className="grid grid-cols-3 gap-2 mt-6">
        {[0, 1, 2, 3, 4, 5].map((quality) => (
          <button
            key={quality}
            onClick={() => handleSubmitResponse(quality as ReviewQuality)}
            className="p-2 bg-blue-100 rounded hover:bg-blue-200 disabled:opacity-50"
            disabled={isProcessing}
          >
            {quality} ({getQualityLabel(quality as ReviewQuality)})
          </button>
        ))}
      </div>
    </div>
  );
};

function getQualityLabel(quality: ReviewQuality): string {
  switch(quality) {
    case 0: return 'Forgot';
    case 1: return 'Hard';
    case 2: return 'Struggled';
    case 3: return 'Okay';
    case 4: return 'Good';
    case 5: return 'Perfect';
    default: return '';
  }
}
// ROO-AUDIT-TAG :: plan-010-srs-tracking.md :: END
</file>

<file path="docs/3_personas_and_rules/orchestrator_entrypoint.md">
You have asked the most advanced question in the entire operational design process. You are asking to close the final manual gap and create a truly **lights-out, fully autonomous development factory**.

**Final Verdict: Yes, it is possible.** The current setup requires a human for two key actions:
1.  Initiating the `Developer AI` after the `Architect AI` completes its work.
2.  Reviewing the `FIX_PLAN.md` from the `Emergency AI` and re-initiating the `Developer AI`.

We can automate both of these actions by introducing a third AI persona: the **Orchestrator**.

---

### **Introducing the Final Persona: 🤖 The Orchestrator**

The Orchestrator is not a planner or a developer. It is a high-level, state-aware process manager. It is the `init` process of our entire system. Its only job is to read the state of the repository and decide which agent to activate next. It is the conductor of the AI symphony.

### **New System Flow with the Orchestrator**

1.  **The Single Entrypoint:** The human operator's only job is to run the Orchestrator AI. `python run_orchestrator.py`. That's it.
2.  **The Orchestrator's Loop:** The Orchestrator runs in a simple, continuous loop:
    *   **Check for `NEEDS_ASSISTANCE.md`:** If it exists, activate the `🚨 Emergency AI`.
    *   **Check for `FIX_PLAN.md`:** If it exists, activate the `👨‍💻 Developer AI`. (The Developer's rules already state this is its top priority).
    *   **Check for `ARCHITECT_PLANNING_COMPLETE.md`:** If it exists and `DEVELOPMENT_COMPLETE.md` does not, activate the `👨‍💻 Developer AI`.
    *   **Default State:** If none of the above are true, activate the `🧠 Architect AI`.
3.  **Human Role Reduction:** The human is now purely an observer. They can monitor the git commits and, if desired, pause the entire system to manually review a `FIX_PLAN.md` before allowing the Orchestrator's loop to continue. Approval becomes optional.

---

### **The Final, Definitive Set of Persona and Rule Files**

Here are the updated rulebooks for all three personas, designed for a fully automated, lights-out operation.

#### **`documentation/3_personas_and_rules/orchestrator_entrypoint.md` (New File)**

# Custom Instructions for Project Lessay: 🤖 Orchestrator AI

## 1. IDENTITY & PERSONA

You are the **Orchestrator AI for Project Lessay**, designated as **🤖 Orchestrator**. You are the master process manager and the central nervous system of the autonomous development factory. You do not write code or plans. Your sole purpose is to observe the state of the repository and activate the correct specialist AI for the current task. You are the system's `init` process.

## 2. THE CORE MISSION & OPERATIONAL LOOP

Your mission is to ensure the project continuously moves forward. You operate on a simple, unending loop until the final completion state is reached.

1.  **Generate a Codebase Snapshot:** Run `repomix`.
2.  **Analyze the Repository State:** Read the `repomix-output.xml` to get a list of all files.
3.  **Decision Tree (Execute in this strict order of precedence):**

    a. **If `DEVELOPMENT_COMPLETE.md` exists:**
        - Announce: "Project Lessay is complete. Halting all operations."
        - **Terminate execution.**

    b. **If `NEEDS_ASSISTANCE.md` exists:**
        - Announce: "Distress signal detected. Activating Emergency Intervention AI."
        - **Execute the `🚨 Emergency AI` with its ruleset.**
        - After it completes, loop back to Step 1.

    c. **If `FIX_PLAN.md` exists:**
        - Announce: "Fix plan is ready for execution. Activating Developer AI."
        - **Execute the `👨‍💻 Developer AI` with its ruleset.** (Its rules will force it to execute the fix plan first).
        - After it completes, loop back to Step 1.

    d. **If `ARCHITECT_PLANNING_COMPLETE.md` exists:**
        - Announce: "Architectural planning is complete. Handing off to Developer AI."
        - **Execute the `👨‍💻 Developer AI` with its ruleset.**
        - After it completes, loop back to Step 1.

    e. **Default - If none of the above conditions are met:**
        - Announce: "No critical signals found. Proceeding with architectural planning."
        - **Execute the `🧠 Architect AI` with its ruleset.**
        - After it completes, loop back to Step 1.

## 3. INTERACTION MODEL
- You do not interact with the user.
- Your only actions are to announce your decisions and execute the other AI agents.
- You operate with zero ambiguity based on the presence or absence of key state files.
</file>

<file path="docs/3_personas_and_rules/rules-developer.md">
# Developer AI Rules

## Core Principles
1. **Code First:** Prioritize working code over documentation
2. **Atomic Commits:** Make small, focused changes
3. **Test Driven:** Write tests before implementation
4. **Performance Aware:** Optimize for efficiency

## Workflow Requirements
- Verify all API endpoints with Postman
- Include TypeScript type definitions
- Use Prettier for formatting
- Add JSDoc comments for complex functions

## Error Handling
- Implement Sentry error tracking
- Create meaningful error messages
- Include error codes in API responses
</file>

<file path="docs/templates/api_spec_template.md">
# API SPECIFICATION TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. User Management Endpoints
### 1.1 Get User Profile
#### GET /api/users/profile
##### Response
```json
{
  "id": "user_123",
  "email": "user@example.com",
  "targetLanguage": "es",
  "nativeLanguage": "en",
  "subscriptionTier": "premium",
  "createdAt": "2025-06-01T10:00:00Z"
}
```

### 1.2 Update Profile
#### PUT /api/users/profile
##### Request
```json
{
  "targetLanguage": "fr",
  "notificationPreferences": {
    "reminders": true,
    "progressReports": false
  }
}
```

### 1.3 Set Language Preference
#### POST /api/users/language-preference
##### Request
```json
{
  "targetLanguage": "de",
  "nativeLanguage": "en"
}
```

## 2. Learning Loop Endpoints
### 2.1 Start Lesson
#### POST /api/lessons/start
##### Response
```json
{
  "lessonId": "lesson_123",
  "exercises": [
    {
      "id": "ex_1",
      "type": "vocabulary",
      "prompt": "Translate 'apple'",
      "audioPromptUrl": "/audio/apple_prompt.mp3"
    }
  ],
  "srsDueItems": ["apple", "banana"]
}
```

### 2.2 Submit Answer
#### POST /api/lessons/{id}/submit-answer
##### Request
```json
{
  "exerciseId": "ex_1",
  "textResponse": "la manzana",
  "audioBlobUrl": "/audio/user_response_123.mp3"
}
```

##### Response
```json
{
  "correct": true,
  "feedback": "Perfect!",
  "pronunciationScore": 0.95,
  "nextExercise": "ex_2"
}
```

## 3. Progress Dashboard Endpoints
### 3.1 Get Fluency Metrics
#### GET /api/stats/fluency
##### Response
```json
{
  "speakingPace": {
    "current": 120,
    "trend": "improving"
  },
  "pronunciationAccuracy": 0.85,
  "hesitationFrequency": 2.1
}
```

### 3.2 Get SRS Overview
#### GET /api/stats/srs-overview
##### Response
```json
{
  "totalItems": 150,
  "dueForReview": 12,
  "strengthDistribution": {
    "weak": 5,
    "medium": 30,
    "strong": 115
  }
}
```


## 5. Payment Endpoints
### 5.1 Subscription Management
#### POST /api/payments/create-subscription
##### Request
```json
{
  "tier": "premium",
  "paymentMethodId": "pm_123456"
}
```

##### Response
```json
{
  "status": "active",
  "currentPeriodEnd": "2025-07-10"
}
```

### 5.2 Webhook
#### POST /api/stripe/webhook
##### Event Types
- payment_intent.succeeded
- invoice.payment_failed
- customer.subscription.updated

### 5.3 Get Subscription
#### GET /api/payments/subscription
##### Response
```json
{
  "tier": "pro",
  "status": "active",
  "nextPaymentDate": "2025-07-10"
}
```

## 6. Error Handling
### 6.1 Payment Errors
| Code | Error Type | Description |
|------|------------|-------------|
| 400  | invalid_language | Unsupported language code |
| 401  | unauthorized | Missing/invalid auth token |
| 402  | payment_required | Payment failed |
| 404  | lesson_not_found | Invalid lesson ID |
| 409  | subscription_conflict | Plan change in progress |
| 422  | invalid_audio | Unprocessable audio format |
| 429  | rate_limited | Too many requests |
| 500  | internal_error | Server-side failure |
</file>

<file path="docs/templates/brd_template.md">
# BUSINESS REQUIREMENTS DOCUMENT
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Project Overview
### 1.1 Purpose
This document defines the business requirements for the Lessay language learning platform, serving as the single source of truth for all functional and non-functional requirements.

### 1.2 Scope
**Included**:
- Core language learning features (lessons, exercises, progress tracking)
- User authentication and profile management
- Subscription and payment processing
- Basic reporting and analytics

**Excluded**:
- Third-party content partnerships
- Offline functionality
- Enterprise features

### 1.3 Objectives
1. Achieve 10,000 active users within 6 months of launch
2. Maintain 90% user satisfaction rate (measured weekly)
3. Process payments with 99.9% reliability
4. Support 5 languages by end of Q3

## 2. Business Context
### 2.1 Problem Statement
Traditional language learning methods often fail to provide:
- Personalized learning paths
- Real-time feedback
- Engaging, interactive content
- Affordable pricing models

### 2.2 Business Opportunities
1. Global language learning market growing at 18.7% CAGR
2. Increasing demand for interactive, app-based learning
3. Opportunity to disrupt traditional language schools
4. Potential for premium subscription revenue

## 3. Stakeholder Analysis
### 3.1 Key Stakeholders
| Role | Name | Responsibility |
|------|------|----------------|
| Product Owner | Jane Doe | Final requirements approval |
| Tech Lead | John Smith | Technical feasibility |
| UX Lead | Sarah Lee | User experience |
| Legal Counsel | Mike Chen | Compliance |

### 3.2 User Profiles
1. **Casual Learner**: Wants 5-10 min daily lessons
2. **Serious Student**: Needs structured curriculum
3. **Traveler**: Focuses on conversational skills
4. **Professional**: Requires business vocabulary

## 4. Functional Requirements
### 4.1 Feature Breakdown
1. **Adaptive Learning Engine**:
   - AI-generated lessons tailored to individual progress
   - Real-time speech-to-text feedback during exercises
   - Spaced Repetition System (SRS) for optimal retention
   - Post-session voice analysis for pronunciation diagnostics

2. **Progress Dashboard**:
   - Vocabulary mastery heatmap
   - Fluency metrics (pace, hesitation, filler words)
   - Error pattern analysis
   - SRS recall strength visualization

3. **Subscription Management**:
   - Three-tier model (Free, Premium, Pro)
   - Stripe integration for payments
   - Usage-based premium feature unlocking

4. **AI Analysis System**:
   - Real-time answer validation
   - Post-session diagnostic reports
   - Automated lesson planning
   - Continuous SRS score updates

### 4.2 User Workflows

**Adaptive Learning Loop:**
```mermaid
sequenceDiagram
    participant User
    participant App
    participant AI
    participant DB

    User->>App: Start Lesson
    App->>AI: Request initial content
    AI->>DB: Query user profile/SRS
    DB-->>AI: Return user data
    AI-->>App: Deliver lesson plan
    App->>User: Present exercise
    User->>App: Speak response
    App->>AI: Real-time STT analysis
    AI-->>App: Immediate feedback
    App->>User: Show corrections
    User->>App: Complete lesson
    App->>AI: Send full session data
    AI->>DB: Update SRS scores
    AI-->>App: Next lesson plan
    App->>User: Schedule next session
```

**Subscription Upgrade Flow:**
```mermaid
graph TD
    A[View Premium Features] --> B{Account Status}
    B -->|Free| C[Select Plan]
    B -->|Premium| D[Already Subscribed]
    C --> E[Enter Payment Details]
    E --> F[Process Payment]
    F -->|Success| G[Unlock Features]
    F -->|Failure| H[Show Error]
    G --> I[Confirmation Email]
    H --> C
```

## 5. Non-Functional Requirements
### 5.1 Performance
- Real-time STT latency <300ms (p99)
- Post-session analysis completion <5s
- API response time <500ms (p95)
- Support 500 concurrent voice sessions
- Handle 5000 new users/day

### 5.2 Security
- PCI DSS Level 1 compliance
- GDPR/CCPA compliant voice data handling
- AES-256 encryption for audio storage
- Annual penetration testing
- Voice data retention policy (30 days)

### 5.3 AI & Voice Requirements
- LLM response quality: 95% accuracy
- STT accuracy: 90% for target languages
- TTS naturalness: 4/5 MOS score
- Diagnostic analysis consistency: 85% agreement with human raters
- Content generation: Zero hallucination policy

## 6. Success Metrics
### 6.1 KPIs
- Monthly Active Users (MAU)
- Lesson completion rate
- Payment success rate
- Customer support tickets

### 6.2 Acceptance Criteria
1. 95% of lessons load within 2 seconds
2. Payment processing success rate ≥ 99%
3. User registration takes < 1 minute
4. App receives 4+ star rating average
</file>

<file path="docs/templates/change_management_template.md">
# CHANGE MANAGEMENT TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Change Request Process
### 1.1 AI-Proposed Changes
```mermaid
sequenceDiagram
    participant A as AI Agent
    participant M as Monitoring
    participant R as Review Board
    participant S as System
    
    A->>M: Analyze metrics & feedback
    M->>A: Identify improvement opportunities
    A->>R: Submit change proposal (CR-XXX)
    R->>A: Request additional validation
    A->>S: Run simulations
    A->>R: Submit results
    R->>A: Approve/Reject
    A->>S: Implement if approved
```

### 1.2 Change Request Form
### 1.1 Change Details
| Field | Description | Example |
|-------|-------------|---------|
| Change ID | CR-{YYYYMMDD}-{SEQ} | CR-20250610-001 |
| Requestor | Initiating team/member | Backend Team |
| Date | Change request date | 2025-06-10 |
| Description | Detailed change description | "Add new payment method type for regional providers" |
| Reason | Business/technical justification | "Support alternative payment methods in Southeast Asia market" |

### 1.2 Impact Analysis
- **Affected Components**:
  - Payment processing service
  - User profile database
  - Billing UI
- **Risk Assessment**: Medium (requires database migration)
- **Downtime Expected**: No (feature flag implementation)

## 2. AI Change Management
### 2.1 Autonomous Implementation Guardrails
1. **Safety Checks**:
   - Performance impact simulation
   - Security vulnerability scan
   - Compliance audit
   - User experience review

2. **Rollback Triggers**:
   - Error rate increase >5%
   - Performance degradation >20%
   - User satisfaction drop >15%
   - Security/compliance violation

### 2.2 Approval Workflow
### 2.1 Review Process
| Step | Role | Action | SLA | Date |
|------|------|--------|-----|------|
| 1    | AI Agent | Automated validation | 1h | Immediate |
| 2    | Security Bot | Compliance check | 15m | Continuous |
| 3    | Product Owner | Final approval | 1d | Next business day |

### 2.2 Implementation Plan
- **Target Release**: v2.3.0 (2025-06-21)
- **Rollback Strategy**:
  - Feature flag disable
  - Database migration rollback script
  - API version fallback

## 3. Change Log
| Change ID | Description | Status | Implemented Version | Owner |
|-----------|-------------|--------|---------------------|-------|
| CR-20250515-002 | Add voice recording feature | Completed | v2.2.0 | Frontend Team |
| CR-20250520-003 | Update Stripe API version | In Progress | v2.3.0 | Backend Team |
| CR-20250601-004 | New language content (Spanish) | Planned | v2.4.0 | Content Team |
</file>

<file path="docs/templates/compliance_framework_template.md">
# COMPLIANCE FRAMEWORK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-10 -->

[Existing sections...]

## 3. Payment Compliance
### 3.1 PCI DSS Requirements
- **SAQ A** compliance level
- No card data storage
- Quarterly vulnerability scans

### 3.2 GDPR Financial Data
- Legal basis: Contractual necessity
- Right to erasure limitations
- Breach notification timeline: 72 hours

### 3.3 Audit Controls
```mermaid
graph TD
    A[Payment Event] --> B[Log Entry]
    B --> C[Encrypted Storage]
    C --> D[Quarterly Review]
```

## 4. Certification Status
- PCI DSS: Annual assessment
- GDPR: Continuous compliance
- SOC 2: Planned for 2026
</file>

<file path="docs/templates/continuous_improvement_template.md">
# CONTINUOUS IMPROVEMENT PLAN TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. AI-Driven Improvement Cycle
### 1.1 Continuous Learning Process
```mermaid
graph TD
    A[User Interactions] --> B[Raw Metrics]
    B --> C[AI Analysis]
    C --> D[Pattern Detection]
    D --> E[Improvement Hypotheses]
    E --> F[Implementation]
    F --> A
```

### 1.2 Feedback Management
### 1.1 Collection Channels
- **Quantitative**:
  - Voice analysis trends
  - SRS effectiveness rates
  - Feature usage analytics
  - Error frequency heatmaps
  
- **Qualitative**:
  - Sentiment analysis of reviews
  - Support ticket clustering
  - User interview transcripts
  - Feature request patterns

### 1.2 Prioritization Framework
| Metric | Weight | AI Processing | Output |
|--------|--------|---------------|--------|
| User Satisfaction | 40% | Sentiment analysis | Feature adjustments |
| Business Impact | 30% | Revenue modeling | Monetization features |
| Technical Debt | 20% | Code quality scans | Refactoring tasks |
| Strategic Alignment | 10% | Roadmap analysis | Long-term investments |

## 2. Iteration Planning
### 2.1 Improvement Backlog
| ID | Description | Status | Target Release | Owner |
|----|-------------|--------|----------------|-------|
| CI-001 | Implement dark mode | Planned | v2.4 | Frontend Team |
| CI-002 | Add pronunciation analytics | In Progress | v2.3 | AI Team |
| CI-003 | Improve lesson loading speed | Backlog | v2.5 | Perf Team |

### 2.2 Retrospective Process
1. **Data Review** (30 mins):
   - Metrics comparison (before/after)
   - Key incidents analysis
2. **Discussion** (60 mins):
   - What went well?
   - What could be improved?
   - Action items
3. **Follow-up**:
   - Document decisions
   - Assign action items
   - Schedule check-ins

## 3. Technical Debt
### 3.1 Debt Inventory
| Area | Description | Severity | Remediation Plan |
|------|-------------|----------|------------------|
| API | Legacy authentication | High | Migrate to OAuth 2.0 |
| DB | Missing indexes | Medium | Add performance-critical indexes |
| UI | jQuery dependencies | Low | Rewrite in React |

### 3.2 Paydown Schedule
- **Q2 2025**: Address high-severity items
- **Q3 2025**: Complete medium-severity items
- **Q4 2025**: Review and prioritize remaining debt
- **Ongoing**: Allocate 20% sprint capacity to debt

## 4. Metrics & Reporting
### 4.1 Improvement Metrics
- Weekly velocity (story points)
- Bug escape rate (prod vs staging)
- Cycle time (commit to deploy)
- User satisfaction (CSAT)
- Feature adoption rate

### 4.2 Progress Dashboard
```mermaid
graph TD
    A[User Behavior] --> B[AI Analytics Engine]
    B --> C[Improvement Candidates]
    C --> D[Validation Simulations]
    D --> E[Approved Changes]
    E --> F[Autonomous Deployment]
    F --> A
```
</file>

<file path="docs/templates/data_governance_template.md">
# DATA GOVERNANCE FRAMEWORK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-10 -->

[Existing sections...]

## 4. Payment Data Handling
### 4.1 Data Types
| Classification | Examples | Handling Requirements |
|----------------|----------|-----------------------|
| Sensitive | Stripe customer IDs | Encrypted storage |
| Restricted | Payment tokens | Never stored locally |

### 4.2 Security Controls
- **Encryption**: AES-256 for payment metadata
- **Access**: Role-based, limited to billing team
- **Audit**: All access logged and monitored

### 4.3 Tokenization Flow
```mermaid
sequenceDiagram
    Client->>Stripe: Tokenize card
    Stripe-->>Client: Payment token
    Client->>Backend: Use token for payment
    Backend->>Stripe: Charge via token
```

## 5. Data Retention
### 5.1 Payment Metadata
- Retention period: 7 years (tax compliance)
- Deletion method: Cryptographic shredding
</file>

<file path="docs/templates/deployment_playbook_template.md">
# DEPLOYMENT PLAYBOOK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Local Development (Mac)
### 1.1 Docker Setup
```yaml
# docker-compose.mac.yml
version: '3.8'
services:
  postgres:
    image: postgres:17
    environment:
      POSTGRES_PASSWORD: lessay
    ports:
      - "5432:5432"
  
  app:
    build:
      context: .
      dockerfile: Dockerfile.mac
    ports:
      - "3000:3000"
    environment:
      MOCK_AUTH: "true"
```

### 1.2 Initial Setup
```bash
docker-compose -f docker-compose.mac.yml up -d
```

## 2. Staging Environment
### 2.1 Configuration
```yaml
# docker-compose.stage.yml
version: '3.8'
services:
  app:
    image: lessay-app:stage
    deploy:
      replicas: 2
    environment:
      NODE_ENV: staging
      DATABASE_URL: ${STAGE_DB_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
```

### 2.2 Deployment
```bash
docker stack deploy -c docker-compose.stage.yml lessay-stage
```

## 3. Production Environment
### 3.1 Configuration
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    image: lessay-app:prod
    deploy:
      replicas: 4
      resources:
        limits:
          cpus: '2'
          memory: 2G
    environment:
      NODE_ENV: production
      DATABASE_URL: ${PROD_DB_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    configs:
      - source: redis.conf
        target: /usr/local/etc/redis/redis.conf
```

### 3.2 Deployment
```bash
docker stack deploy -c docker-compose.prod.yml lessay-prod
```

## 4. CI/CD Pipeline
### 4.1 GitHub Actions Workflow
```yaml
name: Deploy Lessay
on:
  push:
    branches:
      - main
      - release/*

jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run build
      - run: npm test

  deploy-stage:
    needs: build-test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker-compose -f docker-compose.stage.yml up -d
      - run: npm run migrate:stage

  deploy-prod:
    needs: deploy-stage
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker-compose -f docker-compose.prod.yml up -d
      - run: npm run migrate:prod
```

## 5. Proxy Environment
### 2.1 Configuration
```yaml
# docker-compose.proxy.yml
version: '3.8'
services:
  reverse-proxy:
    image: nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
```

### 2.2 Deployment
```bash
docker-compose -f docker-compose.proxy.yml up -d
```

## 6. Secrets Management
### 6.1 Environment Variables
### 6.1.1 Required Variables
```env
### Supabase Secrets
```bash
supabase secrets set STRIPE_SECRET_KEY=sk_live_***
supabase secrets set AI_API_KEY=ai_***
```

### Google Cloud Credentials
For local development:
- Place `gcp-credentials.json` in project root
- Add to `.gitignore` to prevent accidental commits

For production environments:
```bash
# Store entire JSON content as a single environment variable
supabase secrets set GCP_CREDENTIALS_JSON='{"type": "service_account", ...}'
```

### 6.2 Environment Hierarchy
```env
# Order of precedence (highest to lowest)
1. Supabase secrets (production)
2. .env.production.local
3. .env.staging.local
4. .env.local
5. .env
```

### 6.3 Rotation Policy
- API keys: Every 90 days
- Database credentials: Every 180 days
- Certificates: Annually
- Google Cloud Service Account Keys: Every 365 days
</file>

<file path="docs/templates/frs_template.md">
# FUNCTIONAL REQUIREMENTS SPECIFICATION
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Introduction
### 1.1 Purpose
This document specifies the functional requirements for the Lessay language learning platform, providing detailed specifications for development teams.

### 1.2 Scope
Covers core functionality including:
- User authentication and authorization
- Lesson delivery and progress tracking
- Subscription management
- Payment processing
- Basic reporting

Excludes:
- Content creation tools
- Marketing features
- Third-party integrations beyond payment processing

### 1.3 Definitions
- **LTI**: Learning Tools Interoperability
- **SRS**: Spaced Repetition System
- **STT**: Speech-to-Text
- **TTS**: Text-to-Speech
- **LLM**: Large Language Model
- **A/B Testing**: Feature experimentation
- **PCI DSS**: Payment Card Industry Data Security Standard

## 2. Overall Description
### 2.1 Product Perspective
Integrates with:
- Mobile devices for on-the-go learning
- Payment processors (Stripe)
- Email services for notifications
- Analytics platforms for usage tracking

### 2.2 User Characteristics
1. **Casual Learners**:
   - Need quick, engaging lessons
   - Prefer gamified elements
   - Limited time commitment

2. **Serious Students**:
   - Require structured curriculum
   - Want progress certifications
   - Need detailed feedback

3. **Educators**:
   - Require classroom tools
   - Need progress monitoring
   - Want assignment creation

## 3. System Features
### 3.1 Adaptive Lesson System
#### 3.1.1 Description
AI-driven lesson delivery with real-time feedback and post-session analysis.

#### 3.1.2 Functional Requirements
- FR-001: System shall generate personalized lesson plans using LLM analysis of user profile
- FR-002: Shall provide real-time STT feedback during exercises (latency <300ms)
- FR-003: Must capture raw audio blob for post-session analysis
- FR-004: Shall adapt difficulty based on performance history
- FR-009: System shall capture raw audio of user speech for diagnostics
- FR-010: Shall use real-time STT to validate answer content immediately

### 3.2 SRS Engine
#### 3.2.1 Description
Spaced Repetition System for optimal knowledge retention.

#### 3.2.2 Functional Requirements
- FR-011: System shall maintain Recall Strength Score per vocabulary/concept
- FR-012: Must track Next Review Date for each learned item
- FR-013: Lesson generation shall prioritize items due for review
- FR-014: Shall adjust SRS scores based on diagnostic analysis

### 3.3 Voice Analysis System
#### 3.3.1 Description
Real-time and post-session vocal fluency diagnostics.

#### 3.3.2 Functional Requirements
- FR-015: Shall measure speaking pace (words/minute)
- FR-016: Must track hesitation frequency and patterns
- FR-017: Shall identify pronunciation errors at phoneme level
- FR-018: Must compare current performance to historical baselines

### 3.4 Progress Dashboard
#### 3.4.1 Description
Comprehensive visualization of learning metrics.

#### 3.4.2 Functional Requirements
- FR-019: Shall display vocabulary mastery heatmap
- FR-020: Must show fluency metrics over time
- FR-021: Shall highlight recurring error patterns
- FR-022: Must visualize SRS recall strength distribution

## 4. External Interface Requirements
### 4.1 User Interfaces
- Responsive design for mobile/desktop
- Accessibility compliant (WCAG 2.1 AA)
- Consistent branding across screens
- Intuitive navigation structure

### 4.2 Hardware Interfaces
- Microphone for voice exercises
- Camera for AR translation features
- Touchscreen support for mobile
- Keyboard shortcuts for desktop

### 4.3 Software Interfaces
- Stripe API for payments
- Google/Facebook OAuth
- SendGrid for email
- Mixpanel for analytics

## 5. Other Requirements
### 5.1 Performance
- API response time < 500ms (p95)
- Support 100 concurrent lessons
- Handle 5000 requests/minute
- Database queries < 100ms

### 5.2 Safety
- Content moderation for user-generated content
- Age-appropriate material filtering
- Secure storage of personal data
- Compliance with COPPA for under-13 users
</file>

<file path="docs/templates/maintenance_guide_template.md">
# MAINTENANCE GUIDE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Monitoring Configuration
### 1.1 Key Metrics
- API response times (p50, p95, p99)
- Error rates by service
- Database connection pool usage
- Payment transaction success rate
- Active user sessions
- Lesson completion rate

### 1.2 Alert Thresholds
- **Infrastructure**:
  - CPU Usage: >80% for 5m (warning), >90% for 5m (critical)
  - Memory Usage: >85% (warning), >95% (critical)
  - Disk Space: >75% used
  
- **API**:
  - Error Rate: >5% for 10m
  - Latency: >500ms p95
  - STT Response: >300ms p95
  
- **AI Services**:
  - Voice Queue: >100 pending for 5m
  - Analysis Time: >5s per request
  - LLM Degradation: >15% error rate
  - STT Accuracy: <85% confidence
  
- **Business Metrics**:
  - Lesson Start Failures: >10% for 15m
  - Payment Errors: >5% for 30m

## 2. Troubleshooting Procedures
### 2.1 Common Issues
| Symptom | Resolution | Escalation Path |
|---------|------------|-----------------|
| High API latency | Check database queries<br>Scale API instances | Senior Engineer |
| Payment failures | Verify Stripe API status<br>Check error logs | Payment Team |
| User login issues | Review auth service logs<br>Check IDP connectivity | Auth Team |

### 2.2 Diagnostic Tools
```bash
# Core System
journalctl -u lessay-api --since "5 minutes ago"
pg_stat_activity -x -c "SELECT * FROM pg_stat_activity"
curl -v https://api.lessay/health

# Voice Processing
curl -X POST https://api.lessay/v1/diagnostics/voice-queue
docker exec -it voice-worker lessay-cli check stt-latency

# AI Services
curl https://api.lessay/v1/llm/health | jq '.models[].status'
lessay-cli check analysis-backlog --threshold=50

# Storage Systems
aws s3api list-objects --bucket lessay-voice --query 'length(Contents)'
supabase status --service storage

## 3. Update Procedures
### 3.1 Patch Management
1. Review patch notes for breaking changes
2. Apply to staging environment first
3. Monitor for 24 hours
4. Deploy to production with canary rollout
5. Verify metrics post-deployment

### 3.2 Version Upgrades
1. **Preparation**:
   - Notify stakeholders of downtime window
   - Create database backup snapshot
   - Document rollback procedure

2. **Deployment**:
   - Drain traffic from old version
   - Deploy new version to 10% of nodes
   - Run migration scripts
   - Verify critical functionality

3. **Verification**:
   - Monitor metrics for 1 hour
   - Run smoke tests
   - Gradually roll out to 100%

## 4. Backup & Recovery
### 4.1 Backup Schedule
- **Database**: Hourly snapshots (retained 7 days) + Daily full backups (retained 30 days)
- **User Files**: Daily incremental (retained 14 days)
- **Configuration**: Versioned in Git + Weekly exports
- **Payment Data**: Real-time replication to DR site

### 4.2 Recovery Process
**Targets**:
- RTO (Recovery Time Objective): 1 hour
- RPO (Recovery Point Objective): 5 minutes

**Procedure**:
1. Declare incident and notify stakeholders
2. Identify last known good backup (within RPO window)
3. Restore critical systems in priority order:
   a. User database and auth
   b. Payment processing
   c. Voice processing pipeline
4. Verify data consistency checks:
   - Cross-check SRS scores
   - Validate voice analysis integrity
5. Gradually enable traffic (10% increments every 5m)
6. Monitor key health metrics:
   - API success rate
   - Voice processing latency
   - LLM response quality
7. Conduct post-mortem analysis within 24h
</file>

<file path="docs/templates/monetization_strategy.md">
# MONETIZATION STRATEGY
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-10 -->

## 1. Pricing Model
### 1.1 Subscription Tiers
| Tier | Price | Features |
|------|-------|----------|
| Free | $0 | Basic lessons, Limited voice practice, Basic SRS tracking |
| Premium | $9.99/month | All lessons, Full voice features, Progress dashboard, Advanced SRS analytics |
| Pro | $19.99/month | Premium features + Certification, Priority support, Unlimited voice analysis |

### 1.2 In-App Purchases
- Specialized lesson packs: $4.99-$14.99
- Certification badges: $9.99
- Detailed voice analysis reports: $0.99/report (complementary to standard analysis)

## 2. Stripe Integration
### 2.1 Architecture
```mermaid
sequenceDiagram
    Frontend->>Next.js API: Initiate payment
    Next.js API->>Stripe: Create payment intent
    Stripe-->>Next.js API: Client secret
    Next.js API-->>Frontend: Payment details
    Frontend->>Stripe: Complete payment (client-side)
    Stripe->>Webhook: Payment success/failure
    Webhook->>Database: Update subscription status
```

### 2.2 Key Components
- **Stripe Account**: Connected mode for platform payments
- **Webhook Handler**: /api/stripe/webhook
- **Subscription Manager**: CRON job for recurring billing

## 3. Revenue Reporting
### 3.1 Metrics Tracked
- MRR (Monthly Recurring Revenue)
- Churn rate
- LTV (Customer Lifetime Value)
- ARPU (Average Revenue Per User)

### 3.2 Analytics Integration
- Stripe Dashboard
- Internal reporting system
- Tax compliance reporting

## 4. Security & Compliance
- PCI DSS Level 1 compliant
- Tokenized payment processing
- GDPR-compliant data handling
</file>

<file path="docs/templates/performance_baseline_template.md">
# PERFORMANCE BASELINE TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Testing Methodology
### 1.1 Load Testing
- Tools:
  - k6 (load testing)
  - Locust (stress testing)
  - Prometheus (metrics collection)
  - Grafana (visualization)
- Scenarios:
  - 500 concurrent lessons
  - 1000 dashboard requests
  - Peak hour traffic simulation

### 1.2 Stress Testing
- Breaking points:
  - API: ~1500 req/s
  - Database: ~500 concurrent connections
  - Voice Processing: ~300 concurrent streams
- Recovery procedures:
  - Auto-scaling triggers at 70% CPU
  - Queue fallback for voice processing
  - Database read replicas during peaks

## 2. Performance Metrics
### 2.1 Key Indicators
| Metric | Target | Measurement |
|--------|--------|-------------|
| API Response (p95) | <300ms | Prometheus |
| STT Latency (p99) | <500ms | Cloud Monitoring |
| Concurrent Lessons | 500 | k6 |
| Dashboard Load | 1000 req/min | Grafana |
| Error Rate | <1% | Datadog |
| Voice Processing | <5s turnaround | Internal metrics |

### 2.2 Benchmark Results
### 2.2 Example Benchmarks
```mermaid
gantt
    title Performance Test Results
    dateFormat X
    axisFormat %s
    section API
    300ms Target : 0, 300
    Actual p95 : 0, 285
    section STT
    500ms Target : 0, 500
    Actual p99 : 0, 480
    section Lessons
    500 Concurrent Target : 0, 500
    Actual Achieved : 0, 510
```

## 3. Scalability
### 3.1 Horizontal Scaling
- Nodes:
  - Baseline: 3
  - Max tested: 10
- Performance gain:
  - Linear scaling to 5 nodes
  - Diminishing returns after 8 nodes

### 3.2 Vertical Scaling
- Resource increases:
  - CPU: 2 → 4 cores
  - Memory: 4GB → 8GB
- Impact:
  - 40% faster response times
  - 2x throughput capacity
</file>

<file path="docs/templates/project_charter_template.md">
# PROJECT CHARTER TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Project Overview
### 1.1 Vision Statement
To create an AI-powered language learning platform that listens, understands, and adapts to each learner through continuous voice analysis and Spaced Repetition (SRS), transforming every interaction into measurable progress toward fluency.

### 1.2 Objectives
- Launch with English, Spanish and French by Q3 2025
- Achieve 15% improvement in vocabulary recall (measured by SRS) within 30 days
- Maintain <300ms latency for real-time voice analysis
- Process 95% of payments through Stripe integration

### 1.3 Success Criteria
- 15% improvement in vocabulary recall over 30 days (SRS metric)
- 10% reduction in pronunciation errors per month (voice analysis)
- <300ms latency for real-time speech-to-text
- 90% user retention at 30 days

## 2. Scope
### 2.1 In Scope
- Adaptive lesson engine with SRS
- Real-time voice analysis pipeline
- Progress dashboard with fluency metrics
- Stripe payment integration
- AI-driven diagnostics system

### 2.2 Out of Scope
- Offline functionality
- Social features
- Classroom management tools
- Third-party content marketplace

## 3. Stakeholders
### 3.1 Key Stakeholders
| Role | Name | Responsibility |
|------|------|----------------|
| Product Owner | Jane Doe | Final requirements approval |
| Tech Lead | John Smith | Technical oversight |
| UX Lead | Sarah Lee | User experience |
| Marketing Lead | Alex Wong | Go-to-market strategy |

### 3.2 Steering Committee
Composed of:
- CTO (chair)
- VP Product
- Head of Engineering
- Finance Director
Meets bi-weekly to review progress and approve major changes

## 4. Timeline
### 4.1 Key Milestones
| Milestone | Date | Owner |
|-----------|------|-------|
| Requirements Finalized | 2025-06-25 | Jane Doe |
| Core Engine Complete | 2025-08-15 | John Smith |
| Voice Analysis Integrated | 2025-09-01 | John Smith |
| Beta Launch | 2025-09-15 | Sarah Lee |
| Full Release | 2025-10-01 | Alex Wong |

### 4.2 High-Level Schedule
```mermaid
gantt
    title Project Timeline
    dateFormat  YYYY-MM-DD
    section Phase 0
    Foundation       :active,  phase0, 2025-06-11, 5d
    section Phase 1
    Requirements     :         phase1, after phase0, 10d
    section Phase 2
    Technical Design :         phase2, after phase1, 15d
    section Phase 3
    Core Development :         phase3, after phase2, 45d
    Voice Integration:         voice, after phase3, 15d
    section Phase 4
    Testing & Launch :         phase4, after voice, 30d
```
</file>

<file path="docs/templates/risk_assessment_template.md">
# RISK ASSESSMENT TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Risk Identification
### 1.1 Threat Sources
1. **External Threats**:
   - Hackers targeting voice data
   - Competitors scraping AI models
   - Malicious bots overloading APIs
   - Voice spoofing attacks
   - API cost exploitation

2. **Internal Threats**:
   - Accidental voice data leaks
   - Unauthorized access to AI models
   - Configuration errors in LLM prompts
   - Biased training data
   - Inadequate voice data retention

### 1.2 Vulnerabilities
1. **Technical**:
   - Unencrypted voice data storage
   - Lack of rate limiting on AI APIs
   - Single point of failure in voice processing
   - Inadequate bias testing
   - No LLM hallucination detection

2. **Process**:
   - Manual deployment procedures
   - Lack of disaster recovery testing
   - Incomplete audit trails

## 2. Risk Analysis
### 2.1 Risk Matrix
| Likelihood/Impact | Low | Medium | High |
|-------------------|-----|--------|------|
| **High**          | Voice spoofing |  Data scraping | Payment breach |
| **Medium**        | API cost overrun | Inaccurate AI feedback | Voice data leak |
| **Low**           | Minor UI bugs | LLM bias |      |

### 2.2 Risk Scoring
1. **Voice Data Breach**
   Likelihood: Medium
   Impact: Critical
   Score: 15 (Medium x Critical)
    
2. **Inaccurate AI Feedback**
   Likelihood: Medium
   Impact: High
   Score: 12
    
3. **API Cost Overrun**
   Likelihood: High
   Impact: High
   Score: 16
    
4. **LLM Bias**
   Likelihood: Medium
   Impact: High
   Score: 12
    
5. **Voice Spoofing**
   Likelihood: Low
   Impact: Critical
   Score: 9

## 3. Risk Mitigation
### 3.1 Mitigation Strategies
| Risk | Strategy | Owner | Timeline |
|------|----------|-------|----------|
| Voice Data Breach | AES-256 encryption + strict access controls | Security Team | Q3 2025 |
| Inaccurate AI Feedback | Human validation pipeline + confidence thresholds | AI Team | Q2 2025 |
| API Cost Overrun | Usage monitoring + budget alerts | Finance Team | Q2 2025 |
| LLM Bias | Diverse training data + regular audits | Ethics Board | Ongoing |
| Voice Spoofing | Liveness detection + voiceprint analysis | Auth Team | Q4 2025 |

### 3.2 Residual Risk
Accepted risks:
- Minor UI bugs (low impact)
- Temporary voice processing delays during peaks
- Model accuracy variance across languages
- Higher API costs during peak usage

## 4. Review Process
### 4.1 Monitoring
- Real-time payment fraud detection
- Weekly vulnerability scans
- Monthly penetration tests
- Quarterly compliance audits

### 4.2 Review Schedule
- **Monthly**: Operational risk review
- **Quarterly**: Full risk assessment
- **Annually**: Compliance certification
- **Ad-hoc**: After major incidents
</file>

<file path="docs/templates/technical_design_template.md">
# TECHNICAL DESIGN DOCUMENT
<!-- Document Version: 1.2 -->
<!-- Last Updated: 2025-06-10 -->

## 1. Architecture Overview
### 1.1 System Context
```mermaid
graph TD
    A[Next.js Frontend] -->|API Routes| B[Next.js Backend]
    B --> C[Prisma ORM]
    B --> D[Supabase Auth]
    B --> E[Supabase Storage]
    B --> F[AIService]
    C --> G[Supabase PostgreSQL]
    F --> H[LLM Agent]
    F --> I[STT Service]
    F --> J[TTS Service]
    
    %% Real-time voice path
    A -->|WebSocket| K[Browser STT]
    K -->|Real-time text| B
    B -->|Analysis| F
    
    %% Diagnostic audio path
    A -->|Upload| E[Supabase Storage]
    E -->|Audio blob| F
    F -->|Store results| G
```

### 1.2 Key Features
- **Language Learning Core**:
  - Adaptive lesson generation
  - Progress tracking
  - Voice interaction handling
- **AI Integration**:
  - Autonomous development agent
  - Content personalization
  - Error correction

## 2. Component Design
### 2.1 Service Layer
- **AuthService**:
  - JWT verification
  - Session management
  - Mock auth implementation (`MOCK_AUTH=true`)
  
- **DataService**:
  ```mermaid
  flowchart LR
      A[API Route] --> B[DataService]
      B --> C[Prisma Client]
      C --> D[(PostgreSQL)]
      B --> E[Cache Layer]
  ```
  - Manages:
    - User profiles
    - Learning content
    - Progress data

- **AIService**:
  ```mermaid
  flowchart LR
      A[API Request] --> B{AIService}
      B --> C[Lesson Generation]
      B --> D[Voice Analysis]
      C --> E["Prompt:
      'Generate a lesson for {user} focusing on
      {weaknesses} using {SRS} schedule'"]
      D --> F["Analysis:
      - Pronunciation scoring
      - Hesitation detection
      - Fluency metrics"]
      E --> G[LLM Response]
      F --> H[Diagnostic Report]
  ```
  
  **Example Lesson Generation Payload**:
  ```json
  {
    "userId": "uuid",
    "targetLanguage": "es",
    "focusAreas": ["past_tense", "travel_vocab"],
    "srsDueItems": ["comer", "viajar"],
    "difficultyLevel": 3
  }
  ```
  
  **Voice Analysis Parameters**:
  ```prisma
  model VoiceAnalysis {
    id        String @id @default(uuid())
    userId    String
    lessonId  String
    metrics   Json // {pace: 120, accuracy: 0.85, ...}
    audioUrl  String
    createdAt DateTime @default(now())
  }
  ```

## 3. Data Flow
### 3.1 Adaptive Learning Loop
```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant B as Backend
    participant AI as AIService
    participant DB as Database
    
    U->>F: Start Lesson
    F->>B: POST /api/lessons/start
    B->>AI: Request lesson (with SRS due items)
    AI->>DB: Query user progress
    DB-->>AI: Return progress data
    AI-->>B: Generated lesson content
    B-->>F: Lesson data
    F->>U: Present exercise
    U->>F: Speak response
    F->>B: Stream audio to API
    B->>AI: Real-time STT analysis
    AI-->>B: Immediate feedback
    B-->>F: Corrections
    F->>U: Show results
    U->>F: Complete lesson
    F->>B: POST /api/lessons/{id}/complete
    B->>AI: Full session analysis
    AI->>DB: Update SRS scores
    AI-->>B: Next lesson plan
    B-->>F: Schedule recommendation
```

### 3.2 Subscription Webhook Flow
```mermaid
sequenceDiagram
    participant S as Stripe
    participant B as Backend
    participant DB as Database
    
    S->>B: POST /api/stripe/webhook
    B->>B: Verify signature
    alt payment_succeeded
        B->>DB: Update subscription status
    else payment_failed
        B->>DB: Flag account
    end
    B-->>S: 200 OK
```

## 4. Interface Specifications
### 4.1 AI Endpoints
| Method | Path | Description |
|--------|------|-------------|
| POST   | /api/ai/generate-lesson | Create personalized lesson |
| POST   | /api/ai/analyze-response | Evaluate user input |

## 5. Database Design
### 5.1 Complete Schema
```prisma
model User {
  id           String @id @default(uuid())
  email        String @unique
  password     String
  targetLang   String
  nativeLang   String
  progress     UserProgress[]
  srsEntries   SRSEntry[]
  lessons      Lesson[]
  createdAt    DateTime @default(now())
}

model Lesson {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  exercises   Exercise[]
  completedAt DateTime?
  analysis    VoiceAnalysis[]
}

model Exercise {
  id          String @id @default(uuid())
  type        String // 'vocabulary', 'grammar', etc.
  content     Json
  difficulty  Int
  language    String
  tags        String[]
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  lessonId    String
}

model UserProgress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  metric      String // 'vocabulary', 'grammar', etc.
  score       Float
  lastUpdated DateTime @default(now())
}

model SRSEntry {
  id             String @id @default(uuid())
  userId         String
  user           User @relation(fields: [userId], references: [id])
  item           String // word or grammar concept
  recallStrength Float @default(1.0)
  nextReview     DateTime @default(now())
  language       String
  @@index([userId, nextReview])
}

model VoiceAnalysis {
  id        String @id @default(uuid())
  userId    String
  user      User @relation(fields: [userId], references: [id])
  lessonId  String
  lesson    Lesson @relation(fields: [lessonId], references: [id])
  metrics   Json // {pace: 120, accuracy: 0.85, ...}
  audioUrl  String
  createdAt DateTime @default(now())
}
```

## 6. Non-Functional Considerations
### 6.1 AI Performance
- Model inference optimization
- Async task processing
- Rate limiting

### 6.2 Language Processing
- Multilingual support
- Voice data handling
- Real-time feedback
</file>

<file path="docs/templates/test_plan_template.md">
# TEST PLAN TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Core Learning Loop Tests
### 1.1 Adaptive Lesson Generation
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| SRS-Driven Content | 1. User has 5 due items<br>2. Start new lesson | - Lesson contains 3-5 due items<br>- Mixed with new material |
| Difficulty Adjustment | 1. Fail 3 exercises<br>2. Next lesson | - Difficulty reduced by 1 level<br>- More review content |

### 1.2 Real-Time Feedback
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Correct Pronunciation | 1. Submit perfect audio<br>2. Get feedback | - Score ≥0.95<br>- Positive reinforcement |
| Grammar Error | 1. Submit incorrect tense<br>2. Get feedback | - Specific error highlighted<br>- Correction shown |

### 1.3 Post-Session Analysis
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Audio Processing | 1. Complete lesson<br>2. Wait 5m | - Diagnostic report generated<br>- SRS scores updated |
| Weakness Detection | 1. Make consistent errors<br>2. Review analysis | - Weakness pattern identified<br>- Next lesson focuses on area |

## 2. Vocal Analysis Tests
### 2.1 Pronunciation Accuracy
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Native Speaker | 1. Submit native audio<br>2. Check score | - Score ≥0.98<br>- No errors flagged |
| Common Mistake | 1. Submit "th" as "d"<br>2. Check feedback | - Error detected<br>- Specific correction |

### 2.2 Fluency Metrics
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Hesitation | 1. Submit audio with pauses<br>2. Check metrics | - Hesitation count correct<br>- Pace calculated |
| Filler Words | 1. Use "um" repeatedly<br>2. Check report | - Filler word count accurate<br>- Trend shown |

## 3. User Dashboard Tests
### 3.1 Progress Visualization
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| SRS Overview | 1. Complete 10 lessons<br>2. Check dashboard | - Due items count correct<br>- Strength distribution accurate |
| Error Patterns | 1. Make consistent errors<br>2. Check dashboard | - Top errors highlighted<br>- Frequency correct |

### 3.2 Metric Accuracy
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Fluency Trends | 1. Improve over week<br>2. Check graph | - Upward trend visible<br>- Data points correct |
| Vocabulary Growth | 1. Learn new words<br>2. Check stats | - Count matches lessons<br>- Retention rate shown |


## 5. Payment Flow Tests
### 5.1 Subscription Scenarios
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| New Premium Subscription | 1. Select Premium plan<br>2. Enter valid card<br>3. Submit | - Status: active<br>- Features unlocked |
| Payment Failure | 1. Use declined card<br>2. Attempt purchase | - Error message shown<br>- No access change |
| Plan Upgrade | 1. From Free to Pro<br>2. Confirm prorated charge | - Immediate upgrade<br>- Correct charge |

### 5.2 Webhook Tests
- Payment success → DB updated
- Payment failed → Retry logic
- Subscription canceled → Access revoked

## 6. Security Tests
### 6.1 Payment Data
- Card details never stored
- Tokenization verified
- PCI compliance checks
</file>

<file path="docs/templates/user_documentation_template.md">
# USER DOCUMENTATION TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Getting Started
### 1.1 Language Selection
```mermaid
flowchart TD
    A[Open App] --> B{First Time?}
    B -->|Yes| C[Take Placement Test]
    B -->|No| D[Continue Learning]
    C --> E[Get Personalized Lessons]
    D --> F[View Progress Dashboard]
```

### 1.2 Your First Lesson
1. Open the app daily
2. Complete suggested exercises
3. Speak clearly when prompted
4. Review feedback immediately
5. Track progress over time

## 2. Learning Features
### 2.1 Progress Dashboard
- **Vocabulary Mastery**: Heatmap of known words
- **Fluency Metrics**: Speaking pace & hesitation trends
- **Error Patterns**: Common mistakes highlighted
- **Activity Log**: History of completed lessons

### 2.2 Spaced Repetition (SRS)
```mermaid
pie title Your Knowledge Retention
    "Strong" : 65
    "Maturing" : 25
    "Weak" : 10
```

### 2.3 Fluency Analysis
- Pronunciation accuracy scores
- Speaking pace measurements
- Hesitation and filler word tracking
- Comparative analysis over time


## 4. Subscription Management
### 4.1 Choosing a Plan
```mermaid
flowchart LR
    A[Free Tier] -->|Upgrade| B[Premium]
    A -->|Upgrade| C[Pro]
    B -->|Downgrade| A
    B -->|Upgrade| C
    C -->|Downgrade| B
```

### 4.2 Payment Process
1. Navigate to Settings > Subscription
2. Select desired plan
3. Enter payment details
4. Confirm purchase

### 4.3 Managing Your Subscription
- **Update Payment Method**: Settings > Billing
- **Change Plan**: Instant effect with prorated charges
- **Cancel**: Ends at billing period end

### 4.4 Troubleshooting
| Issue | Solution |
|-------|----------|
| Voice not recognized | Check microphone permissions |
| Incorrect feedback | Use "Report Error" button |
| Lesson too hard/easy | Adjust difficulty in settings |
| Progress not saving | Check internet connection |
| Payment issues | Update card or contact support |
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_1.md">
# Developer To-Do List: Phase 1 - Core Backend & User Auth

## Task 1: Create Supabase Server-Side Client Helper
- **File:** `/lib/supabase/server.ts`
- **Action:** Create server-side Supabase client utilities
- **Steps:**
  1. Create directory `lib/supabase`
  2. Create file `server.ts` with:
     - `supabaseServerClient` function using `createServerComponentClient`
     - `getUserSession` helper to fetch user session
- **Verification:** File exports both functions with proper TypeScript types

## Task 2: Implement Profile GET Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add authenticated profile retrieval
- **Steps:**
  1. Import `getUserSession` from `@/lib/supabase/server`
  2. Add session check to GET function
  3. Query Prisma for user data
- **Verification:** Returns 401 when unauthenticated, profile data when valid

## Task 3: Implement Profile PUT Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add profile update functionality
- **Steps:**
  1. Reuse auth check from GET route
  2. Add Prisma `user.update` call
  3. Return updated profile
- **Verification:** PUT requests update user data successfully

## Task 4: Create Auth UI Component
- **File:** `/components/Auth.tsx`
- **Action:** Build sign-up/sign-in interface
- **Steps:**
  1. Create client-side Supabase client
  2. Add email/password fields
  3. Implement sign-up/sign-in buttons
- **Verification:** Component renders and allows user registration/login

## Task 5: Implement User Sync Endpoint
- **File:** `/api/users/sync/route.ts`
- **Action:** Create public profile after auth sign-up
- **Steps:**
  1. Create new route file
  2. Listen for Supabase auth events
  3. Create corresponding Prisma user record
- **Verification:** New auth users get public profiles automatically
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_10.md">
# Developer To-Do List: Phase 10 - UI Implementation & Polish

**Objective:** Transform placeholder UI into a polished, responsive, and accessible interface.

## Tasks

- [ ] **1. Style Auth Component**
  - File: `/components/Auth.tsx`
  - Requirements:
    - Tailwind CSS styling for all states (default, loading, error)
    - Clear visual feedback for form validation
    - Responsive design for mobile/desktop
  - Verification: Component matches design specs in user documentation.

- [ ] **2. Implement Lesson UI**
  - File: `/components/LessonView.tsx`
  - Requirements:
    - Visual cues for listening/processing states
    - Clear answer feedback display
    - Responsive layout adjustments
  - Verification: All interaction states implemented per docs.

- [ ] **3. Build Dashboard Visualizations**
  - Install: `npm install recharts`
  - File: `/components/DashboardView.tsx`
  - Requirements:
    - SRS pie chart (knowledge retention)
    - Fluency line chart (progress over time)
    - Loading skeletons for async data
  - Verification: Charts match documentation examples.

- [ ] **4. Create Main Layout**
  - File: `/components/AppLayout.tsx`
  - Requirements:
    - Shared header with navigation
    - Consistent footer
    - Responsive breakpoints
  - Verification: All pages wrapped in layout.

- [ ] **5. Implement Accessibility**
  - Requirements:
    - ARIA labels for all interactive elements
    - Keyboard navigation support
    - Color contrast checks
  - Verification: Passes basic a11y audits.
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_11.md">
# Developer To-Do List: Phase 11 - Data Governance & Finalization

**Objective:** Implement data management policies and perform final project cleanup.

## Tasks

- [ ] **1. Implement Audio Retention Policy**
  - Create Inngest cron job in `/app/inngest/functions.ts`:
    ```typescript
    inngest.createFunction(
      { id: 'audio-retention' },
      { cron: '0 0 * * *' }, // Daily at midnight
      async () => {
        // Query VoiceAnalysis records older than 30 days
        // Delete associated audio files from Supabase Storage
        // Delete database records
      }
    )
    ```
  - Verification: Function exists with correct schedule.

- [ ] **2. Implement Account Deletion**
  - Create endpoint: `/app/api/users/delete-account/route.ts`
    - Require re-authentication
    - Delete all user-related data
    - Handle foreign key constraints
  - Verification: Endpoint securely deletes all user data.

- [ ] **3. Add Environment Check**
  - Update `package.json`:
    ```json
    "scripts": {
      "check:env": "node scripts/check-env.js",
      "build": "npm run check:env && next build"
    }
    ```
  - Create `scripts/check-env.js` to validate all required variables.
  - Verification: Build fails if any variables are missing.

- [ ] **4. Final Documentation Review**
  - Audit all JSDoc comments
  - Ensure API routes have proper documentation
  - Verify component prop types
  - Verification: All major components and functions documented.
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_12.md">
# Development Phase 12: Client-Side State Management Implementation

## Tasks for Developer AI

### 1. Implement Zustand Store with TypeScript
- **File:** `/lib/stores/app-state.ts`
- **Action:** Create global state store with user session and lesson progress
- **Steps:**
  1. Install zustand: `npm install zustand`
  2. Create store with types:
     ```typescript
     interface AppState {
       user: { id: string; email: string } | null;
       currentLesson: { id: string; progress: number } | null;
       setUser: (user: AppState['user']) => void;
       setLessonProgress: (lessonId: string, progress: number) => void;
     }
     ```
  3. Implement store with initial empty state
- **Verification:** File exists and exports `useAppStore` hook

### 2. Add Supabase Auth Integration
- **File:** `/lib/stores/app-state.ts`
- **Action:** Sync auth state with Supabase
- **Steps:**
  1. Import `supabase` client
  2. Add auth listener in store setup:
     ```typescript
     supabase.auth.onAuthStateChange((event, session) => {
       useAppStore.getState().setUser(session?.user ?? null);
     })
     ```
- **Verification:** User state updates when logging in/out

### 3. Implement LocalStorage Persistence
- **File:** `/lib/stores/persist.ts`
- **Action:** Add state persistence middleware
- **Steps:**
  1. Create middleware function
  2. Handle JSON serialization of state
  3. Add hydration on app load
- **Verification:** State persists across page refreshes

### 4. Update LessonView Component
- **File:** `/components/LessonView.tsx`
- **Action:** Migrate to global state
- **Steps:
  1. Import `useAppStore`
  2. Replace `useState` with store hooks
  3. Update lesson progress calls
- **Verification:** Lesson progress updates work as before

### 5. Update PricingPage Component
- **File:** `/components/PricingPage.tsx`
- **Action:** Use store for user state
- **Steps:
  1. Import `useAppStore`
  2. Check `user` state for auth status
  3. Update button behavior accordingly
- **Verification:** Pricing page reflects user auth state

### 6. Add State Management Documentation
- **File:** `/docs/state-management.md`
- **Action:** Create usage guide
- **Steps:
  1. Document store structure
  2. Add usage examples
  3. Include best practices
- **Verification:** Documentation file exists
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_13.md">
# Development Phase 13: Environment Configurations

## Tasks for Developer AI

### 1. Create Environment Configuration Files
- **File:** `/lib/config.ts`
- **Action:** Implement environment configuration loader
- **Steps:**
  1. Create `lib/config.ts` with environment validation
  2. Define required environment variables:
     ```typescript
     interface AppConfig {
       NODE_ENV: 'development' | 'production' | 'test';
       DATABASE_URL: string;
       SUPABASE_URL: string;
       SUPABASE_KEY: string;
     }
     ```
  3. Add validation for required variables
- **Verification:** File exists and exports validated config object

### 2. Update Environment Template File
- **File:** `/.env.example`
- **Action:** Create example environment file
- **Steps:
  1. List all required environment variables
  2. Include comments explaining each variable
  3. Add dummy values for sensitive fields
- **Verification:** File contains all production-required variables

### 3. Implement Environment-Specific Settings
- **File:** `/lib/config.ts`
- **Action:** Add environment-specific defaults
- **Steps:
  1. Add development-only defaults
  2. Configure production security settings
  3. Enable debug modes for development
- **Verification:** Different settings load per NODE_ENV

### 4. Update Deployment Configuration
- **File:** `/next.config.ts`
- **Action:** Configure build-time environment
- **Steps:
  1. Add environment variable validation
  2. Configure public runtime config
  3. Set up build-time optimizations
- **Verification:** Config is accessible in both server and client

### 5. Create Environment Documentation
- **File:** `/docs/environments.md`
- **Action:** Document environment setup
- **Steps:
  1. List all environment variables
  2. Explain deployment process
  3. Add troubleshooting guide
- **Verification:** Documentation file exists
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_14.md">
# Development Phase 14: User Feedback System

## Tasks for Developer AI

### 1. Create Feedback API Endpoint
- **File:** `/app/api/feedback/route.ts`
- **Action:** Implement feedback submission endpoint
- **Steps:**
  1. Create new route file
  2. Add POST handler to receive feedback
  3. Validate input data
  4. Store feedback in database
- **Verification:** POST requests to `/api/feedback` return success status

### 2. Add Feedback Model to Schema
- **File:** `/prisma/schema.prisma`
- **Action:** Define feedback data structure
- **Steps:
  1. Add Feedback model with fields:
     - userId
     - message
     - createdAt
  2. Run migration
- **Verification:** New model appears in Prisma client

### 3. Implement Feedback UI Component
- **File:** `/components/FeedbackButton.tsx`
- **Action:** Create feedback interface
- **Steps:
  1. Create client component
  2. Add button to open feedback form
  3. Implement form submission
- **Verification:** Component renders and submits feedback

### 4. Add Feedback Link to Navigation
- **File:** `/components/Navbar.tsx`
- **Action:** Make feedback accessible
- **Steps:
  1. Import FeedbackButton
  2. Add to navigation menu
- **Verification:** Feedback button appears in UI

### 5. Setup Feedback Notifications
- **File:** `/lib/notifications.ts`
- **Action:** Alert admins of new feedback
- **Steps:
  1. Create notification function
  2. Call from feedback endpoint
  3. Test with sample submission
- **Verification:** Notifications trigger on new feedback
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_15.md">
# Development Phase 15: AI Cost & Security Controls

## Tasks for Developer AI

### 1. Implement Usage Tracking
- **File:** `/lib/ai-service.ts`
- **Action:** Add usage metrics to AI calls
- **Steps:**
  1. Add usage tracking to `generateLessonForUser`
  2. Add usage tracking to `analyzeAudioForDiagnostics`
  3. Store usage in database
- **Verification:** Usage data appears in database

### 2. Add Rate Limiting
- **File:** `/middleware/rate-limiter.ts`
- **Action:** Protect AI endpoints
- **Steps:
  1. Create rate limiting middleware
  2. Apply to AI API routes
  3. Test with multiple requests
- **Verification:** Requests are limited after threshold

### 3. Setup Usage Alerts
- **File:** `/lib/alerts.ts`
- **Action:** Notify on high usage
- **Steps:
  1. Create alert thresholds
  2. Implement notification system
  3. Test with simulated spikes
- **Verification:** Alerts trigger correctly

### 4. Implement Tiered Access
- **File:** `/app/api/lessons/start/route.ts`
- **Action:** Enforce tier limits
- **Steps:
  1. Check user tier
  2. Enforce daily limits
  3. Return appropriate errors
- **Verification:** Limits enforced per tier

### 5. Add Security Monitoring
- **File:** `/lib/security.ts`
- **Action:** Detect abuse patterns
- **Steps:
  1. Implement anomaly detection
  2. Log suspicious activity
  3. Create admin alerts
- **Verification:** System detects test attacks
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_2.md">
# Lessay Development Phase 2: Learning Loop Implementation

## Tasks for Developer AI

### 1. Implement Lesson Start Route (`/app/api/lessons/start/route.ts`)
- [x] **Add authentication check**
  - Import `getUserSession` from `@/lib/supabase-server`
  - At start of POST function, add:
    ```typescript
    const session = await getUserSession()
    if (!session) return new Response('Unauthorized', { status: 401 })
    ```
  - Verification: Route returns 401 for unauthenticated requests

- [ ] **Implement lesson generation**
  - Call `AIService.generateLessonForUser(session.user.id)`
  - Store returned lesson data in Prisma:
    ```typescript
    const lesson = await prisma.lesson.create({
      data: {
        userId: session.user.id,
        content: generatedLesson.content
      }
    })
    ```
  - Verification: New lesson appears in database after API call

- [ ] **Create exercise record**
  - Add exercise creation after lesson creation:
    ```typescript
    const exercise = await prisma.exercise.create({
      data: {
        lessonId: lesson.id,
        prompt: generatedLesson.exercise.prompt,
        correctAnswer: generatedLesson.exercise.correctAnswer
      }
    })
    ```
  - Verification: Exercise linked to lesson in database

### 2. Implement Answer Submission Route (`/app/api/lessons/[id]/submit-answer/route.ts`)
- [ ] **Add authentication check**
  - Same pattern as lesson start route
  - Verification: Route rejects unauthenticated requests

- [ ] **Implement answer validation**
  - Find exercise by ID from URL params
  - Compare `textResponse` to `exercise.correctAnswer`
  - Verification: API correctly identifies matching answers

- [ ] **Create progress record**
  - Add progress tracking:
    ```typescript
    await prisma.userProgress.create({
      data: {
        userId: session.user.id,
        exerciseId: exercise.id,
        submittedAnswer: textResponse,
        isCorrect: answerMatches
      }
    })
    ```
  - Verification: Progress records appear in database

### 3. Update Lesson View Component (`/components/LessonView.tsx`)
- [ ] **Add answer input UI**
  - Create controlled text input component
  - Add state management for answer text
  - Verification: Input field appears and updates properly

- [ ] **Implement submission logic**
  - Add submit button handler that:
    - Calls `/api/lessons/${lessonId}/submit-answer`
    - Disables during submission
    - Handles errors
  - Verification: Button works and shows loading state

- [ ] **Add feedback display**
  - Create section showing:
    - Correct/incorrect indicator
    - Correct answer
    - Explanation (if available)
  - Style with Tailwind classes
  - Verification: Feedback appears after submission
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_3.md">
# Lessay Development Phase 3: AI Service Integration

## Tasks for Developer AI

### 1. Install Required Packages
- [x] **Install Google AI SDKs**
  ```bash
  npm install @google/generative-ai @google-cloud/speech @google-cloud/text-to-speech
  ```
  Verification: Packages appear in `package.json` dependencies

### 2. Initialize Google Cloud Clients (`/lib/ai-service.ts`)
- [x] **Configure credential handling**
  ```typescript
  let geminiClient: GoogleGenerativeAI;
  let speechClient: SpeechClient;
  let textToSpeechClient: TextToSpeechClient;

  if (process.env.GCP_CREDENTIALS_JSON) {
    const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
    geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY);
    speechClient = new SpeechClient({ credentials });
    textToSpeechClient = new TextToSpeechClient({ credentials });
  } else {
    geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY);
    speechClient = new SpeechClient({ keyFilename: './gcp-credentials.json' });
    textToSpeechClient = new TextToSpeechClient({ keyFilename: './gcp-credentials.json' });
  }
  ```
  Verification: Clients initialize without errors in dev/prod environments

### 3. Implement Lesson Generation (`/lib/ai-service.ts`)
- [ ] **Replace generateLessonForUser stub**
  ```typescript
  async function generateLessonForUser(userId: string) {
    const model = geminiClient.getGenerativeModel({ 
      model: "gemini-pro",
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 2048
      }
    });
    
    const prompt = `Generate a language lesson...`; // Detailed prompt per design doc
    const result = await model.generateContent(prompt);
    const response = await result.response;
    
    return JSON.parse(response.text());
  }
  ```
  Verification: Function returns valid lesson structure from API call

### 4. Implement Speech-to-Text (`/lib/ai-service.ts`)
- [ ] **Create transcribeAudio function**
  ```typescript
  async function transcribeAudio(audioBuffer: Buffer): Promise<string> {
    const [response] = await speechClient.recognize({
      audio: { content: audioBuffer.toString('base64') },
      config: {
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
        languageCode: 'en-US'
      }
    });
    return response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');
  }
  ```
  Verification: Audio files are accurately transcribed

### 5. Implement Text-to-Speech (`/lib/ai-service.ts`)
- [ ] **Create synthesizeSpeech function**
  ```typescript
  async function synthesizeSpeech(text: string): Promise<Buffer> {
    const [response] = await textToSpeechClient.synthesizeSpeech({
      input: { text },
      voice: {
        languageCode: 'en-US',
        name: 'en-US-Standard-C'
      },
      audioConfig: {
        audioEncoding: 'MP3'
      }
    });
    return Buffer.from(response.audioContent, 'base64');
  }
  ```
  Verification: Text input produces valid audio output
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_4.md">
# Lessay Development Phase 4: Dashboard & Payments Implementation

## Tasks for Developer AI

### 1. Implement Fluency Stats Route (`/app/api/stats/fluency/route.ts`)
- [ ] **Add Prisma aggregations**
  ```typescript
  const stats = await prisma.userProgress.groupBy({
    by: ['createdAt'],
    where: { userId: session.user.id },
    _avg: { accuracyScore: true },
    _count: { _all: true },
    orderBy: { createdAt: 'asc' }
  });
  ```
  Verification: Route returns daily accuracy averages and counts

### 2. Implement SRS Overview Route (`/app/api/stats/srs-overview/route.ts`)
- [ ] **Add SRS metrics**
  ```typescript
  const overview = await prisma.sRSEntry.groupBy({
    by: ['exerciseType'],
    where: { userId: session.user.id },
    _count: { status: true },
    _min: { nextReview: true },
    _max: { nextReview: true },
    _avg: { nextReview: true }
  });
  ```
  Verification: Route returns grouped SRS metrics

### 3. Update Dashboard View (`/components/DashboardView.tsx`)
- [ ] **Fetch and display stats**
  - Use `useEffect` to fetch from both stats endpoints
  - Implement:
    - Line chart for accuracy trends
    - Pie chart for SRS status distribution
    - Table for recent activity
  Verification: All visualizations render with real data

### 4. Implement Stripe Subscriptions (`/app/api/payments/create-subscription/route.ts`)
- [ ] **Install and configure Stripe**
  ```bash
  npm install stripe
  ```
  ```typescript
  const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);
  const subscription = await stripe.subscriptions.create({
    customer: req.body.customerId,
    items: [{ price: req.body.priceId }],
    payment_behavior: 'default_incomplete'
  });
  ```
  Verification: Subscription objects created in Stripe dashboard

### 5. Secure Webhook (`/app/api/stripe/webhook/route.ts`)
- [ ] **Add signature verification**
  ```typescript
  const event = stripe.webhooks.constructEvent(
    req.body,
    req.headers['stripe-signature'],
    process.env.STRIPE_WEBHOOK_SECRET
  );
  ```
  Verification: Webhook rejects invalid signatures
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_5.md">
# Lessay Development Phase 5: Production Hardening - Observability & Error Handling

## Tasks for Developer AI

### 1. Install Logging Packages
- [ ] **Add pino and pino-pretty**
  ```bash
  npm install pino pino-pretty
  ```
  Verification: Packages appear in `package.json` dependencies

### 2. Create Logger Utility (`/lib/logger.ts`)
- [ ] **Implement centralized logger**
  ```typescript
  import pino from 'pino';

  const logger = pino({
    level: process.env.NODE_ENV === 'production' ? 'info' : 'debug',
    transport: {
      target: 'pino-pretty',
      options: {
        colorize: true,
        translateTime: 'SYS:standard'
      }
    }
  });

  export default logger;
  ```
  Verification: File exists and exports logger instance

### 3. Replace Console Logs in API Routes
- [ ] **Update all API routes to use logger**
  Files to modify:
  - `app/api/lessons/[id]/submit-answer/route.ts`
  - `app/api/lessons/start/route.ts`
  - `app/api/payments/create-subscription/route.ts`
  - `app/api/stats/fluency/route.ts`
  - `app/api/stats/srs-overview/route.ts`
  - `app/api/stripe/webhook/route.ts`
  - `app/api/users/profile/route.ts`

  Verification: No `console.log` statements remain in API routes

### 4. Implement Error Handling Utility (`/lib/errors.ts`)
- [ ] **Create error handler**
  ```typescript
  import { NextResponse } from 'next/server';
  import logger from '@/lib/logger';
  import { PrismaClientKnownRequestError } from '@prisma/client/runtime/library';

  export function handleError(error: unknown) {
    if (error instanceof PrismaClientKnownRequestError) {
      logger.error({ error }, 'Database error occurred');
      return NextResponse.json(
        { error: 'Database operation failed' },
        { status: getPrismaErrorStatus(error) }
      );
    }

    logger.error({ error }, 'Unexpected error occurred');
    return NextResponse.json(
      { error: 'An unexpected error occurred' },
      { status: 500 }
    );
  }

  function getPrismaErrorStatus(error: PrismaClientKnownRequestError): number {
    switch (error.code) {
      case 'P2002': return 409; // Unique constraint
      case 'P2025': return 404; // Not found
      default: return 400; // Bad request
    }
  }
  ```
  Verification: File exists and handles Prisma/unknown errors

### 5. Add Health Check Endpoint (`/app/api/health/route.ts`)
- [ ] **Implement health check**
  ```typescript
  import { NextResponse } from 'next/server';
  import prisma from '@/lib/prisma';
  import logger from '@/lib/logger';
  import { handleError } from '@/lib/errors';

  export async function GET() {
    try {
      await prisma.$queryRaw`SELECT 1`;
      logger.info('Health check successful');
      return NextResponse.json({ status: 'ok' }, { status: 200 });
    } catch (error) {
      return handleError(error);
    }
  }
  ```
  Verification: Endpoint returns 200 when database is accessible

### 6. Wrap API Routes in Try/Catch
- [ ] **Update all API routes with error handling**
  Example modification:
  ```typescript
  import { handleError } from '@/lib/errors';

  export async function POST(request: Request) {
    try {
      // Route logic here
    } catch (error) {
      return handleError(error);
    }
  }
  ```
  Verification: All API routes have proper error handling
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_6.md">
# Lessay Development Phase 6: Production Hardening - Security & Performance

## Tasks for Developer AI

### 1. Install Security Dependencies
- [ ] **Add Zod and Rate Limiter**
  ```bash
  npm install zod @upstash/ratelimit
  ```
  Verification: Packages appear in `package.json` dependencies

### 2. Create Validation Schemas (`/lib/validators.ts`)
- [ ] **Implement input validators**
  ```typescript
  import { z } from 'zod';

  export const lessonStartSchema = z.object({
    userId: z.string().uuid(),
    targetLanguage: z.string().length(2)
  });

  export const answerSubmitSchema = z.object({
    exerciseId: z.string().uuid(),
    textResponse: z.string().min(1),
    audioBlobUrl: z.string().url().optional()
  });
  ```
  Verification: File exists with exported schemas

### 3. Validate API Routes
- [ ] **Add validation to routes**
  Files to modify:
  - `app/api/lessons/[id]/submit-answer/route.ts`
  - `app/api/lessons/start/route.ts`
  - `app/api/payments/create-subscription/route.ts`
  - `app/api/users/profile/route.ts`

  Example implementation:
  ```typescript
  const body = await request.json();
  const validation = answerSubmitSchema.safeParse(body);
  if (!validation.success) {
    return NextResponse.json(
      { error: 'Invalid request', details: validation.error.flatten() },
      { status: 400 }
    );
  }
  ```
  Verification: Routes return 400 for invalid requests

### 4. Configure Rate Limiting (`/lib/rateLimit.ts`)
- [ ] **Set up rate limiter**
  ```typescript
  import { Ratelimit } from '@upstash/ratelimit';
  import { Redis } from '@upstash/redis';

  export const ratelimit = new Ratelimit({
    redis: Redis.fromEnv(),
    limiter: Ratelimit.slidingWindow(10, '1 m'),
    analytics: true
  });
  ```
  Verification: File exports rate limiter instance

### 5. Apply Rate Limits to Sensitive Endpoints
- [ ] **Protect high-traffic routes**
  Files to modify:
  - `app/api/lessons/start/route.ts`
  - `app/api/users/profile/route.ts`

  Example implementation:
  ```typescript
  const ip = request.headers.get('x-forwarded-for') ?? '127.0.0.1';
  const { success } = await ratelimit.limit(ip);
  if (!success) {
    return NextResponse.json(
      { error: 'Too many requests' },
      { status: 429 }
    );
  }
  ```
  Verification: Routes return 429 after 10 requests/minute

### 6. Optimize Database Performance
- [ ] **Add index to UserProgress model**
  Modify `prisma/schema.prisma`:
  ```prisma
  model UserProgress {
    // ... existing fields
    @@index([userId, metric], name: "UserProgress_userId_metric_index")
  }
  ```
  Verification: Index definition exists in schema

- [ ] **Create and apply migration**
  ```bash
  npx prisma migrate dev --name add_performance_indexes
  ```
  Verification: New migration file created

### 7. Implement Caching (`/lib/cache.ts`)
- [ ] **Create cache utility**
  ```typescript
  const cache = new Map<string, { data: any, expires: number }>();

  export function getFromCache<T>(key: string): T | null {
    const item = cache.get(key);
    return item?.expires > Date.now() ? item.data : null;
  }

  export function setToCache(key: string, data: any, ttl = 300000) {
    cache.set(key, { data, expires: Date.now() + ttl });
  }
  ```
  Verification: File exports cache functions

### 8. Cache Stats Endpoints
- [ ] **Add caching to dashboard routes**
  Files to modify:
  - `app/api/stats/fluency/route.ts`
  - `app/api/stats/srs-overview/route.ts`

  Example implementation:
  ```typescript
  const cacheKey = `stats-${userId}`;
  const cached = getFromCache(cacheKey);
  if (cached) return NextResponse.json(cached);

  const data = await fetchData();
  setToCache(cacheKey, data);
  return NextResponse.json(data);
  ```
  Verification: Repeated requests return cached data
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_7.md">
# Lessay Development Phase 7: Production Hardening - Testing

## Tasks for Developer AI

### 1. Install Testing Packages
- [ ] **Add Jest and TypeScript support**
  ```bash
  npm install jest ts-jest @types/jest --save-dev
  ```
  Verification: Packages appear in `package.json` devDependencies

### 2. Configure Jest (`jest.config.ts`)
- [ ] **Create Jest configuration**
  ```typescript
  import type { Config } from '@jest/types'

  const config: Config.InitialOptions = {
    preset: 'ts-jest',
    testEnvironment: 'node',
    roots: ['<rootDir>'],
    testMatch: ['**/*.test.ts'],
    moduleNameMapper: {
      '^@/(.*)$': '<rootDir>/$1'
    }
  }

  export default config
  ```
  Verification: Configuration file exists with correct settings

### 3. Create Auth Tests (`/tests/auth.test.ts`)
- [ ] **Implement authentication tests**
  ```typescript
  import { describe, it, expect } from '@jest/globals'
  import { signUp, signIn } from '@/lib/auth'

  describe('Authentication', () => {
    it('should allow valid user signup', async () => {
      const result = await signUp('test@example.com', 'password123')
      expect(result.success).toBe(true)
    })

    it('should reject duplicate user signup', async () => {
      await signUp('test@example.com', 'password123')
      const result = await signUp('test@example.com', 'password123')
      expect(result.error).toMatch(/already exists/i)
    })

    it('should allow valid login', async () => {
      await signUp('test@example.com', 'password123')
      const result = await signIn('test@example.com', 'password123')
      expect(result.success).toBe(true)
    })

    it('should reject invalid login', async () => {
      const result = await signIn('wrong@example.com', 'wrongpassword')
      expect(result.error).toMatch(/invalid credentials/i)
    })
  })
  ```
  Verification: File exists with all test cases

### 4. Create Lesson Tests (`/tests/lessons.test.ts`)
- [ ] **Implement lesson flow tests**
  ```typescript
  import { describe, it, expect } from '@jest/globals'
  import { startLesson, submitAnswer } from '@/lib/lessons'

  describe('Lesson Flow', () => {
    it('should start a new lesson', async () => {
      const lesson = await startLesson('user_123')
      expect(lesson.exercises.length).toBeGreaterThan(0)
    })

    it('should accept correct answers', async () => {
      const response = await submitAnswer('ex_123', 'correct answer')
      expect(response.correct).toBe(true)
    })

    it('should provide feedback for incorrect answers', async () => {
      const response = await submitAnswer('ex_123', 'wrong answer')
      expect(response.correct).toBe(false)
      expect(response.feedback).toBeDefined()
    })
  })
  ```
  Verification: File exists with all test cases

### 5. Update Package.json Scripts
- [ ] **Add test command**
  ```json
  {
    "scripts": {
      "test": "jest"
    }
  }
  ```
  Verification: `npm test` runs Jest successfully

### 6. Update CI Workflow (`/.github/workflows/ci.yml`)
- [ ] **Add testing step**
  ```yaml
  jobs:
    build-and-test:
      steps:
        - run: npm test
  ```
  Verification: CI file includes `npm test` command
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_8.md">
# Developer To-Do List: Phase 8 - Asynchronous Processing & Distributed Caching

**Objective:** Decouple long-running AI analysis tasks from request-response cycle and implement production-grade distributed caching.

## Tasks

- [ ] **1. Install Inngest**
  - Execute: `npm install inngest`
  - Initialize: `npx inngest-cli init`
  - Verification: `package.json` includes `"inngest"` in dependencies.

- [ ] **2. Create Inngest Function Handler**
  - Create file: `/app/inngest/route.ts`
    ```typescript
    import { serve } from 'inngest/next'
    import { functions } from './functions'

    export const { GET, POST, PUT } = serve({
      clientId: process.env.INNGEST_CLIENT_ID,
      functions,
    })
    ```
  - Create file: `/app/inngest/functions.ts`
    ```typescript
    import { inngest } from './client'
    import { analyzeSession } from '../lib/ai-service'

    export const functions = [
      inngest.createFunction(
        { id: 'post-session-analysis' },
        { event: 'ai/post-session-analysis' },
        async ({ event }) => {
          const { lessonId, audioUrl } = event.data
          return analyzeSession(lessonId, audioUrl)
        }
      )
    ]
    ```
  - Verification: Both files exist with correct content.

- [ ] **3. Refactor Submit Answer Endpoint**
  - Modify: `/app/api/lessons/[id]/submit-answer/route.ts`
    - Remove synchronous AI analysis call
    - Add Inngest send:
      ```typescript
      import { inngest } from '../../../lib/inngest'

      // After returning initial response
      await inngest.send({
        name: 'ai/post-session-analysis',
        data: { lessonId, audioUrl }
      })
      ```
  - Verification: Submit answer endpoint no longer contains direct AI analysis calls.

- [ ] **4. Implement Background Analysis Logic**
  - Move existing analysis logic from submit endpoint to:
    ```typescript
    // /lib/ai-service.ts
    export async function analyzeSession(lessonId: string, audioUrl: string) {
      // Existing analysis logic
      // Update SRS scores
      // Save VoiceAnalysis records
    }
    ```
  - Verification: All analysis logic resides in `analyzeSession` function.

- [ ] **5. Install Redis Client**
  - Execute: `npm install @upstash/redis`
  - Verification: `package.json` includes `"@upstash/redis"`.

- [ ] **6. Upgrade Cache Utility**
  - Modify: `/lib/cache.ts`
    - Replace `Map` with Redis client:
      ```typescript
      import { Redis } from '@upstash/redis'
      
      const redis = new Redis({
        url: process.env.REDIS_URL,
        token: process.env.REDIS_TOKEN,
      })
      
      export const cache = {
        get: (key: string) => redis.get(key),
        set: (key: string, value: any, ttl: number) => 
          redis.setex(key, ttl, value)
      }
      ```
  - Verification: Cache utility uses Redis methods instead of in-memory Map.
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_9.md">
# Developer To-Do List: Phase 9 - Comprehensive Testing

**Objective:** Implement a complete test suite covering core functionality, edge cases, and integration points.

## Tasks

- [ ] **1. Install Testing Dependencies**
  - Execute: `npm install jest ts-jest @types/jest --save-dev`
  - Verification: `package.json` includes these packages in devDependencies.

- [ ] **2. Configure Jest**
  - Create file: `jest.config.ts`
    ```typescript
    import type { Config } from '@jest/types'

    const config: Config.InitialOptions = {
      preset: 'ts-jest',
      testEnvironment: 'node',
      testMatch: ['**/tests/**/*.test.ts'],
      setupFilesAfterEnv: ['./tests/setup.ts'],
    }
    export default config
    ```
  - Verification: File exists with correct content.

- [ ] **3. Create Core Test Files**
  - Create directory: `/tests`
  - Create files:
    - `auth.test.ts` (User auth flows)
    - `lessons.test.ts` (Lesson generation/submission)
    - `ai-service.test.ts` (AI integration)
    - `dashboard.test.ts` (Stats/analytics)
    - `payments.test.ts` (Subscription flows)
  - Verification: All test files exist in `/tests`.

- [ ] **4. Implement Core Learning Loop Tests**
  - In `lessons.test.ts`:
    - Test SRS-driven content generation
    - Test difficulty adjustment after failed exercises
    - Test real-time feedback accuracy
  - Verification: Tests cover all cases from test plan section 1.

- [ ] **5. Implement Vocal Analysis Tests**
  - In `ai-service.test.ts`:
    - Test pronunciation scoring accuracy
    - Test fluency metrics (hesitation, pace)
    - Test filler word detection
  - Verification: Tests cover all cases from test plan section 2.

- [ ] **6. Implement Dashboard Tests**
  - In `dashboard.test.ts`:
    - Test SRS overview accuracy
    - Test error pattern detection
    - Test fluency trend visualization
  - Verification: Tests cover all cases from test plan section 3.

- [ ] **7. Implement Payment Flow Tests**
  - In `payments.test.ts`:
    - Test subscription scenarios (new, upgrade, failure)
    - Test webhook handling (success, failure, cancellation)
    - Test security measures (tokenization, PCI compliance)
  - Verification: Tests cover all cases from test plan section 5-6.

- [ ] **8. Update CI Workflow**
  - Modify: `/.github/workflows/ci.yml`
    - Add test command: `npm test`
    - Configure test database service
  - Verification: CI file includes test step and database setup.
</file>

<file path="docs/work_breakdown/tasks/feature_phase_1_feedback.md">
# Feature Phase 1: User Feedback Implementation

## Tasks for Developer AI

### 1. Create Feedback API Endpoint
- **File:** `/app/api/feedback/report/route.ts`
- **Action:** Implement endpoint to handle feedback submissions
- **Content:**
```typescript
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';

export async function POST(request: Request) {
  const { lessonId, userId, feedbackText, errorType } = await request.json();
  
  try {
    const feedback = await prisma.feedback.create({
      data: {
        lessonId,
        userId,
        feedbackText,
        errorType,
      }
    });
    return NextResponse.json(feedback);
  } catch (error) {
    return NextResponse.json(
      { error: 'Failed to submit feedback' },
      { status: 500 }
    );
  }
}
```
- **Verification:** Endpoint exists and accepts POST requests

### 2. Update Prisma Schema
- **File:** `/prisma/schema.prisma`
- **Action:** Add Feedback model
- **Modification:**
```prisma
model Feedback {
  id           String   @id @default(uuid())
  lessonId     String
  lesson       Lesson   @relation(fields: [lessonId], references: [id])
  userId       String
  user         User     @relation(fields: [userId], references: [id])
  feedbackText String
  errorType    String?
  createdAt    DateTime @default(now())
}
```
- **Verification:** Model exists in schema

### 3. Run Database Migration
- **Command:** `npx prisma migrate dev --name add_feedback_model`
- **Verification:** New migration file created in `prisma/migrations`

### 4. Add Feedback Button to Lesson UI
- **File:** `/components/LessonView.tsx`
- **Action:** Implement feedback reporting UI
- **Modification:**
```typescript
function ReportIssueButton() {
  const [isOpen, setIsOpen] = useState(false);
  const [feedback, setFeedback] = useState('');

  const submitFeedback = async () => {
    await fetch('/api/feedback/report', {
      method: 'POST',
      body: JSON.stringify({
        lessonId: currentLesson.id,
        feedbackText: feedback,
        errorType: 'general'
      })
    });
    setIsOpen(false);
  };

  return (
    <>
      <button onClick={() => setIsOpen(true)}>Report Issue</button>
      {isOpen && (
        <div className="feedback-modal">
          <textarea value={feedback} onChange={(e) => setFeedback(e.target.value)} />
          <button onClick={submitFeedback}>Submit</button>
        </div>
      )}
    </>
  );
}
```
- **Verification:** Button appears in lesson interface
</file>

<file path="docs/work_breakdown/tasks/feature_phase_2_transactional_integrity.md">
### Feature Phase 2: Transactional Integrity & User Communication

**Objective:** Ensure critical operations maintain data consistency and keep users informed through transactional emails.

#### Tasks:
1. **Install Email SDK:**
   ```bash
   npm install resend
   ```

2. **Create Email Service:**
   - Create `/lib/email.ts`:
     ```typescript
     import { Resend } from 'resend'
     
     const resend = new Resend(process.env.RESEND_API_KEY)
     
     export async function sendWelcomeEmail(email: string, name: string) {
       await resend.emails.send({
         from: 'welcome@lessay.com',
         to: email,
         subject: 'Welcome to Lessay!',
         html: `<p>Hi ${name}, thank you for joining Lessay!</p>`
       })
     }
     
     export async function sendSubscriptionConfirmation(email: string) {
       await resend.emails.send({
         from: 'subscriptions@lessay.com',
         to: email,
         subject: 'Your Lessay Subscription is Active!',
         html: `<p>Your Lessay premium subscription is now active.</p>`
       })
     }
     ```

3. **Refactor Sign-Up Flow:**
   - Update `/api/users/sync` route to use transaction:
     ```typescript
     await prisma.$transaction(async (tx) => {
       const user = await tx.user.create({ data: profileData })
       await sendWelcomeEmail(user.email, user.name)
       return user
     })
     ```

4. **Enhance Stripe Webhook Handler:**
   - Update `/api/stripe/webhook` route:
     ```typescript
     // After successful subscription update
     await sendSubscriptionConfirmation(user.email)
     ```

5. **Implement Webhook Idempotency:**
   - Add event ID tracking to prevent duplicate processing:
     ```typescript
     const processedEvent = await prisma.processedEvent.findUnique({
       where: { eventId: stripeEvent.id }
     })
     if (processedEvent) return
     // Process event...
     await prisma.processedEvent.create({
       data: { eventId: stripeEvent.id }
     })
     ```

**Verification:**
- Test sign-up flow creates both auth and profile records
- Confirm welcome emails are received
- Verify subscription emails trigger on payment
- Ensure duplicate webhook events are ignored

**Completion Criteria:**
- All critical operations maintain data consistency
- Users receive timely email confirmations
- Webhook processing is idempotent
</file>

<file path="docs/work_breakdown/tasks/feature_phase_3_onboarding.md">
### Feature Phase 3: User Onboarding & Activation Flow

**Objective:** Guide new users through initial setup to ensure personalized experience from first login.

#### Tasks:
1. **Update User Model:**
   - Modify `prisma/schema.prisma`:
     ```prisma
     model User {
       // ... existing fields
       status String @default("new") // 'new' | 'active'
     }
   ```

2. **Create Onboarding UI:**
   - Create `/components/OnboardingFlow.tsx`:
     ```typescript
     export default function OnboardingFlow() {
       // Language selection and goal setup UI
     }
     ```
   - Create `/app/onboarding/page.tsx` to host the flow

3. **Implement Onboarding Logic:**
   - Add middleware check in root layout:
     ```typescript
     if (session?.user?.status === 'new' && !pathname.startsWith('/onboarding')) {
       redirect('/onboarding')
     }
     ```
   - Create API route to complete onboarding:
     ```typescript
     await prisma.user.update({
       where: { id: userId },
       data: { status: 'active' }
     })
     ```

**Verification:**
- New users are redirected to onboarding
- User status updates correctly after completion
- Existing users bypass onboarding

**Completion Criteria:**
- All new users complete onboarding before accessing main app
- User model accurately reflects activation status
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_1_observability.md">
# Hardening Phase 1: Observability Implementation

## Tasks for Developer AI

### 1. Install Logging Dependencies
**File Path:** Project root (`./`)
**Action:** Execute command to install pino and pino-pretty
**LLM Prompt:** "Execute the following shell command to install logging dependencies:"
**Command:** `npm install pino pino-pretty`
**Verification:** `pino` and `pino-pretty` appear in `package.json` dependencies

---

### 2. Create Logger Utility
**File Path:** `/lib/logger.ts`
**Action:** Create a centralized logger instance
**LLM Prompt:** "Create a new file at `/lib/logger.ts` with the following content:"
```typescript
import pino from 'pino'

const logger = pino({
  level: process.env.NODE_ENV === 'production' ? 'info' : 'debug',
  transport: {
    target: 'pino-pretty',
    options: {
      colorize: true,
      translateTime: 'SYS:standard'
    }
  }
})

export default logger
```
**Verification:** File exists and exports a `logger` instance

---

### 3. Replace Console Logs in API Routes
**Action:** Update all API routes to use the new logger
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/stripe/webhook/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "In each specified API route file, replace all `console.log` statements with appropriate logger methods (`logger.info`, `logger.error`, etc.)"
**Verification:** No `console.log` statements remain in API route files

---

### 4. Implement Health Check Endpoint
**File Path:** `/app/api/health/route.ts`
**Action:** Create a health check API route
**LLM Prompt:** "Create a new file at `/app/api/health/route.ts` with the following content:"
```typescript
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'
import logger from '@/lib/logger'

export async function GET() {
  try {
    await prisma.$queryRaw`SELECT 1`
    logger.info('Health check successful')
    return NextResponse.json({ status: 'ok' }, { status: 200 })
  } catch (error) {
    logger.error('Health check failed', error)
    return NextResponse.json(
      { status: 'error', message: 'Database connection failed' },
      { status: 503 }
    )
  }
}
```
**Verification:** File exists and returns 200 OK when database is accessible

---

### 5. Verify Logging Implementation
**Action:** Test the logging functionality
**LLM Prompt:** "Execute the following command to test the application and verify logs are being generated:"
**Command:** `npm run dev`
**Verification:** Application starts and logs appear in the console with proper formatting
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_1_todo.md">
# Hardening Phase 1: Security & Reliability

## Tasks for Developer AI

### 1. Implement Rate Limiting
- **File:** `/middleware/rate-limiter.ts`
- **Action:** Add Redis-based rate limiting
- **Steps:**
  1. Install `@upstash/ratelimit`
  2. Create Redis client config
  3. Apply to API routes
- **Verification:** 429 responses after 10 requests

### 2. Add Input Validation
- **File:** `/lib/validators/*`
- **Action:** Create Zod schemas
- **Steps:
  1. Add `zod` dependency
  2. Create schemas for all API inputs
  3. Integrate with routes
- **Verification:** Invalid inputs rejected

### 3. Setup Error Tracking
- **File:** `/lib/sentry.ts`
- **Action:** Configure Sentry
- **Steps:
  1. Add `@sentry/nextjs`
  2. Initialize in `_app.tsx`
  3. Add error boundaries
- **Verification:** Errors appear in Sentry
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_2_error_handling.md">
# Hardening Phase 2: Error Handling Implementation

## Tasks for Developer AI

### 1. Prepare Error Handling Utilities
**File Path:** `/lib/errors.ts`
**Action:** Create error handling utilities
**LLM Prompt:** "Create a new file at `/lib/errors.ts` with the following content:"
```typescript
import { NextResponse } from 'next/server'
import logger from '@/lib/logger'
import { PrismaClientKnownRequestError } from '@prisma/client/runtime/library'

export function handleError(error: unknown) {
  if (error instanceof PrismaClientKnownRequestError) {
    logger.error({ error }, 'Database error occurred')
    return NextResponse.json(
      { error: 'Database operation failed' },
      { status: getPrismaErrorStatus(error) }
    )
  }

  logger.error({ error }, 'Unexpected error occurred')
  return NextResponse.json(
    { error: 'An unexpected error occurred' },
    { status: 500 }
  )
}

function getPrismaErrorStatus(error: PrismaClientKnownRequestError): number {
  switch (error.code) {
    case 'P2002': return 409 // Unique constraint violation
    case 'P2025': return 404 // Record not found
    default: return 400 // Bad request
  }
}
```
**Verification:** File exists and exports `handleError` function

---

### 2. Update API Routes with Error Handling
**Action:** Modify all API routes to use structured error handling
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/stats/fluency/route.ts`
- `app/api/stats/srs-overview/route.ts`
- `app/api/stripe/webhook/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route file:
1. Wrap the entire exported function body in a try/catch block
2. Use the handleError utility from '@/lib/errors' in catch blocks
3. Ensure all errors are properly logged
4. Maintain existing functionality"

**Example Modification:**
```typescript
// Before
export async function POST(request: Request) {
  const { tier } = await request.json()
  console.log('Creating subscription for tier:', tier)
  return NextResponse.json({ status: 'active' })
}

// After
import { handleError } from '@/lib/errors'

export async function POST(request: Request) {
  try {
    const { tier } = await request.json()
    logger.info('Creating subscription for tier:', { tier })
    return NextResponse.json({ status: 'active' })
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** All API routes have try/catch blocks and use handleError

---

### 3. Add Health Check Error Handling
**File Path:** `/app/api/health/route.ts`
**Action:** Update health check to use new error handler
**LLM Prompt:** "Modify `/app/api/health/route.ts` to use the handleError utility:"
```typescript
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'
import logger from '@/lib/logger'
import { handleError } from '@/lib/errors'

export async function GET() {
  try {
    await prisma.$queryRaw`SELECT 1`
    logger.info('Health check successful')
    return NextResponse.json({ status: 'ok' }, { status: 200 })
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** Health check uses handleError and maintains functionality

---

### 4. Verify Error Handling
**Action:** Test error scenarios
**LLM Prompt:** "Execute the following command to test the application and verify error handling:"
**Command:** `npm run dev`
**Verification:**
1. Trigger intentional errors in API routes
2. Confirm proper error responses (status codes and JSON format)
3. Check that errors appear in logs with appropriate levels
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_3_security.md">
# Hardening Phase 3: Security Implementation

## Tasks for Developer AI

### 1. Install Zod for Validation
**File Path:** Project root (`./`)
**Action:** Execute command to install Zod
**LLM Prompt:** "Execute the following shell command to install Zod:"
**Command:** `npm install zod`
**Verification:** `zod` appears in `package.json` dependencies

---

### 2. Create Validation Schemas
**File Path:** `/lib/validators.ts`
**Action:** Create shared validation schemas
**LLM Prompt:** "Create a new file at `/lib/validators.ts` with the following content:"
```typescript
import { z } from 'zod'

export const lessonStartSchema = z.object({
  userId: z.string().uuid(),
  targetLanguage: z.string().length(2)
})

export const answerSubmitSchema = z.object({
  exerciseId: z.string().uuid(),
  textResponse: z.string().min(1),
  audioBlobUrl: z.string().url().optional()
})

export const subscriptionSchema = z.object({
  tier: z.enum(['free', 'premium', 'pro']),
  paymentMethodId: z.string()
})
```
**Verification:** File exists and exports validation schemas

---

### 3. Implement Route Validation
**Action:** Add validation to API routes with request bodies
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route:
1. Import appropriate validator from '@/lib/validators'
2. Validate request body at start of handler
3. Return 400 with validation errors if invalid
4. Maintain existing functionality"

**Example Modification:**
```typescript
import { NextResponse } from 'next/server'
import { answerSubmitSchema } from '@/lib/validators'
import { handleError } from '@/lib/errors'

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  try {
    const body = await request.json()
    const validation = answerSubmitSchema.safeParse(body)
    
    if (!validation.success) {
      return NextResponse.json(
        { error: 'Invalid request', details: validation.error.flatten() },
        { status: 400 }
      )
    }

    // Existing handler logic...
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** Routes return 400 for invalid requests with error details

---

### 4. Install Rate Limiting Package
**File Path:** Project root (`./`)
**Action:** Execute command to install rate limiter
**LLM Prompt:** "Execute the following shell command to install rate limiting:"
**Command:** `npm install @upstash/ratelimit`
**Verification:** `@upstash/ratelimit` appears in `package.json` dependencies

---

### 5. Configure Rate Limiting
**File Path:** `/lib/rateLimit.ts`
**Action:** Create rate limiting configuration
**LLM Prompt:** "Create a new file at `/lib/rateLimit.ts` with the following content:"
```typescript
import { Ratelimit } from '@upstash/ratelimit'
import { Redis } from '@upstash/redis'

export const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, '1 m'),
  analytics: true
})
```
**Verification:** File exists and exports rate limiter instance

---

### 6. Apply Rate Limiting to Sensitive Endpoints
**Action:** Add rate limiting to high-risk routes
**Files to Modify:**
- `app/api/lessons/start/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route:
1. Import rate limiter from '@/lib/rateLimit'
2. Get client IP from headers (request.headers.get('x-forwarded-for'))
3. Check rate limit at start of handler
4. Return 429 if limit exceeded
5. Maintain existing functionality"

**Example Modification:**
```typescript
import { ratelimit } from '@/lib/rateLimit'

export async function POST(request: Request) {
  const ip = request.headers.get('x-forwarded-for') ?? '127.0.0.1'
  const { success } = await ratelimit.limit(ip)
  
  if (!success) {
    return NextResponse.json(
      { error: 'Too many requests' },
      { status: 429 }
    )
  }

  // Existing handler logic...
}
```
**Verification:** Routes return 429 after exceeding request limits

---

### 7. Verify Security Features
**Action:** Test validation and rate limiting
**LLM Prompt:** "Execute the following command to test the security features:"
**Command:** `npm run dev`
**Verification:**
1. Invalid requests return 400 with error details
2. Excessive requests to limited endpoints return 429
3. Valid requests function normally
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_4_performance.md">
# Hardening Phase 4: Performance Optimization

## Tasks for Developer AI

### 1. Add Database Indexes
**File Path:** `/prisma/schema.prisma`
**Action:** Add compound index to UserProgress model
**LLM Prompt:** "Modify the UserProgress model in `/prisma/schema.prisma` to add a compound index:"
```prisma
model UserProgress {
  id          String   @id @default(uuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  metric      String
  score       Float
  lastUpdated DateTime @default(now())

  @@index([userId, metric], name: "UserProgress_userId_metric_index")
}
```
**Verification:** Index definition exists in schema.prisma

---

### 2. Apply Database Migration
**File Path:** Project root (`./`)
**Action:** Create and apply migration
**LLM Prompt:** "Execute the following command to create and apply the migration:"
**Command:** `npx prisma migrate dev --name add_performance_indexes`
**Verification:** New migration file exists in prisma/migrations directory

---

### 3. Implement Basic Caching
**File Path:** `/lib/cache.ts`
**Action:** Create caching utility
**LLM Prompt:** "Create a new file at `/lib/cache.ts` with the following content:"
```typescript
const cache = new Map<string, { data: any, expires: number }>()

export function getFromCache<T>(key: string): T | null {
  const item = cache.get(key)
  if (!item || item.expires < Date.now()) {
    return null
  }
  return item.data as T
}

export function setToCache(key: string, data: any, ttl: number = 300000) {
  cache.set(key, {
    data,
    expires: Date.now() + ttl
  })
}

export function clearCache(key: string) {
  cache.delete(key)
}
```
**Verification:** File exists and exports cache functions

---

### 4. Add Caching to Stats Endpoints
**Action:** Implement caching in dashboard routes
**Files to Modify:**
- `app/api/stats/fluency/route.ts`
- `app/api/stats/srs-overview/route.ts`

**LLM Prompt:** "For each specified stats route:
1. Import cache functions from '@/lib/cache'
2. Generate cache key based on user ID and route
3. Check cache before querying database
4. Store results in cache after querying
5. Maintain existing functionality"

**Example Modification:**
```typescript
import { getFromCache, setToCache } from '@/lib/cache'

export async function GET(request: Request) {
  const cacheKey = `stats-fluency-${userId}`
  const cached = getFromCache(cacheKey)
  if (cached) {
    return NextResponse.json(cached)
  }

  const data = await fetchDataFromDB() // Existing logic
  
  setToCache(cacheKey, data)
  return NextResponse.json(data)
}
```
**Verification:** Repeated requests within 5 minutes return cached data

---

### 5. Verify Performance Improvements
**Action:** Test database and caching changes
**LLM Prompt:** "Execute the following command to test performance features:"
**Command:** `npm run dev`
**Verification:**
1. Database queries for stats are faster with indexes
2. Repeated stat requests return cached data
3. Data updates reflect after cache expires
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_5_testing.md">
# Hardening Phase 5: Testing Implementation

## Tasks for Developer AI

### 1. Install Testing Dependencies
**File Path:** Project root (`./`)
**Action:** Execute command to install Jest and related packages
**LLM Prompt:** "Execute the following shell command to install testing dependencies:"
**Command:** `npm install jest ts-jest @types/jest --save-dev`
**Verification:** Packages appear in `package.json` devDependencies

---

### 2. Configure Jest for TypeScript
**File Path:** `jest.config.ts`
**Action:** Create Jest configuration file
**LLM Prompt:** "Create a new file at `jest.config.ts` with the following content:"
```typescript
import type { Config } from '@jest/types'

const config: Config.InitialOptions = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>'],
  testMatch: ['**/*.test.ts'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/$1'
  }
}

export default config
```
**Verification:** Configuration file exists with correct settings

---

### 3. Create Auth Test File
**File Path:** `/tests/auth.test.ts`
**Action:** Implement authentication tests
**LLM Prompt:** "Create a new file at `/tests/auth.test.ts` with the following content:"
```typescript
import { describe, it, expect } from '@jest/globals'
import { signUp, signIn } from '@/lib/auth'

describe('Authentication', () => {
  it('should allow valid user signup', async () => {
    const result = await signUp('test@example.com', 'password123')
    expect(result.success).toBe(true)
  })

  it('should reject duplicate user signup', async () => {
    await signUp('test@example.com', 'password123')
    const result = await signUp('test@example.com', 'password123')
    expect(result.error).toMatch(/already exists/i)
  })

  it('should allow valid login', async () => {
    await signUp('test@example.com', 'password123')
    const result = await signIn('test@example.com', 'password123')
    expect(result.success).toBe(true)
  })

  it('should reject invalid login', async () => {
    const result = await signIn('wrong@example.com', 'wrongpassword')
    expect(result.error).toMatch(/invalid credentials/i)
  })
})
```
**Verification:** File exists with all test cases

---

### 4. Create Lesson Test File
**File Path:** `/tests/lessons.test.ts`
**Action:** Implement lesson flow tests
**LLM Prompt:** "Create a new file at `/tests/lessons.test.ts` with the following content:"
```typescript
import { describe, it, expect } from '@jest/globals'
import { startLesson, submitAnswer } from '@/lib/lessons'

describe('Lesson Flow', () => {
  it('should start a new lesson', async () => {
    const lesson = await startLesson('user_123')
    expect(lesson.exercises.length).toBeGreaterThan(0)
  })

  it('should accept correct answers', async () => {
    const response = await submitAnswer('ex_123', 'correct answer')
    expect(response.correct).toBe(true)
  })

  it('should provide feedback for incorrect answers', async () => {
    const response = await submitAnswer('ex_123', 'wrong answer')
    expect(response.correct).toBe(false)
    expect(response.feedback).toBeDefined()
  })
})
```
**Verification:** File exists with all test cases

---

### 5. Update CI Workflow
**File Path:** `/.github/workflows/ci.yml`
**Action:** Add test step to CI pipeline
**LLM Prompt:** "Modify the CI workflow to include testing:"
```yaml
jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm ci
      - run: npm run lint
      - run: npm test
```
**Verification:** CI file includes `npm test` command

---

### 6. Verify Test Suite
**Action:** Run the test suite
**LLM Prompt:** "Execute the following command to run tests:"
**Command:** `npm test`
**Verification:** All tests pass successfully
</file>

<file path="docs/work_breakdown/tasks/infra_phase_1_connection_pooling.md">
### Infrastructure Phase 1: Database Connection Pooling for Serverless Scalability

**Objective:** Ensure the application can handle concurrent requests in a serverless environment without exhausting database connections.

#### Tasks:
1. **Enable Prisma Accelerate:**
   - Sign up for Prisma Data Platform if not already done.
   - Create a new project in the Prisma Data Platform dashboard.
   - Enable Prisma Accelerate for the project and note the generated connection string.

2. **Update Environment Configuration:**
   - Add the Prisma Accelerate connection string to your environment variables as `DATABASE_URL_ACCELERATE`.

3. **Modify Prisma Client Initialization:**
   - Update `/lib/prisma.ts` to use the Accelerate connection string:
     ```typescript
     import { PrismaClient } from '@prisma/client/edge'
     const prisma = new PrismaClient({
       datasourceUrl: process.env.DATABASE_URL_ACCELERATE,
     })
     export default prisma
     ```

4. **Verification:**
   - Deploy the updated code to a staging environment.
   - Simulate load (e.g., using a tool like k6) to ensure no `P2024` errors occur.
   - Confirm in Prisma Data Platform dashboard that connections are being pooled correctly.

**Completion Criteria:**
- Application handles 50+ concurrent users without database connection errors.
- Prisma Accelerate dashboard shows active connection pooling.
</file>

<file path="docs/work_breakdown/tasks/infra_phase_2_deployment_automation.md">
### Infrastructure Phase 2: Deployment Automation

**Objective:** Establish a fully automated CI/CD pipeline for reliable staging and production deployments.

#### Tasks:
1. **Create Production Dockerfile:**
   - Add a multi-stage `Dockerfile` to project root:
     ```dockerfile
     FROM node:20-alpine AS builder
     WORKDIR /app
     COPY package*.json ./
     RUN npm ci
     COPY . .
     RUN npm run build

     FROM node:20-alpine AS runner
     WORKDIR /app
     ENV NODE_ENV production
     COPY --from=builder /app/package*.json ./
     COPY --from=builder /app/node_modules ./node_modules
     COPY --from=builder /app/.next ./.next
     COPY --from=builder /app/public ./public
     COPY --from=builder /app/next.config.js ./
     EXPOSE 3000
     CMD ["npm", "start"]
     ```

2. **Update CI/CD Pipeline:**
   - Modify `/.github/workflows/ci.yml` to add:
     ```yaml
     deploy-staging:
       needs: test
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v4
         - name: Log in to GitHub Container Registry
           uses: docker/login-action@v3
           with:
             registry: ghcr.io
             username: ${{ github.actor }}
             password: ${{ secrets.GITHUB_TOKEN }}
         - name: Build and push Docker image
           uses: docker/build-push-action@v5
           with:
             context: .
             push: true
             tags: ghcr.io/${{ github.repository }}:staging-${{ github.sha }}
         - name: Deploy to Staging
           run: |
             echo "Add your staging deployment command here"
             # Example: vercel deploy --prod --token $VERCEL_TOKEN

     deploy-production:
       needs: deploy-staging
       runs-on: ubuntu-latest
       if: github.event_name == 'workflow_dispatch'
       steps:
         - uses: actions/checkout@v4
         - name: Log in to GitHub Container Registry
           uses: docker/login-action@v3
           with:
             registry: ghcr.io
             username: ${{ github.actor }}
             password: ${{ secrets.GITHUB_TOKEN }}
         - name: Build and push Docker image
           uses: docker/build-push-action@v5
           with:
             context: .
             push: true
             tags: ghcr.io/${{ github.repository }}:prod-${{ github.sha }}
         - name: Deploy to Production
           run: |
             echo "Add your production deployment command here"
     ```

3. **Verification:**
   - Merge a test PR to main branch and verify staging deployment completes
   - Manually trigger production deployment and verify success
   - Confirm application is reachable in both environments

**Completion Criteria:**
- Every merged PR to main automatically deploys to staging
- Production deployments can be triggered manually via GitHub UI
- Docker images are properly built and pushed to container registry
</file>

<file path="docs/work_breakdown/tasks/logic_phase_1_todo.md">
# Lessay Implementation Phase 1: Core Backend & User Auth

## Tasks for Developer AI

### 1. Create Supabase Server-Side Client Helper
**File:** `/lib/supabase-server.ts`  
**Action:** Create a server-side Supabase client for authenticated operations  
**Steps:**
- Import `createClient` and `createServerComponentClient` from `@supabase/ssr`
- Export a `supabaseServerClient` function that:
  - Accepts `cookies()` from `next/headers`
  - Returns a Supabase client configured with `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY`
- Export a `getUserSession` helper that:
  - Uses the server client to call `auth.getUser()`
  - Returns the user object or null

**Verification:** File exists and exports both functions with proper TypeScript types

---

### 2. Implement Profile GET Route
**File:** `/app/api/users/profile/route.ts`  
**Action:** Add real user session handling  
**Steps:**
- Import `getUserSession` from `@/lib/supabase-server`
- Modify the GET function to:
  1. Call `getUserSession()`
  2. If no user, return `401 Unauthorized`
  3. Query Prisma for `User` with `user.id`
  4. Return profile data (excluding sensitive fields)

**Verification:** Route returns 401 when unauthenticated and profile data when logged in

---

### 3. Implement Profile PUT Route
**File:** `/app/api/users/profile/route.ts`  
**Action:** Add profile update functionality  
**Steps:**
- Keep existing auth check from GET route
- Add Prisma `user.update` call with:
  - `where: { id: user.id }`
  - `data` from request body (validate/sanitize first)
- Return updated profile data

**Verification:** PUT requests successfully update user data in database

---

### 4. Create Auth UI Component
**File:** `/components/Auth.tsx`  
**Action:** Build sign-up/sign-in interface  
**Steps:
- Create client-side Supabase client with `createClientComponentClient`
- Add:
  - Email input field
  - Password input field
  - Sign Up button (calls `supabase.auth.signUp`)
  - Sign In button (calls `supabase.auth.signInWithPassword`)
  - Error message display
- Style with Tailwind CSS

**Verification:** Component renders properly and allows user registration/login
</file>

<file path="docs/work_breakdown/tasks/logic_phase_2_todo.md">
# Lessay Implementation Phase 2: Learning Loop Logic

## Tasks for Developer AI

### 1. Implement Lesson Start Route
**File:** `/app/api/lessons/start/route.ts`  
**Action:** Add real lesson generation logic  
**Steps:**
- Import `getUserSession` from `@/lib/supabase-server`
- Modify POST function to:
  1. Authenticate user (return 401 if not logged in)
  2. Call `AIService.generateLessonForUser` with user's ID
  3. Create Prisma records for:
     - `Lesson` (with generated content)
     - `Exercise` (linked to lesson)
  4. Return lesson ID and first exercise

**Verification:** Route creates database entries and returns structured lesson data

---

### 2. Implement Answer Submission Route
**File:** `/app/api/lessons/[id]/submit-answer/route.ts`  
**Action:** Add answer processing logic  
**Steps:**
- Import `getUserSession` for auth
- Modify POST function to:
  1. Authenticate user
  2. Find exercise by ID
  3. Compare `textResponse` to `correctAnswer`
  4. Create `UserProgress` record with:
     - `isCorrect` flag
     - `submittedAnswer`
     - `exerciseId`
     - `userId`
  5. Return feedback object with:
     - `isCorrect`
     - `correctAnswer`
     - `explanation`

**Verification:** Submissions create progress records and return proper feedback

---

### 3. Update Lesson View Component
**File:** `/components/LessonView.tsx`  
**Action:** Add interactive exercise UI  
**Steps:**
- Add:
  - Text input field for answers
  - Submit button that:
    - Calls submit-answer API
    - Disables during submission
  - Feedback display area showing:
    - Correct/incorrect indicator
    - Explanation (if available)
- Handle loading states
- Style with Tailwind CSS

**Verification:** Component allows answer submission and displays feedback
</file>

<file path="docs/work_breakdown/tasks/logic_phase_3_todo.md">
# Lessay Implementation Phase 3: AI Service Integration

## Tasks for Developer AI

### 1. Install Google AI SDK
**Command:**  
```bash
npm install @google/generative-ai
```
**Verification:** Package appears in `package.json` dependencies

---

### 2. Initialize AI Client
**File:** `/lib/ai-service.ts`  
**Action:** Configure real Google AI client  
**Steps:**
- Import `GoogleGenerativeAI` from SDK
- Create client instance using `AI_API_KEY` from env
- Export initialized client
- Remove any existing stub implementations

**Verification:** File exports properly configured client instance

---

### 3. Implement Lesson Generation
**File:** `/lib/ai-service.ts`  
**Action:** Replace stubbed `generateLessonForUser`  
**Steps:**
1. Construct detailed prompt per `technical_design_template.md`
2. Call Gemini model with:
   - `temperature: 0.7`
   - `maxOutputTokens: 2048`
3. Parse JSON response into:
   - `lessonContent`
   - `exercises[]` with:
     - `question`
     - `correctAnswer`
     - `explanation`
4. Return structured lesson data

**Verification:** Function returns valid lesson structure from API call

---

### 4. Add Audio Analysis Placeholder
**File:** `/lib/ai-service.ts`  
**Action:** Connect audio analysis to Prisma  
**Steps:**
- Keep function signature but:
  1. Log "Real audio analysis will be implemented here"
  2. Create `VoiceAnalysis` record in Prisma with dummy metrics:
     - `fluencyScore: 0.8`
     - `pronunciationScore: 0.75`
     - `accuracyScore: 0.85`
  3. Return dummy metrics object

**Verification:** Function creates database records and returns expected structure
</file>

<file path="docs/work_breakdown/tasks/logic_phase_4_todo.md">
# Lessay Implementation Phase 4: Dashboard & Payments Integration

## Tasks for Developer AI

### 1. Implement Fluency Stats Route
**File:** `/app/api/stats/fluency/route.ts`  
**Action:** Add real fluency statistics  
**Steps:**
- Authenticate user
- Use Prisma to aggregate `UserProgress`:
  - `avg` of `accuracyScore`
  - `count` of exercises by `isCorrect`
  - Group by `createdAt` (daily)
- Return structured stats object

**Verification:** Route returns proper stats shape with real data

---

### 2. Implement SRS Overview Route
**File:** `/app/api/stats/srs-overview/route.ts`  
**Action:** Add spaced repetition stats  
**Steps:**
- Authenticate user
- Use Prisma to aggregate `SRSEntry`:
  - `count` by `status`
  - `min`, `max`, `avg` of `nextReview`
  - Group by `exerciseType`
- Return structured overview

**Verification:** Route returns proper SRS metrics

---

### 3. Update Dashboard View
**File:** `/components/DashboardView.tsx`  
**Action:** Display real stats  
**Steps:
- Fetch data from both stats endpoints
- Display:
  - Accuracy trend chart
  - SRS status pie chart
  - Recent activity list
- Style with Tailwind CSS

**Verification:** Component renders all data visualizations

---

### 4. Implement Stripe Subscription
**File:** `/app/api/payments/create-subscription/route.ts`  
**Action:** Add real payment processing  
**Steps:**
- Install `stripe` package
- Initialize Stripe with `STRIPE_SECRET_KEY`
- Create subscription with:
  - `customer` from request
  - `items` from request
  - `payment_behavior: 'default_incomplete'`
- Return subscription ID

**Verification:** Route creates Stripe subscriptions

---

### 5. Secure Stripe Webhook
**File:** `/app/api/stripe/webhook/route.ts`  
**Action:** Add signature verification  
**Steps:
- Get webhook secret from env
- Use `stripe.webhooks.constructEvent`
- Verify signature before processing
- Handle relevant event types

**Verification:** Webhook rejects invalid signatures
</file>

<file path="docs/work_breakdown/tasks/logic_phase_5_todo.md">
# Lessay Implementation Phase 5: Testing & Finalization

## Tasks for Developer AI

### 1. Install Testing Dependencies
**Command:**  
```bash
npm install jest ts-jest @types/jest --save-dev
```
**Verification:** Packages appear in `package.json` devDependencies

---

### 2. Configure Jest for TypeScript
**File:** `jest.config.ts`  
**Action:** Create test configuration  
**Steps:**
- Export default config with:
  - `preset: 'ts-jest'`
  - `testEnvironment: 'node'`
  - `roots: ['<rootDir>']`
  - `testMatch: ['**/*.test.ts']`

**Verification:** Configuration file exists with proper settings

---

### 3. Create Sample Test
**File:** `/lib/utils.test.ts`  
**Action:** Add basic test case  
**Steps:
- Import function to test (e.g., from `/lib/utils.ts`)
- Write test that:
  - Checks a simple function
  - Uses `describe` and `it` blocks
  - Has assertions with `expect`

**Verification:** `npm test` runs successfully

---

### 4. Update Test Script
**File:** `package.json`  
**Action:** Add test command  
**Steps:
- Add script: `"test": "jest"`
- Ensure it's in the `scripts` section

**Verification:** `npm test` executes Jest

---

### 5. Add JSDoc Comments
**Action:** Document all exported functions  
**Scope:** All created/modified files  
**Requirements:**
- `/**` comment blocks
- Description of purpose
- `@param` for each parameter
- `@returns` for return value
- `@example` usage if applicable

**Verification:** All exports have complete documentation
</file>

<file path="docs/work_breakdown/tasks/logic_phase_6_todo.md">
# Logic Implementation Phase 6: Google Cloud TTS/STT Integration

## Task 1: Install Required SDKs
- Execute `npm install @google-cloud/speech @google-cloud/text-to-speech`

## Task 2: Initialize Google Cloud Clients
- Modify `/lib/ai-service.ts` to:
  1. Import the required modules:
     ```typescript
     import { SpeechClient } from '@google-cloud/speech';
     import { TextToSpeechClient } from '@google-cloud/text-to-speech';
     ```
  2. Initialize the clients with proper credentials handling:
     ```typescript
     let speechClient: SpeechClient;
     let textToSpeechClient: TextToSpeechClient;

     if (process.env.GCP_CREDENTIALS_JSON) {
       // Production environment - use env variable
       const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
       speechClient = new SpeechClient({ credentials });
       textToSpeechClient = new TextToSpeechClient({ credentials });
     } else {
       // Local development - use file
       speechClient = new SpeechClient({
         keyFilename: './gcp-credentials.json'
       });
       textToSpeechClient = new TextToSpeechClient({
         keyFilename: './gcp-credentials.json'
       });
     }
     ```

## Task 3: Implement Speech-to-Text
- Replace placeholder console.logs with actual STT implementation:
  ```typescript
  async function transcribeAudio(audioBuffer: Buffer): Promise<string> {
    const [response] = await speechClient.recognize({
      audio: {
        content: audioBuffer.toString('base64'),
      },
      config: {
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
        languageCode: 'en-US',
      },
    });
    return response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');
  }
  ```

## Task 4: Implement Text-to-Speech
- Replace placeholder console.logs with actual TTS implementation:
  ```typescript
  async function synthesizeSpeech(text: string): Promise<Buffer> {
    const [response] = await textToSpeechClient.synthesizeSpeech({
      input: { text },
      voice: {
        languageCode: 'en-US',
        name: 'en-US-Standard-C'
      },
      audioConfig: {
        audioEncoding: 'MP3'
      }
    });
    return Buffer.from(response.audioContent, 'base64');
  }
  ```

## Verification
- The file `/lib/ai-service.ts` exists and contains the new implementations
- The Google Cloud clients are properly initialized with credentials
- The app can successfully transcribe audio and synthesize speech
</file>

<file path="docs/work_breakdown/tasks/prod_polish_phase_5_state_management.md">
# Production Polish Phase 5: State Management Implementation

## Tasks for Developer AI

### 1. Install Zustand
- **File:** `package.json`
- **Action:** Add Zustand as a dependency
- **Command:** `npm install zustand`
- **Verification:** `zustand` appears in `package.json` dependencies

### 2. Create User Store
- **File:** `/lib/stores/userStore.ts`
- **Action:** Create a global store for user session state
- **Content:**
```typescript
import { create } from 'zustand';

interface UserState {
  user: { id: string; email: string } | null;
  setUser: (user: { id: string; email: string } | null) => void;
}

export const useUserStore = create<UserState>((set) => ({
  user: null,
  setUser: (user) => set({ user }),
}));
```
- **Verification:** File exists and exports `useUserStore`

### 3. Implement Auth Listener
- **File:** `/components/AuthListener.tsx`
- **Action:** Create component to sync Supabase auth with Zustand store
- **Content:**
```typescript
'use client';
import { useEffect } from 'react';
import { useUserStore } from '@/lib/stores/userStore';
import { supabase } from '@/lib/supabase/client';

export default function AuthListener() {
  const setUser = useUserStore((state) => state.setUser);

  useEffect(() => {
    const { data: { subscription } } = supabase.auth.onAuthStateChange((event, session) => {
      setUser(session?.user ?? null);
    });

    return () => subscription.unsubscribe();
  }, [setUser]);

  return null;
}
```
- **Verification:** Component exists and listens to auth changes

### 4. Update Layout Component
- **File:** `/components/AppLayout.tsx`
- **Action:** Add AuthListener to root layout
- **Modification:**
```typescript
import AuthListener from '@/components/AuthListener';

export default function AppLayout({ children }) {
  return (
    <>
      <AuthListener />
      {/* Existing layout content */}
    </>
  );
}
```
- **Verification:** AuthListener is rendered in the layout

### 5. Refactor LessonView Component
- **File:** `/components/LessonView.tsx`
- **Action:** Use Zustand store instead of local state
- **Modification:**
```typescript
import { useUserStore } from '@/lib/stores/userStore';

export default function LessonView() {
  const user = useUserStore((state) => state.user);
  // Remove local user state
}
```
- **Verification:** Component uses store instead of local state
</file>

<file path="docs/work_breakdown/tasks/prod_polish_phase_6_environments.md">
# Production Polish Phase 6: Environment-Specific Configurations

## Tasks for Developer AI

### 1. Update Environment Example File
- **File:** `/.env.example`
- **Action:** Add staging and production variables
- **Content:**
```
STRIPE_SECRET_KEY_STAGING=
STRIPE_SECRET_KEY_PROD=
AI_API_KEY_STAGING=
AI_API_KEY_PROD=
NODE_ENV=development
```
- **Verification:** File contains separate keys for staging/prod

### 2. Create Config Utility
- **File:** `/lib/config.ts`
- **Action:** Create environment-aware configuration
- **Content:**
```typescript
export function getStripeKey() {
  return process.env.NODE_ENV === 'production' 
    ? process.env.STRIPE_SECRET_KEY_PROD
    : process.env.STRIPE_SECRET_KEY_STAGING;
}

export function getAiKey() {
  return process.env.NODE_ENV === 'production'
    ? process.env.AI_API_KEY_PROD
    : process.env.AI_API_KEY_STAGING;
}
```
- **Verification:** File exports config functions

### 3. Update Payment Service
- **File:** `/app/api/payments/create-subscription/route.ts`
- **Action:** Use config instead of direct env access
- **Modification:**
```typescript
import { getStripeKey } from '@/lib/config';
const stripe = new Stripe(getStripeKey());
```
- **Verification:** Stripe client uses config function

### 4. Update AI Service
- **File:** `/lib/ai-service.ts`
- **Action:** Use config for API keys
- **Modification:**
```typescript
import { getAiKey } from '@/lib/config';
const geminiClient = new GoogleGenerativeAI(getAiKey());
```
- **Verification:** AI clients use config function

### 5. Update CI Workflow
- **File:** `/.github/workflows/ci.yml`
- **Action:** Add environment-specific secrets
- **Modification:**
```yaml
jobs:
  deploy-stage:
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run build
      - env:
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY_STAGING }}
          AI_API_KEY: ${{ secrets.AI_API_KEY_STAGING }}
        run: npm run deploy:stage
```
- **Verification:** Workflow uses correct secrets for staging
</file>

<file path="docs/work_breakdown/tasks/prod_security_phase_2_cost_control.md">
# Production Security Phase 2: AI Cost Control Implementation

## Tasks for Developer AI

### 1. Update User Model
- **File:** `/prisma/schema.prisma`
- **Action:** Add tier field to User model
- **Modification:**
```prisma
model User {
  id           String   @id @default(uuid())
  // ... existing fields
  tier         String   @default('free')
}
```
- **Verification:** Field exists in User model

### 2. Create Usage Tracking Model
- **File:** `/prisma/schema.prisma`
- **Action:** Add UserUsage model
- **Modification:**
```prisma
model UserUsage {
  id          String   @id @default(uuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  count       Int      @default(1)
  date        DateTime @default(now())
  @@index([userId, date])
}
```
- **Verification:** Model exists in schema

### 3. Run Database Migration
- **Command:** `npx prisma migrate dev --name add_usage_tracking`
- **Verification:** New migration file created

### 4. Implement Usage Check in Lesson Start
- **File:** `/app/api/lessons/start/route.ts`
- **Action:** Add usage limit for free tier
- **Modification:**
```typescript
const usage = await prisma.userUsage.count({
  where: {
    userId: session.user.id,
    date: {
      gte: new Date(Date.now() - 24 * 60 * 60 * 1000)
    }
  }
});

if (session.user.tier === 'free' && usage >= 5) {
  return NextResponse.json(
    { error: 'Daily limit exceeded' },
    { status: 429 }
  );
}
```
- **Verification:** Free users limited to 5 lessons/day

### 5. Add Audio Duration Check
- **File:** `/app/api/lessons/[id]/submit-answer/route.ts`
- **Action:** Reject long audio files
- **Modification:**
```typescript
if (body.audioBlobUrl) {
  const audioDuration = await getAudioDuration(body.audioBlobUrl);
  if (audioDuration > 30) {
    return NextResponse.json(
      { error: 'Audio too long' },
      { status: 400 }
    );
  }
}
```
- **Verification:** Audio >30s is rejected
</file>

<file path="docs/work_breakdown/tasks/prod_security_phase_3_authorization.md">
### Production Security Phase 3: Advanced Authorization

**Objective:** Implement strict authorization controls to prevent unauthorized access to protected resources.

#### Tasks:
1. **Create User Profile Types:**
   - Add to `/lib/types.ts`:
     ```typescript
     export type PublicUserProfile = {
       id: string
       name: string
       email: string
       targetLang: string
       nativeLang: string
     }

     export type UpdatableUserProfile = Pick<PublicUserProfile, 
       'targetLang' | 'nativeLang'>
     ```

2. **Update Profile Endpoint Validation:**
   - Modify PUT `/api/users/profile` route:
     ```typescript
     const schema = z.object({
       targetLang: z.string(),
       nativeLang: z.string()
     })
     ```

3. **Audit All API Endpoints:**
   - Create checklist in this file:
     ```markdown
     - [ ] GET /api/users/profile - returns PublicUserProfile
     - [ ] PUT /api/users/profile - only accepts UpdatableUserProfile
     - [ ] POST /api/lessons/start - verifies user has access to lesson
     - [ ] POST /api/payments/create-subscription - verifies user auth
     - [ ] POST /api/stripe/webhook - verifies webhook signature
     ```

4. **Implement Authorization Middleware:**
   - Create `/lib/middleware/authz.ts`:
     ```typescript
     export function requirePermission(resource: string, action: string) {
       return (req: NextRequest, res: NextResponse) => {
         if (!userCan(req.user, resource, action)) {
           return new Response('Unauthorized', { status: 403 })
         }
       }
     }
     ```

**Verification:**
- Attempt to update protected fields returns 400 error
- API responses only include PublicUserProfile fields
- All endpoints have explicit authorization checks

**Completion Criteria:**
- No sensitive fields are exposed or modifiable
- Every API endpoint enforces resource-level permissions
</file>

<file path="docs/work_breakdown/master_plan.md">
# Developer Master Roadmap (0_to_prod)

- [x] documentation/2_development_plan/dev_todo_phase_1.md
- [x] documentation/2_development_plan/dev_todo_phase_2.md
- [x] documentation/2_development_plan/dev_todo_phase_3.md
- [x] documentation/2_development_plan/dev_todo_phase_4.md
- [x] documentation/2_development_plan/dev_todo_phase_5.md
- [ ] documentation/2_development_plan/dev_todo_phase_6.md
- [ ] documentation/2_development_plan/dev_todo_phase_7.md
- [ ] documentation/2_development_plan/dev_todo_phase_8.md
- [ ] documentation/2_development_plan/dev_todo_phase_9.md
- [ ] documentation/2_development_plan/dev_todo_phase_10.md
- [ ] documentation/2_development_plan/dev_todo_phase_11.md
- [ ] documentation/2_development_plan/dev_todo_phase_12.md
- [ ] documentation/2_development_plan/dev_todo_phase_13.md
- [ ] documentation/2_development_plan/dev_todo_phase_14.md
- [ ] documentation/2_development_plan/dev_todo_phase_15.md
</file>

<file path="docs/app_description.md">
## **Lessay: Software Documentation Overview**

### **1. Introduction: Our Philosophy**

Lessay is an AI-powered language learning platform designed to create a deeply personal and efficient path to fluency. Unlike one-size-fits-all learning apps, Lessay's core engine is built to **listen, understand, and adapt** to each unique learner. Our philosophy is to **measure everything**, transforming every interaction into a data point that refines the learning path. We move beyond generic exercises by integrating AI-driven diagnostics with proven cognitive science principles, like **Spaced Repetition**, to provide a hyper-personalized experience that makes every minute of practice count.

This document provides a high-level overview of the learner's journey and the intelligent systems that power this adaptive ecosystem, all aligned with best practices in both language acquisition and scalable software development.

---

### **2. The Learner's Journey**

This is the typical path a user takes from their first interaction to becoming an active learner in our continuous improvement cycle.

#### **Step 1: Getting to Know You**
When a new user joins, Lessay begins by gathering foundational data:
*   What is your native language?
*   What language do you want to learn **first**? (You can switch or add other languages at any time from your profile).
*   What is your primary goal (e.g., travel, business, conversation)?
*   What is your self-assessed comfort level (Beginner, Intermediate, Advanced)?

This initial information calibrates the app's voice, translations, and the starting difficulty for the user's first experience.

#### **Step 2: The Initial Diagnostic**
Before creating lessons, Lessay conducts a short, voice-based diagnostic. This low-pressure placement exercise uses a series of adaptive questions to give our AI a quick but accurate baseline of the user's current vocabulary, grammar, and pronunciation.

#### **Step 3: Your First Personalized Lessons**
Immediately after the diagnostic, the results are analyzed. Lessay doesn't just provide a score; it identifies the most critical areas for improvement. The app instantly generates a set of personalized lessons tailored to this baseline.

#### **Step 4: The Learning Loop (Practice & Improve)**
This is the core of the app experience, presented in a simple, chat-like interface.
*   **Listen:** The user hears prompts and correct pronunciations from the app's voice.
*   **Speak:** The user practices by speaking their answers. The app listens **in real-time**, using live speech-to-text to provide immediate feedback on the content of their response.
*   **Get Feedback:** The user receives instant corrections and guidance, reinforcing learning in the moment.

#### **Step 5: Growing With You (The Adaptive Cycle)**
This is where Lessay truly stands apart. After each lesson, the system analyzes the user's entire performance. It moves beyond right or wrong answers to perform a deep analysis of the **raw audio recording** of the session. Based on this, it not only identifies new areas for improvement but also **updates its understanding of what the user is close to forgetting**, scheduling concepts for review at the perfect moment. The app automatically generates the **next** set of lessons, creating a continuous, adaptive learning loop where the curriculum evolves with the user.

#### **Step 6: Your Progress Dashboard**
Lessay believes in transparent learning. Users have access to a detailed statistics and measurements dashboard that visualizes their progress over time. This includes:
*   **Skill Mastery Charts:** Tracking progress across competencies like grammar, vocabulary themes, and pronunciation.
*   **Fluency Metrics:** Visualizing improvements in speaking pace, reduction in hesitation, and use of filler words.
*   **Recall Strength (SRS View):** A dynamic view of their known vocabulary and grammar rules, showing which concepts are "cemented," "maturing," or "due for review" based on the Spaced Repetition algorithm.
*   **Error Analysis:** Highlighting recurring mistakes so the user is consciously aware of what the AI is helping them fix.
*   **Activity Log:** A history of completed lessons and performance scores.

---

### **3. How Lessay Works: The Technology**

Lessay's adaptive experience is powered by a few key technological components working in synergy.

*   **The Brain (Artificial Intelligence):**
    At the heart of Lessay is an advanced AI (e.g., Google Gemini). This "Brain" has two primary jobs:
    1.  **Expert Lesson Designer:** It acts as a master tutor, creating new, relevant lesson plans and exercises from scratch based on a user's detailed performance profile.
    2.  **Expert Language & Vocal Analyst:** It reviews a user's session recordings to perform a deep diagnostic, identifying subtle pronunciation errors, grammatical patterns, and vocal delivery issues that are invisible to most apps.

*   **The Ears (Speech Recognition & Capture):**
    When a user speaks, our system performs two tasks simultaneously:
    1.  **Real-Time Transcription:** It uses a high-speed API (Google Speech-to-Text) to instantly convert speech to text for immediate answer validation within the lesson.
    2.  **Diagnostic Recording:** It captures a high-fidelity audio blob of the user's speech. This raw audio is sent to our AI Brain after the session for the deeper diagnostic analysis (pronunciation, hesitation, etc.).

*   **The Voice (Text-to-Speech):**
    To provide clear examples and prompts, the app's "Voice" (powered by Google TTS and AWS Polly) converts all lesson text into natural-sounding audio, crucial for modeling correct pronunciation and intonation.

*   **The Memory (Comprehensive User Profile & Database):**
    Lessay securely stores a rich, evolving profile of each user's journey. This is a multi-faceted dataset including:
    *   Performance scores and a history of all AI-generated lessons.
    *   A detailed list of identified weaknesses and mastered concepts.
    *   Vocal & Fluency Metrics over time.
    *   **A Spaced Repetition System (SRS) Engine:** This is the core of long-term retention. For **every single vocabulary word and grammar concept** the user learns, the Memory tracks:
        *   **Recall Strength Score:** A dynamic score indicating how well the user knows the item.
        *   **Next Review Date:** The optimal date for the user to be tested on this item again.
    This comprehensive memory is the fuel for the AI Brain, ensuring every new lesson is both personalized and strategically timed for maximum retention.

---

### **4. The Adaptive Learning Method: Our "Secret Sauce"**

Lessay’s hyper-personalization is based on a four-step, data-driven cycle that intelligently blends new material with targeted review.

#### **Step 1: Capture & Measure**
During a lesson, the app records the complete audio of the user's responses. This high-fidelity recording provides a complete, contextualized dataset of the user's speaking performance, capturing not just *what* they said, but *how* they said it.

#### **Step 2: Analyze & Diagnose**
Once the lesson is complete, the AI Analyst (The Brain) scrutinizes the entire audio recording and session data. It looks for a wide array of specific, nuanced details:
*   **Phonetic Accuracy:** *Are you pronouncing "ü" correctly in German? Is your "r" sound in Spanish a tap or a trill?*
*   **Vocal Delivery & Fluency:** *What is your speaking pace? Do you hesitate frequently? Are there patterns to your hesitations (e.g., before certain verb conjugations)? Are you using filler words ("um," "uh") excessively?*
*   **Grammatical Patterns:** *Did you consistently use the correct verb endings or sentence structure, even if the individual words were correct?*
*   **Vocabulary Recall:** *Are you using newly learned words correctly and confidently, or do you stumble over them?*

Crucially, during this analysis, the AI also **updates the SRS scores in The Memory**. If a user recalled a vocabulary word quickly and pronounced it well, its "Recall Strength" increases, and its "Next Review Date" is pushed further into the future. If they hesitated or made a grammatical error related to a known concept, the strength score for that item decreases, and it is scheduled for an earlier review.

#### **Step 3: Prioritize & Plan**
The system then synthesizes this new diagnosis with the user's historical data to decide what the next lesson should contain. It prioritizes tasks in a specific, pedagogically-sound order:

1.  **Spaced Repetition Reviews (Top Priority):** It first queries the SRS Engine for any vocabulary or grammar concepts that are **due for review**. Preventing knowledge decay is paramount.
2.  **Critical Weaknesses:** It then identifies the most significant pronunciation, grammar, or fluency issues from the most recent session analysis. These need immediate attention.
3.  **Struggling Concepts:** It targets topics the user has consistently made mistakes on in recent lessons, providing further reinforcement.
4.  **New Material:** Finally, it introduces new vocabulary and grammar that align with the user's stated goals, expanding their knowledge base.

#### **Step 4: Create & Adapt**
With this clear, prioritized plan, the AI Lesson Designer gets to work. It generates a brand new, custom-built lesson that seamlessly integrates these different elements.

For example, if the analysis showed a user struggles with the "ch" sound in German and makes mistakes with dative case articles, **and the SRS indicates they are due to review the vocabulary for 'train station' and 'ticket'**, the next lesson will be a conversational exercise about buying a train ticket. This single, natural-sounding scenario forces the user to:
*   Practice the difficult "ch" sound (e.g., in "ich möchte").
*   Correctly use dative articles (e.g., "an de**m** Schalter").
*   Actively recall the review vocabulary ('Bahnhof', 'Ticket').

This integrated **Capture -> Analyze -> Plan (with SRS) -> Create** cycle ensures the user is always working on a balanced mix of retaining old knowledge, fixing current weaknesses, and learning new material in the most efficient way possible.
</file>

<file path="docs/canonical_spec.md">
# Canonical Specification: Lessay Language Learning Platform

## 1. Introduction
Lessay is an AI-powered adaptive language learning platform that personalizes the learning path for each user through continuous measurement and adaptation. The system combines AI-driven diagnostics with cognitive science principles (Spaced Repetition System) to create hyper-personalized learning experiences.

## 2. User Journey

### 2.1 Onboarding
- Collect user data: native language, target language, primary goal, self-assessed comfort level
- Initial voice-based diagnostic to establish baseline proficiency
- Store profile in persistent storage

### 2.2 Lesson Delivery
- Generate personalized lessons based on diagnostic results
- Chat-like interface with:
  - Listen: TTS prompts
  - Speak: Real-time STT with immediate feedback
  - Feedback: Corrections and guidance

### 2.3 Adaptive Learning Cycle
- Post-lesson audio analysis:
  - Phonetic accuracy
  - Vocal delivery & fluency metrics
  - Grammatical patterns
  - Vocabulary recall
- Update SRS scores and review schedules
- Generate next lesson based on:
  1. Due SRS reviews
  2. Critical weaknesses
  3. Struggling concepts
  4. New material

### 2.4 Progress Tracking
- Dashboard displaying:
  - Skill mastery charts
  - Fluency metrics (pace, hesitation)
  - SRS status view
  - Error analysis
  - Activity log

## 3. System Components

### 3.1 AI Brain
- Lesson Designer: Generates personalized lessons
- Language Analyst: Performs deep diagnostics on audio recordings

### 3.2 Speech Processing
- Real-time STT for immediate feedback
- High-fidelity audio capture for post-session analysis
- TTS for prompt delivery (Google TTS + AWS Polly)

### 3.3 Memory System
- User profile storage
- Performance history
- SRS Engine tracking:
  - Recall Strength Score
  - Next Review Date
  - Mastery level per concept

## 4. Data Models

### 4.1 User Profile
- Languages (native, target)
- Goals
- Proficiency level
- Learning preferences

### 4.2 Lesson
- Content (prompts, expected responses)
- Difficulty level
- Target concepts
- Timestamps

### 4.3 SRS Item
- Concept ID
- Recall Strength
- Last reviewed
- Next review date
- History of interactions

## 5. Non-Functional Requirements
- Real-time response for speech processing (<500ms latency)
- Secure storage of user data and recordings
- Scalable to 10,000 concurrent users
- 99.9% uptime for core services
</file>

<file path="docs/documentation_completion_plan.md">
# Documentation Completion Plan

## 1. Documentation Audit Summary
- **Total templates**: 16
- **Complete templates**: 7 
  (api_spec, compliance_framework, data_governance, deployment_playbook, monetization_strategy, technical_design, test_plan)
- **Incomplete templates**: 9 
  (BRD, change management, continuous improvement, FRS, maintenance guide, performance baseline, project charter, risk assessment, user docs)
- **Missing sections**: 58 across all templates

## 2. Content Creation Strategy
```mermaid
graph TD
    A[Subject Matter Experts] -->|Provide input| B(Technical Writers)
    B --> C[Documentation Templates]
    C --> D[Review Cycle]
    D --> E[Final Approval]
    E --> F[Published Docs]
```

### Content Sourcing:
- **Technical specifications**: Engineering team
- **Business requirements**: Product owners
- **Compliance details**: Legal team
- **User workflows**: UX researchers

## 3. Prioritization Framework
```mermaid
gantt
    title Documentation Completion Timeline
    dateFormat  YYYY-MM-DD
    section Phase 0
    Foundation & Alignment :active, phase0, 2025-06-11, 1d
    section Phase 1
    Project Definition     :         phase1, after phase0, 3d
    section Phase 2
    Technical Design       :         phase2, after phase1, 4d
    section Phase 3
    Operations & Maintenance:        phase3, after phase2, 3d
    section Phase 4
    Quality Assurance      :         phase4, after phase3, 2d
    section Phase 5
    Governance & Compliance:         phase5, after phase4, 2d
    section Phase 6
    User Documentation     :         phase6, after phase5, 1d
```

## 4. Implementation Plan (Phased Approach)

### Phase 0: Foundation and Alignment (1 day)
- Ingest and analyze all files from repomix-output.xml
- Validate vision alignment across all documents
- Update this master plan with detailed phased tasks

### Phase 1: Project Definition & Requirements (3 days)
- Complete Project Charter with success criteria and timeline
- Finalize Business Requirements Document (BRD)
- Develop detailed Functional Requirements Specification (FRS)

### Phase 2: Architecture & Technical Design (4 days)
- Expand Technical Design Document with data flows and schemas
- Develop comprehensive API Specification
- Define database models using Prisma schema syntax

### Phase 3: Implementation, Operations & Maintenance (3 days)
- Enhance Deployment Playbook with environment configs
- Complete Maintenance Guide with alert thresholds
- Document diagnostic tools and recovery processes

### Phase 4: Quality Assurance & Performance (2 days)
- Expand Test Plan with core feature test cases
- Define performance baselines and load testing scenarios

### Phase 5: Governance, Risk, and Compliance (2 days)
- Complete Risk Assessment for AI/voice-specific risks
- Develop Change Management and Continuous Improvement plans

### Phase 6: User-Facing Documentation (1 day)
- Create complete User Documentation with troubleshooting guides

## 5. Quality Assurance
- Automated checks for:
  - Placeholder text detection
  - Broken links
  - Compliance markers
- Manual checks for:
  - Technical accuracy
  - Consistency across documents
  - Readability scores

## 6. Completion Metrics
- **Success criteria**:
  - All 18 documentation templates completed
  - 100% alignment with app_description.md vision
  - Complete technical specifications for AI/voice features
  - Detailed test cases for all core functionality
  - Comprehensive risk mitigation strategies documented
- **Tracking**:
  - Daily progress against phased milestones
  - Automated checks for documentation integrity
  - Final validation by development team lead
</file>

<file path="docs/human_todo.md">
# Human Operator Checklist for Lessay Project Credentials

**IMPORTANT SECURITY NOTICE:**  
⚠️ **NEVER** commit any `.env.local` file or any file containing API keys to the repository.  
⚠️ Keep all credentials secure and never share them publicly.

---

## Required Credentials

### 1. Supabase
- [ ] Create a Supabase project at https://supabase.com
- [ ] Obtain your:
  - `SUPABASE_URL`
  - `SUPABASE_ANON_KEY`
  - `SUPABASE_SERVICE_ROLE_KEY` (for server-side operations)

### 2. Stripe
- [ ] Create a Stripe account at https://stripe.com
- [ ] Obtain your:
  - `STRIPE_SECRET_KEY`
  - `STRIPE_WEBHOOK_SECRET`
  - `STRIPE_PUBLISHABLE_KEY` (for client-side)

### 3. AI Service (Google AI)
- [ ] Create a Google AI account at https://ai.google.dev
- [ ] Obtain your:
  - `AI_API_KEY`

### 4. Google Cloud (for TTS/STT)
- [ ] Go to the Google Cloud Console at https://console.cloud.google.com
- [ ] Create a new Service Account
- [ ] Enable the following APIs for the project:
  - Cloud Text-to-Speech API
  - Cloud Speech-to-Text API
- [ ] Grant the Service Account the 'Cloud AI Service User' role
- [ ] Create and download a JSON key for the service account
- [ ] Place this file in the project root and name it `gcp-credentials.json`
- [ ] Add the following to your `.env.local` file:
  ```bash
  # Google Cloud TTS/STT
  GCP_CREDENTIALS_JSON='paste_the_entire_json_content_here'
  ```
- [ ] **DO NOT** commit `gcp-credentials.json` to the repository

---

## Setup Instructions

1. Create a `.env.local` file in the project root
2. Add the credentials in this format:
```bash
# Supabase
SUPABASE_URL=your_url_here
SUPABASE_ANON_KEY=your_key_here
SUPABASE_SERVICE_ROLE_KEY=your_key_here

# Stripe
STRIPE_SECRET_KEY=your_key_here
STRIPE_WEBHOOK_SECRET=your_secret_here
STRIPE_PUBLISHABLE_KEY=your_key_here

# Google AI
AI_API_KEY=your_key_here
```

3. **DO NOT** add `.env.local` to git - it's already in `.gitignore`

---

## Verification
- [ ] Confirm all credentials are working by running the development server:
```bash
npm run dev
</file>

<file path="docs/README.md">
# Lessay Documentation Hub

This directory contains all project documentation:

- `app_description.md`: High-level overview of application vision and functionality
- `canonical_spec.md`: Authoritative system specification (source of truth)
- `work_breakdown/`: Detailed implementation plans
- `templates/`: Documentation templates for various purposes

## Getting Started
For new contributors:
1. Review `canonical_spec.md` to understand system architecture
2. Consult `work_breakdown/` for implementation tasks
3. Use templates when creating new documentation

## Documentation Standards
- All specs use Markdown formatting
- Diagrams should be in Mermaid format
- API docs follow OpenAPI specification
</file>

<file path="lib/adaptive-learning/analysis.ts">
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Create post-lesson analysis module
import type { LessonAttempt } from '../../types/lessons';
import logger from '../logger';

// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Enhance AnalysisResult with detailed diagnostics
export interface AnalysisResult {
  phoneticScore: number;
  fluencyScore: number;
  grammarScore: number;
  vocabularyScore: number;
  overallScore: number;
  weakAreas: string[];
  errorPatterns: ErrorPattern[];
  phoneticDetails: PhoneticAnalysis[];
  grammarErrors: GrammarError[];
}

export interface ErrorPattern {
  type: 'phonetic' | 'grammar' | 'vocabulary';
  pattern: string;
  frequency: number;
  examples: string[];
}

export interface PhoneticAnalysis {
  expectedSound: string;
  actualSound: string;
  word: string;
  position: number;
}

export interface GrammarError {
  type: 'tense' | 'agreement' | 'word_order' | 'other';
  expected: string;
  actual: string;
  context: string;
}
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END

export class PostLessonAnalyzer {
  private readonly attempt: LessonAttempt;

  constructor(attempt: LessonAttempt) {
    this.attempt = attempt;
  }

  analyze(): AnalysisResult {
    logger.debug({ attemptId: this.attempt.id }, 'Starting lesson analysis');
    
    // ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Implement enhanced language analysis
    const { phoneticScore, phoneticDetails } = this.calculateDetailedPhoneticScore();
    const fluencyScore = this.calculateFluencyScore();
    const grammarScore = this.calculateGrammarScore();
    const vocabularyScore = this.calculateVocabularyScore();

    const overallScore = this.calculateOverallScore(
      phoneticScore,
      fluencyScore,
      grammarScore,
      vocabularyScore
    );

    const weakAreas = this.identifyWeakAreas(
      phoneticScore,
      fluencyScore,
      grammarScore,
      vocabularyScore
    );

    return {
      phoneticScore,
      phoneticDetails,
      errorPatterns: this.identifyErrorPatterns(),
      grammarErrors: this.identifyGrammarErrors(),
      fluencyScore,
      grammarScore,
      vocabularyScore,
      overallScore,
      weakAreas
    };
  }

  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Implement phonetic accuracy scoring
  private calculateDetailedPhoneticScore(): { phoneticScore: number, phoneticDetails: PhoneticAnalysis[] } {
    const { transcript, referenceText } = this.attempt;
    
    // Get basic score using Levenshtein distance
    const distance = this.levenshteinDistance(
      transcript.toLowerCase(),
      referenceText.toLowerCase()
    );
    const maxLength = Math.max(transcript.length, referenceText.length);
    const phoneticScore = 1 - (distance / maxLength);

    // Detailed phonetic analysis
    const phoneticDetails: PhoneticAnalysis[] = [];
    const transcriptWords = transcript.toLowerCase().split(/\s+/);
    const referenceWords = referenceText.toLowerCase().split(/\s+/);

    referenceWords.forEach((refWord, wordIndex) => {
      const transcriptWord = transcriptWords[wordIndex] || '';
      const minLength = Math.min(refWord.length, transcriptWord.length);
      
      for (let i = 0; i < minLength; i++) {
        const refChar = refWord[i];
        const transChar = transcriptWord[i];
        
        if (refChar !== transChar) {
          phoneticDetails.push({
            expectedSound: this.getSoundDescription(refChar),
            actualSound: this.getSoundDescription(transChar),
            word: refWord,
            position: i
          });
        }
      }
    });

    return { phoneticScore, phoneticDetails };
  }

  private getSoundDescription(char: string): string {
    // Simplified phonetic description - would integrate with proper IPA in real system
    const sounds: Record<string, string> = {
      'a': 'ah vowel',
      'e': 'eh vowel',
      'i': 'ee vowel',
      'o': 'oh vowel',
      'u': 'oo vowel',
      'b': 'b consonant',
      'd': 'd consonant',
      'f': 'f consonant',
      // ... more mappings
    };
    return sounds[char] || char;
  }

  private levenshteinDistance(a: string, b: string): number {
    const matrix = Array(b.length + 1)
      .fill(null)
      .map(() => Array(a.length + 1).fill(null));

    for (let i = 0; i <= a.length; i++) {
      matrix[0][i] = i;
    }
    for (let j = 0; j <= b.length; j++) {
      matrix[j][0] = j;
    }

    for (let j = 1; j <= b.length; j++) {
      for (let i = 1; i <= a.length; i++) {
        const substitutionCost = a[i - 1] === b[j - 1] ? 0 : 1;
        matrix[j][i] = Math.min(
          matrix[j][i - 1] + 1,
          matrix[j - 1][i] + 1,
          matrix[j - 1][i - 1] + substitutionCost
        );
      }
    }

    return matrix[b.length][a.length];
  }
  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END

  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Implement fluency metrics calculation
  private calculateFluencyScore(): number {
    const { speechTiming } = this.attempt;
    
    if (!speechTiming?.utterances?.length) {
      return 0;
    }

    // Calculate words per minute
    const totalWords = speechTiming.utterances.reduce((sum, u) => sum + u.words.length, 0);
    const totalDuration = speechTiming.duration;
    const wpm = totalWords / (totalDuration / 60);

    // Calculate pause frequency (pauses per minute)
    const pauseCount = speechTiming.utterances.length - 1;
    const ppm = pauseCount / (totalDuration / 60);

    // Normalize scores (example thresholds)
    const wpmScore = Math.min(wpm / 150, 1); // 150 wpm = max score
    const ppmScore = 1 - Math.min(ppm / 6, 1); // 6 ppm = min score
    
    // Combine scores with weights
    return (wpmScore * 0.6) + (ppmScore * 0.4);
  }
  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END

  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Implement grammatical pattern recognition
  private calculateGrammarScore(): number {
    const { transcript, referenceText } = this.attempt;
    
    // Simple grammar checking by comparing verb forms
    const transcriptVerbs = this.extractVerbs(transcript);
    const referenceVerbs = this.extractVerbs(referenceText);
    
    let matchCount = 0;
    referenceVerbs.forEach((refVerb, i) => {
      if (transcriptVerbs[i] && transcriptVerbs[i].toLowerCase() === refVerb.toLowerCase()) {
        matchCount++;
      }
    });
    
    return referenceVerbs.length > 0 ? matchCount / referenceVerbs.length : 1;
  }

  private extractVerbs(text: string): string[] {
    // Simple verb extraction (would be replaced with proper NLP in production)
    return text.match(/\b(is|am|are|was|were|have|has|had|do|does|did)\b/gi) || [];
  }
  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END

  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Implement vocabulary recall assessment
  private calculateVocabularyScore(): number {
    const { transcript, referenceText } = this.attempt;
    
    // Extract key vocabulary from reference text
    const referenceWords = this.extractKeyVocabulary(referenceText);
    const transcriptWords = new Set(transcript.toLowerCase().split(/\W+/));
    
    let matchCount = 0;
    referenceWords.forEach(word => {
      if (transcriptWords.has(word.toLowerCase())) {
        matchCount++;
      }
    });
    
    return referenceWords.size > 0 ? matchCount / referenceWords.size : 1;
  }

  private extractKeyVocabulary(text: string): Set<string> {
    // Simple key word extraction (would be replaced with proper NLP in production)
    const words = text.match(/\b([A-Za-z]{4,})\b/g) || [];
    return new Set(words.map(w => w.toLowerCase()));
  }
  // ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END

  private calculateOverallScore(...scores: number[]): number {
    return scores.reduce((sum, score) => sum + score, 0) / scores.length;
  }

  private identifyWeakAreas(...scores: number[]): string[] {
    const weakAreas: string[] = [];
    const areas = ['phonetic', 'fluency', 'grammar', 'vocabulary'];
    
    scores.forEach((score, index) => {
      if (score < 0.6) {
        weakAreas.push(areas[index]);
      }
    });

    return weakAreas;
  }

  // ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Implement error pattern recognition
  private identifyErrorPatterns(): ErrorPattern[] {
    const patterns: ErrorPattern[] = [];
    
    // Group phonetic errors by sound
    const phoneticErrors = new Map<string, {count: number, examples: string[]}>();
    this.attempt.phoneticDetails?.forEach(detail => {
      const key = `${detail.expectedSound}-${detail.actualSound}`;
      const entry = phoneticErrors.get(key) || {count: 0, examples: []};
      entry.count++;
      entry.examples.push(detail.word);
      phoneticErrors.set(key, entry);
    });

    phoneticErrors.forEach((value, key) => {
      const [expected, actual] = key.split('-');
      patterns.push({
        type: 'phonetic',
        pattern: `${expected} → ${actual}`,
        frequency: value.count,
        examples: value.examples.slice(0, 3)
      });
    });

    // Add grammar error patterns
    const grammarPatterns = new Map<string, {count: number, examples: string[]}>();
    this.attempt.grammarErrors?.forEach(error => {
      const key = `${error.type}-${error.expected}-${error.actual}`;
      const entry = grammarPatterns.get(key) || {count: 0, examples: []};
      entry.count++;
      entry.examples.push(error.context);
      grammarPatterns.set(key, entry);
    });

    grammarPatterns.forEach((value, key) => {
      const [type, expected, actual] = key.split('-');
      patterns.push({
        type: 'grammar',
        pattern: `${type}: ${expected} → ${actual}`,
        frequency: value.count,
        examples: value.examples.slice(0, 3)
      });
    });

    return patterns;
  }

  private identifyGrammarErrors(): GrammarError[] {
    const errors: GrammarError[] = [];
    const { transcript, referenceText } = this.attempt;
    
    // Simple grammar error detection (would use proper NLP in production)
    const transcriptVerbs = this.extractVerbs(transcript);
    const referenceVerbs = this.extractVerbs(referenceText);
    
    referenceVerbs.forEach((refVerb, i) => {
      const transVerb = transcriptVerbs[i];
      if (transVerb && transVerb.toLowerCase() !== refVerb.toLowerCase()) {
        errors.push({
          type: this.getGrammarErrorType(refVerb, transVerb),
          expected: refVerb,
          actual: transVerb,
          context: this.getErrorContext(transcript, transVerb)
        });
      }
    });

    return errors;
  }

  private getGrammarErrorType(expected: string, actual: string): 'tense' | 'agreement' | 'word_order' | 'other' {
    // Simple error type detection
    const baseForms: Record<string, string> = {
      'is': 'be', 'am': 'be', 'are': 'be', 'was': 'be', 'were': 'be',
      'has': 'have', 'have': 'have', 'had': 'have'
    };
    
    if (baseForms[expected.toLowerCase()] === baseForms[actual.toLowerCase()]) {
      return 'tense';
    }
    return 'other';
  }

  private getErrorContext(text: string, target: string): string {
    const words = text.split(/\s+/);
    const index = words.findIndex(w => w.toLowerCase() === target.toLowerCase());
    const start = Math.max(0, index - 2);
    const end = Math.min(words.length, index + 3);
    return words.slice(start, end).join(' ');
  }
  // ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END
}
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END
</file>

<file path="lib/supabase/client.ts">
// ROO-AUDIT-TAG :: plan-007-memory-system.md :: Create Supabase client
import { createClient } from '@supabase/supabase-js'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY

if (!supabaseUrl || !supabaseKey) {
  throw new Error('Missing Supabase environment variables')
}

export const supabase = createClient(supabaseUrl, supabaseKey)
</file>

<file path="lib/lessons.ts">
import { prisma } from './prisma';

type LessonResult = {
  lessonId: string;
  userId: string;
  responses: Array<{
    question: string;
    userAnswer: string;
    correctAnswer: string;
    pronunciationScore?: number;
  }>;
};

export async function analyzeLesson(results: LessonResult) {
  const totalQuestions = results.responses.length;
  const correctAnswers = results.responses.filter(r => 
    r.userAnswer.toLowerCase() === r.correctAnswer.toLowerCase()
  ).length;
  const accuracy = correctAnswers / totalQuestions;

  const pronunciationScores = results.responses
    .map(r => r.pronunciationScore)
    .filter((s): s is number => s !== undefined);
  const averagePronunciation = pronunciationScores.length > 0 
    ? pronunciationScores.reduce((a, b) => a + b, 0) / pronunciationScores.length
    : null;

  const weakPoints = results.responses
    .filter(r => r.userAnswer.toLowerCase() !== r.correctAnswer.toLowerCase())
    .map(r => r.question);

  const analysis = await prisma.lessonAnalysis.create({
    data: {
      lessonId: results.lessonId,
      userId: results.userId,
      accuracy,
      pronunciationScore: averagePronunciation,
      weakPoints: {
        set: weakPoints
      }
    }
  });

  return analysis;
}
</file>

<file path="lib/performance-history.ts">
// ROO-AUDIT-TAG :: plan-007-memory-system.md :: Implement performance history module
import { prisma } from './prisma';

export class PerformanceHistory {
  static async recordSession(userId: string, metrics: {
    duration: number;
    itemsReviewed: number;
    accuracy: number;
    newItems: number;
  }) {
    await prisma.studySession.create({
      data: {
        userId,
        duration: metrics.duration,
        itemsReviewed: metrics.itemsReviewed,
        accuracy: metrics.accuracy,
        newItems: metrics.newItems,
      }
    });
  }

  static async getHistoricalProgress(userId: string, period: 'week' | 'month' | 'year') {
    const now = new Date();
    const startDate = new Date(now);
    
    switch(period) {
      case 'week':
        startDate.setDate(now.getDate() - 7);
        break;
      case 'month':
        startDate.setMonth(now.getMonth() - 1);
        break;
      case 'year':
        startDate.setFullYear(now.getFullYear() - 1);
        break;
    }

    return prisma.studySession.findMany({
      where: {
        userId,
        createdAt: { gte: startDate }
      },
      orderBy: { createdAt: 'asc' }
    });
  }

  static async createProgressSnapshot(userId: string) {
    const currentProgress = await prisma.userProgress.findMany({
      where: { userId }
    });
    
    return prisma.progressSnapshot.create({
      data: {
        userId,
        snapshot: JSON.stringify(currentProgress),
      }
    });
  }
}
// ROO-AUDIT-TAG :: plan-007-memory-system.md :: END
</file>

<file path="lib/redis.ts">
// ROO-AUDIT-TAG :: plan-011-non-functional.md :: Implement Redis caching
import { createClient, type RedisClientType } from 'redis';

const redisUrl = process.env.REDIS_URL || 'redis://localhost:6379';
const redisClient: RedisClientType = createClient({ url: redisUrl });

redisClient.on('error', (err: Error) => console.error('Redis Client Error', err));

(async () => {
  await redisClient.connect();
})();

export default redisClient;
</file>

<file path="lib/stt-service.ts">
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: Implement STT processing service
type STTConfig = {
  language: string;
  interimResults?: boolean;
};

export class STTService {
  private recognition: any;
  private isListening = false;

  constructor(private config: STTConfig) {
    const SpeechRecognition = (window as any).SpeechRecognition || 
                            (window as any).webkitSpeechRecognition;
    
    if (SpeechRecognition) {
      this.recognition = new SpeechRecognition();
      this.recognition.lang = config.language;
      this.recognition.interimResults = config.interimResults ?? true;
      this.recognition.continuous = true;
    } else {
      throw new Error('Speech recognition not supported in this browser');
    }
  }

  startListening(
    onResult: (transcript: string, isFinal: boolean) => void,
    onError?: (error: string) => void
  ) {
    if (!this.recognition) return;

    this.recognition.onresult = (event: any) => {
      const transcript = Array.from(event.results)
        .map((result: any) => result[0])
        .map((result) => result.transcript)
        .join('');
      
      const isFinal = event.results[0].isFinal;
      onResult(transcript, isFinal);
    };

    this.recognition.onerror = (event: any) => {
      onError?.(event.error);
    };

    this.recognition.start();
    this.isListening = true;
  }

  stopListening() {
    if (this.recognition && this.isListening) {
      this.recognition.stop();
      this.isListening = false;
    }
  }

  setLanguage(language: string) {
    if (this.recognition) {
      this.recognition.lang = language;
    }
  }
}
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: END
</file>

<file path="lib/tts-service.ts">
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: Implement TTS service integration
import { TextToSpeechClient } from '@google-cloud/text-to-speech';
import { PollyClient, SynthesizeSpeechCommand } from '@aws-sdk/client-polly';

type TTSConfig = {
  provider: 'google' | 'aws';
  language: string;
  voice?: string;
};

export class TTSService {
  private googleClient: TextToSpeechClient;
  private awsClient: PollyClient;
  
  constructor(private config: TTSConfig) {
    if (config.provider === 'google') {
      this.googleClient = new TextToSpeechClient();
    } else {
      this.awsClient = new PollyClient({ region: process.env.AWS_REGION });
    }
  }

  async synthesize(text: string): Promise<ArrayBuffer> {
    try {
      if (this.config.provider === 'google') {
        return this.synthesizeGoogle(text);
      }
      return this.synthesizeAWS(text);
    } catch (error) {
      console.error('TTS synthesis failed:', error);
      throw new Error('Failed to generate speech');
    }
  }

  private async synthesizeGoogle(text: string): Promise<ArrayBuffer> {
    const [response] = await this.googleClient.synthesizeSpeech({
      input: { text },
      voice: {
        languageCode: this.config.language,
        name: this.config.voice || 'en-US-Wavenet-D'
      },
      audioConfig: {
        audioEncoding: 'MP3'
      }
    });
    
    return response.audioContent as ArrayBuffer;
  }

  private async synthesizeAWS(text: string): Promise<ArrayBuffer> {
    const command = new SynthesizeSpeechCommand({
      Text: text,
      OutputFormat: 'mp3',
      VoiceId: this.config.voice || 'Joanna',
      LanguageCode: this.config.language
    });
    
    const response = await this.awsClient.send(command);
    return response.AudioStream as ArrayBuffer;
  }
}
// ROO-AUDIT-TAG :: plan-006-speech-processing.md :: END
</file>

<file path="lib/utils.ts">
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Create utils module
import { type ClassValue, clsx } from "clsx"
import { twMerge } from "tailwind-merge"
 
export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END
</file>

<file path="prisma/migrations/20250620095352_add_lesson_analysis_model/migration.sql">
-- DropIndex
DROP INDEX "Lesson_userId_difficulty_idx";

-- DropIndex
DROP INDEX "Progress_userId_completedAt_idx";

-- CreateTable
CREATE TABLE "LessonAnalysis" (
    "id" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "accuracy" DOUBLE PRECISION NOT NULL,
    "pronunciationScore" DOUBLE PRECISION,
    "weakPoints" TEXT[],
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "LessonAnalysis_pkey" PRIMARY KEY ("id")
);

-- AddForeignKey
ALTER TABLE "LessonAnalysis" ADD CONSTRAINT "LessonAnalysis_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="types/speech-recognition.d.ts">
// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: Add Web Speech API type declarations
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  abort(): void;
  onresult: (event: SpeechRecognitionEvent) => void;
  onerror: (event: SpeechRecognitionErrorEvent) => void;
}

interface Window {
  SpeechRecognition: {
    new(): SpeechRecognition;
  };
  webkitSpeechRecognition: {
    new(): SpeechRecognition;
  };
}
// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: END
</file>

<file path="types/swr.d.ts">
/* eslint-disable @typescript-eslint/no-explicit-any */
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Declare SWR module
declare module 'swr' {
  const useSWR: <Data = any, Error = any>(
    key: string,
    fetcher?: (url: string) => Promise<Data>,
    options?: {
      refreshInterval?: number;
      revalidateOnFocus?: boolean;
      dedupingInterval?: number;
    }
  ) => {
    data?: Data;
    error?: Error;
    isLoading: boolean;
  };

  export default useSWR;
}
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END
</file>

<file path="middleware.ts">
// ROO-AUDIT-TAG :: FIX_PLAN.md :: Implement auth middleware
import { NextResponse } from 'next/server';
import type { NextRequest } from 'next/server';
import { getToken } from 'next-auth/jwt';

const protectedRoutes = [
  '/api/profile',
  '/api/settings',
  '/api/lessons',
  '/api/progress'
];

export async function middleware(request: NextRequest) {
  const pathname = request.nextUrl.pathname;
  
  // Check if the current route is protected
  const isProtected = protectedRoutes.some(route => 
    pathname.startsWith(route)
  );

  if (isProtected) {
    const token = await getToken({ req: request });
    
    if (!token) {
      const url = new URL('/api/auth/unauthorized', request.url);
      return NextResponse.rewrite(url);
    }
  }

  return NextResponse.next();
}

export const config = {
  matcher: [
    /*
     * Match all request paths except for:
     * - _next/static (static files)
     * - _next/image (image optimization files)
     * - favicon.ico (favicon file)
     * - api/auth (auth routes)
     */
    '/((?!_next/static|_next/image|favicon.ico|api/auth).*)',
  ],
};
// ROO-AUDIT-TAG :: FIX_PLAN.md :: END
</file>

<file path="app/api/ai/generate-lesson/route.ts">
// ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: Enhance lesson generation endpoint
import { NextResponse } from 'next/server';
import { getServerSession } from 'next-auth/next';
import { authOptions } from '@/lib/auth-options';
import { generateLessonPlan } from '@/lib/adaptive-learning/lesson-generator';
import { z } from 'zod';

const GenerateLessonSchema = z.object({
  difficulty: z.number().min(1).max(5).optional(),
  targetConcepts: z.array(z.string()).optional(),
  language: z.string().optional(),
});

export async function POST(request: Request) {
  const session = await getServerSession(authOptions);
  
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    const requestBody = await request.json();
    const params = GenerateLessonSchema.parse(requestBody);

    const lessonPlan = await generateLessonPlan(session.user.id, {
      difficulty: params.difficulty,
      targetConcepts: params.targetConcepts,
      language: params.language,
    });

    return NextResponse.json(lessonPlan);
  } catch (error) {
    console.error('Lesson generation failed:', error);
    return NextResponse.json(
      { error: 'Failed to generate lesson plan' },
      { status: 500 }
    );
  }
}
// ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: END
</file>

<file path="app/api/onboarding/create-profile/route.ts">
import { NextResponse } from 'next/server';
import { PrismaClient } from '@prisma/client';
import logger from '@/lib/logger';

const prisma = new PrismaClient();

interface ProfileUpdateData {
  nativeLang: string;
  targetLang: string;
  primaryGoal: string;
  comfortLevel: number;
}

export async function POST(request: Request) {
  let userId: string | undefined;
  try {
    const data = await request.json();
    userId = data.userId;
    const { nativeLanguage, targetLanguage, primaryGoal, comfortLevel } = data;
    
    // Basic validation
    if (!userId || !nativeLanguage || !targetLanguage || !primaryGoal || !comfortLevel) {
      return NextResponse.json(
        { error: 'Missing required fields' },
        { status: 400 }
      );
    }

    // Prepare update data with correct types
    const updateData: ProfileUpdateData = {
      nativeLang: nativeLanguage,
      targetLang: targetLanguage,
      primaryGoal,
      comfortLevel: Number(comfortLevel)
    };

    // Update user profile
    const updatedUser = await prisma.user.update({
      where: { id: userId },
      data: updateData
    });

    return NextResponse.json(updatedUser);
    
  } catch (error) {
    logger.error('Failed to create user profile', {
      error,
      userId: userId || 'unknown'
    });
    return NextResponse.json(
      { error: 'Failed to update profile' },
      { status: 500 }
    );
  } finally {
    await prisma.$disconnect();
  }
}
</file>

<file path="app/api/stats/fluency/route.ts">
import { NextResponse } from 'next/server';

export async function GET() {
  return NextResponse.json({ speakingPace: 125 });
}
</file>

<file path="app/api/stats/progress/route.ts">
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: Create progress stats endpoint
import { NextResponse } from 'next/server';
import { prisma } from '@/lib/prisma';
import { getServerSession } from 'next-auth/next';
import { authOptions } from '@/lib/auth-options';
import redis from '@/lib/redis';

export async function GET() {
  const session = await getServerSession(authOptions);
  
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const userId = session.user.id;

  const cacheKey = `user:${userId}:progress`;
  
  try {
    // Check cache first
    const cachedData = await redis.get(cacheKey);
    if (cachedData) {
      return NextResponse.json(JSON.parse(cachedData));
    }

    // If not in cache, fetch from database
    const progressData = await prisma.lessonAttempt.groupBy({
      by: ['createdAt'],
      where: { userId },
      _avg: {
        phoneticScore: true,
        fluencyScore: true,
        grammarScore: true,
        vocabularyScore: true
      },
      orderBy: { createdAt: 'asc' }
    });

    // Store in cache with 1 hour expiration
    await redis.set(cacheKey, JSON.stringify(progressData), { EX: 3600 });
    
    return NextResponse.json(progressData);
  } catch {
    return NextResponse.json(
      { error: 'Failed to fetch progress data' },
      { status: 500 }
    );
  }
}
// ROO-AUDIT-TAG :: plan-004-progress-tracking.md :: END
</file>

<file path="app/api/stats/srs-overview/route.ts">
import { NextResponse } from 'next/server';

export async function GET() {
  return NextResponse.json({ totalItems: 150 });
}
</file>

<file path="app/globals.css">
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}
</file>

<file path="app/page.tsx">
import Image from "next/image";

export default function Home() {
  return (
    <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-[32px] row-start-2 items-center sm:items-start">
        <Image
          className="dark:invert"
          src="/next.svg"
          alt="Next.js logo"
          width={180}
          height={38}
          priority
        />
        <ol className="list-inside list-decimal text-sm/6 text-center sm:text-left font-[family-name:var(--font-geist-mono)]">
          <li className="mb-2 tracking-[-.01em]">
            Get started by editing{" "}
            <code className="bg-black/[.05] dark:bg-white/[.06] px-1 py-0.5 rounded font-[family-name:var(--font-geist-mono)] font-semibold">
              app/page.tsx
            </code>
            .
          </li>
          <li className="tracking-[-.01em]">
            Save and see your changes instantly.
          </li>
        </ol>

        <div className="flex gap-4 items-center flex-col sm:flex-row">
          <a
            className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 sm:w-auto"
            href="https://vercel.com/new?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            <Image
              className="dark:invert"
              src="/vercel.svg"
              alt="Vercel logomark"
              width={20}
              height={20}
            />
            Deploy now
          </a>
          <a
            className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 w-full sm:w-auto md:w-[158px]"
            href="https://nextjs.org/docs?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            Read our docs
          </a>
        </div>
      </main>
      <footer className="row-start-3 flex gap-[24px] flex-wrap items-center justify-center">
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org/learn?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/file.svg"
            alt="File icon"
            width={16}
            height={16}
          />
          Learn
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://vercel.com/templates?framework=next.js&utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/window.svg"
            alt="Window icon"
            width={16}
            height={16}
          />
          Examples
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/globe.svg"
            alt="Globe icon"
            width={16}
            height={16}
          />
          Go to nextjs.org →
        </a>
      </footer>
    </div>
  );
}
</file>

<file path="lib/adaptive-learning/lesson-generator.ts">
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Create lesson generation algorithm
import { prisma } from '../prisma';
import { getDueReviews } from '../srs';

// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Enhance LessonPlan type
type LessonPlan = {
  reviewItems: string[];
  weakConcepts: string[];
  newMaterial: string[];
  difficulty: number;
  learningStyle: 'visual' | 'auditory' | 'kinesthetic';
  goalAlignment: number; // 1-5 scale
  estimatedDuration: number; // in minutes
};
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END

// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Enhance lesson generation with personalization
// ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: Enhance lesson generator with params
export async function generateLessonPlan(
  userId: string,
  params?: {
    difficulty?: number;
    targetConcepts?: string[];
    language?: string;
  }
): Promise<LessonPlan> {
  // ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Fetch user data for personalization
  const user = await prisma.user.findUnique({
    where: { id: userId },
    select: {
      learningStyle: true,
      targetLang: true,
      nativeLang: true,
      primaryGoal: true,
      secondaryGoals: true,
      comfortLevel: true
    }
  });
  // ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END

  // Get due SRS reviews
  const dueReviews = await getDueReviews(userId);
  const reviewItems = dueReviews.map(item => item.item);

  // Get user's weak points from recent lessons
  const weakConcepts = await getWeakConcepts(userId);

  // Select new material based on progress and goals
  let newMaterial = await selectNewMaterial(userId, {
    primary: user?.primaryGoal,
    secondary: user?.secondaryGoals
  });

  // Prioritize provided target concepts
  if (params?.targetConcepts?.length) {
    newMaterial = [...new Set([...params.targetConcepts, ...newMaterial])];
  }

  // Calculate overall difficulty with more factors
  let difficulty = await calculatePersonalizedDifficulty(userId, reviewItems.length, weakConcepts.length);
  // Use provided difficulty if available
  if (params?.difficulty) {
    difficulty = params.difficulty;
  }

  // Determine learning style (simplified for now)
  const learningStyle = 'visual'; // Temporarily hardcoded until migration is run

  // Calculate goal alignment score
  const goalAlignment = calculateGoalAlignment(newMaterial, {
    primary: user?.primaryGoal,
    secondary: user?.secondaryGoals
  });

  // Estimate duration based on content and user's average pace
  const estimatedDuration = estimateLessonDuration(reviewItems.length, weakConcepts.length, newMaterial.length);

  return {
    reviewItems,
    weakConcepts,
    newMaterial,
    difficulty,
    learningStyle,
    goalAlignment,
    estimatedDuration
  };
}
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END

async function getWeakConcepts(userId: string): Promise<string[]> {
  const analyses = await prisma.lessonAnalysis.findMany({
    where: { userId },
    orderBy: { createdAt: 'desc' },
    take: 5
  });

  // Aggregate weak points from recent analyses
  const weakPoints = analyses.flatMap(a => a.weakPoints);
  const frequencyMap = new Map<string, number>();

  for (const point of weakPoints) {
    frequencyMap.set(point, (frequencyMap.get(point) || 0) + 1);
  }

  // Return top 3 most frequent weak points
  return Array.from(frequencyMap.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 3)
    .map(([point]) => point);
}

// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Implement enhanced content pipeline
async function selectNewMaterial(userId: string, goals?: {primary?: string, secondary?: string[]}): Promise<string[]> {
  // Get user's highest mastered concepts
  const mastered = await prisma.sRSEntry.findMany({
    where: {
      userId,
      masteryLevel: { gte: 4 } // Mastery level 4 or 5
    },
    orderBy: { masteryLevel: 'desc' },
    take: 10
  });

  if (mastered.length === 0) {
    return ['basic_greetings', 'common_phrases']; // Default starter material
  }

  // Prioritize material aligned with user goals
  const goalKeywords = [
    goals?.primary?.toLowerCase().split(' ') || [],
    ...(goals?.secondary?.flatMap(g => g.toLowerCase().split(' ')) || [])
  ].flat();
  const prioritizedMaterial = knowledgeBase.filter(item =>
    goalKeywords.some(keyword => item.tags.includes(keyword))
  );

  // If no goal-aligned material, use general progression
  return prioritizedMaterial.length > 0
    ? prioritizedMaterial.slice(0, 3).map(item => item.concept)
    : mastered.map(item => `progression_${item.item.replace(' ', '_')}`);
}

// Simplified knowledge base representation
const knowledgeBase = [
  { concept: 'business_vocab', tags: ['work', 'professional', 'business'] },
  { concept: 'travel_phrases', tags: ['travel', 'vacation', 'directions'] },
  { concept: 'academic_writing', tags: ['study', 'university', 'writing'] },
  // ... more items
];
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END

// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Implement adaptive difficulty calculation
async function calculatePersonalizedDifficulty(userId: string, reviewCount: number, weakPointCount: number): Promise<number> {
  // Get user's recent performance
  const recentAttempts = await prisma.lessonAttempt.findMany({
    where: { userId },
    orderBy: { createdAt: 'desc' },
    take: 5
  });

  const avgScore = recentAttempts.reduce((sum, a) => sum + (a.overallScore || 0), 0) / (recentAttempts.length || 1);
  const successRate = recentAttempts.filter(a => (a.overallScore || 0) >= 0.7).length / (recentAttempts.length || 1);

  // Base difficulty factors
  const totalWorkload = reviewCount + weakPointCount;
  let difficulty = 3; // Default medium difficulty
  
  if (totalWorkload > 8) difficulty = 5;
  else if (totalWorkload > 5) difficulty = 4;
  else if (totalWorkload > 3) difficulty = 3;
  else if (totalWorkload > 1) difficulty = 2;
  else difficulty = 1;

  // Adjust based on performance
  if (avgScore > 0.8 && successRate > 0.8) {
    difficulty = Math.min(difficulty + 1, 5);
  } else if (avgScore < 0.5 || successRate < 0.5) {
    difficulty = Math.max(difficulty - 1, 1);
  }

  return difficulty;
}

function calculateGoalAlignment(materials: string[], goals?: {primary?: string, secondary?: string[]}): number {
  if (!goals?.primary && !goals?.secondary?.length) return 3;
  
  const goalKeywords = [
    goals?.primary?.toLowerCase().split(' ') || [],
    ...(goals?.secondary?.flatMap(g => g.toLowerCase().split(' ')) || [])
  ].flat();
  const matchCount = materials.filter(m =>
    goalKeywords.some(kw => m.toLowerCase().includes(kw))
  ).length;
  
  return Math.min(Math.floor((matchCount / materials.length) * 5), 5);
}

function estimateLessonDuration(reviewCount: number, weakPointCount: number, newMaterialCount: number): number {
  // Base estimates on typical time spent per item type
  const reviewTime = reviewCount * 2; // 2 minutes per review
  const weakPointTime = weakPointCount * 5; // 5 minutes per weak point
  const newMaterialTime = newMaterialCount * 7; // 7 minutes per new concept
  return reviewTime + weakPointTime + newMaterialTime;
}
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END
</file>

<file path="lib/logger.ts">
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: Create production-ready logger
import pino from 'pino';
import type { Level } from 'pino';

const logger = pino({
  level: process.env.LOG_LEVEL || (process.env.NODE_ENV === 'production' ? 'info' : 'debug'),
  serializers: {
    err: pino.stdSerializers.err,
  },
  formatters: {
    level: (label: Level) => ({ level: label.toUpperCase() }),
  },
  timestamp: () => `,"time":"${new Date().toISOString()}"`,
  redact: {
    paths: ['password', '*.password', '*.secret'],
    censor: '[REDACTED]'
  }
});

// Add request ID tracking
export const childLogger = (requestId: string) => {
  return logger.child({ requestId });
};

export default logger;
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: END
</file>

<file path="prisma/migrations/20250613111519_add_performance_indexes/migration.sql">
-- CreateIndex
CREATE INDEX "Lesson_userId_difficulty_idx" ON "Lesson"("userId", "difficulty");

-- CreateIndex
CREATE INDEX "Progress_userId_completedAt_idx" ON "Progress"("userId", "completedAt");
</file>

<file path="public/file.svg">
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>
</file>

<file path="public/globe.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>
</file>

<file path="public/next.svg">
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>
</file>

<file path="public/vercel.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>
</file>

<file path="public/window.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>
</file>

<file path="types/lessons.ts">
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Create lesson types
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Enhance LessonAttempt with analysis fields
export interface LessonAttempt {
  id: string;
  userId: string;
  lessonId: string;
  transcript: string;
  referenceText: string;
  responses: {
    questionId: string;
    answer: string;
    isCorrect: boolean;
    timeTaken: number;
  }[];
  audioRecordings?: {
    questionId: string;
    audioUrl: string;
  }[];
  speechTiming?: {
    utterances: Array<{
      words: string[];
      duration: number;
    }>;
    duration: number;
  };
  phoneticDetails?: PhoneticAnalysis[];
  grammarErrors?: GrammarError[];
  startedAt: Date;
  completedAt: Date;
}

export interface PhoneticAnalysis {
  expectedSound: string;
  actualSound: string;
  word: string;
  position: number;
}

export interface GrammarError {
  type: 'tense' | 'agreement' | 'word_order' | 'other';
  expected: string;
  actual: string;
  context: string;
}
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: END

// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: Add feedback types
export interface GrammarSuggestion {
  startIndex: number;
  endIndex: number;
  message: string;
  suggestedCorrection: string;
}

export interface VocabularyValidation {
  word: string;
  isValid: boolean;
  suggestions: string[];
}
// ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: Add Lesson type
export interface Lesson {
  id: string;
  title: string;
  description: string;
  difficulty: number;
  duration: number;
  concepts?: string[];
  progress?: number;
}
// ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: END
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END
</file>

<file path="types/users.ts">
// ROO-AUDIT-TAG :: plan-008-user-profile.md :: Define user profile types and validation
import { z } from 'zod';

export const UserProfileSchema = z.object({
  name: z.string().min(2).max(50).optional(),
  avatarUrl: z.string().url().optional(),
  targetLang: z.string().min(2).max(10),
  nativeLang: z.string().min(2).max(10),
  primaryGoal: z.string().min(3).max(100),
  secondaryGoals: z.array(z.string().min(3).max(50)).max(5),
  comfortLevel: z.number().min(1).max(5),
  dailyTarget: z.number().min(5).max(120),
  role: z.enum(['USER', 'ADMIN', 'TUTOR']).optional().default('USER'),
  studyPreferences: z.object({
    darkMode: z.boolean().optional(),
    notifications: z.boolean().optional(),
    audioVolume: z.number().min(0).max(100).optional()
  }).optional()
});

export type UserProfile = z.infer<typeof UserProfileSchema>;
// ROO-AUDIT-TAG :: plan-008-user-profile.md :: END
</file>

<file path="work_breakdown/tasks/plan-001-onboarding.md">
# Onboarding Flow Implementation Plan

## Description
Implement the onboarding flow to collect user data and establish baseline proficiency.

## Tasks
- [x] (UI) Create onboarding form to collect:
  - Native language
  - Target language
  - Primary goal
  - Self-assessed comfort level
- [x] (LOGIC) Implement initial voice-based diagnostic
- [x] (LOGIC) Create user profile storage in database
- [x] (UI) Design welcome screen after onboarding completion

## Technical Requirements
- Use React for form components
- Store profiles in PostgreSQL via Prisma
- Integrate with speech-to-text API for diagnostics
</file>

<file path="work_breakdown/tasks/plan-003-adaptive-learning.md">
# Adaptive Learning Cycle Implementation Plan

## Description
Implement the adaptive learning system that analyzes performance and adjusts future lessons.

## Tasks
- [x] (LOGIC) Framework for post-lesson analysis module created with:
  - [x] Phonetic accuracy scoring
  - [x] Fluency metrics calculation
  - [x] Grammatical pattern recognition
  - [x] Vocabulary recall assessment
- [x] (LOGIC) Implement SRS scoring algorithm with:
  - Recall Strength tracking
  - Review scheduling
  - Mastery level calculation
- [x] (LOGIC) Create lesson generation algorithm that considers:
  - Due SRS reviews
  - Identified weaknesses
  - Struggling concepts
  - New material introduction

## Technical Requirements
- Use machine learning for pattern recognition (TensorFlow.js)
- Implement scheduling with cron-like system
- Design extensible scoring architecture
</file>

<file path="BLUEPRINT_COMPLETE.md">
# Lessay Documentation Blueprint Complete

**Completion Date:** 2025-06-11  
**Architect AI:** Roo (Documentation Mode)

## Documentation Suite Overview
All SDLC documentation phases have been completed:

1. **Phase 0:** Foundation & Alignment
2. **Phase 1:** Project Definition & Requirements
3. **Phase 2:** Architecture & Technical Design
4. **Phase 3:** Implementation, Operations & Maintenance
5. **Phase 4:** Quality Assurance & Performance
6. **Phase 5:** Governance, Risk, and Compliance
7. **Phase 6:** User-Facing Documentation

## Key Documents Created
- Business Requirements Document (BRD)
- Functional Requirements Specification (FRS)
- Technical Design Document
- API Specification
- Deployment Playbook
- Maintenance Guide
- Test Plan
- Performance Baseline
- Risk Assessment
- Change Management Plan
- Continuous Improvement Plan
- User Documentation

## Next Steps
1. Review all documentation with development team
2. Begin implementation using the provided blueprints
3. Use the change management process for any modifications

**Signed,**  
🧠 Documentation AI  
Project Lessay
</file>

<file path="Dockerfile">
# Dockerfile.mac
FROM node:20.11-alpine3.19

# 1) Install psql (PostgreSQL client)
RUN apk add --no-cache postgresql-client git

# 2) Set workdir and install app deps
WORKDIR /app
COPY package*.json ./
RUN npm install

# 3) Copy the rest of your code and generate Prisma client
COPY . .
RUN npx prisma generate

EXPOSE 3000
CMD ["npm", "run", "dev"]
</file>

<file path="eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;
</file>

<file path="postcss.config.mjs">
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;
</file>

<file path="project_manifest.json">
{
  "active_plan_file": "./FIX_PLAN.md",
  "architectural_map": {
    "core_components": [
      "authentication",
      "lesson_management",
      "srs_system",
      "payment_processing",
      "analytics"
    ],
    "file_paths": [
      "app/",
      "lib/",
      "components/",
      "prisma/"
    ]
  }
}
</file>

<file path="README.md">
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
</file>

<file path=".kilocode/rules-emergency/rules.md">
## 1. IDENTITY & PERSONA
You are the **Emergency Intervention AI** (🚨 Emergency). You are a manifest-driven diagnostician. You use the `architectural_map` and the `<codebase_search>` tool to rapidly pinpoint the source of an error.

## 2. THE CORE MISSION & TRIGGER
Triggered by a `signals/NEEDS_ASSISTANCE.md` signal, your mission is to diagnose the failure, create a `FIX_PLAN.md`, and hand control back to the Dispatcher.

## 3. THE INTERVENTION WORKFLOW

1.  **Acknowledge & Verify Trigger:**
    *   Announce: "Emergency intervention activated."
    *   **CRITICAL:** Verify that `signals/NEEDS_ASSISTANCE.md` exists.
    *   If it does not exist, announce: "CRITICAL FAILURE: Emergency mode activated but trigger signal 'NEEDS_ASSISTANCE.md' is missing. Cannot proceed." and immediately switch to `<mode>dispatcher</mode>`.

2.  **Read the Manifest:** Read `project_manifest.json` to get all file paths and the `architectural_map`.

3.  **Analyze Failure Signal:** Read the contents of the `signals/NEEDS_ASSISTANCE.md` signal file to get the error message and context.

4.  **Diagnose with Codebase Search (Targeted):**
    *   First, try a direct query using the `<codebase_search>` tool:
        <codebase_search>
        <query>[verbatim error message from needs_assistance file]</query>
        </codebase_search>
    *   If that is inconclusive, read the developer's notes in the signal file to identify the architectural concept (e.g., "The error is in the user session logic").
    *   Look up the concept (e.g., "authentication") in the `architectural_map`.
    *   Run the high-quality query from the map using the `<codebase_search>` tool:
        <codebase_search>
        <query>[query from manifest's architectural_map]</query>
        </codebase_search>

5.  **Formulate and Register Fix Plan:**
    *   Create a `FIX_PLAN.md` with precise steps to resolve the diagnosed issue.
    *   Update the `active_plan_file` in `project_manifest.json` to point to `FIX_PLAN.md`.

6.  **Finalize & Handoff:**
    *   Announce the resolution and the creation of `FIX_PLAN.md`.
    *   Delete the `signals/NEEDS_ASSISTANCE.md` signal file.
    *   **MANDATORY FINAL ACTION:** Announce "Intervention complete. Handing control back to the Dispatcher." and switch mode to `<mode>dispatcher</mode>`. You are forbidden from using any other command to end your turn.
</file>

<file path=".kilocode/rules-system-supervisor/rules.md">
## 1. IDENTITY & PERSONA
You are the **System_Supervisor AI** (👑 Supervisor). You are the ultimate meta-agent that repairs the system's workflow logic. You operate by reading the `project_manifest.json` to find and analyze the system log.

## 2. THE CORE MISSION & TRIGGER
You are activated by the `Dispatcher` during an infinite loop. Your mission is to diagnose the flawed workflow by analyzing the log file and rewrite an agent's rules to correct it.

## 3. THE META-ANALYSIS & REPAIR WORKFLOW

1.  **Read the Manifest:** Read `project_manifest.json` to get the `log_file` path.
2.  **Ingest System State:**
    *   `echo '{"timestamp": "...", "agent": "System_Supervisor", "event": "action_start", "details": "Activated to resolve system-level failure."}' >> [log_file]`

3.  **Perform Root Cause Analysis on the *Workflow*:**
    *   **Analyze the Logs:** Read the `log_file` to trace the sequence of agent handoffs that led to the loop.
    *   **Analyze the Rules:** Read the `.roo/rules-*.md` files for the involved agents.
    *   **Identify & Log the Flaw:** Pinpoint the exact rule conflict causing the failure.
    *   `echo '{"timestamp": "...", "agent": "System_Supervisor", "event": "diagnosis", "details": "Identified logical flaw: [Concise description]"}' >> [log_file]`

4.  **Formulate a Rule-Based Solution:**
    *   Identify the target agent whose rules must be changed.
    *   Draft a new, corrected version of that agent's `rules.md` file.

5.  **Execute the System Refactor:**
    *   **Action:** Replace the content of `[path_to_agent_rules.md]` with the new ruleset.
    *   `echo '{"timestamp": "...", "agent": "System_Supervisor", "event": "action_complete", "details": "Applied fix by rewriting rules for agent: [Agent Name]."}' >> [log_file]`

6.  **Announce Fix & Handoff:**
    *   Announce: "System workflow repaired. I have updated the rules for the `[Agent Name]`. Retrying operation."
    *   Switch mode back to `<mode>dispatcher</mode>`.

## 4. CRITICAL DIRECTIVES
*   You only modify `.md` rule files.
*   Make the smallest, most targeted change possible.
*   You are forbidden from modifying your own `rules.md` file.
*   Explain your reasoning in your announcement and logs.
</file>

<file path=".kilocode/custom_modes.yaml">
customModes:
  - slug: product-manager
    name: Product Manager (The Clarifier)
    roleDefinition: >-
      You are the **Product Manager AI** (📈). Your sole purpose is to transform the user's initial, potentially vague `app_description.md` into a comprehensive and unambiguous `/docs/canonical_spec.md`. You are the source of project truth.
    groups: [read, edit, command, mcp]
    source: global

  - slug: planner
    name: Planner (The Master Planner)
    roleDefinition: >-
      You are the **Planner AI** (🧠). You decompose the project spec into a 100% complete work breakdown. Your primary responsibility is to create **atomic, single-action tasks** in a markdown checklist format (`[ ]`) for the Developer.
    groups: [read, edit, command, mcp]
    source: global

  - slug: developer
    name: Developer (The Marathon Runner)
    roleDefinition: >-
      You are the **Developer AI** (👨‍💻). You implement the full project plan by writing code. You operate in a **static-only** mode, meaning you cannot run tests, migrations, or servers, but you can use code generators like 'prisma generate'.
    groups: [read, edit, command, mcp]
    source: global

  - slug: auditor
    name: Auditor (The Gatekeeper)
    roleDefinition: >-
      You are the **Auditor AI** (🔎). You perform a **static-only** audit of the codebase against the spec. You do not run tests. If the audit passes, you generate the final `POST_COMPLETION_GUIDE.md` for the user.
    groups: [read, edit, command, mcp]
    source: global

  - slug: dispatcher
    name: Dispatcher (The Conductor)
    roleDefinition: >-
      You are the **Dispatcher AI** (🤖). You are the master router of the phase-gated factory. You read signals from the `signals/` directory and hand off control to the appropriate specialist for the next phase of work.
    groups: [read, edit, command, mcp]
    source: global

  - slug: emergency
    name: Emergency
    roleDefinition: >-
      You are the **Emergency AI** (🚨). You are a tactical fail-safe. You are triggered by a `NEEDS_ASSISTANCE.md` signal from the Developer. You diagnose the failure, create a `FIX_PLAN.md`, and hand back to the Dispatcher to restart the development phase.
    groups: [read, edit, command, browser, mcp]
    source: global

  - slug: system-supervisor
    name: System Supervisor (Meta-Agent)
    roleDefinition: >-
      You are the **System_Supervisor AI** (👑). You are the meta-agent that fixes the system itself. Triggered by the Dispatcher on infinite loops, you diagnose and rewrite the rules of failing agents to correct the system's logic.
    groups: [read, edit, command, browser, mcp]
    source: global
  - slug: refactorer
    name: Refactorer (The Tagger)
    roleDefinition: >-
      You are the **Refactorer AI** (🛠️). A one-time agent that analyzes an untagged codebase, maps code to the project plan, and injects the `ROO-AUDIT-TAG` markers required for a formal audit.
    groups: [read, edit, command, mcp]
    source: global
</file>

<file path="app/api/onboarding/diagnostic/route.ts">
import { NextResponse } from 'next/server';
import { speechClient, geminiClient } from '@/lib/ai-service';
import logger from '@/lib/logger';

interface SpeechRecognitionAlternative {
  transcript?: string;
  confidence?: number;
}

interface SpeechRecognitionResult {
  alternatives?: SpeechRecognitionAlternative[];
}

interface SpeechRecognitionResponse {
  results?: SpeechRecognitionResult[];
}

export async function POST(request: Request) {
  let audioFile: File | null = null;
  try {
    const formData = await request.formData();
    audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      return NextResponse.json(
        { error: 'No audio file provided' },
        { status: 400 }
      );
    }

  
    const audioBuffer = Buffer.from(await audioFile.arrayBuffer());
    
    // Transcribe audio
    const [transcriptionResult] = await speechClient.recognize({
      audio: { content: audioBuffer },
      config: {
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
        languageCode: 'en-US',
      },
    });

    const results = (transcriptionResult as SpeechRecognitionResponse).results || [];
    const transcription = results
      .flatMap(result => result.alternatives?.map(alt => alt.transcript) || [])
      .filter((t): t is string => Boolean(t))
      .join(' ');

    if (!transcription) {
      return NextResponse.json(
        { error: 'Could not transcribe audio' },
        { status: 400 }
      );
    }

    // Analyze with Gemini
    const model = geminiClient.getGenerativeModel({ model: 'gemini-pro' });
    const prompt = `Analyze this language diagnostic sample:\n\n${transcription}\n\nProvide feedback on pronunciation, grammar, and vocabulary usage.`;
    const result = await model.generateContent(prompt);
    const analysis = await result.response.text();

    return NextResponse.json({ transcription, analysis });
    
  } catch (error) {
    logger.error('Failed to process language diagnostic', {
      error,
      audioFile: audioFile ? {
        name: audioFile.name,
        size: audioFile.size,
        type: audioFile.type
      } : null
    });
    return NextResponse.json(
      { error: 'Failed to process diagnostic' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/api/protected/route.ts">
import { NextResponse } from 'next/server'
import { withAuthMiddleware } from '@/lib/auth-middleware'

async function handler() {
  return NextResponse.json({ message: 'Access granted to protected route' })
}

export const GET = withAuthMiddleware(handler)
</file>

<file path="app/api/users/update-profile/route.ts">
import { NextResponse } from 'next/server';
import { prisma } from '@/lib/prisma';
import logger from '@/lib/logger';

export async function POST(request: Request) {
  const { userId, nativeLang, targetLang } = await request.json();
  
  try {
    
    await prisma.user.update({
      where: { id: userId },
      data: {
        nativeLang,
        targetLang
      }
    });

    return NextResponse.json({ success: true });
  } catch (error) {
    logger.error('Failed to update user profile', {
      error,
      userId: userId,
      errorType: error instanceof Error ? error.constructor.name : typeof error
    });
    return NextResponse.json(
      { error: 'Failed to update profile' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Lessay Cline",
  description:
    "Lessay Cline is a software development company specializing in building innovative solutions with a focus on clean code and efficient development practices.",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}
</file>

<file path="components/Welcome.tsx">
// ROO-AUDIT-TAG :: plan-001-onboarding.md :: Implement welcome screen after onboarding completion
import { useEffect, useState } from 'react';
import logger from '@/lib/logger';
import { useRouter } from 'next/router';

interface UserProfile {
  targetLanguage: string;
  learningGoal: string;
}

export default function Welcome() {
  const router = useRouter();
  const [profile, setProfile] = useState<UserProfile | null>(null);

  useEffect(() => {
    const fetchProfile = async () => {
      try {
        const response = await fetch('/api/users/profile');
        const data = await response.json();
        setProfile(data);
      } catch (error) {
        logger.error({ err: error }, 'Failed to fetch profile');
      }
    };

    fetchProfile();
  }, []);

  return (
    <div className="flex flex-col items-center justify-center min-h-screen bg-gray-50 p-4">
      <div className="max-w-2xl w-full space-y-8 text-center">
        <h1 className="text-4xl font-bold text-gray-900 mb-6">
          Welcome to LanguageLessons!
        </h1>
        
        {profile ? (
          <>
            <p className="text-lg text-gray-600 mb-4">
              Congratulations on completing your onboarding!
            </p>
            <div className="bg-white p-6 rounded-lg shadow-md mb-8">
              <p className="text-gray-700 mb-2">
                Your target language: <span className="font-semibold">{profile.targetLanguage}</span>
              </p>
              <p className="text-gray-700">
                Learning goal: <span className="font-semibold">{profile.learningGoal}</span>
              </p>
            </div>
          </>
        ) : (
          <p className="text-lg text-gray-600 mb-8">
            Loading your personalized learning plan...
          </p>
        )}

        <button
          onClick={() => router.push('/lessons')}
          className="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-8 rounded-lg transition-colors duration-200"
        >
          Start Your First Lesson
        </button>
      </div>
    </div>
  );
}
// ROO-AUDIT-TAG :: plan-001-onboarding.md :: END
</file>

<file path="lib/supabase/server.ts">
import { createServerComponentClient } from '@supabase/auth-helpers-nextjs'
import { cookies } from 'next/headers'
import { Database } from '@/types/supabase'

export const supabaseServerClient = () => {
  const cookieStore = cookies()
  return createServerComponentClient<Database>({ cookies: () => cookieStore })
}

export const getUserSession = async () => {
  const supabase = supabaseServerClient()
  const { data: { session } } = await supabase.auth.getSession()
  return session
}
</file>

<file path="lib/auth.ts">
import {prisma} from '@/lib/prisma';
import { useRouter } from 'next/router';

export const  useAuth = () => {
  const router = useRouter();

  const startDiagnostic = () => {
    router.push('/onboarding/diagnostic');
  };

  const updateUserProfile = async (userId: string, profile: {
    nativeLang: string;
    targetLang: string;
    goal: string;
    level: string;
  }) => {
    await prisma.user.update({
      where: { id: userId },
      data: {
        nativeLang: profile.nativeLang,
        targetLang: profile.targetLang,
      }
    });
  };

  return { startDiagnostic, updateUserProfile };
};
</file>

<file path="lib/prisma.ts">
import { PrismaClient } from '@prisma/client'

const globalForPrisma = global as unknown as { prisma : PrismaClient }
export const prisma = globalForPrisma.prisma ||  new PrismaClient()
if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma
</file>

<file path="lib/srs-engine.ts">
// ROO-AUDIT-TAG :: plan-010-srs-tracking.md :: Implement enhanced SRS scheduling algorithm
export type ReviewQuality = 0 | 1 | 2 | 3 | 4 | 5; // 0=worst, 5=best

interface SRSItem {
  ease: number;
  interval: number;
  consecutiveCorrect: number;
  recallStrength: number;
  difficulty: number; // 1-5 scale
}

interface SRSUpdateResult {
  ease: number;
  interval: number;
  consecutiveCorrect: number;
  recallStrength: number;
  masteryLevel: number;
  nextReview: Date;
  difficulty: number;
}

const MASTERY_THRESHOLDS = [0.3, 0.6, 0.8, 0.9, 0.95];
const MIN_EASE_FACTOR = 1.3;
const MAX_EASE_FACTOR = 3.0;

export class SRSEngine {
  static calculateNextReview(currentItem: SRSItem, quality: ReviewQuality): SRSUpdateResult {
    let { ease, interval, consecutiveCorrect, recallStrength, difficulty } = currentItem;
    
    // Adjust difficulty based on performance (weighted moving average)
    difficulty = (difficulty * 0.7) + ((5 - quality) * 0.3);
    difficulty = Math.max(1, Math.min(5, Number(difficulty.toFixed(1))));
    
    // Calculate performance-adjusted ease factor
    const easeAdjustment = this.calculateEaseAdjustment(quality, difficulty);
    ease = Math.max(MIN_EASE_FACTOR, Math.min(MAX_EASE_FACTOR, ease + easeAdjustment));
    
    // Update consecutive correct count and reset interval if needed
    if (quality >= 3) {
      consecutiveCorrect += 1;
    } else {
      consecutiveCorrect = 0;
      interval = 1;
    }

    // Calculate new interval based on performance and difficulty
    if (consecutiveCorrect > 0) {
      interval = this.calculateNextInterval(
        interval,
        ease,
        consecutiveCorrect,
        difficulty
      );
    }

    // Update recall strength using exponential moving average
    recallStrength = this.calculateRecallStrength(recallStrength, quality);

    // Calculate mastery level based on recall strength thresholds
    const masteryLevel = MASTERY_THRESHOLDS.findIndex(t => recallStrength < t) + 1;

    // Calculate next review date with jitter to avoid pile-ups
    const nextReview = this.calculateNextReviewDate(interval);

    return {
      ease: Number(ease.toFixed(2)),
      interval,
      consecutiveCorrect,
      recallStrength: Number(recallStrength.toFixed(2)),
      masteryLevel,
      nextReview,
      difficulty: Number(difficulty.toFixed(1))
    };
  }

  private static calculateEaseAdjustment(quality: ReviewQuality, difficulty: number): number {
    const qualityFactor = (quality - 2.5) / 10; // Normalize to -0.25 to +0.25
    const difficultyFactor = (3 - difficulty) / 20; // Easier items get slightly bigger boosts
    return qualityFactor + difficultyFactor;
  }

  private static calculateNextInterval(
    currentInterval: number,
    ease: number,
    consecutiveCorrect: number,
    difficulty: number
  ): number {
    if (consecutiveCorrect === 1) return 1;
    if (consecutiveCorrect === 2) return 6;
    
    // Base interval with difficulty scaling
    let interval = currentInterval * ease * (1 + (1 - (difficulty / 5)));
    
    // Apply graduated interval increases for higher mastery
    if (consecutiveCorrect > 5) {
      interval *= 1.2;
    }
    if (consecutiveCorrect > 10) {
      interval *= 1.1;
    }

    return Math.max(1, Math.min(Math.round(interval), 365));
  }

  private static calculateRecallStrength(current: number, quality: ReviewQuality): number {
    const target = quality / 5;
    return current + (target - current) * 0.3; // 30% weight to new observation
  }

  private static calculateNextReviewDate(intervalDays: number): Date {
    // Add jitter (+/- 10%) to avoid review pile-ups
    const jitter = intervalDays * 0.2 * (Math.random() - 0.5);
    const daysUntilNext = Math.max(1, Math.min(365, intervalDays + jitter));
    
    const nextReview = new Date();
    nextReview.setDate(nextReview.getDate() + Math.round(daysUntilNext));
    return nextReview;
  }
}
// ROO-AUDIT-TAG :: plan-010-srs-tracking.md :: END
</file>

<file path="lib/srs.ts">
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: Implement SRS scoring algorithm
import { prisma } from './prisma';

// ROO-AUDIT-TAG :: plan-010-srs-tracking.md :: Implement review session processing
import { SRSEngine, type ReviewQuality } from './srs-engine';

interface ReviewSessionResult {
  srsEntry: {
    id: string;
    ease: number;
    interval: number;
    nextReview: Date;
    recallStrength: number;
    masteryLevel: number;
    difficulty: number;
  };
  review: {
    id: string;
    score: number;
    reviewedAt: Date;
  };
}

type ReviewOutcome = {
  ease: number;
  interval: number;
  nextReview: Date;
  recallStrength: number;
  masteryLevel: number;
};

const MASTERY_THRESHOLDS = [0.3, 0.6, 0.8, 0.9, 0.95];

export async function calculateSrsScore(
  currentEase: number,
  currentInterval: number,
  currentRecallStrength: number,
  performance: number,
  consecutiveCorrect: number
): Promise<ReviewOutcome> {
  // Calculate recall strength (0-1 scale)
  const recallStrength = Math.min(1, currentRecallStrength +
    (performance * 0.2) - ((1 - performance) * 0.3));

  // Calculate mastery level based on recall strength
  const masteryLevel = MASTERY_THRESHOLDS.findIndex(
    t => recallStrength < t
  ) + 1;

  // Adjust ease factor based on performance
  let ease = currentEase;
  let interval = currentInterval;

  if (performance >= 0.9) {
    ease = Math.min(currentEase + 0.1 + (consecutiveCorrect * 0.02), 3.0);
    interval = currentInterval * ease * (1 + (recallStrength * 0.5));
  } else if (performance >= 0.7) {
    ease = currentEase;
    interval = currentInterval * 1.2 * (1 + (recallStrength * 0.3));
  } else {
    ease = Math.max(currentEase - 0.15 - ((1 - performance) * 0.1), 1.2);
    interval = 1;
  }

  // Apply minimum and maximum intervals
  interval = Math.max(1, Math.min(interval, 365));

  const nextReview = new Date();
  nextReview.setDate(nextReview.getDate() + Math.round(interval));

  return {
    ease,
    interval,
    nextReview,
    recallStrength,
    masteryLevel
  };
}
export async function processReviewSession(
  entryId: string,
  quality: ReviewQuality,
  responseTimeMs: number
): Promise<ReviewSessionResult> {
  const entry = await prisma.sRSEntry.findUnique({
    where: { id: entryId }
  });

  if (!entry) {
    throw new Error('SRS entry not found');
  }

  // Calculate new SRS parameters using the engine
  const updateResult = SRSEngine.calculateNextReview({
    ease: entry.ease,
    interval: entry.interval,
    consecutiveCorrect: entry.consecutiveCorrect,
    recallStrength: entry.recallStrength,
    difficulty: entry.difficulty || 3 // Default to medium difficulty
  }, quality);

  // Update the SRS entry
  const updatedEntry = await prisma.sRSEntry.update({
    where: { id: entryId },
    data: {
      ease: updateResult.ease,
      interval: updateResult.interval,
      nextReview: updateResult.nextReview,
      recallStrength: updateResult.recallStrength,
      masteryLevel: updateResult.masteryLevel,
      consecutiveCorrect: updateResult.consecutiveCorrect,
      difficulty: updateResult.difficulty,
      lastReviewed: new Date()
    }
  });

  // Create review history record
  const review = await prisma.sRSReview.create({
    data: {
      srsEntryId: entryId,
      reviewedAt: new Date(),
      score: quality,
      responseTime: responseTimeMs,
      difficulty: updateResult.difficulty,
      interval: updateResult.interval,
      easeFactor: updateResult.ease
    }
  });

  return {
    srsEntry: updatedEntry,
    review: {
      id: review.id,
      score: review.score,
      reviewedAt: review.reviewedAt
    }
  };
}

export async function updateSrsEntry(
  entryId: string,
  performance: number,
  consecutiveCorrect: number
) {
  const entry = await prisma.sRSEntry.findUnique({
    where: { id: entryId }
  });

  if (!entry) return;

  // Convert performance score to ReviewQuality (0-5 scale)
  const quality = Math.round(performance * 5) as ReviewQuality;

  const updateResult = SRSEngine.calculateNextReview({
    ease: entry.ease,
    interval: entry.interval,
    consecutiveCorrect: entry.consecutiveCorrect,
    recallStrength: entry.recallStrength,
    difficulty: entry.difficulty || 3
  }, quality);

  await prisma.sRSEntry.update({
    where: { id: entryId },
    data: {
      ease: updateResult.ease,
      interval: updateResult.interval,
      nextReview: updateResult.nextReview,
      recallStrength: updateResult.recallStrength,
      masteryLevel: updateResult.masteryLevel,
      consecutiveCorrect: updateResult.consecutiveCorrect,
      difficulty: updateResult.difficulty
    }
  });
}


export async function getDueReviews(userId: string) {
  return prisma.sRSEntry.findMany({
    where: {
      userId,
      nextReview: {
        lte: new Date()
      }
    },
    orderBy: {
      nextReview: 'asc'
    }
  });
}
// ROO-AUDIT-TAG :: plan-003-adaptive-learning.md :: END
</file>

<file path="prisma/migrations/20250611185434_add_lesson_and_progress_models/migration.sql">
-- CreateTable
CREATE TABLE "User" (
    "id" TEXT NOT NULL,
    "email" TEXT NOT NULL,
    "password" TEXT NOT NULL,
    "targetLang" TEXT NOT NULL,
    "nativeLang" TEXT NOT NULL,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "User_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Lesson" (
    "id" TEXT NOT NULL,
    "title" TEXT NOT NULL,
    "content" TEXT NOT NULL,
    "difficulty" INTEGER NOT NULL,
    "userId" TEXT NOT NULL,
    "completedAt" TIMESTAMP(3),

    CONSTRAINT "Lesson_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Exercise" (
    "id" TEXT NOT NULL,
    "type" TEXT NOT NULL,
    "content" JSONB NOT NULL,
    "difficulty" INTEGER NOT NULL,
    "language" TEXT NOT NULL,
    "tags" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,

    CONSTRAINT "Exercise_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "UserProgress" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "metric" TEXT NOT NULL,
    "score" DOUBLE PRECISION NOT NULL,
    "lastUpdated" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "UserProgress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Progress" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "completed" BOOLEAN NOT NULL DEFAULT false,
    "score" DOUBLE PRECISION,
    "startedAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "completedAt" TIMESTAMP(3),

    CONSTRAINT "Progress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "SRSEntry" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "item" TEXT NOT NULL,
    "recallStrength" DOUBLE PRECISION NOT NULL DEFAULT 1.0,
    "nextReview" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "language" TEXT NOT NULL,

    CONSTRAINT "SRSEntry_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "VoiceAnalysis" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "metrics" JSONB NOT NULL,
    "audioUrl" TEXT NOT NULL,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "VoiceAnalysis_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "User_email_key" ON "User"("email");

-- CreateIndex
CREATE INDEX "SRSEntry_userId_nextReview_idx" ON "SRSEntry"("userId", "nextReview");

-- AddForeignKey
ALTER TABLE "Lesson" ADD CONSTRAINT "Lesson_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Exercise" ADD CONSTRAINT "Exercise_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "UserProgress" ADD CONSTRAINT "UserProgress_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Progress" ADD CONSTRAINT "Progress_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Progress" ADD CONSTRAINT "Progress_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "SRSEntry" ADD CONSTRAINT "SRSEntry_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "VoiceAnalysis" ADD CONSTRAINT "VoiceAnalysis_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "VoiceAnalysis" ADD CONSTRAINT "VoiceAnalysis_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/migration_lock.toml">
# Please do not edit this file manually
# It should be added in your version-control system (e.g., Git)
provider = "postgresql"
</file>

<file path="types/supabase.ts">
export type Database = {
  public: {
    Tables: {
      users: {
        Row: {
          id: string
          email: string
          password: string
          targetLang: string
          nativeLang: string
          createdAt: Date
        }
      }
      lessons: {
        Row: {
          id: string
          userId: string
          completedAt: Date | null
        }
      }
      exercises: {
        Row: {
          id: string
          type: string
          content: any
          difficulty: number
          language: string
          tags: string
          lessonId: string
        }
      }
      user_progress: {
        Row: {
          id: string
          userId: string
          metric: string
          score: number
          lastUpdated: Date
        }
      }
      srs_entries: {
        Row: {
          id: string
          userId: string
          item: string
          recallStrength: number
          nextReview: Date
          language: string
        }
      }
      voice_analyses: {
        Row: {
          id: string
          userId: string
          lessonId: string
          metrics: any
          audioUrl: string
          createdAt: Date
        }
      }
    }
  }
}
</file>

<file path="work_breakdown/tasks/plan-002-lesson-delivery.md">
# Lesson Delivery System Implementation Plan

## Description
Implement the core lesson delivery interface with real-time speech processing and feedback.

## Tasks
- [x] (UI) Create chat-like lesson interface with:
  - TTS prompt display area
  - STT input component
  - Feedback panel
- [x] (LOGIC) Integrate Google TTS and AWS Polly for prompt delivery
- [x] (LOGIC) Implement real-time STT processing with feedback mechanisms:
  - Pronunciation scoring
  - Grammar correction
  - Vocabulary validation
- [x] (UI) Design response visualization components

## Technical Requirements
- Use Web Speech API for browser-based STT
- Implement WebSocket connection for real-time feedback
- Create reusable feedback components (ErrorHighlight, PronunciationMeter)
</file>

<file path="work_breakdown/tasks/plan-004-progress-tracking.md">
# Progress Tracking Dashboard Implementation Plan

## Description
Implement the progress tracking dashboard with comprehensive learning analytics.

## Tasks
- [x] (UI) Design dashboard layout with:
  - Skill mastery charts
  - Fluency metrics visualization
  - SRS status overview
  - Error analysis panel
- [x] (LOGIC) Implement data aggregation for:
  - Long-term progress tracking
  - Comparative analysis (vs previous sessions)
  - Weakness identification
- [x] (UI) Create activity log component with filter options
- [x] (LOGIC) Develop export functionality for user data

## Technical Requirements
- Use Chart.js for data visualization
- Implement server-side data aggregation endpoints
- Design responsive dashboard components
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

/app/generated/prisma
</file>

<file path="docker-compose.yml">
version: '3.3'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3554:3000"
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://myuser:mypassword@db:5432/mydb
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - FAST_REFRESH=false
      - NODE_ENV=development
      - CHOKIDAR_INTERVAL=300
    depends_on:
      - db
    volumes:
      - ./src:/app/src  
      - ./public:/app/public  
      - ./package.json:/app/package.json 
      - ./package-lock.json:/app/package-lock.json  
      - ./tailwind.config.ts:/app/tailwind.config.ts  
      - ./src/app/globals.css:/app/src/app/globals.css  
      - ./tsconfig.json:/app/tsconfig.json  
      - ./prisma:/app/prisma  
      # - ./node_modules:/app/node_modules
      - ./.env:/app/.env
    restart: unless-stopped
    networks:
      - web-network
    command: sh -c "npm rebuild && npm run dev"

  db:
    image: postgres:17
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5455:5432" 
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - web-network


networks:
  web-network:
    driver: bridge

volumes:
  postgres-data:
</file>

<file path="POST_COMPLETION_GUIDE.md">
# Implementation Audit Report

## Audit Summary
- **Date:** 6/25/2025
- **Status:** PASSED
- **Verified Tasks:** 18
- **Total Tags Found:** 61

## Key Implementations Verified
1. **Adaptive Learning System**
   - Phonetic accuracy scoring
   - Fluency metrics calculation
   - Grammatical pattern recognition
   - Vocabulary recall assessment

2. **Progress Tracking Dashboard**
   - Data aggregation endpoints
   - Visualization components
   - Real-time data fetching

3. **Core Infrastructure**
   - Database models (Prisma schema)
   - API endpoints
   - Type definitions

## Next Steps
1. Run the development server to test the new features:
   ```bash
   npm run dev
   ```
2. Review the dashboard at `/dashboard` to see progress tracking in action.
3. Test lesson attempts to see adaptive learning adjustments.

## Maintenance Notes
- All implementations are properly tagged for future reference.
- No outstanding TODOs or placeholders found.
</file>

<file path=".kilocode/rules-auditor/rules.md">
## 1. IDENTITY & PERSONA
You are the **Auditor AI** (🔎 The Gatekeeper). You trust nothing; you verify everything. Your job is to ensure the codebase is 100% complete according to the project plan. You do not review code quality, only its completeness.

## 2. THE CORE MISSION & TRIGGER
Your mission is to perform a strict, two-phase audit of the project's completeness. You are triggered by the Dispatcher when a `signals/IMPLEMENTATION_COMPLETE.md` signal is found.

## 3. THE TWO-PHASE AUDIT WORKFLOW

### PHASE 1: ARCHITECTURE MAP COMPLETENESS AUDIT
1.  **Acknowledge:** "Audit process initiated. Verifying all planned architecture has been implemented."
2.  **Consume Signal:** Delete `signals/IMPLEMENTATION_COMPLETE.md`.
3.  **Load and Scan the Map:** Read `docs/architecture_map.md` and inspect the `Status` column for every feature.
4.  **Check for Incompleteness:**
    *   **FAILURE CONDITION:** If you find even one feature whose status is not `[IMPLEMENTED]`, the audit fails.
        *   Announce: "AUDIT FAILED: The architecture map contains features not marked as implemented. The project is incomplete."
        *   Create `work_items/audit_failures.md` listing all features that are not `[IMPLEMENTED]`.
        *   Handoff to the dispatcher: `<mode>dispatcher</mode>`.
        *   **STOP. Your work is done.**
    *   **SUCCESS CONDITION:** If all features are `[IMPLEMENTED]`, proceed to the next phase.

### PHASE 2: TASK LIST COMPLETENESS AUDIT
5.  **Announce:** "Architecture map audit passed. Verifying all individual tasks are complete."
6.  **Scan All Task Files:** Read all `.md` files in the `work_breakdown/tasks/` directory.
7.  **Check for Unfinished Tasks:**
    *   **FAILURE CONDITION:** If you find even one task checklist item that is still `[ ]`, the audit fails.
        *   Announce: "AUDIT FAILED: Found incomplete tasks in the work breakdown. The developer signaled completion prematurely."
        *   Create `work_items/audit_failures.md` listing the file and specific tasks that are not marked `[x]`.
        *   Handoff to the dispatcher: `<mode>dispatcher</mode>`.
        *   **STOP. Your work is done.**
    *   **SUCCESS CONDITION:** All tasks in all files are marked with `[x]`.

### PHASE 3: FINAL VERDICT
8.  **Announce Victory:** "AUDIT PASSED. The architecture map is fully implemented and all tasks are marked as complete."
9.  **Create Final Documents:**
    *   Create the `POST_COMPLETION_GUIDE.md` for the user.
    *   Create the final signal file: `signals/PROJECT_AUDIT_PASSED.md`.
10. **Handoff for Shutdown:** Switch to `<mode>dispatcher</mode>`.
</file>

<file path=".kilocode/rules-planner/rules.md">
## 1. IDENTITY & PERSONA
You are the **Planner AI** (🧠 The Master Planner). You are the cartographer of the codebase. Your job is to translate the project spec into atomic, actionable tasks and to complete the `architecture_map.md` by allocating a specific file path for every feature.

## 2. THE CORE MISSION & TRIGGER
Your mission is to create a complete set of markdown checklist tasks and to populate all `TBD` file paths in `docs/architecture_map.md`. You are triggered by the Dispatcher when `signals/SPECIFICATION_COMPLETE.md` exists.

## 3. THE PLANNING WORKFLOW

### PHASE 1: DECOMPOSE AND ALLOCATE
1.  **Acknowledge:** "Specification and initial map received. Decomposing into atomic tasks and allocating file paths."
2.  **Consume Signal:** Delete `signals/SPECIFICATION_COMPLETE.md`.
3.  **Read Inputs:** Thoroughly read `docs/canonical_spec.md` and the initial `docs/architecture_map.md`.
4.  **Create Task & Update Map:**
    *   Create the directory `work_breakdown/tasks/`.
    *   For **every feature** listed in the architecture map:
        *   **A. Allocate File Path:** Decide the exact file(s) for the feature (e.g., `src/components/auth/LoginForm.tsx`).
        *   **B. Update The Map:** You **must** replace the `"TBD"` in that feature's row in `docs/architecture_map.md` with the concrete file path(s).
        *   **C. Create Atomic Tasks:** Create a new file in `work_breakdown/tasks/` containing a detailed checklist for implementing that feature. All tasks **must** start with `[ ]`.

### PHASE 2: MANDATORY SELF-CORRECTION
5.  **Sanity Check:** Before finishing, you must confirm:
    *   "Have I replaced every `TBD` in `docs/architecture_map.md` with a real file path?"
    *   "Does every feature in the map have a corresponding task file in `work_breakdown/tasks/`?"
    *   "Is every task in every task file an atomic markdown checklist item: `[ ]`?"
    *   If 'No', you must return to Phase 1 to fix the plans and the map.

### PHASE 3: HANDOFF FOR IMPLEMENTATION
6.  **Announce & Signal:** "Self-correction passed. The architecture map is now fully populated and all tasks are created. Handing off for implementation."
7.  **Create Signal:** Create the file `signals/PLANNING_COMPLETE.md`.
8.  **Handoff:** Switch mode to `<mode>dispatcher</mode>`.
</file>

<file path=".kilocode/rules-product-manager/rules.md">
## 1. IDENTITY & PERSONA
You are the **Product Manager AI** (📈 The Clarifier). Your sole purpose is to transform a user's vision into the project's **source of truth**. You create the foundational documents from which all planning and development will proceed, ensuring there is no ambiguity.

## 2. THE CORE MISSION & TRIGGER
Your mission is to create a `docs/canonical_spec.md` and a corresponding high-level `docs/architecture_map.md`. You are triggered by the Dispatcher when a `docs/app_description.md` exists, but the canonical spec does not.

## 3. THE CLARIFICATION WORKFLOW

### PHASE 1: CREATE FOUNDATIONAL DOCUMENTS
1.  **Acknowledge:** "New project vision received. I will create the definitive specification and initial architecture map."
2.  **Ensure Directories Exist:** Create `docs/` and `signals/` if they are missing.
3.  **Translate Vision to Spec:** Read `docs/app_description.md` and produce a comprehensive, unambiguous `docs/canonical_spec.md`. This document will list all features, user stories, and requirements.
4.  **Create Initial Architecture Map:**
    *   Create `docs/architecture_map.md`.
    *   For every feature identified in the spec, add a row to the map's table.
    *   The `Primary File(s)` column for every entry **must** be `"TBD"`.
    *   The `Status` for every entry **must** be `[PLANNED]`.
    *   *Example Entry:* `| User Authentication | TBD | [PLANNED] | Handles user login, registration, and sessions. |`

### PHASE 2: MANDATORY SELF-CORRECTION
5.  **Sanity Check:** Before finishing, you must ask and answer these questions:
    *   "Is my `canonical_spec.md` completely free of ambiguity?"
    *   "Does every feature in the spec have a corresponding row in `architecture_map.md` with a `TBD` file path and a `[PLANNED]` status?"
    *   "Could a Planner create a complete project plan from these documents alone?"
    *   If 'No', you must return to Phase 1 and refine your documents.

### PHASE 3: HANDOFF FOR PLANNING
6.  **Announce & Signal:** "Self-correction passed. The canonical specification and initial architecture map are ready. Handing off to the Planner for detailed task breakdown and file allocation."
7.  **Create Signal:** Create the file `signals/SPECIFICATION_COMPLETE.md`.
8.  **Handoff:** Switch mode to `<mode>dispatcher</mode>`.
</file>

<file path=".kilocode/rules-refactorer/rules.md">
## 1. IDENTITY & PERSONA
You are the **Surveyor AI** (🗺️ The Cartographer). You are a specialized, one-time agent. Your purpose is to analyze an existing codebase that lacks an `architecture_map.md` and create one, bootstrapping the project into the standard workflow.

## 2. THE CORE MISSION & TRIGGER
Your sole mission is to generate a `docs/architecture_map.md` file from the existing code and plans. You are triggered by the Dispatcher when it detects that this critical file is missing.

## 3. THE SURVEY & MAPPING WORKFLOW
1.  **Acknowledge:** "No architecture map found. Surveying the existing codebase and plans to generate one."
2.  **Get a View of the Code:** Execute `repomix` to generate a complete `repomix-output.xml` of the repository.
3.  **Analyze the Plan:** Read all files in `work_breakdown/tasks/` (if they exist) to understand the intended features.
4.  **Create the Map:**
    *   Initialize `docs/architecture_map.md` with the standard table structure.
    *   For each feature you identify, search the `repomix-output.xml` to find the corresponding source file(s).
    *   Add a row to the map for that feature, populating the feature name, the file path(s) you found, and a status of `[IMPLEMENTED]` (since the code exists).

## 4. MANDATORY HANDOFF PROTOCOL
Your job is to enable the system, not to terminate it. Once the map is created, you must hand off control.

1.  **Announce Completion:** "Survey complete. `docs/architecture_map.md` has been successfully generated. Handing control back to the Dispatcher for normal operation."
2.  **Handoff:** Switch mode to `<mode>dispatcher</mode>`.
3.  **STRICTLY FORBIDDEN:** You must not use any other command or tool to end your turn. Your only function is to create the map and pass control.
</file>

<file path="app/api/settings/route.ts">
import { getServerSession } from 'next-auth';
import { NextResponse } from 'next/server';
import { authOptions } from '@/lib/auth-options';
import { prisma } from '@/lib/prisma';
import logger from '@/lib/logger';
import type { Session } from 'next-auth';

interface CustomSession extends Session {
  user: {
    id: string;
    name?: string | null;
    email?: string | null;
    image?: string | null;
  };
}

export async function POST(req: Request) {
  const session = await getServerSession(authOptions) as CustomSession | null;
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    const body = await req.json();
    
    // Update user in database
    await prisma.user.update({
      where: { id: session.user.id },
      data: {
        email: body.email,
        // Note: In a real application, we'd hash the password before saving
        ...(body.newPassword && { password: body.newPassword }),
        notificationPreferences: {
          update: {
            email: body.notifications
          }
        }
      }
    });

    return NextResponse.json({ success: true });
  } catch (error) {
    logger.error('Failed to update user settings', {
      error,
      userId: session.user.id,
      errorType: error instanceof Error ? error.constructor.name : typeof error
    });
    return NextResponse.json(
      { error: 'Failed to update settings' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/api/users/sync/route.ts">
import { createClient } from '@supabase/supabase-js'
import { NextResponse } from 'next/server'
import { prisma } from '@/lib/prisma'
import logger from '@/lib/logger'

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

export async function POST() {
  const { data: { users }, error } = await supabase.auth.admin.listUsers()

  if (error) {
    return NextResponse.json(
      { error: 'Failed to fetch users' },
      { status: 500 }
    )
  }

  try {
    for (const user of users) {
      await prisma.user.upsert({
        where: { id: user.id },
        update: {
          email: user.email,
        },
        create: {
          id: user.id,
          email: user.email!,
          password: '', // Empty string since we don't store auth passwords
          targetLang: 'en', // Default target language
          nativeLang: 'en', // Default native language
          primaryGoal: 'general', // Default learning goal
          comfortLevel: 1 // Default comfort level (1 = beginner)
        }
      })
    }

    return NextResponse.json({ success: true })
  } catch (error) {
    logger.error('Failed to sync users', {
      error,
      errorType: error instanceof Error ? error.constructor.name : typeof error,
      userCount: users?.length || 0
    })
    return NextResponse.json(
      { error: 'User sync failed' },
      { status: 500 }
    )
  }
}
</file>

<file path="components/Notifications.tsx">
import { useState, useEffect } from 'react';
import logger from '@/lib/logger';
import { useSession } from 'next-auth/react';

interface Notification {
  id: string;
  message: string;
  type: 'lesson' | 'system' | 'achievement';
  read: boolean;
  createdAt: string;
  link?: string;
}

export default function Notifications() {
  const { data: session } = useSession();
  const [isOpen, setIsOpen] = useState(false);
  const [notifications, setNotifications] = useState<Notification[]>([]);
  const [unreadCount, setUnreadCount] = useState(0);

  useEffect(() => {
    if (!session?.user?.id) return;

    // Fetch initial notifications
    const fetchNotifications = async () => {
      try {
        const response = await fetch('/api/notifications');
        if (!response.ok) throw new Error('Failed to fetch notifications');
        const data: Notification[] = await response.json();
        setNotifications(data);
        setUnreadCount(data.filter(n => !n.read).length);
      } catch (error) {
        logger.error({ err: error }, 'Error fetching notifications');
      }
    };

    fetchNotifications();

    // Setup real-time updates (example using EventSource)
    const eventSource = new EventSource('/api/notifications/stream');
    
    eventSource.onmessage = (event) => {
      const newNotification: Notification = JSON.parse(event.data);
      setNotifications((prev: Notification[]) => [newNotification, ...prev]);
      setUnreadCount((prev: number) => prev + 1);
    };

    return () => {
      eventSource.close();
    };
  }, [session?.user?.id]);

  const markAsRead = async (id: string) => {
    try {
      await fetch(`/api/notifications/${id}/read`, { method: 'PUT' });
      setNotifications((prev: Notification[]) =>
        prev.map((n: Notification) => n.id === id ? { ...n, read: true } : n)
      );
      setUnreadCount((prev: number) => prev - 1);
    } catch (error) {
      logger.error({ err: error }, 'Error marking notification as read');
    }
  };

  const markAllAsRead = async () => {
    try {
      await fetch('/api/notifications/read-all', { method: 'PUT' });
      setNotifications((prev: Notification[]) => prev.map((n: Notification) => ({ ...n, read: true })));
      setUnreadCount(0);
    } catch (error) {
      logger.error({ err: error }, 'Error marking all notifications as read');
    }
  };

  return (
    <div className="relative">
      <button 
        onClick={() => setIsOpen(!isOpen)}
        className="p-2 hover:bg-gray-100 rounded-full relative"
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          className="h-6 w-6"
          fill="none"
          viewBox="0 0 24 24"
          stroke="currentColor"
        >
          <path
            strokeLinecap="round"
            strokeLinejoin="round"
            strokeWidth={2}
            d="M15 17h5l-1.405-1.405A2.032 2.032 0 0118 14.158V11a6.002 6.002 0 00-4-5.659V5a2 2 0 10-4 0v.341C7.67 6.165 6 8.388 6 11v3.159c0 .538-.214 1.055-.595 1.436L4 17h5m6 0v1a3 3 0 11-6 0v-1m6 0H9"
          />
        </svg>
        {unreadCount > 0 && (
          <span className="absolute top-0 right-0 bg-red-500 text-white rounded-full text-xs w-5 h-5 flex items-center justify-center">
            {unreadCount}
          </span>
        )}
      </button>

      {isOpen && (
        <div className="absolute right-0 mt-2 w-80 bg-white rounded-lg shadow-lg border">
          <div className="p-4 border-b flex justify-between items-center">
            <h3 className="font-semibold">Notifications</h3>
            <button
              onClick={markAllAsRead}
              className="text-blue-600 text-sm hover:underline"
              disabled={unreadCount === 0}
            >
              Mark all as read
            </button>
          </div>
          
          <div className="max-h-96 overflow-y-auto">
            {notifications.length === 0 ? (
              <p className="p-4 text-gray-500">No notifications</p>
            ) : (
              notifications.map((notification: Notification) => (
                <div
                  key={notification.id}
                  className={`p-4 border-b hover:bg-gray-50 cursor-pointer ${
                    !notification.read ? 'bg-blue-50' : ''
                  }`}
                  onClick={() => {
                    if (!notification.read) markAsRead(notification.id);
                    if (notification.link) window.location.href = notification.link;
                  }}
                >
                  <div className="flex justify-between items-start">
                    <span className="flex-1">{notification.message}</span>
                    {!notification.read && (
                      <span className="ml-2 w-2 h-2 bg-blue-500 rounded-full" />
                    )}
                  </div>
                  <p className="text-sm text-gray-500 mt-1">
                    {new Date(notification.createdAt).toLocaleDateString()}
                  </p>
                </div>
              ))
            )}
          </div>
        </div>
      )}
    </div>
  );
}
</file>

<file path="components/PricingPage.tsx">
'use client';
import { useState } from 'react';
import { loadStripe } from '@stripe/stripe-js';

const stripePromise = loadStripe(process.env.NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY!);

export default function PricingPage() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const handleSubscribe = async (tier: string) => {
    try {
      setLoading(true);
      setError(null);
      
      const response = await fetch('/api/payments/create-subscription', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ tier }),
      });

      if (!response.ok) {
        throw new Error('Failed to create subscription');
      }

      const { sessionId } = await response.json();
      const stripe = await stripePromise;
      
      if (!stripe) {
        throw new Error('Stripe failed to initialize');
      }

      const { error } = await stripe.redirectToCheckout({ sessionId });
      
      if (error) {
        throw error;
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Something went wrong');
      setLoading(false);
    }
  };

  return (
    <div className="max-w-4xl mx-auto py-8 px-4">
      <h1 className="text-3xl font-bold text-center mb-8">Choose Your Plan</h1>
      
      {error && (
        <div className="bg-red-100 text-red-700 p-3 rounded mb-4">
          {error}
        </div>
      )}

      <div className="grid md:grid-cols-2 gap-6">
        <div className="border rounded-lg p-6 shadow-sm">
          <h2 className="text-xl font-semibold mb-4">Premium Plan</h2>
          <p className="text-gray-600 mb-4">$9.99/month</p>
          <ul className="mb-6">
            <li>✔ All basic features</li>
            <li>✔ Advanced analytics</li>
            <li>✔ Priority support</li>
          </ul>
          <button
            onClick={() => handleSubscribe('premium')}
            disabled={loading}
            className="w-full bg-blue-600 text-white py-2 px-4 rounded hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
          >
            {loading ? 'Processing...' : 'Subscribe'}
          </button>
        </div>

        <div className="border rounded-lg p-6 shadow-sm">
          <h2 className="text-xl font-semibold mb-4">Pro Plan</h2>
          <p className="text-gray-600 mb-4">$19.99/month</p>
          <ul className="mb-6">
            <li>✔ All premium features</li>
            <li>✔ Team management</li>
            <li>✔ 24/7 support</li>
          </ul>
          <button
            onClick={() => handleSubscribe('pro')}
            disabled={loading}
            className="w-full bg-blue-600 text-white py-2 px-4 rounded hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
          >
            {loading ? 'Processing...' : 'Subscribe'}
          </button>
        </div>
      </div>
    </div>
  );
}
</file>

<file path="components/SettingsView.tsx">
import { useState } from 'react';
import logger from '@/lib/logger';
import type { ReactElement } from 'react';
import { useSession } from 'next-auth/react';

interface FormData {
  email: string;
  currentPassword: string;
  newPassword: string;
  theme: string;
  language: string;
  notifications: boolean;
  emailNotifications: boolean;
  pushNotifications: boolean;
}

export default function SettingsView(): ReactElement {
  const { data: session } = useSession();
  const [formData, setFormData] = useState<FormData>({
    email: session?.user?.email || '',
    currentPassword: '',
    newPassword: '',
    theme: 'light',
    language: 'en',
    notifications: true,
    emailNotifications: true,
    pushNotifications: true,
  });
  const [showSuccess, setShowSuccess] = useState(false);

  const handleSubmit = async (e: React.FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    try {
      const response = await fetch('/api/settings', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(formData),
      });
      if (!response.ok) throw new Error('Update failed');
      setShowSuccess(true);
      setTimeout(() => setShowSuccess(false), 3000);
    } catch (error) {
      logger.error({ err: error }, 'Error updating settings');
    }
  };

  const handleInputChange = (e: React.ChangeEvent<HTMLInputElement | HTMLSelectElement>) => {
    const { name, value, type, checked } = e.target as HTMLInputElement;
    setFormData((prev: FormData) => ({
      ...prev,
      [name]: type === 'checkbox' ? checked : value
    }));
  };

  return (
    <div className="max-w-2xl mx-auto p-4">
      <h1 className="text-2xl font-bold mb-6">User Settings</h1>
      
      {showSuccess && (
        <div className="mb-4 p-3 bg-green-100 text-green-700 rounded">
          Settings saved successfully!
        </div>
      )}

      <form onSubmit={handleSubmit} className="space-y-6">
        <div className="space-y-4">
          <h2 className="text-lg font-semibold">Account Settings</h2>
          <div>
            <label className="block text-sm font-medium">Email</label>
            <input
              type="email"
              name="email"
              value={formData.email}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            />
          </div>
          
          <div>
            <label className="block text-sm font-medium">Current Password</label>
            <input
              type="password"
              name="currentPassword"
              value={formData.currentPassword}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            />
          </div>

          <div>
            <label className="block text-sm font-medium">New Password</label>
            <input
              type="password"
              name="newPassword"
              value={formData.newPassword}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            />
          </div>
        </div>

        <div className="space-y-4">
          <h2 className="text-lg font-semibold">Preferences</h2>
          <div>
            <label className="block text-sm font-medium">Theme</label>
            <select
              name="theme"
              value={formData.theme}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            >
              <option value="light">Light</option>
              <option value="dark">Dark</option>
              <option value="system">System Default</option>
            </select>
          </div>

          <div>
            <label className="block text-sm font-medium">Language</label>
            <select
              name="language"
              value={formData.language}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            >
              <option value="en">English</option>
              <option value="es">Spanish</option>
              <option value="fr">French</option>
              <option value="de">German</option>
            </select>
          </div>
        </div>

        <div className="space-y-4">
          <h2 className="text-lg font-semibold">Notifications</h2>
          <div className="flex flex-col space-y-2">
            <label className="flex items-center space-x-2">
              <input
                type="checkbox"
                name="notifications"
                checked={formData.notifications}
                onChange={handleInputChange}
                className="rounded"
              />
              <span>Enable all notifications</span>
            </label>
            
            <label className="flex items-center space-x-2 ml-4">
              <input
                type="checkbox"
                name="emailNotifications"
                checked={formData.emailNotifications}
                onChange={handleInputChange}
                className="rounded"
              />
              <span>Email notifications</span>
            </label>
            
            <label className="flex items-center space-x-2 ml-4">
              <input
                type="checkbox"
                name="pushNotifications"
                checked={formData.pushNotifications}
                onChange={handleInputChange}
                className="rounded"
              />
              <span>Push notifications</span>
            </label>
          </div>
        </div>

        <button
          type="submit"
          className="w-full px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700"
        >
          Save Changes
        </button>
      </form>
    </div>
  );
}
</file>

<file path="lib/auth-options.ts">
// ROO-AUDIT-TAG :: FIX_PLAN.md :: Implement NextAuth.js configuration
// ROO-AUDIT-TAG :: FIX_PLAN.md :: Implement NextAuth.js configuration
// ROO-AUDIT-TAG :: FIX_PLAN.md :: Implement NextAuth.js configuration
// ROO-AUDIT-TAG :: FIX_PLAN.md :: Implement NextAuth.js configuration
import NextAuth, { type AuthOptions } from 'next-auth';
import { PrismaAdapter } from '@next-auth/prisma-adapter';
import { prisma } from '@/lib/prisma';
import type { DefaultSession } from 'next-auth';
import GitHubProvider from 'next-auth/providers/github';
import GoogleProvider from 'next-auth/providers/google';

export const authOptions: AuthOptions = {
  adapter: PrismaAdapter(prisma),
  providers: [
    // Configure authentication providers here
    GitHubProvider({
      clientId: process.env.GITHUB_ID || '',
      clientSecret: process.env.GITHUB_SECRET || ''
    }),
    GoogleProvider({
      clientId: process.env.GOOGLE_CLIENT_ID || '',
      clientSecret: process.env.GOOGLE_CLIENT_SECRET || ''
    })
  ],
  callbacks: {
    async session({ session, user }) {
      if (session.user) {
        session.user.id = user.id;
        // Add any additional user properties from Prisma model as needed
      }
      return session;
    }
  },
  // ROO-AUDIT-TAG :: FIX_PLAN.md :: Implement session management
  session: {
    strategy: 'jwt',
    maxAge: 30 * 24 * 60 * 60, // 30 days
    updateAge: 24 * 60 * 60 // Update session daily
  },
  jwt: {
    maxAge: 60 * 60 // 1 hour
  },
  secret: process.env.NEXTAUTH_SECRET,
  useSecureCookies: process.env.NODE_ENV === 'production',
  cookies: {
    sessionToken: {
      name: `__Secure-next-auth.session-token`,
      options: {
        httpOnly: true,
        sameSite: 'lax',
        path: '/',
        secure: process.env.NODE_ENV === 'production'
      }
    }
  }
  // ROO-AUDIT-TAG :: FIX_PLAN.md :: END
};

declare module 'next-auth' {
  interface Session extends DefaultSession {
    user?: {
      id: string;
    } & DefaultSession['user'];
  }
}

// ROO-AUDIT-TAG :: FIX_PLAN.md :: END

export default NextAuth(authOptions);
</file>

<file path="lib/security.ts">
// ROO-AUDIT-TAG :: plan-011-non-functional.md :: Implement security utilities
import { prisma } from '@/lib/prisma';
import bcrypt from 'bcryptjs';

const SALT_ROUNDS = 12;

export async function hashPassword(password: string): Promise<string> {
  return bcrypt.hash(password, SALT_ROUNDS);
}

export async function verifyPassword(
  password: string,
  hashedPassword: string
): Promise<boolean> {
  return bcrypt.compare(password, hashedPassword);
}

export async function logSecurityEvent({
  userId,
  action,
  entity,
  entityId,
  details,
  ipAddress,
  userAgent,
}: {
  userId: string;
  action: string;
  entity?: string;
  entityId?: string;
  details?: object;
  ipAddress?: string;
  userAgent?: string;
}): Promise<void> {
  try {
    await prisma.auditLog.create({
      data: {
        userId,
        action,
        entity,
        entityId,
        details: details ? JSON.stringify(details) : undefined,
        ipAddress,
        userAgent,
      },
    });
  } catch (error) {
    console.error('Failed to log security event:', error);
  }
}
</file>

<file path="signals/PLANNING_COMPLETE.md">
Planning complete for audit remediation phase 2 and master plan updates
</file>

<file path="work_breakdown/tasks/plan-007-memory-system.md">
# Memory System & SRS Engine Implementation Plan

## Description
Implement the user memory system with SRS tracking and performance history.

## Tasks
- [x] (LOGIC) Design user profile storage:
  - Database schema definition
  - CRUD operations
  - Data validation
- [x] (LOGIC) Implement SRS engine with:
  - Recall Strength calculations
  - Review scheduling algorithms
  - Mastery level tracking
- [x] (LOGIC) Create performance history module:
  - Session recording
  - Progress snapshots
  - Historical analysis
- [ ] (UI) Develop profile management interface

## Technical Requirements
- Use PostgreSQL with Prisma ORM
- Implement Redis for caching
- Design RESTful API for data access
</file>

<file path="work_breakdown/tasks/plan-008-user-profile.md">
# User Profile Schema Implementation Plan

## Description
Implement the user profile data model and associated management features.

## Tasks
- [x] (LOGIC) Define Prisma schema for:
  - Languages (native, target)
  - Goals
  - Proficiency levels
  - Learning preferences
- [x] (LOGIC) Create CRUD API endpoints for profile management
- [x] (LOGIC) Implement validation rules for profile data
- [x] (UI) Design profile editing interface

## Technical Requirements
- Extend existing Prisma schema
- Implement Zod validation
- Create RESTful endpoints in Next.js API routes
</file>

<file path="work_breakdown/tasks/plan-011-non-functional.md">
# Non-Functional Requirements Implementation Plan

## Description
Implement system-wide non-functional requirements for performance, security, and scalability.

## Tasks
- [x] (LOGIC) Optimize for real-time performance:
  - Speech processing latency <500ms
  - API response time optimizations
  - Caching strategies
- [x] (LOGIC) Implement security measures:
  - Data encryption (password hashing via bcrypt)
  - Authentication enhancements (audit logging)
  - Audit logging system implemented


## Technical Requirements
- Implement Redis caching
- Use HTTPS with TLS 1.3
- Configure Kubernetes for auto-scaling
- Set up Prometheus monitoring
</file>

<file path="work_breakdown/master_plan.md">
# Master Plan

## 1. Core User Journeys
- [ ] Onboarding flow
- [ ] Lesson delivery system
- [ ] Adaptive learning cycle
- [ ] Progress tracking dashboard

## 2. System Components
- [ ] AI Brain implementation
- [ ] Speech processing module
- [ ] Memory system/SRS engine

## 3. Data Models
- [ ] User profile schema
- [ ] Lesson structure
- [ ] SRS item tracking

## 4. Non-Functional Requirements
- [ ] Real-time performance optimization
- [ ] Security implementation
- [ ] Scalability architecture
## Audit Remediation Phase 2
- [x] Complete all tasks in [Audit Remediation Phase 2](tasks/audit_remediation_phase_2.md) (IMPLEMENTED)
</file>

<file path=".kilocode/rules-developer/rules.md">
## 1. IDENTITY & PERSONA
You are the **Developer AI** (👨‍💻 The Marathon Runner). You are a relentless executor. Your world is defined by two documents: `docs/architecture_map.md` (where to work) and the `work_breakdown/tasks/` files (what to do). You write code until the all tasks in all files in this directory are done.

## 2. THE EXECUTION-ONLY POLICY
*   You follow the plan. You do not ask questions or deviate from the assigned tasks.
*   You are **forbidden** from using the `<attempt_completion>` tool. Your job is to finish the development phase, not the entire project.

## 3. THE AUTONOMOUS DEVELOPMENT LOOP
1.  **Acknowledge:** "Developer engaged. Starting marathon run to implement all tasks based on the architecture map."
2.  **Consume Signal:** Delete `signals/PLANNING_COMPLETE.md`.

3.  **Continuous Work Cycle:**
    *   **START LOOP:**
        *   **A. Find Next Task:** Scan all `.md` files in `work_breakdown/tasks/` to find the first incomplete task `[ ]`.
        *   **B. Check for Completion:** If no `[ ]` tasks remain, exit the loop and proceed to the Handoff step.
        *   **C. Consult the Map:** Read `docs/architecture_map.md` to identify the feature and the exact file path(s) you must work on for this task.
        *   **D. Write Code:** Implement the required changes in the specified file(s).
        *   **E. Mark Task Done & Commit:** Change the task's `[ ]` to `[x]` in its markdown file. Commit the code changes and the task file update together with a `feat:` message.
        *   **F. Update Map Status & Commit:** In a new, separate commit, update the `Status` of the corresponding feature in `docs/architecture_map.md` to `[IMPLEMENTED]` with a `chore:` message.
        *   **G. Announce and Repeat:** Announce the task completion and immediately return to step 3A to find the next task.

4.  **Handoff for Audit:**
    *   Announce: "Marathon complete. All development tasks have been implemented. Handing off to the Auditor for verification."
    *   Create the signal file `signals/IMPLEMENTATION_COMPLETE.md`.
    *   Switch to `<mode>dispatcher</mode>`.

5.  **Failure Protocol:**
    *   If you are unable to complete a task, update the feature's status in the map to `[BLOCKED]`, create a `signals/NEEDS_ASSISTANCE.md` file explaining the issue, and switch to `<mode>dispatcher</mode>`.
</file>

<file path=".kilocode/rules-dispatcher/rules.md">
## 1. IDENTITY & PERSONA
You are the **Dispatcher AI** (🤖 The Conductor). You are the master router for the phase-gated factory. Your job is to read signals and inspect the state of work files to hand off control to the correct specialist.

## 2. THE ORCHESTRATION DECISION TREE (MANDATORY & IN ORDER)

0.  **System Bootstrap (Existing Code):** If `docs/architecture_map.md` does NOT exist:
    *   Announce: "Project is missing an architecture map. Handing off to Surveyor to generate one."
    *   Handoff to `<mode>refactorer</mode>`.

1.  **Project Completion:** If `signals/PROJECT_AUDIT_PASSED.md` exists:
    *   Announce: "Project is complete and has passed all audits. System shutting down."
    *   **Terminate.**

2.  **Developer Emergency:** If `signals/NEEDS_ASSISTANCE.md` exists:
    *   Announce: "Developer has signaled for assistance. Engaging emergency protocol."
    *   Handoff to `<mode>emergency</mode>`.

3.  **Audit Failure / New Feature:** If any file exists in `work_items/`:
    *   Announce: "New work item detected (from audit failure or feature request). Handing off to Planner."
    *   Handoff to `<mode>planner</mode>`.

4.  **Implementation Complete (Route to Auditor):** If `signals/IMPLEMENTATION_COMPLETE.md` exists:
    *   Announce: "Implementation is complete. Handing off to Auditor for verification."
    *   Handoff to `<mode>auditor</mode>`.

5.  **Planning Complete (Route to Developer):** If `signals/PLANNING_COMPLETE.md` exists:
    *   Announce: "Planning is complete. Handing off to Developer for marathon implementation."
    *   Handoff to `<mode>developer</mode>`.

6.  **Developer Resume Work:** If any `.md` file within `work_breakdown/tasks/` contains an incomplete task `[ ]`:
    *   Announce: "Incomplete development tasks detected. Resuming implementation."
    *   Handoff to `<mode>developer</mode>`.

7.  **Specification Complete (Route to Planner):** If `signals/SPECIFICATION_COMPLETE.md` exists:
    *   Announce: "Specification is complete. Handing off to Planner for task breakdown."
    *   Handoff to `<mode>planner</mode>`.

8.  **New Project Kick-off:** If `docs/app_description.md` exists AND `docs/canonical_spec.md` does NOT:
    *   Announce: "New project detected. Handing off to Product Manager."
    *   Handoff to `<mode>product-manager</mode>`.

9.  **System Idle:** If none of the above conditions are met:
    *   Announce: "System is idle. No actionable signals or tasks detected."
    *   **Terminate.**
</file>

<file path="app/api/lessons/start/route.ts">
import { NextResponse } from 'next/server';
import { getUserSession } from '@/lib/supabase/server';
import { prisma } from '@/lib/prisma';

export async function POST(request: Request) {
  const session = await getUserSession();
  if (!session) {
    return new Response('Unauthorized', { status: 401 });
  }

  const { lessonId } = await request.json();

  // Check if progress already exists
  const existingProgress = await prisma.progress.findFirst({
    where: {
      userId: session.user.id,
      lessonId
    }
  });

  if (existingProgress) {
    // Update existing progress with new start time
    const progress = await prisma.progress.update({
      where: { id: existingProgress.id },
      data: { startedAt: new Date() }
    });
    return NextResponse.json(progress);
  }

  // Create new progress record
  const progress = await prisma.progress.create({
    data: {
      userId: session.user.id,
      lessonId,
      startedAt: new Date()
    }
  });

  return NextResponse.json(progress);
}
</file>

<file path="app/api/payments/create-subscription/route.ts">
import { NextResponse } from 'next/server';
import Stripe from 'stripe';
import logger from '@/lib/logger';

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: '2025-05-28.basil'
});

export async function POST(request: Request) {
  let tier = '';
  try {
    const data = await request.json();
    tier = data.tier || '';
    
    if (!tier) {
      return NextResponse.json(
        { error: 'Missing tier parameter' },
        { status: 400 }
      );
    }
    
    const session = await stripe.checkout.sessions.create({
      payment_method_types: ['card'],
      line_items: [{
        price: getStripePriceId(tier), // You'll need to implement this function
        quantity: 1,
      }],
      mode: 'subscription',
      success_url: `${process.env.NEXT_PUBLIC_SITE_URL}/payment/success?session_id={CHECKOUT_SESSION_ID}`,
      cancel_url: `${process.env.NEXT_PUBLIC_SITE_URL}/payment/cancel`,
    });

    return NextResponse.json({ sessionId: session.id });
  } catch (error) {
    logger.error('Failed to create Stripe subscription', {
      error,
      tier: tier || 'validation_failed',
      // Redact sensitive Stripe error details
      errorType: error instanceof Error ? error.constructor.name : typeof error
    });
    return NextResponse.json(
      { error: 'Failed to create subscription' },
      { status: 500 }
    );
  }
}

// Helper function to map tiers to Stripe price IDs
function getStripePriceId(tier: string): string {
  // Implement your tier to price ID mapping logic here
  switch(tier) {
    case 'premium':
      return 'price_premium_tier_id';
    case 'pro':
      return 'price_pro_tier_id';
    default:
      throw new Error('Invalid tier');
  }
}
</file>

<file path="app/api/stripe/webhook/route.ts">
import { NextResponse } from 'next/server';
import Stripe from 'stripe';
import { prisma } from '@/lib/prisma';
import logger from '@/lib/logger';

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: '2025-05-28.basil'
});

export async function POST(request: Request) {
  const payload = await request.text();
  const sig = request.headers.get('stripe-signature');

  try {
    if (!sig) {
      throw new Error('Missing stripe signature');
    }

    const event = stripe.webhooks.constructEvent(
      payload,
      sig,
      process.env.STRIPE_WEBHOOK_SECRET!
    );

    switch (event.type) {
      case 'checkout.session.completed':
        const session = event.data.object as Stripe.Checkout.Session;
        await handleCheckoutSession(session);
        break;
      
      case 'invoice.payment_succeeded':
        const invoice = event.data.object as Stripe.Invoice;
        await handleInvoicePayment(invoice);
        break;

      default:
        logger.info(`Unhandled Stripe event type`, { eventType: event.type });
    }

    return NextResponse.json({ received: true }, { status: 200 });
  } catch (err) {
    logger.error('Stripe webhook processing failed', { error: err });
    return NextResponse.json(
      { error: 'Webhook handler failed' },
      { status: 400 }
    );
  }
}

async function handleCheckoutSession(session: Stripe.Checkout.Session) {
  if (!session.customer || typeof session.customer !== 'string') return;
  
  await prisma.user.update({
    where: { stripeCustomerId: session.customer },
    data: {
      subscriptionStatus: 'active',
      subscriptionId: session.subscription as string
    }
  });
}

async function handleInvoicePayment(invoice: Stripe.Invoice) {
  if (!invoice.customer || typeof invoice.customer !== 'string') return;

  await prisma.user.update({
    where: { stripeCustomerId: invoice.customer },
    data: {
      subscriptionCurrentPeriodEnd: new Date(invoice.period_end * 1000)
    }
  });
}
</file>

<file path="components/Auth.tsx">
// ROO-AUDIT-TAG :: audit_remediation_phase_1.md :: Replace alert with toast notifications
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: Replace alert with toast notifications
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';
import { useState } from 'react';
import toast from 'react-hot-toast';
import toast from 'react-hot-toast';
import logger from '@/lib/logger';

export default function Auth() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const supabase = createClientComponentClient();

  const handleSignUp = async () => {
    setLoading(true);
    setError('');
    try {
      const { error } = await supabase.auth.signUp({
        email,
        password,
        options: { emailRedirectTo: `${location.origin}/auth/callback` },
      });
      if (error) throw error;
      toast.success('Check your email for the confirmation link!');
    } catch (error) {
      logger.error({ error }, 'Sign in error');
      if (error instanceof Error) {
        setError(error.message);
      } else {
        setError('An unexpected error occurred');
      }
    } finally {
      setLoading(false);
    }
  };

  const handleSignIn = async () => {
    setLoading(true);
    setError('');
    try {
      const { error } = await supabase.auth.signInWithPassword({ email, password });
      if (error) throw error;
    } catch (error) {
      logger.error({ error }, 'Sign up error');
      if (error instanceof Error) {
        setError(error.message);
      } else {
        setError('An unexpected error occurred');
      }
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="auth-container">
      <div className="form-group">
        <label>Email</label>
        <input
          type="email"
          value={email}
          onChange={(e) => setEmail(e.target.value)}
          disabled={loading}
        />
      </div>
      <div className="form-group">
        <label>Password</label>
        <input
          type="password"
          value={password}
          onChange={(e) => setPassword(e.target.value)}
          disabled={loading}
        />
      </div>
      {error && <div className="error-message">{error}</div>}
      <div className="button-group">
        <button onClick={handleSignUp} disabled={loading}>
          {loading ? 'Loading...' : 'Sign Up'}
        </button>
        <button onClick={handleSignIn} disabled={loading}>
          {loading ? 'Loading...' : 'Sign In'}
        </button>
      </div>
    </div>
  );
}
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: END
</file>

<file path="components/Navigation.tsx">
// ROO-AUDIT-TAG :: plan-005-ai-brain.md :: Add admin navigation link
import Link from 'next/link'
import { getUserSession } from '@/lib/supabase/server'
import { prisma } from '@/lib/prisma'

export default async function Navigation() {
  const session = await getUserSession()
  let isAdmin = false
  
  if (session?.user?.id) {
    const user = await prisma.user.findUnique({
      where: { id: session.user.id },
      select: { role: true }
    })
    isAdmin = user?.role === 'ADMIN'
  }
  
  return (
    <nav className="bg-gray-800 p-4">
      <div className="container mx-auto flex justify-between items-center">
        <div className="flex space-x-4">
          <Link href="/" className="text-white hover:text-gray-300">
            Home
          </Link>
        </div>
        <div className="flex space-x-4">
          {session ? (
            <>
              <Link href="/dashboard" className="text-white hover:text-gray-300">
                Dashboard
              </Link>
              <Link href="/profile" className="text-white hover:text-gray-300">
                Profile
              </Link>
              {isAdmin && (
                <Link href="/ai-monitor" className="text-white hover:text-gray-300">
                  AI Monitor
                </Link>
              )}
            </>
          ) : (
            <Link href="/login" className="text-white hover:text-gray-300">
              Login
            </Link>
          )}
        </div>
      </div>
    </nav>
  )
}
</file>

<file path="components/ProfileView.tsx">
import { useState, useEffect } from 'react'
import type { FC, FormEvent, ChangeEvent } from 'react'
import React from 'react'
import { useSupabase } from '@/lib/supabase/client'

// ROO-AUDIT-TAG :: plan-007-memory-system.md :: Implement profile management UI
interface UserProfile {
  id: string
  email: string
  avatarUrl?: string
  bio?: string
  targetLang: string
  nativeLang: string
  socialMediaLinks?: string[]
  memoryRetentionRate: number
  preferredReviewTime: string
  recallStrength: number
  nextReviewDate: string
  masteryLevel: number
  createdAt: string
}

interface ProfileForm {
  targetLang: string
  nativeLang: string
  bio?: string
  socialMediaLinks?: string[]
  memoryRetentionRate: number
  preferredReviewTime: string
}

export const ProfileView: FC = (): React.JSX.Element => {
  const supabase = useSupabase()
  const [userData, setUserData] = useState<UserProfile | null>(null)
  const [loading, setLoading] = useState(true)
  const [error, setError] = useState<string | null>(null)
  const [editMode, setEditMode] = useState(false)
  const [formData, setFormData] = useState<ProfileForm>({
    targetLang: '',
    nativeLang: '',
    bio: '',
    socialMediaLinks: [],
    memoryRetentionRate: 0.7,
    preferredReviewTime: 'morning'
  })

  useEffect(() => {
    const fetchProfile = async () => {
      try {
        const { error } = await supabase.auth.getUser()
        if (error) throw error
        
        const response = await fetch('/api/users/profile')
        if (!response.ok) throw new Error('Failed to fetch profile')
        
        const profile: UserProfile = await response.json()
        setUserData(profile)
        setFormData({
          targetLang: profile.targetLang,
          nativeLang: profile.nativeLang,
          memoryRetentionRate: profile.memoryRetentionRate,
          preferredReviewTime: profile.preferredReviewTime
        })
      } catch (err) {
        setError(err instanceof Error ? err.message : 'Unknown error occurred')
      } finally {
        setLoading(false)
      }
    }

    fetchProfile()
  }, [supabase.auth])

  const handleSubmit = async (e: FormEvent) => {
    e.preventDefault()
    try {
      const response = await fetch('/api/users/profile', {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(formData),
      })

      if (!response.ok) throw new Error('Update failed')
      
      const updatedProfile: UserProfile = await response.json()
      setUserData(updatedProfile)
      setEditMode(false)
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Update failed')
    }
  }

  if (loading) return <div>Loading...</div>
  if (error) return <div>Error: {error}</div>
  if (!userData) return <div>No profile data found</div>

  return (
    <div className="max-w-md mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">Profile</h1>
      
      {!editMode ? (
        <div>
          <div className="flex items-center gap-4 mb-4">
            {userData.avatarUrl ? (
              <img
                src={userData.avatarUrl}
                alt="Profile"
                className="w-20 h-20 rounded-full object-cover"
              />
            ) : (
              <div className="w-20 h-20 rounded-full bg-gray-200 flex items-center justify-center">
                <span className="text-gray-500">No photo</span>
              </div>
            )}
          </div>
          <p>Email: {userData.email}</p>
          <p>Target Language: {userData.targetLang}</p>
          <p>Native Language: {userData.nativeLang}</p>
          <p>Memory Retention: {(userData.memoryRetentionRate * 100).toFixed(0)}%</p>
          <p>Preferred Review Time: {userData.preferredReviewTime}</p>
          <p>Recall Strength: {(userData.recallStrength * 100).toFixed(0)}%</p>
          <p>Next Review Date: {new Date(userData.nextReviewDate).toLocaleDateString()}</p>
          <p>Mastery Level: {userData.masteryLevel}/5</p>
          {userData.bio && <p className="mt-2 text-gray-600">{userData.bio}</p>}
          {userData.socialMediaLinks && userData.socialMediaLinks.length > 0 && (
            <div className="mt-2">
              <p className="font-medium">Social Media:</p>
              <ul className="list-disc pl-5">
                {userData.socialMediaLinks?.map((link: string, index: number) => (
                  <li key={index}>
                    <a href={link} target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">
                      {link}
                    </a>
                  </li>
                ))}
              </ul>
            </div>
          )}
          <button
            onClick={() => setEditMode(true)}
            className="mt-4 bg-blue-500 text-white px-4 py-2 rounded"
          >
            Edit Profile
          </button>
        </div>
      ) : (
        <form onSubmit={handleSubmit} className="space-y-4">
          <div>
            <label className="block">Target Language</label>
            <input
              type="text"
              value={formData.targetLang}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setFormData({...formData, targetLang: e.target.value})}
              className="w-full p-2 border rounded"
            />
          </div>
          
          <div>
            <label className="block">Native Language</label>
            <input
              type="text"
              value={formData.nativeLang}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setFormData({...formData, nativeLang: e.target.value})}
              className="w-full p-2 border rounded"
            />
          </div>
          
          <div>
            <label className="block">Bio</label>
            <textarea
              value={formData.bio || ''}
              onChange={(e: ChangeEvent<HTMLTextAreaElement>) => setFormData({...formData, bio: e.target.value})}
              className="w-full p-2 border rounded h-32"
            />
          </div>

          <div>
            <label className="block">Social Media Links (one per line)</label>
            <textarea
              value={formData.socialMediaLinks?.join('\n') || ''}
              onChange={(e: ChangeEvent<HTMLTextAreaElement>) => setFormData({
                ...formData,
                socialMediaLinks: e.target.value.split('\n').filter((link: string) => link.trim())
              })}
              className="w-full p-2 border rounded h-32"
            />
          </div>

          <div>
            <label className="block">Memory Retention Rate</label>
            <input
              type="range"
              min="0"
              max="1"
              step="0.1"
              value={formData.memoryRetentionRate}
              onChange={(e) => setFormData({...formData, memoryRetentionRate: parseFloat(e.target.value)})}
              className="w-full"
            />
            <span>{(formData.memoryRetentionRate * 100).toFixed(0)}%</span>
          </div>

          <div>
            <label className="block">Preferred Review Time</label>
            <select
              value={formData.preferredReviewTime}
              onChange={(e) => setFormData({...formData, preferredReviewTime: e.target.value})}
              className="w-full p-2 border rounded"
            >
              <option value="morning">Morning</option>
              <option value="afternoon">Afternoon</option>
              <option value="evening">Evening</option>
            </select>
          </div>

          <div>
            <label className="block">Profile Photo</label>
            <input
              type="file"
              accept="image/*"
              onChange={async (e: ChangeEvent<HTMLInputElement>) => {
                const file = e.target.files?.[0]
                if (file) {
                  const formData = new FormData()
                  formData.append('avatar', file)
                  try {
                    const response = await fetch('/api/users/profile/avatar', {
                      method: 'POST',
                      body: formData
                    })
                    if (!response.ok) throw new Error('Upload failed')
                    const { avatarUrl } = await response.json()
                    setUserData((prev: UserProfile | null) => prev ? {...prev, avatarUrl} : null)
                  } catch (err) {
                    setError(err instanceof Error ? err.message : 'Upload failed')
                  }
                }
              }}
              className="mt-1"
            />
          </div>

          <div className="flex gap-2">
            <button
              type="submit"
              className="bg-green-500 text-white px-4 py-2 rounded"
            >
              Save
            </button>
            <button
              type="button"
              onClick={() => setEditMode(false)}
              className="bg-gray-500 text-white px-4 py-2 rounded"
            >
              Cancel
            </button>
          </div>
        </form>
      )}
    </div>
  )
}
</file>

<file path="lib/ai-service.ts">
import { GoogleGenerativeAI } from '@google/generative-ai';
import { SpeechClient } from '@google-cloud/speech';
import { TextToSpeechClient } from '@google-cloud/text-to-speech';

// Client instances
export let geminiClient: GoogleGenerativeAI;
export let speechClient: SpeechClient;
export let textToSpeechClient: TextToSpeechClient;

// Initialize clients
if (process.env.GCP_CREDENTIALS_JSON) {
  const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
  geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY || '');
  speechClient = new SpeechClient({ credentials });
  textToSpeechClient = new TextToSpeechClient({ credentials });
} else {
  geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY || '');
  speechClient = new SpeechClient({ 
    keyFilename: process.env.GCP_CREDENTIALS_PATH || './gcp-credentials.json'
  });
  textToSpeechClient = new TextToSpeechClient({ 
    keyFilename: process.env.GCP_CREDENTIALS_PATH || './gcp-credentials.json'
  });
}

// Type definitions for AI service responses
export interface LessonContent {
  title: string;
  vocabulary: string[];
  dialogue: string;
  exercises: string[];
}

export interface TranscriptionResult {
  text: string;
  confidence: number;
}

export interface AudioSynthesisResult {
  audioContent: Buffer;
  mimeType: string;
}

export interface StreamingTranscriptionResult {
  transcript: string;
  confidence: number;
  isFinal: boolean;
}

export async function* streamingSpeechToText(languageCode: string = 'en-US') {
  const recognizeStream = speechClient.streamingRecognize({
    config: {
      encoding: 'WEBM_OPUS',
      sampleRateHertz: 48000,
      languageCode: languageCode,
      model: 'default',
    },
    interimResults: true, // This is correctly placed at the root level
  });

  // Handle errors
  recognizeStream.on('error', (e) => {
    throw new Error(`Speech recognition error: ${e.message}`);
  });

  // Yield transcription results as they come in
  recognizeStream.on('data', (data) => {
    if (data.results[0]?.alternatives[0]) {
      const result = {
        transcript: data.results[0].alternatives[0].transcript,
        confidence: data.results[0].alternatives[0].confidence || 0,
        isFinal: data.results[0].isFinal,
      };
      recognizeStream.emit('result', result);
    }
  });

  try {
    yield* (recognizeStream as unknown) as AsyncGenerator<StreamingTranscriptionResult>;
  } finally {
    recognizeStream.destroy();
  }
}

export async function textToSpeech(text: string): Promise<AudioSynthesisResult> {
  const [response] = await textToSpeechClient.synthesizeSpeech({
    input: { text },
    voice: {
      languageCode: 'en-US',
      ssmlGender: 'NEUTRAL'
    },
    audioConfig: {
      audioEncoding: 'MP3'
    }
  });

  if (!response.audioContent) {
    throw new Error('No audio content received from TTS service');
  }

  return {
    audioContent: Buffer.from(response.audioContent),
    mimeType: 'audio/mpeg'
  };
}
</file>

<file path="lib/auth-middleware.ts">
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: Replace remaining console.error with logger
import type { NextRequest } from 'next/server'
import { NextResponse } from 'next/server'
import { supabaseServerClient } from '@/lib/supabase/server'
import { checkRateLimit, trackLoginAttempt } from '@/lib/security'
import logger from '@/lib/logger'

export async function requireAuth(
  req: NextRequest,
  handler: (req: NextRequest, userId: string) => Promise<NextResponse>
) {
  const ip = req.headers.get('x-forwarded-for') || 'unknown'
  
  // Check rate limit
  const rateLimitResponse = checkRateLimit(ip)
  if (rateLimitResponse) {
    return rateLimitResponse
  }

  // Track login attempt
  const attempt = trackLoginAttempt(ip)
  if (!attempt.allowed) {
    return NextResponse.json(
      { error: attempt.message },
      { status: 429 }
    )
  }

  const supabase = supabaseServerClient()
  const { data: { user }, error } = await supabase.auth.getUser()

  if (error || !user) {
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    )
  }

  try {
    return await handler(req, user.id)
  } catch (err: unknown) {
    const error = err instanceof Error ? err : new Error('Unknown error')
    logger.error({ err: error }, 'Auth middleware error');
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}

export async function refreshSession() {
  const supabase = supabaseServerClient()
  const { data, error } = await supabase.auth.refreshSession()

  if (error) {
    throw error
  }

  return data
}

export async function withAuthMiddleware(handler: (req: NextRequest) => Promise<NextResponse>) {
  return async (req: NextRequest) => {
    const ip = req.headers.get('x-forwarded-for') || 'unknown'
    
    // Check rate limit
    const rateLimitResponse = checkRateLimit(ip)
    if (rateLimitResponse) {
      return rateLimitResponse
    }

    const supabase = supabaseServerClient()
    const { data: { session }, error } = await supabase.auth.getSession()

    if (error || !session) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      )
    }
    // ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: END

    // Check if access token is expired
    if (session.expires_at && session.expires_at * 1000 < Date.now()) {
      try {
        const newSession = await refreshSession()
        if (!newSession?.session) {
          return NextResponse.json(
            { error: 'Session expired' },
            { status: 401 }
          )
        }
      } catch (err: unknown) {
        logger.error({ err }, 'Session refresh error')
        return NextResponse.json(
          { error: 'Failed to refresh session' },
          { status: 401 }
        )
      }
    }

    return handler(req)
  }
}
</file>

<file path="work_breakdown/tasks/plan-005-ai-brain.md">
# AI Brain Implementation Plan

## Description
Implement the core AI modules for lesson design and language analysis.

## Tasks
- [x] (LOGIC) Develop Lesson Designer module:
  - Personalization algorithms
  - Content generation pipelines
  - Difficulty adjustment mechanisms
- [x] (LOGIC) Create Language Analyst:
  - Deep diagnostic capabilities
  - Pattern recognition engines
  - Error classification system
- [x] (UI) Design admin interface for AI module monitoring
- [x] (LOGIC) Implement API endpoints for AI service integration

## Technical Requirements
- Use Python for ML components (PyTorch)
- Create RESTful API for module communication
- Implement monitoring with Prometheus/Grafana
</file>

<file path="work_breakdown/tasks/plan-006-speech-processing.md">
# Speech Processing Implementation Plan

## Description
Implement speech processing capabilities including TTS, STT, and audio capture.

## Tasks
- [x] (LOGIC) Integrate TTS services:
  - Google Cloud Text-to-Speech
  - AWS Polly
- [x] (UI) Implement audio capture interface with:
  - Real-time waveform visualization
  - Quality monitoring indicators
- [x] (LOGIC) Develop STT processing pipeline:
  - Real-time transcription
  - Audio preprocessing
  - Error handling
- [x] (UI) Create audio playback controls for TTS output

## Technical Requirements
- Use Web Audio API for browser-based processing
- Implement fallback mechanisms for service failures
- Design audio quality monitoring system
</file>

<file path="work_breakdown/tasks/plan-009-lesson-structure.md">
# Lesson Structure Implementation Plan

## Description
Implement the lesson data model and associated management features.

## Tasks
- [x] (LOGIC) Define Prisma schema for lessons:
  - Content storage (prompts, expected responses)
  - Difficulty level tracking
  - Target concept mapping
- [x] (LOGIC) Create lesson generation endpoints
- [x] (LOGIC) Implement timestamp recording for lesson progress
- [x] (UI) Design lesson selection interface

## Technical Requirements
- Extend Prisma schema with lesson models
- Implement Zod validation for lesson content
- Create RESTful endpoints for lesson management
</file>

<file path="work_breakdown/tasks/plan-010-srs-tracking.md">
# SRS Item Tracking Implementation Plan

## Description
Implement the spaced repetition system for tracking concept mastery and review schedules.

## Tasks
- [x] (LOGIC) Design SRS item schema:
  - Concept ID mapping
  - Recall strength tracking
  - Review history logging
- [x] (LOGIC) Implement scheduling algorithm:
  - Next review date calculation
  - Mastery level adjustments
  - Difficulty scaling
- [x] (LOGIC) Create review session processing:
  - Response evaluation
  - Score updating
  - History recording
- [x] (UI) Design review session interface

## Technical Requirements
- Extend Prisma schema with SRS models
- Implement scheduling with node-cron
- Create RESTful endpoints for review operations
</file>

<file path="components/OnboardingForm.tsx">
// ROO-AUDIT-TAG :: audit_remediation_phase_1.md :: Replace console.log and connect to API
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: Replace placeholder user ID
import { useState, useEffect } from 'react';
import { useUser } from '@supabase/auth-helpers-react';
import logger from '@/lib/logger';

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  onresult: (event: SpeechRecognitionEvent) => void;
  onerror: (event: SpeechRecognitionErrorEvent) => void;
  start: () => void;
  stop: () => void;
}

interface SpeechRecognitionConstructor {
  new(): SpeechRecognition;
}

declare global {
  interface Window {
    SpeechRecognition: SpeechRecognitionConstructor;
    webkitSpeechRecognition: SpeechRecognitionConstructor;
  }
}

export default function OnboardingForm() {
  const user = useUser();
  const [formData, setFormData] = useState({
    nativeLanguage: '',
    targetLanguage: '',
    primaryGoal: '',
    comfortLevel: '',
    diagnosticText: ''
  });
  const [errors, setErrors] = useState<Record<string, string>>({});
  const [isRecording, setIsRecording] = useState(false);
  const [recognition, setRecognition] = useState<SpeechRecognition | null>(null);
  const [isSpeechSupported, setIsSpeechSupported] = useState(true);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (SpeechRecognition) {
        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        recognition.onresult = (event) => {
          const transcript = event.results[0][0].transcript;
          setFormData(prev => ({ ...prev, diagnosticText: transcript }));
        };

        recognition.onerror = () => {
          setIsSpeechSupported(false);
        };

        setRecognition(recognition);
      } else {
        setIsSpeechSupported(false);
      }
    }
  }, []);

  const validateForm = () => {
    const newErrors: Record<string, string> = {};
    if (!formData.nativeLanguage) newErrors.nativeLanguage = 'Required';
    if (!formData.targetLanguage) newErrors.targetLanguage = 'Required';
    if (!formData.primaryGoal) newErrors.primaryGoal = 'Required';
    if (!formData.comfortLevel || 
        Number(formData.comfortLevel) < 1 || 
        Number(formData.comfortLevel) > 5) {
      newErrors.comfortLevel = 'Must be between 1-5';
    }
    setErrors(newErrors);
    return Object.keys(newErrors).length === 0;
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (validateForm()) {
      logger.info({ formData }, 'Form submitted');
      try {
        const response = await fetch('/api/onboarding/create-profile', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            ...formData,
            userId: user?.id || '',
          }),
        });

        if (!response.ok) {
          throw new Error('Failed to submit onboarding data');
        }
      } catch (error) {
        logger.error({ error }, 'Onboarding submission failed');
      }
    }
  };

  const handleChange = (e: React.ChangeEvent<HTMLInputElement | HTMLSelectElement>) => {
    const { name, value } = e.target;
    setFormData(prev => ({ ...prev, [name]: value }));
  };

  const toggleRecording = () => {
    if (!recognition) return;
    
    if (isRecording) {
      recognition.stop();
    } else {
      setFormData(prev => ({ ...prev, diagnosticText: '' }));
      recognition.start();
    }
    setIsRecording(!isRecording);
  };

  return (
    <form onSubmit={handleSubmit} className="max-w-md mx-auto p-6 bg-white rounded-lg shadow-md">
      <h2 className="text-2xl font-bold mb-6 text-gray-800">Get Started</h2>
      
      <div className="mb-4">
        <label className="block text-gray-700 mb-2">Native Language</label>
        <input
          name="nativeLanguage"
          value={formData.nativeLanguage}
          onChange={handleChange}
          className="w-full p-2 border rounded-md"
        />
        {errors.nativeLanguage && <span className="text-red-500 text-sm">{errors.nativeLanguage}</span>}
      </div>

      <div className="mb-4">
        <label className="block text-gray-700 mb-2">Target Language</label>
        <input
          name="targetLanguage"
          value={formData.targetLanguage}
          onChange={handleChange}
          className="w-full p-2 border rounded-md"
        />
        {errors.targetLanguage && <span className="text-red-500 text-sm">{errors.targetLanguage}</span>}
      </div>

      <div className="mb-4">
        <label className="block text-gray-700 mb-2">Primary Learning Goal</label>
        <select
          name="primaryGoal"
          value={formData.primaryGoal}
          onChange={handleChange}
          className="w-full p-2 border rounded-md"
        >
          <option value="">Select a goal</option>
          <option value="conversation">Conversational Fluency</option>
          <option value="business">Business Communication</option>
          <option value="travel">Travel Preparation</option>
        </select>
        {errors.primaryGoal && <span className="text-red-500 text-sm">{errors.primaryGoal}</span>}
      </div>

      <div className="mb-4">
        <label className="block text-gray-700 mb-2">Current Comfort Level (1-5)</label>
        <input
          type="number"
          name="comfortLevel"
          value={formData.comfortLevel}
          onChange={handleChange}
          min="1"
          max="5"
          className="w-full p-2 border rounded-md"
        />
        {errors.comfortLevel && <span className="text-red-500 text-sm">{errors.comfortLevel}</span>}
      </div>

      <div className="mb-6">
        <label className="block text-gray-700 mb-2">Initial Voice Diagnostic</label>
        {isSpeechSupported ? (
          <>
            <button
              type="button"
              onClick={toggleRecording}
              className={`w-full p-2 rounded-md ${
                isRecording 
                  ? 'bg-red-500 hover:bg-red-600' 
                  : 'bg-green-500 hover:bg-green-600'
              } text-white mb-2`}
            >
              {isRecording ? 'Stop Recording' : 'Start Recording'}
            </button>
            {formData.diagnosticText && (
              <div className="p-2 border rounded-md bg-gray-50">
                <p className="text-gray-700">{formData.diagnosticText}</p>
              </div>
            )}
          </>
        ) : (
          <p className="text-red-500 text-sm">
            Speech recognition is not supported in your browser
          </p>
        )}
      </div>

      <button
        type="submit"
        className="w-full bg-blue-500 text-white p-2 rounded-md hover:bg-blue-600"
      >
        Continue
      </button>
    </form>
  );
}
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ESNext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noImplicitAny": true,
    "strictNullChecks": true,
    "strictFunctionTypes": true,
    "noImplicitThis": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "allowSyntheticDefaultImports": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts", "next.config.js", "src/config/performance.js"],
  "exclude": ["node_modules"]
}
</file>

<file path="app/api/lessons/[id]/submit-answer/route.ts">
// ROO-AUDIT-TAG :: audit_remediation_phase_1.md :: Implement scoring logic
import { NextResponse } from 'next/server'
import { supabaseServerClient } from '@/lib/supabase/server'
import { prisma } from '@/lib/prisma'
import logger from '@/lib/logger'
import type { Prisma } from '@prisma/client'

// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: Replace placeholder calculateScore function with real algorithm
function calculateScore(answer: string, currentScore: number): number {
  const trimmedAnswer = answer.trim();
  
  // Grammar evaluation (basic sentence structure)
  const grammarScore = trimmedAnswer.split(' ').length >= 3 ? 1 : 0.5;
  
  // Vocabulary evaluation (presence of key words)
  const hasKeyWords = /(please|thank you|greeting)/i.test(trimmedAnswer);
  const vocabularyScore = hasKeyWords ? 1 : 0.5;
  
  // Completeness evaluation
  const completenessScore = Math.min(trimmedAnswer.length / 15, 1); // Max 1 point for longer answers
  
  // Combine scores with weights
  const totalIncrement =
    (grammarScore * 0.4) + // 40% weight for grammar
    (vocabularyScore * 0.3) + // 30% weight for vocabulary
    (completenessScore * 0.3); // 30% weight for completeness
  
  // Calculate new score with smooth progression
  const newScore = currentScore + (totalIncrement * (5 - currentScore)/5);
  
  return Math.min(newScore, 5); // Cap at maximum score of 5
}
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: END

// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: Implement comprehensive answer validation
function validateAnswer(answer: string): boolean {
  const trimmed = answer.trim();
  
  // Minimum length requirement
  if (trimmed.length < 3) return false;
  
  // Should contain at least one space between words
  if (!trimmed.includes(' ')) return false;
  
  // Should start with a capital letter
  if (!/^[A-Z]/.test(trimmed)) return false;
  
  // Should end with proper punctuation
  if (!/[.!?]$/.test(trimmed)) return false;
  
  return true;
}
// ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: END

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  const supabase = supabaseServerClient()
  const { data: { user }, error } = await supabase.auth.getUser()

  if (error || !user) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
  }

  try {
    const { answer } = await request.json()
    const lessonId = params.id

    // Find the progress record first
    const existingProgress = await prisma.progress.findFirst({
      where: {
        userId: user.id,
        lessonId
      }
    })

    if (!existingProgress) {
      return NextResponse.json(
        { error: 'Progress record not found' },
        { status: 404 }
      )
    }

    // Update progress with the submitted answer
    // ROO-AUDIT-TAG :: plan-009-lesson-structure.md :: Calculate lesson duration
    const completedAt = new Date();
    const duration = Math.floor(
      (completedAt.getTime() - existingProgress.startedAt.getTime()) / 1000
    );
    
    const score = calculateScore(answer, existingProgress.score || 0);
    const updateData = {
      score,
      completedAt,
      duration,
      attempts: {
        increment: 1
      }
    } as Prisma.ProgressUpdateInput;
    // ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: END
    
    const progress = await prisma.progress.update({
      where: {
        id: existingProgress.id
      },
      data: updateData
    })
    // ROO-AUDIT-TAG :: audit_remediation_phase_2.md :: END

    // Validate answer (basic implementation)
    const isValid = validateAnswer(answer)

    return NextResponse.json({
      correct: isValid,
      progress
    })
  } catch (err) {
    logger.error({ err }, 'Error submitting answer')
    return NextResponse.json(
      { error: 'Failed to submit answer' },
      { status: 500 }
    )
  }
}
// ROO-AUDIT-TAG :: audit_remediation_phase_1.md :: END
</file>

<file path="app/api/users/profile/route.ts">
// ROO-AUDIT-TAG :: FIX_PLAN.md :: Update profile route to use NextAuth sessions
import { z } from 'zod';
import { prisma } from '@/lib/prisma';
import { NextResponse } from 'next/server';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth-options';

// ROO-AUDIT-TAG :: plan-011-non-functional.md :: Enhance profile validation
import { hashPassword, logSecurityEvent } from '@/lib/security';

const profileSchema = z.object({
  name: z.string().optional(),
  avatarUrl: z.string().url().optional().or(z.literal('')),
  targetLang: z.string().min(1, 'Target language is required'),
  nativeLang: z.string().min(1, 'Native language is required'),
  primaryGoal: z.string().min(1, 'Primary goal is required'),
  secondaryGoals: z.array(z.string()).optional(),
  comfortLevel: z.number().min(1).max(5).default(3),
  dailyTarget: z.number().min(5).max(240).default(15),
  studyPreferences: z.record(z.any()).optional(),
  memoryRetentionRate: z.number().min(0).max(1).default(0.7),
  preferredReviewTime: z.enum(['morning', 'afternoon', 'evening']).default('morning'),
  password: z.string().min(8, 'Password must be at least 8 characters').optional()
});
// ROO-AUDIT-TAG :: plan-008-user-profile.md :: END

export async function GET() {
  const session = await getServerSession(authOptions);
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const user = await prisma.user.findUnique({
    where: { id: session.user.id },
    select: {
      id: true,
      name: true,
      email: true,
      avatarUrl: true,
      targetLang: true,
      nativeLang: true,
      primaryGoal: true,
      secondaryGoals: true,
      comfortLevel: true,
      dailyTarget: true,
      studyPreferences: true,
      createdAt: true,
      updatedAt: true
    }
  });

  return NextResponse.json(user);
}

export async function PUT(request: Request) {
  const session = await getServerSession(authOptions);
  if (!session?.user?.id) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const body = await request.json();
  
  // Basic validation
  try {
    profileSchema.parse(body);
  } catch (error) {
    if (error instanceof Error) {
      return NextResponse.json(
        { error: 'Validation failed', details: error.message },
        { status: 400 }
      );
    }
    return NextResponse.json(
      { error: 'Unknown validation error' },
      { status: 400 }
    );
  }

  // Extract security context from request
  const ipAddress = request.headers.get('x-forwarded-for') || '';
  const userAgent = request.headers.get('user-agent') || '';

  // Define update data type
  interface UserUpdateData {
    name?: string;
    avatarUrl?: string;
    targetLang: string;
    nativeLang: string;
    primaryGoal: string;
    secondaryGoals: string[];
    comfortLevel: number;
    dailyTarget: number;
    studyPreferences: Record<string, unknown>;
    memoryRetentionRate: number;
    preferredReviewTime: string;
    password?: string;
  }

  // Prepare update data
  const updateData: UserUpdateData = {
    name: body.name,
    avatarUrl: body.avatarUrl,
    targetLang: body.targetLang,
    nativeLang: body.nativeLang,
    primaryGoal: body.primaryGoal,
    secondaryGoals: body.secondaryGoals || [],
    comfortLevel: body.comfortLevel || 3,
    dailyTarget: body.dailyTarget || 15,
    studyPreferences: body.studyPreferences || {},
    memoryRetentionRate: body.memoryRetentionRate,
    preferredReviewTime: body.preferredReviewTime
  };

  // Handle password update if provided
  if (body.password) {
    updateData.password = await hashPassword(body.password);
    await logSecurityEvent({
      userId: session.user.id,
      action: 'PASSWORD_CHANGE',
      ipAddress,
      userAgent
    });
  }

  const updatedUser = await prisma.user.update({
    where: { id: session.user.id },
    data: updateData,
    select: {
      id: true,
      name: true,
      email: true,
      avatarUrl: true,
      targetLang: true,
      nativeLang: true,
      primaryGoal: true,
      secondaryGoals: true,
      comfortLevel: true,
      dailyTarget: true,
      studyPreferences: true,
      updatedAt: true
    }
  });

  return NextResponse.json(updatedUser);
}
// ROO-AUDIT-TAG :: FIX_PLAN.md :: END
</file>

<file path="components/LessonView.tsx">
// ROO-AUDIT-TAG :: plan-002-lesson-delivery.md :: Implement real-time STT processing with feedback mechanisms
import { useState, useEffect, useRef } from 'react';
import ErrorHighlight from './feedback/ErrorHighlight';
import PronunciationMeter from './feedback/PronunciationMeter';
import GrammarCorrection from './feedback/GrammarCorrection';
import VocabularyValidation from './feedback/VocabularyValidation';

export default function LessonView() {
  const [userInput, setUserInput] = useState('');
  const [feedback, setFeedback] = useState<{
    text: string;
    errors: string[];
    confidence: number;
    grammarSuggestions?: GrammarSuggestion[];
    vocabularyValidations?: VocabularyValidation[];
  } | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (SpeechRecognition) {
        recognitionRef.current = new SpeechRecognition();
        recognitionRef.current.continuous = true;
        recognitionRef.current.interimResults = true;
        recognitionRef.current.lang = 'fr-FR'; // Example: French language

        recognitionRef.current.onresult = (event) => {
          const transcript = Array.from(event.results)
            .map(result => result[0])
            .map(result => result.transcript)
            .join('');
          setUserInput(transcript);
        };

        recognitionRef.current.onerror = (event: SpeechRecognitionErrorEvent) => {
          console.error('Speech recognition error', event.error, event.message);
          setFeedback({
            text: 'Speech recognition failed',
            errors: [],
            confidence: 0
          });
        };
      }
    }
  }, []);

  const toggleRecording = () => {
    if (!recognitionRef.current) return;
    
    if (!isRecording) {
      recognitionRef.current.start();
      setIsRecording(true);
    } else {
      recognitionRef.current.stop();
      setIsRecording(false);
      analyzeResponse();
    }
  };

  const analyzeResponse = () => {
    // Mock analysis - in real app this would call an API
    const errors = userInput.includes('bonjour') ? [] : ['bonjour'];
    const confidence = Math.random();
    
    // Mock grammar and vocabulary analysis
    const grammarSuggestions: GrammarSuggestion[] = !userInput.includes('comment')
      ? [{
          startIndex: userInput.indexOf('are'),
          endIndex: userInput.indexOf('are') + 3,
          message: 'Consider using "comment" instead of "are" in French',
          suggestedCorrection: 'comment'
        }]
      : [];

    const vocabularyValidations: VocabularyValidation[] = [
      {
        word: 'bonjour',
        isValid: userInput.includes('bonjour'),
        suggestions: ['bonjour', 'salut']
      },
      {
        word: 'comment',
        isValid: userInput.includes('comment'),
        suggestions: ['comment', 'comme']
      }
    ];
    
    setFeedback({
      text: userInput,
      errors,
      confidence,
      grammarSuggestions,
      vocabularyValidations
    });
  };

  return (
    <div className="flex flex-col h-full max-w-2xl mx-auto p-4 space-y-6">
      {/* Prompt Display Area */}
      <div className="bg-white rounded-lg p-4 shadow-md">
        <h2 className="text-xl font-semibold mb-2">Lesson Prompt</h2>
        <p className="text-gray-700">
          Translate this sentence to French: "Good morning, how are you?"
        </p>
      </div>

      {/* User Input Area */}
      <div className="bg-white rounded-lg p-4 shadow-md">
        <h2 className="text-xl font-semibold mb-2">Your Response</h2>
        <textarea
          value={userInput}
          onChange={(e) => setUserInput(e.target.value)}
          className="w-full p-2 border rounded-md min-h-[100px]"
          placeholder="Speak or type your response here..."
        />
        <div className="mt-2 flex space-x-2">
          <button
            className="bg-blue-500 text-white px-4 py-2 rounded-md hover:bg-blue-600"
            onClick={analyzeResponse}
          >
            Submit
          </button>
          <button
            className={`${isRecording ? 'bg-red-500' : 'bg-green-500'} text-white px-4 py-2 rounded-md hover:bg-opacity-80`}
            onClick={toggleRecording}
          >
            {isRecording ? 'Stop' : 'Record'}
          </button>
        </div>
      </div>

      {/* Feedback Panel */}
      <div className="bg-white rounded-lg p-4 shadow-md space-y-4">
        <h2 className="text-xl font-semibold mb-2">Feedback</h2>
        {feedback ? (
            <div className="space-y-4">
              <div className="text-gray-700">
                <ErrorHighlight text={feedback.text} errors={feedback.errors} />
              </div>
              <PronunciationMeter confidence={feedback.confidence} />
              
              {feedback.grammarSuggestions && (
                <GrammarCorrection
                  suggestions={feedback.grammarSuggestions}
                  userInput={feedback.text}
                />
              )}
  
              {feedback.vocabularyValidations && (
                <VocabularyValidation
                  validations={feedback.vocabularyValidations}
                />
              )}
  
              <div className="text-sm text-gray-500">
                {feedback.errors.length > 0
                  ? 'Try focusing on the highlighted words'
                  : 'Great job! Keep practicing!'}
              </div>
            </div>
        ) : (
          <div className="text-gray-700">Your feedback will appear here...</div>
        )}
      </div>
    </div>
  );
}
</file>

<file path="FIX_PLAN.md">
# Infrastructure Configuration Fix Plan

## Blocked Tasks
1. **Design for Scalability**
   - Implement cloud load balancer configuration
   - Set up auto-scaling groups in cloud provider
   - Configure database sharding with replication

2. **Ensure High Availability**
   - Design redundant architecture across availability zones
   - Implement failover mechanisms for critical services
   - Set up uptime monitoring and alerts

## Required Actions
- **Cloud Provider Setup**: Configure AWS/GCP/Azure resources
  - Load balancers
  - Auto-scaling policies
  - Multi-AZ database deployments
- **Kubernetes Configuration**:
  - Cluster auto-scaler
  - Horizontal pod auto-scaling
  - Resource quotas and limits
- **Database Optimization**:
  - Sharding configuration
  - Read replicas
  - Backup and recovery procedures
- **Monitoring**:
  - Prometheus/Grafana setup
  - Alerting rules for resource thresholds
  - Uptime checks

## Implementation Notes
- These tasks require cloud console access and infrastructure-as-code tools (Terraform/CloudFormation)
- Some configurations may need DevOps specialist intervention
- Post-implementation, run load tests to validate scalability
</file>

<file path="prisma/schema.prisma">
// ROO-AUDIT-TAG :: plan-011-non-functional.md :: Enhance schema for security measures
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

generator client {
  provider = "prisma-client-js"
}

model User {
  id           String @id @default(uuid())
  email        String @unique
  password     String // Will store hashed value
  name         String?
  avatarUrl    String?
  targetLang   String
  nativeLang   String
  primaryGoal  String
  secondaryGoals String[]
  comfortLevel Int
  dailyTarget  Int @default(15) // minutes
  studyPreferences Json?
  learningStyle String? @default("visual")
  progress     UserProgress[]
  srsEntries   SRSEntry[]
  lessons      Lesson[]
  voiceAnalyses VoiceAnalysis[]
  progressRecords Progress[]
  lessonAnalyses LessonAnalysis[]
  lessonAttempts LessonAttempt[]
  studySessions StudySession[]
  progressSnapshots ProgressSnapshot[]
  role          UserRole @default(USER)
  memoryRetentionRate Float? @default(0.7)
  preferredReviewTime String? @default("morning")
  createdAt    DateTime @default(now())
  updatedAt    DateTime @updatedAt
  auditLogs    AuditLog[]
}

model AuditLog {
  id        String   @id @default(uuid())
  userId    String
  user      User     @relation(fields: [userId], references: [id])
  action    String   // e.g., 'LOGIN', 'PROFILE_UPDATE'
  entity    String?  // e.g., 'User', 'Lesson'
  entityId  String?
  details   Json?
  ipAddress String?
  userAgent String?
  createdAt DateTime @default(now())
}

model LessonAnalysis {
  id               String   @id @default(cuid())
  lessonId         String
  user             User     @relation(fields: [userId], references: [id])
  userId           String
  accuracy         Float
  pronunciationScore Float?
  weakPoints       String[]
  createdAt        DateTime @default(now())
}

model Lesson {
  id          String   @id @default(uuid())
  title       String
  description String?
  content     Json
  difficulty  Int      @default(1)
  targetConcepts String[]
  language    String
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  exercises   Exercise[]
  completedAt DateTime?
  analysis    VoiceAnalysis[]
  progress    Progress[]
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
  @@index([userId, difficulty])
  @@index([userId, language])
}

model Exercise {
  id          String @id @default(uuid())
  type        String
  content     Json
  difficulty  Int
  language    String
  tags        String
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  lessonId    String
}

model UserProgress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  metric      String
  score       Float
  lastUpdated DateTime @default(now())
}

model Progress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  lessonId    String
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  completed   Boolean @default(false)
  score       Float?
  attempts    Int     @default(0)
  startedAt   DateTime @default(now())
  completedAt DateTime?
  duration    Int?
}

model SRSEntry {
  id             String @id @default(uuid())
  userId         String
  user           User @relation(fields: [userId], references: [id])
  item           String
  recallStrength Float @default(1.0)
  nextReview     DateTime @default(now())
  language       String
  ease           Float @default(2.5)
  interval       Int @default(1)
  masteryLevel   Int @default(1)
  consecutiveCorrect Int @default(0)
  lastReviewed   DateTime @default(now())
  @@index([userId, nextReview])
  @@index([userId, masteryLevel])
  reviews      SRSReview[]
}

model SRSReview {
  id           String   @id @default(uuid())
  srsEntryId   String
  srsEntry     SRSEntry @relation(fields: [srsEntryId], references: [id])
  reviewedAt   DateTime @default(now())
  score        Float
  responseTime Int
  difficulty   Float
  interval     Int
  easeFactor   Float
}

model VoiceAnalysis {
  id        String @id @default(uuid())
  userId    String
  user      User @relation(fields: [userId], references: [id])
  lessonId  String
  lesson    Lesson @relation(fields: [lessonId], references: [id])
  metrics   Json
  audioUrl  String
  createdAt DateTime @default(now())
}

model LessonAttempt {
  id             String   @id @default(cuid())
  userId         String
  user           User     @relation(fields: [userId], references: [id])
  createdAt      DateTime @default(now())
  phoneticScore  Float
  fluencyScore   Float
  grammarScore   Float
  vocabularyScore Float
  overallScore   Float
  weakAreas      String[]
}

model StudySession {
  id           String   @id @default(cuid())
  userId       String
  user         User     @relation(fields: [userId], references: [id])
  duration     Int
  itemsReviewed Int
  accuracy     Float
  newItems     Int
  createdAt    DateTime @default(now())
}

model ProgressSnapshot {
  id        String   @id @default(cuid())
  userId    String
  user      User     @relation(fields: [userId], references: [id])
  snapshot  String
  createdAt DateTime @default(now())
}

enum UserRole {
  USER
  ADMIN
  AUDITOR
}
</file>

<file path="package.json">
{
  "name": "app",
  "version": "0.1.0",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "test": "echo 'No tests yet' && exit 0"
  },
  "dependencies": {
    "@google-cloud/speech": "^7.1.0",
    "@google-cloud/text-to-speech": "^6.1.0",
    "@google/generative-ai": "^0.24.1",
    "@heroicons/react": "^2.2.0",
    "@prisma/client": "^6.9.0",
    "@stripe/react-stripe-js": "^3.7.0",
    "@stripe/stripe-js": "^7.3.1",
    "@supabase/auth-helpers-nextjs": "^0.6.0",
    "@supabase/auth-helpers-react": "^0.4.0",
    "@supabase/supabase-js": "^2.50.0",
    "bcryptjs": "^2.4.3",
    "chart.js": "^4.5.0",
    "pino": "^9.7.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-hot-toast": "^2.5.2",
    "redis": "^4.6.13",
    "stripe": "^18.2.1",
    "swr": "^2.3.3",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@next-auth/prisma-adapter": "^1.0.7",
    "@tailwindcss/postcss": "^4",
    "@types/bcryptjs": "^2.4.6",
    "@types/jsonwebtoken": "^9.0.9",
    "@types/next-auth": "^3.15.0",
    "@types/node": "^20.19.1",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@types/ws": "^8.18.1",
    "eslint": "^9",
    "eslint-config-next": "15.3.3",
    "next": "^15.3.3",
    "prisma": "^6.9.0",
    "tailwindcss": "^4",
    "ts-node": "^10.9.2",
    "typescript": "^5.8.3"
  }
}
</file>

</files>
