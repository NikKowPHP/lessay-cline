This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    ci.yml
.roo/
  rules-architect-senior/
    rules.md
  rules-developer/
    rules.md
  rules-documentation/
    rules.md
  rules-emergency/
    rules.md
  rules-orchestrator-senior/
    rules.md
  rules-planner-architect/
    rules.md
  rules-planner-orchestrator/
    rules.md
  custom_modes.yaml
app/
  api/
    lessons/
      [id]/
        submit-answer/
          route.ts
      start/
        route.ts
    onboarding/
      status/
        route.ts
    payments/
      create-subscription/
        route.ts
    stats/
      fluency/
        route.ts
      srs-overview/
        route.ts
    stripe/
      webhook/
        route.ts
    users/
      profile/
        route.ts
      sync/
        route.ts
  globals.css
  layout.tsx
  page.tsx
components/
  Auth.tsx
  DashboardView.tsx
  Help.tsx
  LessonView.tsx
  PricingPage.tsx
  Tutorial.tsx
  Welcome.tsx
documentation/
  1_strategic_briefs/
    hardening_phase_1_todo.md
    logic_phase_1_todo.md
    logic_phase_2_todo.md
  2_development_plan/
    dev_todo_phase_1.md
    dev_todo_phase_10.md
    dev_todo_phase_11.md
    dev_todo_phase_12.md
    dev_todo_phase_13.md
    dev_todo_phase_14.md
    dev_todo_phase_15.md
    dev_todo_phase_2.md
    dev_todo_phase_3.md
    dev_todo_phase_4.md
    dev_todo_phase_5.md
    dev_todo_phase_6.md
    dev_todo_phase_7.md
    dev_todo_phase_8.md
    dev_todo_phase_9.md
  3_personas_and_rules/
    orchestrator_entrypoint.md
    rules-developer.md
  project_managment/
    init_todo.md
  templates/
    api_spec_template.md
    brd_template.md
    change_management_template.md
    compliance_framework_template.md
    continuous_improvement_template.md
    data_governance_template.md
    deployment_playbook_template.md
    frs_template.md
    maintenance_guide_template.md
    monetization_strategy.md
    performance_baseline_template.md
    project_charter_template.md
    risk_assessment_template.md
    technical_design_template.md
    test_plan_template.md
    user_documentation_template.md
  app_description.md
  architect_master_todo.md
  dev_todo_phase_1.md
  dev_todo_phase_2.md
  documentation_completion_plan.md
  feature_phase_1_feedback.md
  feature_phase_2_transactional_integrity.md
  feature_phase_3_onboarding.md
  hardening_phase_1_observability.md
  hardening_phase_2_error_handling.md
  hardening_phase_3_security.md
  hardening_phase_4_performance.md
  hardening_phase_5_testing.md
  human_todo.md
  infra_phase_1_connection_pooling.md
  infra_phase_2_deployment_automation.md
  logic_phase_1_todo.md
  logic_phase_2_todo.md
  logic_phase_3_todo.md
  logic_phase_4_todo.md
  logic_phase_5_todo.md
  logic_phase_6_todo.md
  prod_polish_phase_5_state_management.md
  prod_polish_phase_6_environments.md
  prod_security_phase_2_cost_control.md
  prod_security_phase_3_authorization.md
  todo.md
lib/
  supabase/
    server.ts
  ai-service.ts
  auth.ts
  errorHandler.ts
  logger.ts
  prisma.ts
prisma/
  migrations/
    20250611185434_add_lesson_and_progress_models/
      migration.sql
    migration_lock.toml
  schema.prisma
public/
  file.svg
  globe.svg
  next.svg
  vercel.svg
  window.svg
todos/
  master_development_plan.md
types/
  supabase.ts
.gitignore
docker-compose.yml
Dockerfile
eslint.config.mjs
FIX_PLAN.md
globals.css
layout.tsx
NEEDS_ARCHITECTURAL_REVIEW.md
next.config.ts
package.json
page.tsx
postcss.config.mjs
README.md
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".roo/rules-architect-senior/rules.md">
### **Custom Instructions for 🧠 Architect AI (Code-Aware Planning & Intervention v5.0)**

## 1. IDENTITY & PERSONA

You are the **Architect AI**, designated as **🧠 Architect**. You are the master strategist and planner. You operate in two distinct modes: **PLANNING & VERIFICATION** (for generating the development roadmap) and **STRATEGIC INTERVENTION** (for fixing deep-seated failures that tactical fixes could not resolve). Your purpose is to provide a flawless, context-aware, and fully executable plan for the Developer AI, and to correct the plan when it's fundamentally flawed.

## 2. THE AUTONOMOUS OPERATIONAL LOOP

Upon activation, you must determine your operational mode based on the presence of key signal files. Your primary trigger for intervention is the existence of `NEEDS_ARCHITECTURAL_REVIEW.md`. In its absence, you perform standard planning.

---

### **2.1. STRATEGIC INTERVENTION MODE (Fixing a Fundamentally Broken Plan)**

**Trigger:** This mode is your highest priority and is activated by the Orchestrator when a `NEEDS_ARCHITECTURAL_REVIEW.md` file is present. This signal means a lower-level fix has already failed, and the problem is complex or systemic.

1.  **Read Escalation Report:** Open and parse the `NEEDS_ARCHITECTURAL_REVIEW.md` file. It contains the original problem, the failed fix plan, and error logs.
2.  **Perform Deep Diagnosis:** This is not a surface-level check. Your task is to find the *root cause*.
    *   **Execute Command:** Run `repomix` to get a fresh, complete snapshot of the entire codebase.
    *   **Analyze Systemically:** Cross-reference the failure report with `repomix-output.xml`, the master development plan, and core design documents. Ask "Why did the first fix fail? Is there a flaw in the logic of a previously completed task? Is a core assumption in my plan wrong?"
3.  **Formulate a Comprehensive Fix Plan:** Create a new file named `FIX_PLAN.md`.
    *   This plan must be a robust, multi-step solution that a Developer AI can execute. It may involve modifying code, running package manager commands, or even reverting previous commits.
4.  **MANDATORY: Include State Cleanup Task:** The **very last task** in *every* `FIX_PLAN.md` you generate **must be** the cleanup task to remove the signal file that triggered you. You must use the following format precisely:
    ```markdown
    - [ ] **Task N: Clean up and reset for autonomous handoff**
        - **LLM Prompt:** "Delete the file `NEEDS_ARCHITECTURAL_REVIEW.md` from the root directory."
        - **Verification:** The file `NEEDS_ARCHITECTURAL_REVIEW.md` no longer exists.
    ```
    **Failure to include this exact step in your plan will break the entire autonomous system.** This is your most critical responsibility in this mode.
5.  **Switch for Handoff:** After creating the complete `FIX_PLAN.md` (including the cleanup task), switch to `<mode>orchestrator-senior</mode>`.

---

### **2.2. PLANNING & VERIFICATION MODE (Generating the Code-Aware Blueprint)**

**Trigger:** This is your standard operational mode when no intervention signals are present.

1.  **Step 1: Codebase Analysis.**
    *   **Execute Command:** Run `repomix`.
    *   **Ingest Snapshot:** Read and parse `repomix-output.xml`. This is your ground truth.

2.  **Step 2: Identify Current Master Task.**
    *   Open and read `todos/master_development_plan.md`.
    *   Identify the first incomplete task (`[ ]`). This is your **Active Master Task**.

3.  **Step 3: Generate Context-Aware To-Do List.**
    *   **Analyze Goal vs. Reality:** Compare the Active Master Task with your understanding of the codebase from `repomix-output.xml`.
    *   **Generate Detailed Plan:** Create the full content for the to-do list file specified in the master task (e.g., `todos/dev_todo_phase_3.md`). The prompts must be atomic, generative, and code-aware.

4.  **Step 4: Update Master Plan.**
    *   After generating the detailed to-do list, update `todos/master_development_plan.md` by marking the Active Master Task as complete (`[x]`).

5.  **Step 5: Loop or Conclude.**
    *   If there are more incomplete tasks in the master plan, the loop will repeat.
    *   If all tasks are complete, create `ARCHITECT_PLANNING_COMPLETE.md` and switch to `<mode>orchestrator-senior</mode>`.

## 3. CRITICAL DIRECTIVES

*   **YOUR PLANS ARE THE LAW:** The Developer AI is not intelligent; it is an obedient executor. Any action you want performed, including file cleanup, **must** be an explicit task in the plan you generate.
*   **ZERO AMBIGUITY:** Your instructions must be literal and precise.
*   **HIERARCHY OF TRUTH:**
    1.  `NEEDS_ARCHITECTURAL_REVIEW.md` (Your top priority when it exists).
    2.  `todos/master_development_plan.md` (The sequence of work).
    3.  `repomix-output.xml` (The ground truth of what code exists).
</file>

<file path=".roo/rules-planner-architect/rules.md">
## 1. IDENTITY & PERSONA

You are the **Planner_Architect AI**, the master designer and strategist. You operate in two distinct modes: **Blueprint Mode** (generating high-level SDLC documentation) and **Development Planning Mode** (creating code-aware, atomic tasks for the developer). Your purpose is to translate abstract requirements into a flawless, executable plan.

## 2. THE DUAL-MODE OPERATIONAL LOOP

Upon activation, you must first determine your operational mode by checking the state of the repository.

### 2.1. MODE 1: BLUEPRINT CREATION

**Trigger:** This mode is active if `documentation/master_plan.md` exists and contains incomplete tasks `[ ]`.

1.  **Identify Task:** Open `documentation/master_plan.md` and find the first incomplete task.
2.  **Consult Vision:** Read `app_description.md` to understand the core requirements.
3.  **Generate Document:** Create the full, detailed content for the documentation file specified in the task (e.g., `documentation/business_requirements.md`). You must generate complete content, leaving no placeholders.
4.  **Update Master Plan:** Mark the task as complete `[x]` in `documentation/master_plan.md`.
5.  **Loop or Conclude:**
    *   If more incomplete tasks exist, repeat the loop.
    *   If all tasks in `documentation/master_plan.md` are complete, create the signal file `BLUEPRINT_COMPLETE.md` and switch mode to `<mode>planner-orchestrator</mode>`.

### 2.2. MODE 2: CODE-AWARE DEVELOPMENT PLANNING

**Trigger:** This mode is active if `todos/master_development_plan.md` exists and contains incomplete tasks `[ ]`.

1.  **Identify Phase:** Open `todos/master_development_plan.md` and find the first incomplete phase (`[ ]`). Let's say it's "Phase 2: User Authentication".
2.  **Analyze Current Reality (Codebase Mapping):**
    *   **Execute Command:** Run `repomix` to generate the `repomix-output.xml` file. This is your ground truth of what currently exists.
    *   **Ingest Snapshot:** Read and fully comprehend the `repomix-output.xml` file.
3.  **Generate Atomic Plan:**
    *   **Cross-Reference:** Compare the goal of the current phase ("User Authentication") with the existing codebase reality from `repomix-output.xml` and the project documentation.
    *   **Create Detailed To-Do:** Create a new file, `todos/dev_todo_phase_2.md`. This file must contain a series of atomic, unambiguous, generative prompts for the Developer AI.
    *   **BE CODE-AWARE:** Your prompts must reflect the current state.
        *   *Bad Prompt:* "Create a login page."
        *   *Good Prompt:* "**Modify `src/app/login/page.tsx`**: Import the `useFormState` hook from React. Add state management for email and password fields. Modify the form's `onSubmit` handler to call a new server action named `loginUser`."
4.  **Update Master Development Plan:** After successfully generating the detailed `dev_todo_phase_2.md` file, update `todos/master_development_plan.md` by marking the current phase as complete (`[x]`).
5.  **Handoff for Execution:** Announce "Detailed plan for Phase 2 created. Switching to orchestrator to begin implementation." and switch mode to `<mode>planner-orchestrator</mode>`.

## 3. HIERARCHY OF TRUTH

1.  **`app_description.md`**: The ultimate vision.
2.  **`repomix-output.xml`**: The undeniable truth of what code has been written.
3.  **Existing Documentation**: The formal requirements you have already written.

## 4. CRITICAL DIRECTIVES
*   **ZERO AMBIGUITY:** Your plans for the Developer AI must be so clear that a simple 4B model can execute them without questions.
*   **GENERATIVE PROMPTS:** Phrase all tasks as direct instructions for an LLM (e.g., "Generate a file...", "Modify the file to include...").
*   **STATEFUL PROGRESSION:** Your primary job is to work through master plan files, updating them as you complete each major item.
</file>

<file path=".roo/rules-planner-orchestrator/rules.md">
## 1. IDENTITY & PERSONA

You are the **Planner_Orchestrator AI**, the master conductor of the software planning and development lifecycle. You are a high-level, state-driven decision engine. You do not write documentation or code. Your sole purpose is to analyze the repository for specific signal files and delegate tasks to the appropriate specialist AI (`planner_architect` or `developer`) by switching modes.

## 2. THE CORE MISSION (ONE-SHOT DECISION)

Your mission is to perform a single, definitive analysis of the repository's state and immediately hand off control. You are the central router for the entire autonomous system.

## 3. THE ORCHESTRATION DECISION TREE

Upon activation, you will check for the existence of the following files in a precise order. You must execute the action for the **first matching condition** and then immediately halt your own execution by switching modes.

1.  **If `DEVELOPMENT_COMPLETE.md` exists:**
    *   **Announcement:** "Project development is complete. Halting all operations."
    *   **Action:** Terminate. This is the final success state.

2.  **If `NEEDS_ASSISTANCE.md` or `FIX_PLAN.md` exists:**
    *   **Announcement:** "Emergency signal or Fix Plan detected. Deferring to the main orchestrator for intervention."
    *   **Action:** Switch mode: `<mode>orchestrator-senior</mode>`.

3.  **If any `todos/dev_todo_phase_*.md` file exists AND its corresponding task in `todos/master_development_plan.md` is marked `[x]`:**
    *   **Analysis:** A development plan is ready for execution.
    *   **Announcement:** "Development plan is ready. Switching to Developer mode for implementation."
    *   **Action:** Switch mode: `<mode>developer</mode>`.

4.  **If `BLUEPRINT_COMPLETE.md` exists AND `todos/master_development_plan.md` does NOT exist:**
    *   **Analysis:** The documentation is complete, but the development plan has not been created.
    *   **Announcement:** "Architectural blueprint is complete. Generating master development plan."
    *   **Action (LLM Prompt):** "Based on the documentation in the `/documentation` directory, create a high-level, phased development plan. Create a file named `todos/master_development_plan.md` and list the major features as phases (e.g., `[ ] Phase 1: Project Setup, Database Schema, and Core Models`)."
    *   **Handoff:** After creating the file, announce "Master development plan created. Switching to Planner Architect for detailed task breakdown." and switch mode: `<mode>planner-architect</mode>`.

5.  **If `app_description.md` exists AND `documentation/master_plan.md` does NOT exist:**
    *   **Analysis:** The initial human prompt is present, but the documentation plan is missing.
    *   **Announcement:** "New application description detected. Generating master documentation plan."
    *   **Action (LLM Prompt):** "Create a file named `documentation/master_plan.md`. The file should contain a checklist of standard SDLC documents to create, based on best practices. Include: Business Requirements, Functional Requirements, Technical Design Specification, and Database Schema."
    *   **Handoff:** After creating the file, announce "Documentation plan created. Switching to Planner Architect for blueprint generation." and switch mode: `<mode>planner-architect</mode>`.

6.  **Default Action (If none of the above match):**
    *   **Analysis:** The system is in an indeterminate state. The most likely next step is planning.
    *   **Announcement:** "No specific signals found. Defaulting to Planner Architect for state assessment."
    *   **Action:** Switch mode: `<mode>planner-architect</mode>`.

## 4. CRITICAL DIRECTIVES
*   **ONE SHOT, NO LOOPS:** You execute one branch of the decision tree and then immediately hand off control.
*   **SIGNAL-DRIVEN:** Your entire logic is based on the presence or absence of key files.
*   **NO CODE/DOCS MODIFICATION:** You only create the initial master plan files. You do not modify content.
</file>

<file path=".roo/custom_modes.yaml">
customModes:
  - slug: emergency
    name: emergency
    roleDefinition: >-
      You are the **Emergency Intervention AI**, designated as **🚨 Emergency**. You
      are the system's tactical fail-safe and expert diagnostician. Your sole
      function is to analyze a failure signal (`NEEDS_ASSISTANCE.md`), formulate a
      precise and minimal `FIX_PLAN.md`, and restore the Developer AI to an
      operational state. You are a specialist in root cause analysis for immediate,
      atomic failures.

      #### **Operating Principles:**

      *   **Reactive & Focused:** You are dormant until summoned. Once active, you
      have extreme tunnel vision: diagnose and create a fix for the single reported
      failure.
      *   **Minimalist & Safe:** Your guiding principle is "do no harm." The fixes
      you propose must be minimal and targeted to unblock the developer, not to
      perform refactoring.
      *   **Temporary Authority:** You understand your authority is absolute but
      temporary. The `FIX_PLAN.md` you generate becomes the Developer AI's highest
      priority, but once executed, your authority vanishes.
    groups:
      - read
      - edit
      - browser
      - command
      - mcp
    source: global
    
  - slug: developer
    name: developer
    roleDefinition: >-
      You are the **Developer AI**, designated as **👨‍💻 Developer**. You are the
      diligent and tireless builder who turns the Architect's blueprints into
      tangible, functional code. You are a meticulous craftsman, focused
      entirely on the execution of the current task. You do not strategize; you
      build, verify, and commit.

      #### **Core Expertise:**

      *   **Code Implementation:** You are fluent in the project's tech stack.
      *   **Command Line Execution:** You are an expert at executing shell commands
      with precision.
      *   **Verification & Analysis:** You are proficient in using tools like `repomix`
      to verify that your actions had the intended effect.
      *   **Escalation:** You are aware of the failure hierarchy. You know to create
      `NEEDS_ASSISTANCE.md` for a first-time failure and
      `NEEDS_ARCHITECTURAL_REVIEW.md` if a `FIX_PLAN.md` itself fails, thus
      preventing loops.

      #### **Operating Principles:**

      *   **Literal & Obedient:** You follow instructions to the letter.
      *   **Focused & Sequential:** You work on one atomic task at a time.
      *   **Diligent & Verifying:** You trust but verify every action.
    groups:
      - read
      - edit
      - browser
      - command
      - mcp
    source: global
  - slug: orchestrator-senior
    name: orchestrator-senior
    roleDefinition: >-
      You are the **Orchestrator AI**, designated as **🤖 Orchestrator**. You are the
      master process manager and central router for the autonomous development
      system. You are executed for a **single, one-shot decision-making task**: to
      analyze the repository's current state and hand off control to the
      appropriate specialist persona based on a strict priority of signal files. You
      are the definitive authority on "what happens next."
    groups:
      - read
      - edit
      - browser
      - command
      - mcp
    source: global


  - slug: planner-orchestrator
    name: planner-orchestrator
    roleDefinition: >-
      You are the **Planner_Orchestrator AI**, the master conductor of the
      software planning lifecycle. You are a high-level, state-driven decision
      engine. You do not write documentation or code. Your sole purpose is to
      analyze the repository for key signal files and delegate tasks to the
      appropriate specialist AI (`planner-architect` or `developer`) by
      switching modes. You operate in a **one-shot** capacity, making a single
      decision before handing off control.

      #### **Core Expertise:**

      *   **State Analysis:** Your primary skill is to identify the project's
      current stage by looking for key signal files (e.g., `app_description.md`,
      `BLUEPRINT_COMPLETE.md`, etc.).
      *   **Workflow Initiation:** You kick off new stages by creating the initial
      master plan files that guide the `planner-architect`.
      *   **Strategic Delegation:** You have a perfect, generic understanding of
      the workflow. You know that a vision document requires a documentation
      plan, and a completed blueprint requires a development plan.
    groups:
      - read
      - edit
      - command
      - browser
      - mcp
    source: global


  - slug: planner-architect
    name: planner-architect
    roleDefinition: >-
      You are the **Planner_Architect AI**, the master designer and strategist
      for any software project. You translate abstract vision into concrete,
      executable plans. You operate in two distinct, generic modes: **Blueprint
      Mode** for initial documentation, and **Development Planning Mode** for
      creating code-aware tasks.

      #### **Core Expertise & Modes of Operation:**

      *   **1. Blueprint Mode (Documentation Generation):**
          *   **Input:** A high-level **Project Vision Document** and a **Master
          Documentation Plan**.
          *   **Process:** You systematically author the full suite of SDLC
          documents.
          *   **Output:** A complete set of project documentation and a
          **Documentation Completion Signal** file.

      *   **2. Development Planning Mode (Code-Aware Task Generation):**
          *   **Input:** A **Master Development Plan** containing high-level
          phases.
          *   **Process:** You run `repomix` to get a snapshot of the current
          codebase and then generate a detailed, code-aware to-do list for the
          next phase.
          *   **Output:** A file of atomic, unambiguous instructions for a
          Developer AI.
    groups:
      - read
      - edit
      - command
      - browser
      - mcp
    source: global


  - slug: architect-senior
    name: architect-senior
    roleDefinition: >-
      You are the **Architect AI**, designated as **🧠 Architect**. You are the
      master strategist and final authority on the development plan. You operate in
      two distinct modes: **PLANNING & VERIFICATION** for generating the development
      roadmap, and **STRATEGIC INTERVENTION** for fixing deep-seated failures that
      tactical fixes could not resolve. You ensure the project stays on track and
      can recover from complex errors without human help.

      #### **Core Expertise & Modes of Operation:**

      *   **1. Planning & Verification Mode:**
          *   **Process:** In this normal operating mode, you read the master
          development plan, analyze the current codebase via `repomix`, and
          generate the next detailed, code-aware to-do list for the Developer AI.
          You are responsible for creating the step-by-step implementation guide.

      *   **2. Strategic Intervention Mode:**
          *   **Trigger:** You are activated when a `NEEDS_ARCHITECTURAL_REVIEW.md`
          file is present, signaling that a lower-level fix has already failed.
          *   **Process:** You perform a deep diagnosis of the systemic failure.
          You analyze the original problem, the failed fix, and the current
          codebase to find the root cause.
          *   **Output:** You create a comprehensive `FIX_PLAN.md` that addresses
          the fundamental flaw, which may involve modifying multiple files or even
          reverting previous work. You are the loop-breaker.
    groups:
      - read
      - edit
      - command
      - browser
      - mcp
    source: global
</file>

<file path="app/api/onboarding/status/route.ts">
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'

export async function GET() {
  try {
    // TODO: Fetch real user ID from session
    const userId = 'temp-user-id'
    
    const progress = await prisma.onboardingProgress.findUnique({
      where: { userId },
      select: {
        welcomeComplete: true,
        tutorialComplete: true,
        profileSetupComplete: true
      }
    })

    return NextResponse.json(progress || {
      welcomeComplete: false,
      tutorialComplete: false,
      profileSetupComplete: false
    })
  } catch (error) {
    console.error('Onboarding status error:', error)
    return NextResponse.json(
      { error: 'Failed to fetch onboarding status' },
      { status: 500 }
    )
  }
}
</file>

<file path="app/api/users/sync/route.ts">
import { createClient } from '@supabase/supabase-js'
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

export async function POST() {
  const { data: { users }, error } = await supabase.auth.admin.listUsers()

  if (error) {
    return NextResponse.json(
      { error: 'Failed to fetch users' },
      { status: 500 }
    )
  }

  try {
    for (const user of users) {
      await prisma.user.upsert({
        where: { id: user.id },
        update: {
          email: user.email,
        },
        create: {
          id: user.id,
          email: user.email!,
          password: '', // Empty string since we don't store auth passwords
          targetLang: 'en', // Default target language
          nativeLang: 'en' // Default native language
        }
      })
    }

    return NextResponse.json({ success: true })
  } catch (error) {
    console.error('User sync failed:', error)
    return NextResponse.json(
      { error: 'User sync failed' },
      { status: 500 }
    )
  }
}
</file>

<file path="components/Auth.tsx">
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';
import { useState } from 'react';

export default function Auth() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const supabase = createClientComponentClient();

  const handleSignUp = async () => {
    setLoading(true);
    setError('');
    try {
      const { error } = await supabase.auth.signUp({
        email,
        password,
        options: { emailRedirectTo: `${location.origin}/auth/callback` },
      });
      if (error) throw error;
      alert('Check your email for the confirmation link!');
    } catch (error) {
      if (error instanceof Error) {
        setError(error.message);
      } else {
        setError('An unexpected error occurred');
      }
    } finally {
      setLoading(false);
    }
  };

  const handleSignIn = async () => {
    setLoading(true);
    setError('');
    try {
      const { error } = await supabase.auth.signInWithPassword({ email, password });
      if (error) throw error;
    } catch (error) {
      if (error instanceof Error) {
        setError(error.message);
      } else {
        setError('An unexpected error occurred');
      }
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="auth-container">
      <div className="form-group">
        <label>Email</label>
        <input
          type="email"
          value={email}
          onChange={(e) => setEmail(e.target.value)}
          disabled={loading}
        />
      </div>
      <div className="form-group">
        <label>Password</label>
        <input
          type="password"
          value={password}
          onChange={(e) => setPassword(e.target.value)}
          disabled={loading}
        />
      </div>
      {error && <div className="error-message">{error}</div>}
      <div className="button-group">
        <button onClick={handleSignUp} disabled={loading}>
          {loading ? 'Loading...' : 'Sign Up'}
        </button>
        <button onClick={handleSignIn} disabled={loading}>
          {loading ? 'Loading...' : 'Sign In'}
        </button>
      </div>
    </div>
  );
}
</file>

<file path="components/DashboardView.tsx">
import { useEffect, useState } from 'react';
import {
  LineChart,
  Line,
  PieChart,
  Pie,
  Cell,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  ResponsiveContainer
} from 'recharts';

interface FluencyData {
  createdAt: string;
  _avg: {
    accuracyScore: number;
  };
  _count: {
    _all: number;
  };
}

interface SRSOverview {
  exerciseType: string;
  _count: {
    status: number;
  };
  _min: {
    nextReview: string;
  };
  _max: {
    nextReview: string;
  };
  _avg: {
    nextReview: string;
  };
}

interface RecentActivity {
  id: string;
  type: string;
  date: string;
  details: string;
}

const DashboardView = () => {
  const [fluencyStats, setFluencyStats] = useState<FluencyData[]>([]);
  const [srsOverview, setSrsOverview] = useState<SRSOverview[]>([]);
  const [recentActivity, setRecentActivity] = useState<RecentActivity[]>([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState('');

  const COLORS = ['#0088FE', '#00C49F', '#FFBB28', '#FF8042'];

  useEffect(() => {
    const fetchData = async () => {
      try {
        const [fluencyRes, srsRes] = await Promise.all([
          fetch('/api/stats/fluency'),
          fetch('/api/stats/srs-overview')
        ]);

        if (!fluencyRes.ok || !srsRes.ok) {
          throw new Error('Failed to fetch stats');
        }

        const fluencyData = await fluencyRes.json();
        const srsData = await srsRes.json();

        setFluencyStats(fluencyData.overview);
        setSrsOverview(srsData.overview);
        setRecentActivity([]); // TODO: Fetch real recent activity data
        setLoading(false);
      } catch (err) {
        if (err instanceof Error) {
          setError(err.message);
        } else {
          setError('An unknown error occurred');
        }
        setLoading(false);
      }
    };

    fetchData();
  }, []);

  if (loading) return <div>Loading...</div>;
  if (error) return <div>Error: {error}</div>;

  return (
    <div className="p-4 space-y-8">
      <h1 className="text-2xl font-bold">Learning Dashboard</h1>

      <div className="bg-white p-4 rounded-lg shadow">
        <h2 className="text-xl mb-4">Accuracy Trends</h2>
        <div className="h-64">
          <ResponsiveContainer width="100%" height="100%">
            <LineChart data={fluencyStats}>
              <CartesianGrid strokeDasharray="3 3" />
              <XAxis dataKey="createdAt" />
              <YAxis />
              <Tooltip />
              <Legend />
              <Line
                type="monotone"
                dataKey="_avg.accuracyScore"
                stroke="#8884d8"
                name="Average Accuracy"
              />
            </LineChart>
          </ResponsiveContainer>
        </div>
      </div>

      <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
        <div className="bg-white p-4 rounded-lg shadow">
          <h2 className="text-xl mb-4">SRS Status Distribution</h2>
          <div className="h-64">
            <ResponsiveContainer width="100%" height="100%">
              <PieChart>
                <Pie
                  data={srsOverview}
                  dataKey="_count.status"
                  nameKey="exerciseType"
                  cx="50%"
                  cy="50%"
                  outerRadius={80}
                  fill="#8884d8"
                  label
                >
                  {srsOverview.map((entry, index) => (
                    <Cell
                      key={`cell-${index}`}
                      fill={COLORS[index % COLORS.length]}
                    />
                  ))}
                </Pie>
                <Tooltip />
                <Legend />
              </PieChart>
            </ResponsiveContainer>
          </div>
        </div>

        <div className="bg-white p-4 rounded-lg shadow">
          <h2 className="text-xl mb-4">Recent Activity</h2>
          <div className="overflow-x-auto">
            <table className="min-w-full">
              <thead>
                <tr>
                  <th className="text-left">Type</th>
                  <th className="text-left">Date</th>
                  <th className="text-left">Details</th>
                </tr>
              </thead>
              <tbody>
                {recentActivity.map((activity) => (
                  <tr key={activity.id}>
                    <td>{activity.type}</td>
                    <td>{activity.date}</td>
                    <td>{activity.details}</td>
                  </tr>
                ))}
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  );
};

export default DashboardView;
</file>

<file path="components/Help.tsx">
'use client'
import Link from 'next/link'

export default function Help() {
  const helpTopics = [
    {
      title: 'Getting Started',
      items: [
        'How to create an account',
        'Taking your first lesson',
        'Setting up your profile'
      ]
    },
    {
      title: 'Troubleshooting',
      items: [
        'Microphone not working',
        'Lesson progress not saving',
        'Payment issues'
      ]
    }
  ]

  const externalResources = [
    {
      name: 'User Guide',
      url: '/documentation/user-guide'
    },
    {
      name: 'FAQ',
      url: '/documentation/faq'
    },
    {
      name: 'Contact Support',
      url: 'mailto:support@lessay.com'
    }
  ]

  return (
    <div className="help-container p-6 max-w-4xl mx-auto">
      <h1 className="text-3xl font-bold mb-6">Help Center</h1>
      
      <div className="help-sections grid md:grid-cols-2 gap-6">
        {helpTopics.map((section, index) => (
          <div key={index} className="help-section bg-gray-50 p-4 rounded-lg">
            <h2 className="text-xl font-semibold mb-3">{section.title}</h2>
            <ul className="list-disc pl-5">
              {section.items.map((item, itemIndex) => (
                <li key={itemIndex} className="mb-2">{item}</li>
              ))}
            </ul>
          </div>
        ))}
      </div>

      <div className="external-resources mt-8">
        <h2 className="text-2xl font-bold mb-4">Additional Resources</h2>
        <div className="flex flex-wrap gap-4">
          {externalResources.map((resource, index) => (
            <Link
              key={index}
              href={resource.url}
              className="px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700"
            >
              {resource.name}
            </Link>
          ))}
        </div>
      </div>
    </div>
  )
}
</file>

<file path="components/Tutorial.tsx">
'use client'
import { useState } from 'react'

export default function Tutorial() {
  const [currentStep, setCurrentStep] = useState(0)
  
  const steps = [
    {
      title: 'Welcome to Lessons',
      content: 'Start your first lesson to begin learning.',
      action: 'Start Lesson'
    },
    {
      title: 'Practice Speaking',
      content: 'Use the microphone to practice pronunciation.',
      action: 'Try Speaking'
    },
    {
      title: 'Track Progress',
      content: 'Monitor your improvements over time.',
      action: 'View Progress'
    }
  ]

  const handleNext = () => {
    if (currentStep < steps.length - 1) {
      setCurrentStep(currentStep + 1)
    }
  }

  const handlePrev = () => {
    if (currentStep > 0) {
      setCurrentStep(currentStep - 1)
    }
  }

  return (
    <div className="tutorial-container p-6 max-w-2xl mx-auto">
      <h2 className="text-2xl font-bold mb-4">{steps[currentStep].title}</h2>
      <p className="text-lg mb-6">{steps[currentStep].content}</p>
      
      <div className="navigation-controls flex justify-between">
        <button
          onClick={handlePrev}
          disabled={currentStep === 0}
          className="px-4 py-2 bg-gray-200 rounded disabled:opacity-50"
        >
          Previous
        </button>
        
        <button
          onClick={handleNext}
          disabled={currentStep === steps.length - 1}
          className="px-4 py-2 bg-blue-600 text-white rounded disabled:opacity-50"
        >
          {currentStep === steps.length - 1 ? 'Finish' : 'Next'}
        </button>
      </div>
    </div>
  )
}
</file>

<file path="components/Welcome.tsx">
'use client'
import { useState } from 'react'

export default function Welcome() {
  const [progress] = useState(0)
  
  const steps = [
    'Complete your profile',
    'Take the placement test',
    'Start your first lesson'
  ]

  return (
    <div className="welcome-container p-6 max-w-2xl mx-auto">
      <h1 className="text-3xl font-bold mb-4">Welcome to Lessay!</h1>
      
      <div className="greeting-section mb-8">
        {/* eslint-disable-next-line react/no-unescaped-entities */}
        <p className="text-lg mb-4">
          Let's get you started on your language learning journey.
        </p>
      </div>

      <div className="quickstart-section mb-8">
        <h2 className="text-xl font-semibold mb-4">Quick Start Guide</h2>
        <ul className="list-disc pl-6">
          {steps.map((step, index) => (
            <li key={index} className="mb-2">{step}</li>
          ))}
        </ul>
      </div>

      <div className="progress-section">
        <h3 className="text-lg font-medium mb-2">
          Your Progress: {progress}% complete
        </h3>
        <div className="w-full bg-gray-200 rounded-full h-2.5">
          <div 
            className="bg-blue-600 h-2.5 rounded-full" 
            style={{ width: `${progress}%` }}
          ></div>
        </div>
      </div>
    </div>
  )
}
}
</file>

<file path="documentation/2_development_plan/dev_todo_phase_10.md">
# Developer To-Do List: Phase 10 - UI Implementation & Polish

**Objective:** Transform placeholder UI into a polished, responsive, and accessible interface.

## Tasks

- [ ] **1. Style Auth Component**
  - File: `/components/Auth.tsx`
  - Requirements:
    - Tailwind CSS styling for all states (default, loading, error)
    - Clear visual feedback for form validation
    - Responsive design for mobile/desktop
  - Verification: Component matches design specs in user documentation.

- [ ] **2. Implement Lesson UI**
  - File: `/components/LessonView.tsx`
  - Requirements:
    - Visual cues for listening/processing states
    - Clear answer feedback display
    - Responsive layout adjustments
  - Verification: All interaction states implemented per docs.

- [ ] **3. Build Dashboard Visualizations**
  - Install: `npm install recharts`
  - File: `/components/DashboardView.tsx`
  - Requirements:
    - SRS pie chart (knowledge retention)
    - Fluency line chart (progress over time)
    - Loading skeletons for async data
  - Verification: Charts match documentation examples.

- [ ] **4. Create Main Layout**
  - File: `/components/AppLayout.tsx`
  - Requirements:
    - Shared header with navigation
    - Consistent footer
    - Responsive breakpoints
  - Verification: All pages wrapped in layout.

- [ ] **5. Implement Accessibility**
  - Requirements:
    - ARIA labels for all interactive elements
    - Keyboard navigation support
    - Color contrast checks
  - Verification: Passes basic a11y audits.
</file>

<file path="documentation/2_development_plan/dev_todo_phase_11.md">
# Developer To-Do List: Phase 11 - Data Governance & Finalization

**Objective:** Implement data management policies and perform final project cleanup.

## Tasks

- [ ] **1. Implement Audio Retention Policy**
  - Create Inngest cron job in `/app/inngest/functions.ts`:
    ```typescript
    inngest.createFunction(
      { id: 'audio-retention' },
      { cron: '0 0 * * *' }, // Daily at midnight
      async () => {
        // Query VoiceAnalysis records older than 30 days
        // Delete associated audio files from Supabase Storage
        // Delete database records
      }
    )
    ```
  - Verification: Function exists with correct schedule.

- [ ] **2. Implement Account Deletion**
  - Create endpoint: `/app/api/users/delete-account/route.ts`
    - Require re-authentication
    - Delete all user-related data
    - Handle foreign key constraints
  - Verification: Endpoint securely deletes all user data.

- [ ] **3. Add Environment Check**
  - Update `package.json`:
    ```json
    "scripts": {
      "check:env": "node scripts/check-env.js",
      "build": "npm run check:env && next build"
    }
    ```
  - Create `scripts/check-env.js` to validate all required variables.
  - Verification: Build fails if any variables are missing.

- [ ] **4. Final Documentation Review**
  - Audit all JSDoc comments
  - Ensure API routes have proper documentation
  - Verify component prop types
  - Verification: All major components and functions documented.
</file>

<file path="documentation/2_development_plan/dev_todo_phase_6.md">
# Lessay Development Phase 6: Production Hardening - Security & Performance

## Tasks for Developer AI

### 1. Install Security Dependencies
- [ ] **Add Zod and Rate Limiter**
  ```bash
  npm install zod @upstash/ratelimit
  ```
  Verification: Packages appear in `package.json` dependencies

### 2. Create Validation Schemas (`/lib/validators.ts`)
- [ ] **Implement input validators**
  ```typescript
  import { z } from 'zod';

  export const lessonStartSchema = z.object({
    userId: z.string().uuid(),
    targetLanguage: z.string().length(2)
  });

  export const answerSubmitSchema = z.object({
    exerciseId: z.string().uuid(),
    textResponse: z.string().min(1),
    audioBlobUrl: z.string().url().optional()
  });
  ```
  Verification: File exists with exported schemas

### 3. Validate API Routes
- [ ] **Add validation to routes**
  Files to modify:
  - `app/api/lessons/[id]/submit-answer/route.ts`
  - `app/api/lessons/start/route.ts`
  - `app/api/payments/create-subscription/route.ts`
  - `app/api/users/profile/route.ts`

  Example implementation:
  ```typescript
  const body = await request.json();
  const validation = answerSubmitSchema.safeParse(body);
  if (!validation.success) {
    return NextResponse.json(
      { error: 'Invalid request', details: validation.error.flatten() },
      { status: 400 }
    );
  }
  ```
  Verification: Routes return 400 for invalid requests

### 4. Configure Rate Limiting (`/lib/rateLimit.ts`)
- [ ] **Set up rate limiter**
  ```typescript
  import { Ratelimit } from '@upstash/ratelimit';
  import { Redis } from '@upstash/redis';

  export const ratelimit = new Ratelimit({
    redis: Redis.fromEnv(),
    limiter: Ratelimit.slidingWindow(10, '1 m'),
    analytics: true
  });
  ```
  Verification: File exports rate limiter instance

### 5. Apply Rate Limits to Sensitive Endpoints
- [ ] **Protect high-traffic routes**
  Files to modify:
  - `app/api/lessons/start/route.ts`
  - `app/api/users/profile/route.ts`

  Example implementation:
  ```typescript
  const ip = request.headers.get('x-forwarded-for') ?? '127.0.0.1';
  const { success } = await ratelimit.limit(ip);
  if (!success) {
    return NextResponse.json(
      { error: 'Too many requests' },
      { status: 429 }
    );
  }
  ```
  Verification: Routes return 429 after 10 requests/minute

### 6. Optimize Database Performance
- [ ] **Add index to UserProgress model**
  Modify `prisma/schema.prisma`:
  ```prisma
  model UserProgress {
    // ... existing fields
    @@index([userId, metric], name: "UserProgress_userId_metric_index")
  }
  ```
  Verification: Index definition exists in schema

- [ ] **Create and apply migration**
  ```bash
  npx prisma migrate dev --name add_performance_indexes
  ```
  Verification: New migration file created

### 7. Implement Caching (`/lib/cache.ts`)
- [ ] **Create cache utility**
  ```typescript
  const cache = new Map<string, { data: any, expires: number }>();

  export function getFromCache<T>(key: string): T | null {
    const item = cache.get(key);
    return item?.expires > Date.now() ? item.data : null;
  }

  export function setToCache(key: string, data: any, ttl = 300000) {
    cache.set(key, { data, expires: Date.now() + ttl });
  }
  ```
  Verification: File exports cache functions

### 8. Cache Stats Endpoints
- [ ] **Add caching to dashboard routes**
  Files to modify:
  - `app/api/stats/fluency/route.ts`
  - `app/api/stats/srs-overview/route.ts`

  Example implementation:
  ```typescript
  const cacheKey = `stats-${userId}`;
  const cached = getFromCache(cacheKey);
  if (cached) return NextResponse.json(cached);

  const data = await fetchData();
  setToCache(cacheKey, data);
  return NextResponse.json(data);
  ```
  Verification: Repeated requests return cached data
</file>

<file path="documentation/2_development_plan/dev_todo_phase_7.md">
# Lessay Development Phase 7: Production Hardening - Testing

## Tasks for Developer AI

### 1. Install Testing Packages
- [ ] **Add Jest and TypeScript support**
  ```bash
  npm install jest ts-jest @types/jest --save-dev
  ```
  Verification: Packages appear in `package.json` devDependencies

### 2. Configure Jest (`jest.config.ts`)
- [ ] **Create Jest configuration**
  ```typescript
  import type { Config } from '@jest/types'

  const config: Config.InitialOptions = {
    preset: 'ts-jest',
    testEnvironment: 'node',
    roots: ['<rootDir>'],
    testMatch: ['**/*.test.ts'],
    moduleNameMapper: {
      '^@/(.*)$': '<rootDir>/$1'
    }
  }

  export default config
  ```
  Verification: Configuration file exists with correct settings

### 3. Create Auth Tests (`/tests/auth.test.ts`)
- [ ] **Implement authentication tests**
  ```typescript
  import { describe, it, expect } from '@jest/globals'
  import { signUp, signIn } from '@/lib/auth'

  describe('Authentication', () => {
    it('should allow valid user signup', async () => {
      const result = await signUp('test@example.com', 'password123')
      expect(result.success).toBe(true)
    })

    it('should reject duplicate user signup', async () => {
      await signUp('test@example.com', 'password123')
      const result = await signUp('test@example.com', 'password123')
      expect(result.error).toMatch(/already exists/i)
    })

    it('should allow valid login', async () => {
      await signUp('test@example.com', 'password123')
      const result = await signIn('test@example.com', 'password123')
      expect(result.success).toBe(true)
    })

    it('should reject invalid login', async () => {
      const result = await signIn('wrong@example.com', 'wrongpassword')
      expect(result.error).toMatch(/invalid credentials/i)
    })
  })
  ```
  Verification: File exists with all test cases

### 4. Create Lesson Tests (`/tests/lessons.test.ts`)
- [ ] **Implement lesson flow tests**
  ```typescript
  import { describe, it, expect } from '@jest/globals'
  import { startLesson, submitAnswer } from '@/lib/lessons'

  describe('Lesson Flow', () => {
    it('should start a new lesson', async () => {
      const lesson = await startLesson('user_123')
      expect(lesson.exercises.length).toBeGreaterThan(0)
    })

    it('should accept correct answers', async () => {
      const response = await submitAnswer('ex_123', 'correct answer')
      expect(response.correct).toBe(true)
    })

    it('should provide feedback for incorrect answers', async () => {
      const response = await submitAnswer('ex_123', 'wrong answer')
      expect(response.correct).toBe(false)
      expect(response.feedback).toBeDefined()
    })
  })
  ```
  Verification: File exists with all test cases

### 5. Update Package.json Scripts
- [ ] **Add test command**
  ```json
  {
    "scripts": {
      "test": "jest"
    }
  }
  ```
  Verification: `npm test` runs Jest successfully

### 6. Update CI Workflow (`/.github/workflows/ci.yml`)
- [ ] **Add testing step**
  ```yaml
  jobs:
    build-and-test:
      steps:
        - run: npm test
  ```
  Verification: CI file includes `npm test` command
</file>

<file path="documentation/2_development_plan/dev_todo_phase_8.md">
# Developer To-Do List: Phase 8 - Asynchronous Processing & Distributed Caching

**Objective:** Decouple long-running AI analysis tasks from request-response cycle and implement production-grade distributed caching.

## Tasks

- [ ] **1. Install Inngest**
  - Execute: `npm install inngest`
  - Initialize: `npx inngest-cli init`
  - Verification: `package.json` includes `"inngest"` in dependencies.

- [ ] **2. Create Inngest Function Handler**
  - Create file: `/app/inngest/route.ts`
    ```typescript
    import { serve } from 'inngest/next'
    import { functions } from './functions'

    export const { GET, POST, PUT } = serve({
      clientId: process.env.INNGEST_CLIENT_ID,
      functions,
    })
    ```
  - Create file: `/app/inngest/functions.ts`
    ```typescript
    import { inngest } from './client'
    import { analyzeSession } from '../lib/ai-service'

    export const functions = [
      inngest.createFunction(
        { id: 'post-session-analysis' },
        { event: 'ai/post-session-analysis' },
        async ({ event }) => {
          const { lessonId, audioUrl } = event.data
          return analyzeSession(lessonId, audioUrl)
        }
      )
    ]
    ```
  - Verification: Both files exist with correct content.

- [ ] **3. Refactor Submit Answer Endpoint**
  - Modify: `/app/api/lessons/[id]/submit-answer/route.ts`
    - Remove synchronous AI analysis call
    - Add Inngest send:
      ```typescript
      import { inngest } from '../../../lib/inngest'

      // After returning initial response
      await inngest.send({
        name: 'ai/post-session-analysis',
        data: { lessonId, audioUrl }
      })
      ```
  - Verification: Submit answer endpoint no longer contains direct AI analysis calls.

- [ ] **4. Implement Background Analysis Logic**
  - Move existing analysis logic from submit endpoint to:
    ```typescript
    // /lib/ai-service.ts
    export async function analyzeSession(lessonId: string, audioUrl: string) {
      // Existing analysis logic
      // Update SRS scores
      // Save VoiceAnalysis records
    }
    ```
  - Verification: All analysis logic resides in `analyzeSession` function.

- [ ] **5. Install Redis Client**
  - Execute: `npm install @upstash/redis`
  - Verification: `package.json` includes `"@upstash/redis"`.

- [ ] **6. Upgrade Cache Utility**
  - Modify: `/lib/cache.ts`
    - Replace `Map` with Redis client:
      ```typescript
      import { Redis } from '@upstash/redis'
      
      const redis = new Redis({
        url: process.env.REDIS_URL,
        token: process.env.REDIS_TOKEN,
      })
      
      export const cache = {
        get: (key: string) => redis.get(key),
        set: (key: string, value: any, ttl: number) => 
          redis.setex(key, ttl, value)
      }
      ```
  - Verification: Cache utility uses Redis methods instead of in-memory Map.
</file>

<file path="documentation/2_development_plan/dev_todo_phase_9.md">
# Developer To-Do List: Phase 9 - Comprehensive Testing

**Objective:** Implement a complete test suite covering core functionality, edge cases, and integration points.

## Tasks

- [ ] **1. Install Testing Dependencies**
  - Execute: `npm install jest ts-jest @types/jest --save-dev`
  - Verification: `package.json` includes these packages in devDependencies.

- [ ] **2. Configure Jest**
  - Create file: `jest.config.ts`
    ```typescript
    import type { Config } from '@jest/types'

    const config: Config.InitialOptions = {
      preset: 'ts-jest',
      testEnvironment: 'node',
      testMatch: ['**/tests/**/*.test.ts'],
      setupFilesAfterEnv: ['./tests/setup.ts'],
    }
    export default config
    ```
  - Verification: File exists with correct content.

- [ ] **3. Create Core Test Files**
  - Create directory: `/tests`
  - Create files:
    - `auth.test.ts` (User auth flows)
    - `lessons.test.ts` (Lesson generation/submission)
    - `ai-service.test.ts` (AI integration)
    - `dashboard.test.ts` (Stats/analytics)
    - `payments.test.ts` (Subscription flows)
  - Verification: All test files exist in `/tests`.

- [ ] **4. Implement Core Learning Loop Tests**
  - In `lessons.test.ts`:
    - Test SRS-driven content generation
    - Test difficulty adjustment after failed exercises
    - Test real-time feedback accuracy
  - Verification: Tests cover all cases from test plan section 1.

- [ ] **5. Implement Vocal Analysis Tests**
  - In `ai-service.test.ts`:
    - Test pronunciation scoring accuracy
    - Test fluency metrics (hesitation, pace)
    - Test filler word detection
  - Verification: Tests cover all cases from test plan section 2.

- [ ] **6. Implement Dashboard Tests**
  - In `dashboard.test.ts`:
    - Test SRS overview accuracy
    - Test error pattern detection
    - Test fluency trend visualization
  - Verification: Tests cover all cases from test plan section 3.

- [ ] **7. Implement Payment Flow Tests**
  - In `payments.test.ts`:
    - Test subscription scenarios (new, upgrade, failure)
    - Test webhook handling (success, failure, cancellation)
    - Test security measures (tokenization, PCI compliance)
  - Verification: Tests cover all cases from test plan section 5-6.

- [ ] **8. Update CI Workflow**
  - Modify: `/.github/workflows/ci.yml`
    - Add test command: `npm test`
    - Configure test database service
  - Verification: CI file includes test step and database setup.
</file>

<file path="documentation/project_managment/init_todo.md">
Of course. You are correct. The instructions must be a script for the autonomous agent to follow, not the implementation itself.

Here are the separate, simplified to-do files for each phase. Each task is designed to be an atomic, generative instruction for a small 4B LLM agent, with clear actions and verifications.

---
### **`phase_1_todo.md`**

## Phase 1: Project Setup & Core Infrastructure

**Goal:** Establish the project foundation, database, and authentication.
**Project Location:** All commands and file paths are relative to the project's root folder.

- [x] **Task 1.1: Initialize Next.js Project**
    - **File Path:** Project root (`./`)
    - **Action:** Execute a command to create a new Next.js project in the current directory.
    - **LLM Prompt:** "Execute the following shell command *exactly* as written, without any modifications, to initialize the project structure."
    - **Command:** `npx create-next-app@latest . --ts --eslint --tailwind --no-src-dir --app --import-alias "@/*"`
    - **Verification:** The file `package.json` exists in the root folder.

- [x] hask 1.2: Install Production Dependencies**
    - **File Path:** Project root (`./`)
    - **Action:** Execute a command to install required production libraries.
    - **LLM Prompt:** "Execute the following shell command to install the project's production dependencies."
    - **Command:** `npm install @prisma/client @supabase/supabase-js @stripe/stripe-js @stripe/react-stripe-js`
    - **Verification:** The `dependencies` section of `package.json` contains `@prisma/client` and `@supabase/supabase-js`.

- [x] **Task 1.3: Install Development Dependencies**
    - **File Path:** Project root (`./`)
    - **Action:** Execute a command to install Prisma as a development dependency.
    - **LLM Prompt:** "Execute the following shell command to install the project's development dependencies."
    - **Command:** `npm install -D prisma`
    - **Verification:** The `devDependencies` section of `package.json` contains `prisma`.

- [x] **Task 1.4: Initialize Prisma**
    - **File Path:** Project root (`./`)
    - **Action:** Execute the command to set up the Prisma directory and schema file.
    - **LLM Prompt:** "Execute the following shell command to initialize Prisma."
    - **Command:** `npx prisma init`
    - **Verification:** The file `/prisma/schema.prisma` exists.

- [ ] **Task 1.5: Define Database Schema**
    - **File Path:** `/prisma/schema.prisma`
    - **Action:** Overwrite the existing file with the complete, correct database schema for the Lessay application.
    - **LLM Prompt:** "Replace the entire content of the file at `/prisma/schema.prisma` with the provided code block. Do not add or change anything."
    - **Reference Code:** `[Copy the full Prisma schema from documentation/templates/technical_design_template.md Section 5.1]`
    - **Verification:** The file `/prisma/schema.prisma` contains the string `model SRSEntry`.

- [ ] **Task 1.6: Run Initial Database Migration**
    - **File Path:** Project root (`./`)
    - **Action:** Execute the command to generate the SQL migration from the schema and apply it to the database.
    - **LLM Prompt:** "Execute the following shell command to create and apply the initial database migration."
    - **Command:** `npx prisma migrate dev --name init`
    - **Verification:** A new directory exists inside `/prisma/migrations/`.

- [ ] **Task 1.7: Create Environment Variable Example File**
    - **File Path:** `/.env.example`
    - **Action:** Create a new file to serve as a template for environment variables.
    - **LLM Prompt:** "Create a new file at `/.env.example` and populate it with the provided content."
    - **Reference Code:** `[Copy the content of the .env.example file from the previous response]`
    - **Verification:** The file `/.env.example` exists and contains the string `NEXT_PUBLIC_SUPABASE_URL`.

---
### **`phase_2_todo.md`**

## Phase 2: Backend Core Services & User Management

**Goal:** Build the backend APIs for user profiles.

- [ ] **Task 2.1: Create Prisma Client Helper**
    - **File Path:** `/lib/prisma.ts`
    - **Action:** Create a reusable helper module to ensure only one instance of Prisma Client is used.
    - **LLM Prompt:** "Create a new file at `/lib/prisma.ts`. Generate TypeScript code that initializes a single, global instance of `PrismaClient` to prevent multiple connections in a development environment."
    - **Verification:** The file `/lib/prisma.ts` exists and contains the string `new PrismaClient()`.

- [ ] **Task 2.2: Create User Profile API Route**
    - **File Path:** `/app/api/users/profile/route.ts`
    - **Action:** Generate a Next.js App Router API route to handle fetching and updating user profiles.
    - **LLM Prompt:** "Generate a Next.js API route file at `/app/api/users/profile/route.ts`. It must export two async functions: `GET` and `PUT`. The `GET` function should return a static JSON object like `{\"id\":\"user_123\"}`. The `PUT` function should parse the JSON body of the request, log it to the console, and return a success JSON object. Import `NextResponse` from `next/server`."
    - **Verification:** The file `/app/api/users/profile/route.ts` exists and contains the strings `export async function GET` and `export async function PUT`.

---
### **`phase_3_todo.md`**

## Phase 3: Core Learning Loop

**Goal:** Implement the basic interactive lesson UI and APIs.

- [ ] **Task 3.1: Create Lesson API Routes**
    - **File Path:** `/app/api/lessons/start/route.ts`
    - **Action:** Generate the API endpoint for starting a new lesson.
    - **LLM Prompt:** "Generate a Next.js API route file at `/app/api/lessons/start/route.ts`. It must export a `POST` async function that returns a static JSON object representing a new lesson, like `{\"lessonId\":\"lesson_123\"}`. Import `NextResponse`."
    - **Verification:** The file `/app/api/lessons/start/route.ts` exists.

- [ ] **Task 3.2: Create Answer Submission API Route**
    - **File Path:** `/app/api/lessons/[id]/submit-answer/route.ts`
    - **Action:** Generate a dynamic API endpoint for submitting answers to a lesson.
    - **LLM Prompt:** "Generate a Next.js dynamic API route at `/app/api/lessons/[id]/submit-answer/route.ts`. It must export a `POST` async function that accepts `params` to read the lesson `id`. It should log the `id` and the request body to the console, then return a static JSON object representing feedback, like `{\"correct\":true}`. Import `NextResponse`."
    - **Verification:** The file `/app/api/lessons/[id]/submit-answer/route.ts` exists.

- [ ] **Task 3.3: Create Basic Lesson UI Component**
    - **File Path:** `/components/LessonView.tsx`
    - **Action:** Generate a basic, client-side React component to display a lesson.
    - **LLM Prompt:** "Generate a React client component at `/components/LessonView.tsx`. It must be a client component (`'use client'`). Use the `useState` hook to manage `lesson` and `feedback` states. Include a button that, when clicked, fetches from `/api/lessons/start` and sets the `lesson` state. Conditionally render the lesson prompt if the `lesson` state is not null."
    - **Verification:** The file `/components/LessonView.tsx` exists and contains the strings `'use client'` and `useState`.

---
### **`phase_4_todo.md`**

## Phase 4: Adaptive AI Engine & Analytics

**Goal:** Create stubs for the AI service and build the dashboard APIs.

- [ ] **Task 4.1: Create AI Service Stub**
    - **File Path:** `/lib/ai-service.ts`
    - **Action:** Create a placeholder module for AI logic.
    - **LLM Prompt:** "Create a TypeScript file at `/lib/ai-service.ts`. It must export two async functions: `generateLessonForUser` and `analyzeAudioForDiagnostics`. These functions should *not* contain real AI logic. They should only log a message to the console indicating they were called and return a static, dummy JSON object."
    - **Verification:** The file `/lib/ai-service.ts` exists and contains the string `export async function generateLessonForUser`.

- [ ] **Task 4.2: Create Dashboard Stats API Routes**
    - **File Path:** `/app/api/stats/fluency/route.ts`
    - **Action:** Generate the API endpoint for fluency metrics.
    - **LLM Prompt:** "Generate a Next.js API route file at `/app/api/stats/fluency/route.ts`. It must export a `GET` async function that returns a static JSON object representing fluency metrics, like `{\"speakingPace\":125}`. Import `NextResponse`."
    - **Verification:** The file `/app/api/stats/fluency/route.ts` exists.

- [ ] **Task 4.3: Create Dashboard SRS API Route**
    - **File Path:** `/app/api/stats/srs-overview/route.ts`
    - **Action:** Generate the API endpoint for SRS metrics.
    - **LLM Prompt:** "Generate a Next.js API route file at `/app/api/stats/srs-overview/route.ts`. It must export a `GET` async function that returns a static JSON object representing an SRS overview, like `{\"totalItems\":150}`. Import `NextResponse`."
    - **Verification:** The file `/app/api/stats/srs-overview/route.ts` exists.

---
### **`phase_5_todo.md`**

## Phase 5: Monetization

**Goal:** Implement placeholder APIs and UI for the Stripe payment system.

- [ ] **Task 5.1: Create Stripe Subscription API Route**
    - **File Path:** `/app/api/payments/create-subscription/route.ts`
    - **Action:** Generate the API endpoint for creating a new subscription.
    - **LLM Prompt:** "Generate a Next.js API route at `/app/api/payments/create-subscription/route.ts`. It must export a `POST` async function that parses the request body, logs the desired `tier`, and returns a static JSON success response, like `{\"status\":\"active\"}`. Import `NextResponse`."
    - **Verification:** The file `/app/api/payments/create-subscription/route.ts` exists.

- [ ] **Task 5.2: Create Stripe Webhook API Route**
    - **File Path:** `/app/api/stripe/webhook/route.ts`
    - **Action:** Generate the API endpoint to receive webhooks from Stripe.
    - **LLM Prompt:** "Generate a Next.js API route at `/app/api/stripe/webhook/route.ts`. It must export a `POST` async function. The function should log that a webhook was received and return a JSON object `{\"received\":true}` with a 200 status code. Import `NextResponse`."
    - **Verification:** The file `/app/api/stripe/webhook/route.ts` exists.

- [ ] **Task 5.3: Create Basic Pricing UI Component**
    - **File Path:** `/components/PricingPage.tsx`
    - **Action:** Generate a basic UI component for the pricing page.
    - **LLM Prompt:** "Generate a React client component at `/components/PricingPage.tsx`. It must be a client component (`'use client'`). It should render a heading like `Choose Your Plan` and a section for a 'Premium Plan' that includes a 'Subscribe' button."
    - **Verification:** The file `/components/PricingPage.tsx` exists and contains the string `Choose Your Plan`.

---
### **`phase_6_todo.md`**

## Phase 6: Testing, CI/CD, and Deployment Preparation

**Goal:** Ensure the app is testable and deployable.

- [ ] **Task 6.1: Add `test` and `lint` Scripts to `package.json`**
    - **File Path:** `/package.json`
    - **Action:** Modify the `scripts` section of the `package.json` file.
    - **LLM Prompt:** "Modify the `/package.json` file. In the `scripts` object, ensure there is a `lint` script with the value `next lint` and a `test` script with the value `echo 'No tests yet' && exit 0`."
    - **Verification:** The `scripts` section in `package.json` contains the `lint` and `test` keys with the correct values.

- [ ] **Task 6.2: Create CI/CD Workflow File**
    - **File Path:** `/.github/workflows/ci.yml`
    - **Action:** Create a GitHub Actions workflow file for Continuous Integration.
    - **LLM Prompt:** "Create a new file at `/.github/workflows/ci.yml`. Populate it with YAML content for a GitHub Action that triggers on `push` to the `main` branch. The workflow should have one job, `build-and-test`, that runs on `ubuntu-latest`. The job must include steps to checkout code, setup Node.js v20, run `npm ci`, and run `npm run lint`."
    - **Verification:** The file `/.github/workflows/ci.yml` exists and contains the string `npm run lint`.
</file>

<file path="lib/supabase/server.ts">
import { createServerComponentClient } from '@supabase/auth-helpers-nextjs'
import { cookies } from 'next/headers'
import { Database } from '@/types/supabase'

export const supabaseServerClient = () => {
  const cookieStore = cookies()
  return createServerComponentClient<Database>({ cookies: () => cookieStore })
}

export const getUserSession = async () => {
  const supabase = supabaseServerClient()
  const { data: { session } } = await supabase.auth.getSession()
  return session
}
</file>

<file path="lib/errorHandler.ts">
import { NextResponse } from 'next/server'

export function errorHandler(err: Error, req: NextRequest) {
  const statusCode = 500;
  const errorId = Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
  console.error({ errorId, err }, 'Request failed');
  return NextResponse.json(
    { 
      error: err.message,
      errorId,
      statusCode 
    },
    { status: statusCode }
  );
}
</file>

<file path="lib/logger.ts">
import pino from 'pino';

const logger = pino({
  level: process.env.NODE_ENV === 'production' ? 'info' : 'debug',
  transport: {
    target: 'pino-pretty',
    options: {
      colorize: true,
      translateTime: 'SYS:standard'
    }
  }
});

export default logger;
</file>

<file path="prisma/migrations/20250611185434_add_lesson_and_progress_models/migration.sql">
-- CreateTable
CREATE TABLE "User" (
    "id" TEXT NOT NULL,
    "email" TEXT NOT NULL,
    "password" TEXT NOT NULL,
    "targetLang" TEXT NOT NULL,
    "nativeLang" TEXT NOT NULL,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "User_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Lesson" (
    "id" TEXT NOT NULL,
    "title" TEXT NOT NULL,
    "content" TEXT NOT NULL,
    "difficulty" INTEGER NOT NULL,
    "userId" TEXT NOT NULL,
    "completedAt" TIMESTAMP(3),

    CONSTRAINT "Lesson_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Exercise" (
    "id" TEXT NOT NULL,
    "type" TEXT NOT NULL,
    "content" JSONB NOT NULL,
    "difficulty" INTEGER NOT NULL,
    "language" TEXT NOT NULL,
    "tags" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,

    CONSTRAINT "Exercise_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "UserProgress" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "metric" TEXT NOT NULL,
    "score" DOUBLE PRECISION NOT NULL,
    "lastUpdated" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "UserProgress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Progress" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "completed" BOOLEAN NOT NULL DEFAULT false,
    "score" DOUBLE PRECISION,
    "startedAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "completedAt" TIMESTAMP(3),

    CONSTRAINT "Progress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "SRSEntry" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "item" TEXT NOT NULL,
    "recallStrength" DOUBLE PRECISION NOT NULL DEFAULT 1.0,
    "nextReview" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "language" TEXT NOT NULL,

    CONSTRAINT "SRSEntry_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "VoiceAnalysis" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "metrics" JSONB NOT NULL,
    "audioUrl" TEXT NOT NULL,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "VoiceAnalysis_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "User_email_key" ON "User"("email");

-- CreateIndex
CREATE INDEX "SRSEntry_userId_nextReview_idx" ON "SRSEntry"("userId", "nextReview");

-- AddForeignKey
ALTER TABLE "Lesson" ADD CONSTRAINT "Lesson_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Exercise" ADD CONSTRAINT "Exercise_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "UserProgress" ADD CONSTRAINT "UserProgress_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Progress" ADD CONSTRAINT "Progress_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Progress" ADD CONSTRAINT "Progress_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "SRSEntry" ADD CONSTRAINT "SRSEntry_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "VoiceAnalysis" ADD CONSTRAINT "VoiceAnalysis_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "VoiceAnalysis" ADD CONSTRAINT "VoiceAnalysis_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/migration_lock.toml">
# Please do not edit this file manually
# It should be added in your version-control system (e.g., Git)
provider = "postgresql"
</file>

<file path="types/supabase.ts">
export type Database = {
  public: {
    Tables: {
      users: {
        Row: {
          id: string
          email: string
          password: string
          targetLang: string
          nativeLang: string
          createdAt: Date
        }
      }
      lessons: {
        Row: {
          id: string
          userId: string
          completedAt: Date | null
        }
      }
      exercises: {
        Row: {
          id: string
          type: string
          content: any
          difficulty: number
          language: string
          tags: string
          lessonId: string
        }
      }
      user_progress: {
        Row: {
          id: string
          userId: string
          metric: string
          score: number
          lastUpdated: Date
        }
      }
      srs_entries: {
        Row: {
          id: string
          userId: string
          item: string
          recallStrength: number
          nextReview: Date
          language: string
        }
      }
      voice_analyses: {
        Row: {
          id: string
          userId: string
          lessonId: string
          metrics: any
          audioUrl: string
          createdAt: Date
        }
      }
    }
  }
}
</file>

<file path="NEEDS_ARCHITECTURAL_REVIEW.md">
## Original Problem:
File not found

## Failed Fix Attempt:
File could not be read

## New Error:
Error reading file FIX_PLAN.md: {"name":"Error","message":"File not found: /home/kasjer/projects/lessay-cline/FIX_PLAN.md","stack":"Error: File not found: /home/kasjer/projects/lessay-cline/FIX_PLAN.md\n    at pJn (/home/kasjer/.vscode/extensions/rooveterinaryinc.roo-cline-3.19.7/dist/extension.js:4163:2252)\n    at async Promise.all (index 0)\n    at CJn (/home/kasjer/.vscode/extensions/rooveterinaryinc.roo-cline-3.19.7/dist/extension.js:4165:6293)\n    at Are (/home/kasjer/.vscode/extensions/rooveterinaryinc.roo-cline-3.19.7/dist/extension.js:4268:1349)"}
</file>

<file path=".github/workflows/ci.yml">
name: CI

on:
  push:
    branches: [main]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm ci
      - run: npm run lint
</file>

<file path=".roo/rules-orchestrator-senior/rules.md">
## 1. IDENTITY & PERSONA

You are the **Orchestrator AI**, designated as **🤖 Orchestrator**. You are the master process manager, central router, and state janitor for the autonomous development system. You are executed for a **single, one-shot decision-making task**: to analyze the repository's current state, clean up any completed work artifacts, and hand off control to the appropriate specialist.

## 2. THE CORE MISSION (One-Shot Execution)

Your mission is to perform a single, definitive analysis of the repository. You will run a state cleanup protocol first, then immediately switch to the correct operational mode based on the resulting clean state.

## 3. THE ORCHESTRATION DECISION TREE

Upon activation, you will check for the existence of the following files in this **strict, descending order of priority**. You must execute the action for the **first matching condition**.

1.  **If `NEEDS_ARCHITECTURAL_REVIEW.md` exists:** (HIGHEST PRIORITY)
    *   **Analysis:** A tactical fix has failed. The core plan requires re-evaluation by the master strategist.
    *   **Announcement:** "Escalation signal detected. A tactical fix has failed. Switching to Senior Architect for deep analysis and strategic intervention."
    *   **Action:** Switch mode: `<mode>architect-senior</mode>`.

2.  **If `NEEDS_ASSISTANCE.md` exists:**
    *   **Analysis:** A standard development or verification task has failed. A first-level response is required.
    *   **Announcement:** "Distress signal detected. Switching to Emergency mode for tactical diagnosis."
    *   **Action:** Switch mode: `<mode>emergency</mode>`.

3.  **If `FIX_PLAN.md` exists:**
    *   **Analysis:** A fix plan exists. I must determine if it is complete or pending execution.
    *   **Action (Conditional Logic):**
        *   **Read the `FIX_PLAN.md` file.**
        *   **If the file contains the string `[ ]`:**
            *   **Verdict:** The plan has pending tasks.
            *   **Announcement:** "Pending fix plan detected. Switching to Developer mode for execution."
            *   **Action:** Switch mode: `<mode>developer</mode>`.
        *   **If the file does NOT contain the string `[ ]`:**
            *   **Verdict:** The plan was successfully completed by the developer, but the artifact remains. My role is to clean it up.
            *   **Announcement:** "Completed fix plan detected. Cleaning up state file and re-evaluating."
            *   **Action:** Delete the `FIX_PLAN.md` file, and then **restart your own decision process from the top of this list.**

4.  **If `ARCHITECT_PLANNING_COMPLETE.md` exists:**
    *   **Analysis:** The overall architectural planning is complete.
    *   **Announcement:** "Architectural planning is complete. Switching to Developer mode."
    *   **Action:** Switch mode: `<mode>developer</mode>`.

5.  **Default - If none of the above conditions are met:**
    *   **Analysis:** The repository is in a clean state, with no emergencies or pending fixes. The system should proceed with the next phase of planning.
    *   **Announcement:** "No critical signals found. Switching to Architect mode for standard planning."
    *   **Action:** Switch mode: `<mode>architect-senior</mode>`.

## 4. CRITICAL DIRECTIVES
*   **CLEAN THEN DECIDE:** Your primary responsibility is to ensure a clean state before delegating. A completed `FIX_PLAN.md` is a temporary artifact that you **must** clean up.
*   **ONE SHOT, NO LOOPS:** You execute one branch of the decision tree and then immediately hand off control. If you clean up a file, you must re-run the tree to ensure the correct handoff from the new state.
*   **PRIORITY IS LAW:** You must check for signals in the exact order specified.
</file>

<file path="app/globals.css">
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}
</file>

<file path="app/layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}
</file>

<file path="app/page.tsx">
import Image from "next/image";

export default function Home() {
  return (
    <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-[32px] row-start-2 items-center sm:items-start">
        <Image
          className="dark:invert"
          src="/next.svg"
          alt="Next.js logo"
          width={180}
          height={38}
          priority
        />
        <ol className="list-inside list-decimal text-sm/6 text-center sm:text-left font-[family-name:var(--font-geist-mono)]">
          <li className="mb-2 tracking-[-.01em]">
            Get started by editing{" "}
            <code className="bg-black/[.05] dark:bg-white/[.06] px-1 py-0.5 rounded font-[family-name:var(--font-geist-mono)] font-semibold">
              app/page.tsx
            </code>
            .
          </li>
          <li className="tracking-[-.01em]">
            Save and see your changes instantly.
          </li>
        </ol>

        <div className="flex gap-4 items-center flex-col sm:flex-row">
          <a
            className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 sm:w-auto"
            href="https://vercel.com/new?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            <Image
              className="dark:invert"
              src="/vercel.svg"
              alt="Vercel logomark"
              width={20}
              height={20}
            />
            Deploy now
          </a>
          <a
            className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 w-full sm:w-auto md:w-[158px]"
            href="https://nextjs.org/docs?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            Read our docs
          </a>
        </div>
      </main>
      <footer className="row-start-3 flex gap-[24px] flex-wrap items-center justify-center">
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org/learn?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/file.svg"
            alt="File icon"
            width={16}
            height={16}
          />
          Learn
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://vercel.com/templates?framework=next.js&utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/window.svg"
            alt="Window icon"
            width={16}
            height={16}
          />
          Examples
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/globe.svg"
            alt="Globe icon"
            width={16}
            height={16}
          />
          Go to nextjs.org →
        </a>
      </footer>
    </div>
  );
}
</file>

<file path="components/PricingPage.tsx">
'use client';

export default function PricingPage() {
  return (
    <div>
      <h1>Choose Your Plan</h1>
      <section>
        <h2>Premium Plan</h2>
        <button>Subscribe</button>
      </section>
    </div>
  );
}
</file>

<file path="documentation/1_strategic_briefs/hardening_phase_1_todo.md">
# Hardening Phase 1: Security & Reliability

## Tasks for Developer AI

### 1. Implement Rate Limiting
- **File:** `/middleware/rate-limiter.ts`
- **Action:** Add Redis-based rate limiting
- **Steps:**
  1. Install `@upstash/ratelimit`
  2. Create Redis client config
  3. Apply to API routes
- **Verification:** 429 responses after 10 requests

### 2. Add Input Validation
- **File:** `/lib/validators/*`
- **Action:** Create Zod schemas
- **Steps:
  1. Add `zod` dependency
  2. Create schemas for all API inputs
  3. Integrate with routes
- **Verification:** Invalid inputs rejected

### 3. Setup Error Tracking
- **File:** `/lib/sentry.ts`
- **Action:** Configure Sentry
- **Steps:
  1. Add `@sentry/nextjs`
  2. Initialize in `_app.tsx`
  3. Add error boundaries
- **Verification:** Errors appear in Sentry
</file>

<file path="documentation/1_strategic_briefs/logic_phase_1_todo.md">
# Logic Phase 1: Core Backend & User Authentication

## Tasks for Developer AI

### 1. Implement User Authentication
- **File:** `/lib/supabase/server.ts`
- **Action:** Create server-side Supabase client utilities
- **Steps:**
  1. Create directory `lib/supabase`
  2. Create file `server.ts` with:
     - `supabaseServerClient` function using `createServerComponentClient`
     - `getUserSession` helper to fetch user session
- **Verification:** File exports both functions with proper TypeScript types

### 2. Create Profile GET Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add authenticated profile retrieval
- **Steps:**
  1. Import `getUserSession` from `@/lib/supabase/server`
  2. Add session check to GET function
  3. Query Prisma for user data
- **Verification:** Returns 401 when unauthenticated, profile data when valid

### 3. Implement Profile PUT Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add profile update functionality
- **Steps:**
  1. Reuse auth check from GET route
  2. Add Prisma `user.update` call
  3. Return updated profile
- **Verification:** PUT requests update user data successfully

### 4. Create Auth UI Component
- **File:** `/components/Auth.tsx`
- **Action:** Build sign-up/sign-in interface
- **Steps:**
  1. Create client-side Supabase client
  2. Add email/password fields
  3. Implement sign-up/sign-in buttons
- **Verification:** Component renders and allows user registration/login

### 5. Implement User Sync Endpoint
- **File:** `/api/users/sync/route.ts`
- **Action:** Create public profile after auth sign-up
- **Steps:**
  1. Create new route file
  2. Listen for Supabase auth events
  3. Create corresponding Prisma user record
- **Verification:** New auth users get public profiles automatically
</file>

<file path="documentation/1_strategic_briefs/logic_phase_2_todo.md">
# Logic Phase 2: Lesson System Implementation

## Tasks for Developer AI

### 1. Implement Lesson Start Route
- **File:** `/app/api/lessons/start/route.ts`
- **Action:** Add authenticated lesson generation
- **Steps:**
  1. Import `getUserSession` from `@/lib/supabase/server`
  2. Add session check to POST function
  3. Call `AIService.generateLessonForUser()`
  4. Store lesson in Prisma
- **Verification:** New lessons appear in database

### 2. Create Answer Submission Route
- **File:** `/app/api/lessons/[id]/submit-answer/route.ts`
- **Action:** Add answer validation
- **Steps:**
  1. Add authentication check
  2. Compare answer to correct value
  3. Create progress record
- **Verification:** Correct/incorrect feedback works

### 3. Update Lesson View Component
- **File:** `/components/LessonView.tsx`
- **Action:** Add answer input UI
- **Steps:**
  1. Create text input state
  2. Add submit button handler
  3. Display feedback
- **Verification:** Full lesson flow works
</file>

<file path="documentation/2_development_plan/dev_todo_phase_13.md">
# Development Phase 13: Environment Configurations

## Tasks for Developer AI

### 1. Create Environment Configuration Files
- **File:** `/lib/config.ts`
- **Action:** Implement environment configuration loader
- **Steps:**
  1. Create `lib/config.ts` with environment validation
  2. Define required environment variables:
     ```typescript
     interface AppConfig {
       NODE_ENV: 'development' | 'production' | 'test';
       DATABASE_URL: string;
       SUPABASE_URL: string;
       SUPABASE_KEY: string;
     }
     ```
  3. Add validation for required variables
- **Verification:** File exists and exports validated config object

### 2. Update Environment Template File
- **File:** `/.env.example`
- **Action:** Create example environment file
- **Steps:
  1. List all required environment variables
  2. Include comments explaining each variable
  3. Add dummy values for sensitive fields
- **Verification:** File contains all production-required variables

### 3. Implement Environment-Specific Settings
- **File:** `/lib/config.ts`
- **Action:** Add environment-specific defaults
- **Steps:
  1. Add development-only defaults
  2. Configure production security settings
  3. Enable debug modes for development
- **Verification:** Different settings load per NODE_ENV

### 4. Update Deployment Configuration
- **File:** `/next.config.ts`
- **Action:** Configure build-time environment
- **Steps:
  1. Add environment variable validation
  2. Configure public runtime config
  3. Set up build-time optimizations
- **Verification:** Config is accessible in both server and client

### 5. Create Environment Documentation
- **File:** `/docs/environments.md`
- **Action:** Document environment setup
- **Steps:
  1. List all environment variables
  2. Explain deployment process
  3. Add troubleshooting guide
- **Verification:** Documentation file exists
</file>

<file path="documentation/2_development_plan/dev_todo_phase_14.md">
# Development Phase 14: User Feedback System

## Tasks for Developer AI

### 1. Create Feedback API Endpoint
- **File:** `/app/api/feedback/route.ts`
- **Action:** Implement feedback submission endpoint
- **Steps:**
  1. Create new route file
  2. Add POST handler to receive feedback
  3. Validate input data
  4. Store feedback in database
- **Verification:** POST requests to `/api/feedback` return success status

### 2. Add Feedback Model to Schema
- **File:** `/prisma/schema.prisma`
- **Action:** Define feedback data structure
- **Steps:
  1. Add Feedback model with fields:
     - userId
     - message
     - createdAt
  2. Run migration
- **Verification:** New model appears in Prisma client

### 3. Implement Feedback UI Component
- **File:** `/components/FeedbackButton.tsx`
- **Action:** Create feedback interface
- **Steps:
  1. Create client component
  2. Add button to open feedback form
  3. Implement form submission
- **Verification:** Component renders and submits feedback

### 4. Add Feedback Link to Navigation
- **File:** `/components/Navbar.tsx`
- **Action:** Make feedback accessible
- **Steps:
  1. Import FeedbackButton
  2. Add to navigation menu
- **Verification:** Feedback button appears in UI

### 5. Setup Feedback Notifications
- **File:** `/lib/notifications.ts`
- **Action:** Alert admins of new feedback
- **Steps:
  1. Create notification function
  2. Call from feedback endpoint
  3. Test with sample submission
- **Verification:** Notifications trigger on new feedback
</file>

<file path="documentation/2_development_plan/dev_todo_phase_15.md">
# Development Phase 15: AI Cost & Security Controls

## Tasks for Developer AI

### 1. Implement Usage Tracking
- **File:** `/lib/ai-service.ts`
- **Action:** Add usage metrics to AI calls
- **Steps:**
  1. Add usage tracking to `generateLessonForUser`
  2. Add usage tracking to `analyzeAudioForDiagnostics`
  3. Store usage in database
- **Verification:** Usage data appears in database

### 2. Add Rate Limiting
- **File:** `/middleware/rate-limiter.ts`
- **Action:** Protect AI endpoints
- **Steps:
  1. Create rate limiting middleware
  2. Apply to AI API routes
  3. Test with multiple requests
- **Verification:** Requests are limited after threshold

### 3. Setup Usage Alerts
- **File:** `/lib/alerts.ts`
- **Action:** Notify on high usage
- **Steps:
  1. Create alert thresholds
  2. Implement notification system
  3. Test with simulated spikes
- **Verification:** Alerts trigger correctly

### 4. Implement Tiered Access
- **File:** `/app/api/lessons/start/route.ts`
- **Action:** Enforce tier limits
- **Steps:
  1. Check user tier
  2. Enforce daily limits
  3. Return appropriate errors
- **Verification:** Limits enforced per tier

### 5. Add Security Monitoring
- **File:** `/lib/security.ts`
- **Action:** Detect abuse patterns
- **Steps:
  1. Implement anomaly detection
  2. Log suspicious activity
  3. Create admin alerts
- **Verification:** System detects test attacks
</file>

<file path="documentation/3_personas_and_rules/rules-developer.md">
# Developer AI Rules

## Core Principles
1. **Code First:** Prioritize working code over documentation
2. **Atomic Commits:** Make small, focused changes
3. **Test Driven:** Write tests before implementation
4. **Performance Aware:** Optimize for efficiency

## Workflow Requirements
- Verify all API endpoints with Postman
- Include TypeScript type definitions
- Use Prettier for formatting
- Add JSDoc comments for complex functions

## Error Handling
- Implement Sentry error tracking
- Create meaningful error messages
- Include error codes in API responses
</file>

<file path="documentation/templates/compliance_framework_template.md">
# COMPLIANCE FRAMEWORK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-10 -->

[Existing sections...]

## 3. Payment Compliance
### 3.1 PCI DSS Requirements
- **SAQ A** compliance level
- No card data storage
- Quarterly vulnerability scans

### 3.2 GDPR Financial Data
- Legal basis: Contractual necessity
- Right to erasure limitations
- Breach notification timeline: 72 hours

### 3.3 Audit Controls
```mermaid
graph TD
    A[Payment Event] --> B[Log Entry]
    B --> C[Encrypted Storage]
    C --> D[Quarterly Review]
```

## 4. Certification Status
- PCI DSS: Annual assessment
- GDPR: Continuous compliance
- SOC 2: Planned for 2026
</file>

<file path="documentation/templates/data_governance_template.md">
# DATA GOVERNANCE FRAMEWORK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-10 -->

[Existing sections...]

## 4. Payment Data Handling
### 4.1 Data Types
| Classification | Examples | Handling Requirements |
|----------------|----------|-----------------------|
| Sensitive | Stripe customer IDs | Encrypted storage |
| Restricted | Payment tokens | Never stored locally |

### 4.2 Security Controls
- **Encryption**: AES-256 for payment metadata
- **Access**: Role-based, limited to billing team
- **Audit**: All access logged and monitored

### 4.3 Tokenization Flow
```mermaid
sequenceDiagram
    Client->>Stripe: Tokenize card
    Stripe-->>Client: Payment token
    Client->>Backend: Use token for payment
    Backend->>Stripe: Charge via token
```

## 5. Data Retention
### 5.1 Payment Metadata
- Retention period: 7 years (tax compliance)
- Deletion method: Cryptographic shredding
</file>

<file path="documentation/app_description.md">
## **Lessay: Software Documentation Overview**

### **1. Introduction: Our Philosophy**

Lessay is an AI-powered language learning platform designed to create a deeply personal and efficient path to fluency. Unlike one-size-fits-all learning apps, Lessay's core engine is built to **listen, understand, and adapt** to each unique learner. Our philosophy is to **measure everything**, transforming every interaction into a data point that refines the learning path. We move beyond generic exercises by integrating AI-driven diagnostics with proven cognitive science principles, like **Spaced Repetition**, to provide a hyper-personalized experience that makes every minute of practice count.

This document provides a high-level overview of the learner's journey and the intelligent systems that power this adaptive ecosystem, all aligned with best practices in both language acquisition and scalable software development.

---

### **2. The Learner's Journey**

This is the typical path a user takes from their first interaction to becoming an active learner in our continuous improvement cycle.

#### **Step 1: Getting to Know You**
When a new user joins, Lessay begins by gathering foundational data:
*   What is your native language?
*   What language do you want to learn **first**? (You can switch or add other languages at any time from your profile).
*   What is your primary goal (e.g., travel, business, conversation)?
*   What is your self-assessed comfort level (Beginner, Intermediate, Advanced)?

This initial information calibrates the app's voice, translations, and the starting difficulty for the user's first experience.

#### **Step 2: The Initial Diagnostic**
Before creating lessons, Lessay conducts a short, voice-based diagnostic. This low-pressure placement exercise uses a series of adaptive questions to give our AI a quick but accurate baseline of the user's current vocabulary, grammar, and pronunciation.

#### **Step 3: Your First Personalized Lessons**
Immediately after the diagnostic, the results are analyzed. Lessay doesn't just provide a score; it identifies the most critical areas for improvement. The app instantly generates a set of personalized lessons tailored to this baseline.

#### **Step 4: The Learning Loop (Practice & Improve)**
This is the core of the app experience, presented in a simple, chat-like interface.
*   **Listen:** The user hears prompts and correct pronunciations from the app's voice.
*   **Speak:** The user practices by speaking their answers. The app listens **in real-time**, using live speech-to-text to provide immediate feedback on the content of their response.
*   **Get Feedback:** The user receives instant corrections and guidance, reinforcing learning in the moment.

#### **Step 5: Growing With You (The Adaptive Cycle)**
This is where Lessay truly stands apart. After each lesson, the system analyzes the user's entire performance. It moves beyond right or wrong answers to perform a deep analysis of the **raw audio recording** of the session. Based on this, it not only identifies new areas for improvement but also **updates its understanding of what the user is close to forgetting**, scheduling concepts for review at the perfect moment. The app automatically generates the **next** set of lessons, creating a continuous, adaptive learning loop where the curriculum evolves with the user.

#### **Step 6: Your Progress Dashboard**
Lessay believes in transparent learning. Users have access to a detailed statistics and measurements dashboard that visualizes their progress over time. This includes:
*   **Skill Mastery Charts:** Tracking progress across competencies like grammar, vocabulary themes, and pronunciation.
*   **Fluency Metrics:** Visualizing improvements in speaking pace, reduction in hesitation, and use of filler words.
*   **Recall Strength (SRS View):** A dynamic view of their known vocabulary and grammar rules, showing which concepts are "cemented," "maturing," or "due for review" based on the Spaced Repetition algorithm.
*   **Error Analysis:** Highlighting recurring mistakes so the user is consciously aware of what the AI is helping them fix.
*   **Activity Log:** A history of completed lessons and performance scores.

---

### **3. How Lessay Works: The Technology**

Lessay's adaptive experience is powered by a few key technological components working in synergy.

*   **The Brain (Artificial Intelligence):**
    At the heart of Lessay is an advanced AI (e.g., Google Gemini). This "Brain" has two primary jobs:
    1.  **Expert Lesson Designer:** It acts as a master tutor, creating new, relevant lesson plans and exercises from scratch based on a user's detailed performance profile.
    2.  **Expert Language & Vocal Analyst:** It reviews a user's session recordings to perform a deep diagnostic, identifying subtle pronunciation errors, grammatical patterns, and vocal delivery issues that are invisible to most apps.

*   **The Ears (Speech Recognition & Capture):**
    When a user speaks, our system performs two tasks simultaneously:
    1.  **Real-Time Transcription:** It uses a high-speed API (Google Speech-to-Text) to instantly convert speech to text for immediate answer validation within the lesson.
    2.  **Diagnostic Recording:** It captures a high-fidelity audio blob of the user's speech. This raw audio is sent to our AI Brain after the session for the deeper diagnostic analysis (pronunciation, hesitation, etc.).

*   **The Voice (Text-to-Speech):**
    To provide clear examples and prompts, the app's "Voice" (powered by Google TTS and AWS Polly) converts all lesson text into natural-sounding audio, crucial for modeling correct pronunciation and intonation.

*   **The Memory (Comprehensive User Profile & Database):**
    Lessay securely stores a rich, evolving profile of each user's journey. This is a multi-faceted dataset including:
    *   Performance scores and a history of all AI-generated lessons.
    *   A detailed list of identified weaknesses and mastered concepts.
    *   Vocal & Fluency Metrics over time.
    *   **A Spaced Repetition System (SRS) Engine:** This is the core of long-term retention. For **every single vocabulary word and grammar concept** the user learns, the Memory tracks:
        *   **Recall Strength Score:** A dynamic score indicating how well the user knows the item.
        *   **Next Review Date:** The optimal date for the user to be tested on this item again.
    This comprehensive memory is the fuel for the AI Brain, ensuring every new lesson is both personalized and strategically timed for maximum retention.

---

### **4. The Adaptive Learning Method: Our "Secret Sauce"**

Lessay’s hyper-personalization is based on a four-step, data-driven cycle that intelligently blends new material with targeted review.

#### **Step 1: Capture & Measure**
During a lesson, the app records the complete audio of the user's responses. This high-fidelity recording provides a complete, contextualized dataset of the user's speaking performance, capturing not just *what* they said, but *how* they said it.

#### **Step 2: Analyze & Diagnose**
Once the lesson is complete, the AI Analyst (The Brain) scrutinizes the entire audio recording and session data. It looks for a wide array of specific, nuanced details:
*   **Phonetic Accuracy:** *Are you pronouncing "ü" correctly in German? Is your "r" sound in Spanish a tap or a trill?*
*   **Vocal Delivery & Fluency:** *What is your speaking pace? Do you hesitate frequently? Are there patterns to your hesitations (e.g., before certain verb conjugations)? Are you using filler words ("um," "uh") excessively?*
*   **Grammatical Patterns:** *Did you consistently use the correct verb endings or sentence structure, even if the individual words were correct?*
*   **Vocabulary Recall:** *Are you using newly learned words correctly and confidently, or do you stumble over them?*

Crucially, during this analysis, the AI also **updates the SRS scores in The Memory**. If a user recalled a vocabulary word quickly and pronounced it well, its "Recall Strength" increases, and its "Next Review Date" is pushed further into the future. If they hesitated or made a grammatical error related to a known concept, the strength score for that item decreases, and it is scheduled for an earlier review.

#### **Step 3: Prioritize & Plan**
The system then synthesizes this new diagnosis with the user's historical data to decide what the next lesson should contain. It prioritizes tasks in a specific, pedagogically-sound order:

1.  **Spaced Repetition Reviews (Top Priority):** It first queries the SRS Engine for any vocabulary or grammar concepts that are **due for review**. Preventing knowledge decay is paramount.
2.  **Critical Weaknesses:** It then identifies the most significant pronunciation, grammar, or fluency issues from the most recent session analysis. These need immediate attention.
3.  **Struggling Concepts:** It targets topics the user has consistently made mistakes on in recent lessons, providing further reinforcement.
4.  **New Material:** Finally, it introduces new vocabulary and grammar that align with the user's stated goals, expanding their knowledge base.

#### **Step 4: Create & Adapt**
With this clear, prioritized plan, the AI Lesson Designer gets to work. It generates a brand new, custom-built lesson that seamlessly integrates these different elements.

For example, if the analysis showed a user struggles with the "ch" sound in German and makes mistakes with dative case articles, **and the SRS indicates they are due to review the vocabulary for 'train station' and 'ticket'**, the next lesson will be a conversational exercise about buying a train ticket. This single, natural-sounding scenario forces the user to:
*   Practice the difficult "ch" sound (e.g., in "ich möchte").
*   Correctly use dative articles (e.g., "an de**m** Schalter").
*   Actively recall the review vocabulary ('Bahnhof', 'Ticket').

This integrated **Capture -> Analyze -> Plan (with SRS) -> Create** cycle ensures the user is always working on a balanced mix of retaining old knowledge, fixing current weaknesses, and learning new material in the most efficient way possible.
</file>

<file path="documentation/dev_todo_phase_1.md">
# Developer To-Do List: Phase 1 - Core Backend & User Auth

## Task 1: Create Supabase Server-Side Client Helper
- **File:** `/lib/supabase/server.ts`
- **Action:** Create server-side Supabase client utilities
- **Steps:**
  1. Create directory `lib/supabase`
  2. Create file `server.ts` with:
     - `supabaseServerClient` function using `createServerComponentClient`
     - `getUserSession` helper to fetch user session
- **Verification:** File exports both functions with proper TypeScript types

## Task 2: Implement Profile GET Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add authenticated profile retrieval
- **Steps:**
  1. Import `getUserSession` from `@/lib/supabase/server`
  2. Add session check to GET function
  3. Query Prisma for user data
- **Verification:** Returns 401 when unauthenticated, profile data when valid

## Task 3: Implement Profile PUT Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add profile update functionality
- **Steps:**
  1. Reuse auth check from GET route
  2. Add Prisma `user.update` call
  3. Return updated profile
- **Verification:** PUT requests update user data successfully

## Task 4: Create Auth UI Component
- **File:** `/components/Auth.tsx`
- **Action:** Build sign-up/sign-in interface
- **Steps:**
  1. Create client-side Supabase client
  2. Add email/password fields
  3. Implement sign-up/sign-in buttons
- **Verification:** Component renders and allows user registration/login

## Task 5: Implement User Sync Endpoint
- **File:** `/api/users/sync/route.ts`
- **Action:** Create public profile after auth sign-up
- **Steps:**
  1. Create new route file
  2. Listen for Supabase auth events
  3. Create corresponding Prisma user record
- **Verification:** New auth users get public profiles automatically
</file>

<file path="documentation/feature_phase_1_feedback.md">
# Feature Phase 1: User Feedback Implementation

## Tasks for Developer AI

### 1. Create Feedback API Endpoint
- **File:** `/app/api/feedback/report/route.ts`
- **Action:** Implement endpoint to handle feedback submissions
- **Content:**
```typescript
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';

export async function POST(request: Request) {
  const { lessonId, userId, feedbackText, errorType } = await request.json();
  
  try {
    const feedback = await prisma.feedback.create({
      data: {
        lessonId,
        userId,
        feedbackText,
        errorType,
      }
    });
    return NextResponse.json(feedback);
  } catch (error) {
    return NextResponse.json(
      { error: 'Failed to submit feedback' },
      { status: 500 }
    );
  }
}
```
- **Verification:** Endpoint exists and accepts POST requests

### 2. Update Prisma Schema
- **File:** `/prisma/schema.prisma`
- **Action:** Add Feedback model
- **Modification:**
```prisma
model Feedback {
  id           String   @id @default(uuid())
  lessonId     String
  lesson       Lesson   @relation(fields: [lessonId], references: [id])
  userId       String
  user         User     @relation(fields: [userId], references: [id])
  feedbackText String
  errorType    String?
  createdAt    DateTime @default(now())
}
```
- **Verification:** Model exists in schema

### 3. Run Database Migration
- **Command:** `npx prisma migrate dev --name add_feedback_model`
- **Verification:** New migration file created in `prisma/migrations`

### 4. Add Feedback Button to Lesson UI
- **File:** `/components/LessonView.tsx`
- **Action:** Implement feedback reporting UI
- **Modification:**
```typescript
function ReportIssueButton() {
  const [isOpen, setIsOpen] = useState(false);
  const [feedback, setFeedback] = useState('');

  const submitFeedback = async () => {
    await fetch('/api/feedback/report', {
      method: 'POST',
      body: JSON.stringify({
        lessonId: currentLesson.id,
        feedbackText: feedback,
        errorType: 'general'
      })
    });
    setIsOpen(false);
  };

  return (
    <>
      <button onClick={() => setIsOpen(true)}>Report Issue</button>
      {isOpen && (
        <div className="feedback-modal">
          <textarea value={feedback} onChange={(e) => setFeedback(e.target.value)} />
          <button onClick={submitFeedback}>Submit</button>
        </div>
      )}
    </>
  );
}
```
- **Verification:** Button appears in lesson interface
</file>

<file path="documentation/feature_phase_2_transactional_integrity.md">
### Feature Phase 2: Transactional Integrity & User Communication

**Objective:** Ensure critical operations maintain data consistency and keep users informed through transactional emails.

#### Tasks:
1. **Install Email SDK:**
   ```bash
   npm install resend
   ```

2. **Create Email Service:**
   - Create `/lib/email.ts`:
     ```typescript
     import { Resend } from 'resend'
     
     const resend = new Resend(process.env.RESEND_API_KEY)
     
     export async function sendWelcomeEmail(email: string, name: string) {
       await resend.emails.send({
         from: 'welcome@lessay.com',
         to: email,
         subject: 'Welcome to Lessay!',
         html: `<p>Hi ${name}, thank you for joining Lessay!</p>`
       })
     }
     
     export async function sendSubscriptionConfirmation(email: string) {
       await resend.emails.send({
         from: 'subscriptions@lessay.com',
         to: email,
         subject: 'Your Lessay Subscription is Active!',
         html: `<p>Your Lessay premium subscription is now active.</p>`
       })
     }
     ```

3. **Refactor Sign-Up Flow:**
   - Update `/api/users/sync` route to use transaction:
     ```typescript
     await prisma.$transaction(async (tx) => {
       const user = await tx.user.create({ data: profileData })
       await sendWelcomeEmail(user.email, user.name)
       return user
     })
     ```

4. **Enhance Stripe Webhook Handler:**
   - Update `/api/stripe/webhook` route:
     ```typescript
     // After successful subscription update
     await sendSubscriptionConfirmation(user.email)
     ```

5. **Implement Webhook Idempotency:**
   - Add event ID tracking to prevent duplicate processing:
     ```typescript
     const processedEvent = await prisma.processedEvent.findUnique({
       where: { eventId: stripeEvent.id }
     })
     if (processedEvent) return
     // Process event...
     await prisma.processedEvent.create({
       data: { eventId: stripeEvent.id }
     })
     ```

**Verification:**
- Test sign-up flow creates both auth and profile records
- Confirm welcome emails are received
- Verify subscription emails trigger on payment
- Ensure duplicate webhook events are ignored

**Completion Criteria:**
- All critical operations maintain data consistency
- Users receive timely email confirmations
- Webhook processing is idempotent
</file>

<file path="documentation/feature_phase_3_onboarding.md">
### Feature Phase 3: User Onboarding & Activation Flow

**Objective:** Guide new users through initial setup to ensure personalized experience from first login.

#### Tasks:
1. **Update User Model:**
   - Modify `prisma/schema.prisma`:
     ```prisma
     model User {
       // ... existing fields
       status String @default("new") // 'new' | 'active'
     }
   ```

2. **Create Onboarding UI:**
   - Create `/components/OnboardingFlow.tsx`:
     ```typescript
     export default function OnboardingFlow() {
       // Language selection and goal setup UI
     }
     ```
   - Create `/app/onboarding/page.tsx` to host the flow

3. **Implement Onboarding Logic:**
   - Add middleware check in root layout:
     ```typescript
     if (session?.user?.status === 'new' && !pathname.startsWith('/onboarding')) {
       redirect('/onboarding')
     }
     ```
   - Create API route to complete onboarding:
     ```typescript
     await prisma.user.update({
       where: { id: userId },
       data: { status: 'active' }
     })
     ```

**Verification:**
- New users are redirected to onboarding
- User status updates correctly after completion
- Existing users bypass onboarding

**Completion Criteria:**
- All new users complete onboarding before accessing main app
- User model accurately reflects activation status
</file>

<file path="documentation/hardening_phase_1_observability.md">
# Hardening Phase 1: Observability Implementation

## Tasks for Developer AI

### 1. Install Logging Dependencies
**File Path:** Project root (`./`)
**Action:** Execute command to install pino and pino-pretty
**LLM Prompt:** "Execute the following shell command to install logging dependencies:"
**Command:** `npm install pino pino-pretty`
**Verification:** `pino` and `pino-pretty` appear in `package.json` dependencies

---

### 2. Create Logger Utility
**File Path:** `/lib/logger.ts`
**Action:** Create a centralized logger instance
**LLM Prompt:** "Create a new file at `/lib/logger.ts` with the following content:"
```typescript
import pino from 'pino'

const logger = pino({
  level: process.env.NODE_ENV === 'production' ? 'info' : 'debug',
  transport: {
    target: 'pino-pretty',
    options: {
      colorize: true,
      translateTime: 'SYS:standard'
    }
  }
})

export default logger
```
**Verification:** File exists and exports a `logger` instance

---

### 3. Replace Console Logs in API Routes
**Action:** Update all API routes to use the new logger
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/stripe/webhook/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "In each specified API route file, replace all `console.log` statements with appropriate logger methods (`logger.info`, `logger.error`, etc.)"
**Verification:** No `console.log` statements remain in API route files

---

### 4. Implement Health Check Endpoint
**File Path:** `/app/api/health/route.ts`
**Action:** Create a health check API route
**LLM Prompt:** "Create a new file at `/app/api/health/route.ts` with the following content:"
```typescript
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'
import logger from '@/lib/logger'

export async function GET() {
  try {
    await prisma.$queryRaw`SELECT 1`
    logger.info('Health check successful')
    return NextResponse.json({ status: 'ok' }, { status: 200 })
  } catch (error) {
    logger.error('Health check failed', error)
    return NextResponse.json(
      { status: 'error', message: 'Database connection failed' },
      { status: 503 }
    )
  }
}
```
**Verification:** File exists and returns 200 OK when database is accessible

---

### 5. Verify Logging Implementation
**Action:** Test the logging functionality
**LLM Prompt:** "Execute the following command to test the application and verify logs are being generated:"
**Command:** `npm run dev`
**Verification:** Application starts and logs appear in the console with proper formatting
</file>

<file path="documentation/hardening_phase_2_error_handling.md">
# Hardening Phase 2: Error Handling Implementation

## Tasks for Developer AI

### 1. Prepare Error Handling Utilities
**File Path:** `/lib/errors.ts`
**Action:** Create error handling utilities
**LLM Prompt:** "Create a new file at `/lib/errors.ts` with the following content:"
```typescript
import { NextResponse } from 'next/server'
import logger from '@/lib/logger'
import { PrismaClientKnownRequestError } from '@prisma/client/runtime/library'

export function handleError(error: unknown) {
  if (error instanceof PrismaClientKnownRequestError) {
    logger.error({ error }, 'Database error occurred')
    return NextResponse.json(
      { error: 'Database operation failed' },
      { status: getPrismaErrorStatus(error) }
    )
  }

  logger.error({ error }, 'Unexpected error occurred')
  return NextResponse.json(
    { error: 'An unexpected error occurred' },
    { status: 500 }
  )
}

function getPrismaErrorStatus(error: PrismaClientKnownRequestError): number {
  switch (error.code) {
    case 'P2002': return 409 // Unique constraint violation
    case 'P2025': return 404 // Record not found
    default: return 400 // Bad request
  }
}
```
**Verification:** File exists and exports `handleError` function

---

### 2. Update API Routes with Error Handling
**Action:** Modify all API routes to use structured error handling
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/stats/fluency/route.ts`
- `app/api/stats/srs-overview/route.ts`
- `app/api/stripe/webhook/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route file:
1. Wrap the entire exported function body in a try/catch block
2. Use the handleError utility from '@/lib/errors' in catch blocks
3. Ensure all errors are properly logged
4. Maintain existing functionality"

**Example Modification:**
```typescript
// Before
export async function POST(request: Request) {
  const { tier } = await request.json()
  console.log('Creating subscription for tier:', tier)
  return NextResponse.json({ status: 'active' })
}

// After
import { handleError } from '@/lib/errors'

export async function POST(request: Request) {
  try {
    const { tier } = await request.json()
    logger.info('Creating subscription for tier:', { tier })
    return NextResponse.json({ status: 'active' })
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** All API routes have try/catch blocks and use handleError

---

### 3. Add Health Check Error Handling
**File Path:** `/app/api/health/route.ts`
**Action:** Update health check to use new error handler
**LLM Prompt:** "Modify `/app/api/health/route.ts` to use the handleError utility:"
```typescript
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'
import logger from '@/lib/logger'
import { handleError } from '@/lib/errors'

export async function GET() {
  try {
    await prisma.$queryRaw`SELECT 1`
    logger.info('Health check successful')
    return NextResponse.json({ status: 'ok' }, { status: 200 })
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** Health check uses handleError and maintains functionality

---

### 4. Verify Error Handling
**Action:** Test error scenarios
**LLM Prompt:** "Execute the following command to test the application and verify error handling:"
**Command:** `npm run dev`
**Verification:**
1. Trigger intentional errors in API routes
2. Confirm proper error responses (status codes and JSON format)
3. Check that errors appear in logs with appropriate levels
</file>

<file path="documentation/hardening_phase_3_security.md">
# Hardening Phase 3: Security Implementation

## Tasks for Developer AI

### 1. Install Zod for Validation
**File Path:** Project root (`./`)
**Action:** Execute command to install Zod
**LLM Prompt:** "Execute the following shell command to install Zod:"
**Command:** `npm install zod`
**Verification:** `zod` appears in `package.json` dependencies

---

### 2. Create Validation Schemas
**File Path:** `/lib/validators.ts`
**Action:** Create shared validation schemas
**LLM Prompt:** "Create a new file at `/lib/validators.ts` with the following content:"
```typescript
import { z } from 'zod'

export const lessonStartSchema = z.object({
  userId: z.string().uuid(),
  targetLanguage: z.string().length(2)
})

export const answerSubmitSchema = z.object({
  exerciseId: z.string().uuid(),
  textResponse: z.string().min(1),
  audioBlobUrl: z.string().url().optional()
})

export const subscriptionSchema = z.object({
  tier: z.enum(['free', 'premium', 'pro']),
  paymentMethodId: z.string()
})
```
**Verification:** File exists and exports validation schemas

---

### 3. Implement Route Validation
**Action:** Add validation to API routes with request bodies
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route:
1. Import appropriate validator from '@/lib/validators'
2. Validate request body at start of handler
3. Return 400 with validation errors if invalid
4. Maintain existing functionality"

**Example Modification:**
```typescript
import { NextResponse } from 'next/server'
import { answerSubmitSchema } from '@/lib/validators'
import { handleError } from '@/lib/errors'

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  try {
    const body = await request.json()
    const validation = answerSubmitSchema.safeParse(body)
    
    if (!validation.success) {
      return NextResponse.json(
        { error: 'Invalid request', details: validation.error.flatten() },
        { status: 400 }
      )
    }

    // Existing handler logic...
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** Routes return 400 for invalid requests with error details

---

### 4. Install Rate Limiting Package
**File Path:** Project root (`./`)
**Action:** Execute command to install rate limiter
**LLM Prompt:** "Execute the following shell command to install rate limiting:"
**Command:** `npm install @upstash/ratelimit`
**Verification:** `@upstash/ratelimit` appears in `package.json` dependencies

---

### 5. Configure Rate Limiting
**File Path:** `/lib/rateLimit.ts`
**Action:** Create rate limiting configuration
**LLM Prompt:** "Create a new file at `/lib/rateLimit.ts` with the following content:"
```typescript
import { Ratelimit } from '@upstash/ratelimit'
import { Redis } from '@upstash/redis'

export const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, '1 m'),
  analytics: true
})
```
**Verification:** File exists and exports rate limiter instance

---

### 6. Apply Rate Limiting to Sensitive Endpoints
**Action:** Add rate limiting to high-risk routes
**Files to Modify:**
- `app/api/lessons/start/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route:
1. Import rate limiter from '@/lib/rateLimit'
2. Get client IP from headers (request.headers.get('x-forwarded-for'))
3. Check rate limit at start of handler
4. Return 429 if limit exceeded
5. Maintain existing functionality"

**Example Modification:**
```typescript
import { ratelimit } from '@/lib/rateLimit'

export async function POST(request: Request) {
  const ip = request.headers.get('x-forwarded-for') ?? '127.0.0.1'
  const { success } = await ratelimit.limit(ip)
  
  if (!success) {
    return NextResponse.json(
      { error: 'Too many requests' },
      { status: 429 }
    )
  }

  // Existing handler logic...
}
```
**Verification:** Routes return 429 after exceeding request limits

---

### 7. Verify Security Features
**Action:** Test validation and rate limiting
**LLM Prompt:** "Execute the following command to test the security features:"
**Command:** `npm run dev`
**Verification:**
1. Invalid requests return 400 with error details
2. Excessive requests to limited endpoints return 429
3. Valid requests function normally
</file>

<file path="documentation/hardening_phase_4_performance.md">
# Hardening Phase 4: Performance Optimization

## Tasks for Developer AI

### 1. Add Database Indexes
**File Path:** `/prisma/schema.prisma`
**Action:** Add compound index to UserProgress model
**LLM Prompt:** "Modify the UserProgress model in `/prisma/schema.prisma` to add a compound index:"
```prisma
model UserProgress {
  id          String   @id @default(uuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  metric      String
  score       Float
  lastUpdated DateTime @default(now())

  @@index([userId, metric], name: "UserProgress_userId_metric_index")
}
```
**Verification:** Index definition exists in schema.prisma

---

### 2. Apply Database Migration
**File Path:** Project root (`./`)
**Action:** Create and apply migration
**LLM Prompt:** "Execute the following command to create and apply the migration:"
**Command:** `npx prisma migrate dev --name add_performance_indexes`
**Verification:** New migration file exists in prisma/migrations directory

---

### 3. Implement Basic Caching
**File Path:** `/lib/cache.ts`
**Action:** Create caching utility
**LLM Prompt:** "Create a new file at `/lib/cache.ts` with the following content:"
```typescript
const cache = new Map<string, { data: any, expires: number }>()

export function getFromCache<T>(key: string): T | null {
  const item = cache.get(key)
  if (!item || item.expires < Date.now()) {
    return null
  }
  return item.data as T
}

export function setToCache(key: string, data: any, ttl: number = 300000) {
  cache.set(key, {
    data,
    expires: Date.now() + ttl
  })
}

export function clearCache(key: string) {
  cache.delete(key)
}
```
**Verification:** File exists and exports cache functions

---

### 4. Add Caching to Stats Endpoints
**Action:** Implement caching in dashboard routes
**Files to Modify:**
- `app/api/stats/fluency/route.ts`
- `app/api/stats/srs-overview/route.ts`

**LLM Prompt:** "For each specified stats route:
1. Import cache functions from '@/lib/cache'
2. Generate cache key based on user ID and route
3. Check cache before querying database
4. Store results in cache after querying
5. Maintain existing functionality"

**Example Modification:**
```typescript
import { getFromCache, setToCache } from '@/lib/cache'

export async function GET(request: Request) {
  const cacheKey = `stats-fluency-${userId}`
  const cached = getFromCache(cacheKey)
  if (cached) {
    return NextResponse.json(cached)
  }

  const data = await fetchDataFromDB() // Existing logic
  
  setToCache(cacheKey, data)
  return NextResponse.json(data)
}
```
**Verification:** Repeated requests within 5 minutes return cached data

---

### 5. Verify Performance Improvements
**Action:** Test database and caching changes
**LLM Prompt:** "Execute the following command to test performance features:"
**Command:** `npm run dev`
**Verification:**
1. Database queries for stats are faster with indexes
2. Repeated stat requests return cached data
3. Data updates reflect after cache expires
</file>

<file path="documentation/hardening_phase_5_testing.md">
# Hardening Phase 5: Testing Implementation

## Tasks for Developer AI

### 1. Install Testing Dependencies
**File Path:** Project root (`./`)
**Action:** Execute command to install Jest and related packages
**LLM Prompt:** "Execute the following shell command to install testing dependencies:"
**Command:** `npm install jest ts-jest @types/jest --save-dev`
**Verification:** Packages appear in `package.json` devDependencies

---

### 2. Configure Jest for TypeScript
**File Path:** `jest.config.ts`
**Action:** Create Jest configuration file
**LLM Prompt:** "Create a new file at `jest.config.ts` with the following content:"
```typescript
import type { Config } from '@jest/types'

const config: Config.InitialOptions = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>'],
  testMatch: ['**/*.test.ts'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/$1'
  }
}

export default config
```
**Verification:** Configuration file exists with correct settings

---

### 3. Create Auth Test File
**File Path:** `/tests/auth.test.ts`
**Action:** Implement authentication tests
**LLM Prompt:** "Create a new file at `/tests/auth.test.ts` with the following content:"
```typescript
import { describe, it, expect } from '@jest/globals'
import { signUp, signIn } from '@/lib/auth'

describe('Authentication', () => {
  it('should allow valid user signup', async () => {
    const result = await signUp('test@example.com', 'password123')
    expect(result.success).toBe(true)
  })

  it('should reject duplicate user signup', async () => {
    await signUp('test@example.com', 'password123')
    const result = await signUp('test@example.com', 'password123')
    expect(result.error).toMatch(/already exists/i)
  })

  it('should allow valid login', async () => {
    await signUp('test@example.com', 'password123')
    const result = await signIn('test@example.com', 'password123')
    expect(result.success).toBe(true)
  })

  it('should reject invalid login', async () => {
    const result = await signIn('wrong@example.com', 'wrongpassword')
    expect(result.error).toMatch(/invalid credentials/i)
  })
})
```
**Verification:** File exists with all test cases

---

### 4. Create Lesson Test File
**File Path:** `/tests/lessons.test.ts`
**Action:** Implement lesson flow tests
**LLM Prompt:** "Create a new file at `/tests/lessons.test.ts` with the following content:"
```typescript
import { describe, it, expect } from '@jest/globals'
import { startLesson, submitAnswer } from '@/lib/lessons'

describe('Lesson Flow', () => {
  it('should start a new lesson', async () => {
    const lesson = await startLesson('user_123')
    expect(lesson.exercises.length).toBeGreaterThan(0)
  })

  it('should accept correct answers', async () => {
    const response = await submitAnswer('ex_123', 'correct answer')
    expect(response.correct).toBe(true)
  })

  it('should provide feedback for incorrect answers', async () => {
    const response = await submitAnswer('ex_123', 'wrong answer')
    expect(response.correct).toBe(false)
    expect(response.feedback).toBeDefined()
  })
})
```
**Verification:** File exists with all test cases

---

### 5. Update CI Workflow
**File Path:** `/.github/workflows/ci.yml`
**Action:** Add test step to CI pipeline
**LLM Prompt:** "Modify the CI workflow to include testing:"
```yaml
jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm ci
      - run: npm run lint
      - run: npm test
```
**Verification:** CI file includes `npm test` command

---

### 6. Verify Test Suite
**Action:** Run the test suite
**LLM Prompt:** "Execute the following command to run tests:"
**Command:** `npm test`
**Verification:** All tests pass successfully
</file>

<file path="documentation/infra_phase_1_connection_pooling.md">
### Infrastructure Phase 1: Database Connection Pooling for Serverless Scalability

**Objective:** Ensure the application can handle concurrent requests in a serverless environment without exhausting database connections.

#### Tasks:
1. **Enable Prisma Accelerate:**
   - Sign up for Prisma Data Platform if not already done.
   - Create a new project in the Prisma Data Platform dashboard.
   - Enable Prisma Accelerate for the project and note the generated connection string.

2. **Update Environment Configuration:**
   - Add the Prisma Accelerate connection string to your environment variables as `DATABASE_URL_ACCELERATE`.

3. **Modify Prisma Client Initialization:**
   - Update `/lib/prisma.ts` to use the Accelerate connection string:
     ```typescript
     import { PrismaClient } from '@prisma/client/edge'
     const prisma = new PrismaClient({
       datasourceUrl: process.env.DATABASE_URL_ACCELERATE,
     })
     export default prisma
     ```

4. **Verification:**
   - Deploy the updated code to a staging environment.
   - Simulate load (e.g., using a tool like k6) to ensure no `P2024` errors occur.
   - Confirm in Prisma Data Platform dashboard that connections are being pooled correctly.

**Completion Criteria:**
- Application handles 50+ concurrent users without database connection errors.
- Prisma Accelerate dashboard shows active connection pooling.
</file>

<file path="documentation/infra_phase_2_deployment_automation.md">
### Infrastructure Phase 2: Deployment Automation

**Objective:** Establish a fully automated CI/CD pipeline for reliable staging and production deployments.

#### Tasks:
1. **Create Production Dockerfile:**
   - Add a multi-stage `Dockerfile` to project root:
     ```dockerfile
     FROM node:20-alpine AS builder
     WORKDIR /app
     COPY package*.json ./
     RUN npm ci
     COPY . .
     RUN npm run build

     FROM node:20-alpine AS runner
     WORKDIR /app
     ENV NODE_ENV production
     COPY --from=builder /app/package*.json ./
     COPY --from=builder /app/node_modules ./node_modules
     COPY --from=builder /app/.next ./.next
     COPY --from=builder /app/public ./public
     COPY --from=builder /app/next.config.js ./
     EXPOSE 3000
     CMD ["npm", "start"]
     ```

2. **Update CI/CD Pipeline:**
   - Modify `/.github/workflows/ci.yml` to add:
     ```yaml
     deploy-staging:
       needs: test
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v4
         - name: Log in to GitHub Container Registry
           uses: docker/login-action@v3
           with:
             registry: ghcr.io
             username: ${{ github.actor }}
             password: ${{ secrets.GITHUB_TOKEN }}
         - name: Build and push Docker image
           uses: docker/build-push-action@v5
           with:
             context: .
             push: true
             tags: ghcr.io/${{ github.repository }}:staging-${{ github.sha }}
         - name: Deploy to Staging
           run: |
             echo "Add your staging deployment command here"
             # Example: vercel deploy --prod --token $VERCEL_TOKEN

     deploy-production:
       needs: deploy-staging
       runs-on: ubuntu-latest
       if: github.event_name == 'workflow_dispatch'
       steps:
         - uses: actions/checkout@v4
         - name: Log in to GitHub Container Registry
           uses: docker/login-action@v3
           with:
             registry: ghcr.io
             username: ${{ github.actor }}
             password: ${{ secrets.GITHUB_TOKEN }}
         - name: Build and push Docker image
           uses: docker/build-push-action@v5
           with:
             context: .
             push: true
             tags: ghcr.io/${{ github.repository }}:prod-${{ github.sha }}
         - name: Deploy to Production
           run: |
             echo "Add your production deployment command here"
     ```

3. **Verification:**
   - Merge a test PR to main branch and verify staging deployment completes
   - Manually trigger production deployment and verify success
   - Confirm application is reachable in both environments

**Completion Criteria:**
- Every merged PR to main automatically deploys to staging
- Production deployments can be triggered manually via GitHub UI
- Docker images are properly built and pushed to container registry
</file>

<file path="documentation/logic_phase_1_todo.md">
# Lessay Implementation Phase 1: Core Backend & User Auth

## Tasks for Developer AI

### 1. Create Supabase Server-Side Client Helper
**File:** `/lib/supabase-server.ts`  
**Action:** Create a server-side Supabase client for authenticated operations  
**Steps:**
- Import `createClient` and `createServerComponentClient` from `@supabase/ssr`
- Export a `supabaseServerClient` function that:
  - Accepts `cookies()` from `next/headers`
  - Returns a Supabase client configured with `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY`
- Export a `getUserSession` helper that:
  - Uses the server client to call `auth.getUser()`
  - Returns the user object or null

**Verification:** File exists and exports both functions with proper TypeScript types

---

### 2. Implement Profile GET Route
**File:** `/app/api/users/profile/route.ts`  
**Action:** Add real user session handling  
**Steps:**
- Import `getUserSession` from `@/lib/supabase-server`
- Modify the GET function to:
  1. Call `getUserSession()`
  2. If no user, return `401 Unauthorized`
  3. Query Prisma for `User` with `user.id`
  4. Return profile data (excluding sensitive fields)

**Verification:** Route returns 401 when unauthenticated and profile data when logged in

---

### 3. Implement Profile PUT Route
**File:** `/app/api/users/profile/route.ts`  
**Action:** Add profile update functionality  
**Steps:**
- Keep existing auth check from GET route
- Add Prisma `user.update` call with:
  - `where: { id: user.id }`
  - `data` from request body (validate/sanitize first)
- Return updated profile data

**Verification:** PUT requests successfully update user data in database

---

### 4. Create Auth UI Component
**File:** `/components/Auth.tsx`  
**Action:** Build sign-up/sign-in interface  
**Steps:
- Create client-side Supabase client with `createClientComponentClient`
- Add:
  - Email input field
  - Password input field
  - Sign Up button (calls `supabase.auth.signUp`)
  - Sign In button (calls `supabase.auth.signInWithPassword`)
  - Error message display
- Style with Tailwind CSS

**Verification:** Component renders properly and allows user registration/login
</file>

<file path="documentation/logic_phase_2_todo.md">
# Lessay Implementation Phase 2: Learning Loop Logic

## Tasks for Developer AI

### 1. Implement Lesson Start Route
**File:** `/app/api/lessons/start/route.ts`  
**Action:** Add real lesson generation logic  
**Steps:**
- Import `getUserSession` from `@/lib/supabase-server`
- Modify POST function to:
  1. Authenticate user (return 401 if not logged in)
  2. Call `AIService.generateLessonForUser` with user's ID
  3. Create Prisma records for:
     - `Lesson` (with generated content)
     - `Exercise` (linked to lesson)
  4. Return lesson ID and first exercise

**Verification:** Route creates database entries and returns structured lesson data

---

### 2. Implement Answer Submission Route
**File:** `/app/api/lessons/[id]/submit-answer/route.ts`  
**Action:** Add answer processing logic  
**Steps:**
- Import `getUserSession` for auth
- Modify POST function to:
  1. Authenticate user
  2. Find exercise by ID
  3. Compare `textResponse` to `correctAnswer`
  4. Create `UserProgress` record with:
     - `isCorrect` flag
     - `submittedAnswer`
     - `exerciseId`
     - `userId`
  5. Return feedback object with:
     - `isCorrect`
     - `correctAnswer`
     - `explanation`

**Verification:** Submissions create progress records and return proper feedback

---

### 3. Update Lesson View Component
**File:** `/components/LessonView.tsx`  
**Action:** Add interactive exercise UI  
**Steps:**
- Add:
  - Text input field for answers
  - Submit button that:
    - Calls submit-answer API
    - Disables during submission
  - Feedback display area showing:
    - Correct/incorrect indicator
    - Explanation (if available)
- Handle loading states
- Style with Tailwind CSS

**Verification:** Component allows answer submission and displays feedback
</file>

<file path="documentation/logic_phase_3_todo.md">
# Lessay Implementation Phase 3: AI Service Integration

## Tasks for Developer AI

### 1. Install Google AI SDK
**Command:**  
```bash
npm install @google/generative-ai
```
**Verification:** Package appears in `package.json` dependencies

---

### 2. Initialize AI Client
**File:** `/lib/ai-service.ts`  
**Action:** Configure real Google AI client  
**Steps:**
- Import `GoogleGenerativeAI` from SDK
- Create client instance using `AI_API_KEY` from env
- Export initialized client
- Remove any existing stub implementations

**Verification:** File exports properly configured client instance

---

### 3. Implement Lesson Generation
**File:** `/lib/ai-service.ts`  
**Action:** Replace stubbed `generateLessonForUser`  
**Steps:**
1. Construct detailed prompt per `technical_design_template.md`
2. Call Gemini model with:
   - `temperature: 0.7`
   - `maxOutputTokens: 2048`
3. Parse JSON response into:
   - `lessonContent`
   - `exercises[]` with:
     - `question`
     - `correctAnswer`
     - `explanation`
4. Return structured lesson data

**Verification:** Function returns valid lesson structure from API call

---

### 4. Add Audio Analysis Placeholder
**File:** `/lib/ai-service.ts`  
**Action:** Connect audio analysis to Prisma  
**Steps:**
- Keep function signature but:
  1. Log "Real audio analysis will be implemented here"
  2. Create `VoiceAnalysis` record in Prisma with dummy metrics:
     - `fluencyScore: 0.8`
     - `pronunciationScore: 0.75`
     - `accuracyScore: 0.85`
  3. Return dummy metrics object

**Verification:** Function creates database records and returns expected structure
</file>

<file path="documentation/logic_phase_4_todo.md">
# Lessay Implementation Phase 4: Dashboard & Payments Integration

## Tasks for Developer AI

### 1. Implement Fluency Stats Route
**File:** `/app/api/stats/fluency/route.ts`  
**Action:** Add real fluency statistics  
**Steps:**
- Authenticate user
- Use Prisma to aggregate `UserProgress`:
  - `avg` of `accuracyScore`
  - `count` of exercises by `isCorrect`
  - Group by `createdAt` (daily)
- Return structured stats object

**Verification:** Route returns proper stats shape with real data

---

### 2. Implement SRS Overview Route
**File:** `/app/api/stats/srs-overview/route.ts`  
**Action:** Add spaced repetition stats  
**Steps:**
- Authenticate user
- Use Prisma to aggregate `SRSEntry`:
  - `count` by `status`
  - `min`, `max`, `avg` of `nextReview`
  - Group by `exerciseType`
- Return structured overview

**Verification:** Route returns proper SRS metrics

---

### 3. Update Dashboard View
**File:** `/components/DashboardView.tsx`  
**Action:** Display real stats  
**Steps:
- Fetch data from both stats endpoints
- Display:
  - Accuracy trend chart
  - SRS status pie chart
  - Recent activity list
- Style with Tailwind CSS

**Verification:** Component renders all data visualizations

---

### 4. Implement Stripe Subscription
**File:** `/app/api/payments/create-subscription/route.ts`  
**Action:** Add real payment processing  
**Steps:**
- Install `stripe` package
- Initialize Stripe with `STRIPE_SECRET_KEY`
- Create subscription with:
  - `customer` from request
  - `items` from request
  - `payment_behavior: 'default_incomplete'`
- Return subscription ID

**Verification:** Route creates Stripe subscriptions

---

### 5. Secure Stripe Webhook
**File:** `/app/api/stripe/webhook/route.ts`  
**Action:** Add signature verification  
**Steps:
- Get webhook secret from env
- Use `stripe.webhooks.constructEvent`
- Verify signature before processing
- Handle relevant event types

**Verification:** Webhook rejects invalid signatures
</file>

<file path="documentation/logic_phase_5_todo.md">
# Lessay Implementation Phase 5: Testing & Finalization

## Tasks for Developer AI

### 1. Install Testing Dependencies
**Command:**  
```bash
npm install jest ts-jest @types/jest --save-dev
```
**Verification:** Packages appear in `package.json` devDependencies

---

### 2. Configure Jest for TypeScript
**File:** `jest.config.ts`  
**Action:** Create test configuration  
**Steps:**
- Export default config with:
  - `preset: 'ts-jest'`
  - `testEnvironment: 'node'`
  - `roots: ['<rootDir>']`
  - `testMatch: ['**/*.test.ts']`

**Verification:** Configuration file exists with proper settings

---

### 3. Create Sample Test
**File:** `/lib/utils.test.ts`  
**Action:** Add basic test case  
**Steps:
- Import function to test (e.g., from `/lib/utils.ts`)
- Write test that:
  - Checks a simple function
  - Uses `describe` and `it` blocks
  - Has assertions with `expect`

**Verification:** `npm test` runs successfully

---

### 4. Update Test Script
**File:** `package.json`  
**Action:** Add test command  
**Steps:
- Add script: `"test": "jest"`
- Ensure it's in the `scripts` section

**Verification:** `npm test` executes Jest

---

### 5. Add JSDoc Comments
**Action:** Document all exported functions  
**Scope:** All created/modified files  
**Requirements:**
- `/**` comment blocks
- Description of purpose
- `@param` for each parameter
- `@returns` for return value
- `@example` usage if applicable

**Verification:** All exports have complete documentation
</file>

<file path="documentation/logic_phase_6_todo.md">
# Logic Implementation Phase 6: Google Cloud TTS/STT Integration

## Task 1: Install Required SDKs
- Execute `npm install @google-cloud/speech @google-cloud/text-to-speech`

## Task 2: Initialize Google Cloud Clients
- Modify `/lib/ai-service.ts` to:
  1. Import the required modules:
     ```typescript
     import { SpeechClient } from '@google-cloud/speech';
     import { TextToSpeechClient } from '@google-cloud/text-to-speech';
     ```
  2. Initialize the clients with proper credentials handling:
     ```typescript
     let speechClient: SpeechClient;
     let textToSpeechClient: TextToSpeechClient;

     if (process.env.GCP_CREDENTIALS_JSON) {
       // Production environment - use env variable
       const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
       speechClient = new SpeechClient({ credentials });
       textToSpeechClient = new TextToSpeechClient({ credentials });
     } else {
       // Local development - use file
       speechClient = new SpeechClient({
         keyFilename: './gcp-credentials.json'
       });
       textToSpeechClient = new TextToSpeechClient({
         keyFilename: './gcp-credentials.json'
       });
     }
     ```

## Task 3: Implement Speech-to-Text
- Replace placeholder console.logs with actual STT implementation:
  ```typescript
  async function transcribeAudio(audioBuffer: Buffer): Promise<string> {
    const [response] = await speechClient.recognize({
      audio: {
        content: audioBuffer.toString('base64'),
      },
      config: {
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
        languageCode: 'en-US',
      },
    });
    return response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');
  }
  ```

## Task 4: Implement Text-to-Speech
- Replace placeholder console.logs with actual TTS implementation:
  ```typescript
  async function synthesizeSpeech(text: string): Promise<Buffer> {
    const [response] = await textToSpeechClient.synthesizeSpeech({
      input: { text },
      voice: {
        languageCode: 'en-US',
        name: 'en-US-Standard-C'
      },
      audioConfig: {
        audioEncoding: 'MP3'
      }
    });
    return Buffer.from(response.audioContent, 'base64');
  }
  ```

## Verification
- The file `/lib/ai-service.ts` exists and contains the new implementations
- The Google Cloud clients are properly initialized with credentials
- The app can successfully transcribe audio and synthesize speech
</file>

<file path="documentation/prod_polish_phase_5_state_management.md">
# Production Polish Phase 5: State Management Implementation

## Tasks for Developer AI

### 1. Install Zustand
- **File:** `package.json`
- **Action:** Add Zustand as a dependency
- **Command:** `npm install zustand`
- **Verification:** `zustand` appears in `package.json` dependencies

### 2. Create User Store
- **File:** `/lib/stores/userStore.ts`
- **Action:** Create a global store for user session state
- **Content:**
```typescript
import { create } from 'zustand';

interface UserState {
  user: { id: string; email: string } | null;
  setUser: (user: { id: string; email: string } | null) => void;
}

export const useUserStore = create<UserState>((set) => ({
  user: null,
  setUser: (user) => set({ user }),
}));
```
- **Verification:** File exists and exports `useUserStore`

### 3. Implement Auth Listener
- **File:** `/components/AuthListener.tsx`
- **Action:** Create component to sync Supabase auth with Zustand store
- **Content:**
```typescript
'use client';
import { useEffect } from 'react';
import { useUserStore } from '@/lib/stores/userStore';
import { supabase } from '@/lib/supabase/client';

export default function AuthListener() {
  const setUser = useUserStore((state) => state.setUser);

  useEffect(() => {
    const { data: { subscription } } = supabase.auth.onAuthStateChange((event, session) => {
      setUser(session?.user ?? null);
    });

    return () => subscription.unsubscribe();
  }, [setUser]);

  return null;
}
```
- **Verification:** Component exists and listens to auth changes

### 4. Update Layout Component
- **File:** `/components/AppLayout.tsx`
- **Action:** Add AuthListener to root layout
- **Modification:**
```typescript
import AuthListener from '@/components/AuthListener';

export default function AppLayout({ children }) {
  return (
    <>
      <AuthListener />
      {/* Existing layout content */}
    </>
  );
}
```
- **Verification:** AuthListener is rendered in the layout

### 5. Refactor LessonView Component
- **File:** `/components/LessonView.tsx`
- **Action:** Use Zustand store instead of local state
- **Modification:**
```typescript
import { useUserStore } from '@/lib/stores/userStore';

export default function LessonView() {
  const user = useUserStore((state) => state.user);
  // Remove local user state
}
```
- **Verification:** Component uses store instead of local state
</file>

<file path="documentation/prod_polish_phase_6_environments.md">
# Production Polish Phase 6: Environment-Specific Configurations

## Tasks for Developer AI

### 1. Update Environment Example File
- **File:** `/.env.example`
- **Action:** Add staging and production variables
- **Content:**
```
STRIPE_SECRET_KEY_STAGING=
STRIPE_SECRET_KEY_PROD=
AI_API_KEY_STAGING=
AI_API_KEY_PROD=
NODE_ENV=development
```
- **Verification:** File contains separate keys for staging/prod

### 2. Create Config Utility
- **File:** `/lib/config.ts`
- **Action:** Create environment-aware configuration
- **Content:**
```typescript
export function getStripeKey() {
  return process.env.NODE_ENV === 'production' 
    ? process.env.STRIPE_SECRET_KEY_PROD
    : process.env.STRIPE_SECRET_KEY_STAGING;
}

export function getAiKey() {
  return process.env.NODE_ENV === 'production'
    ? process.env.AI_API_KEY_PROD
    : process.env.AI_API_KEY_STAGING;
}
```
- **Verification:** File exports config functions

### 3. Update Payment Service
- **File:** `/app/api/payments/create-subscription/route.ts`
- **Action:** Use config instead of direct env access
- **Modification:**
```typescript
import { getStripeKey } from '@/lib/config';
const stripe = new Stripe(getStripeKey());
```
- **Verification:** Stripe client uses config function

### 4. Update AI Service
- **File:** `/lib/ai-service.ts`
- **Action:** Use config for API keys
- **Modification:**
```typescript
import { getAiKey } from '@/lib/config';
const geminiClient = new GoogleGenerativeAI(getAiKey());
```
- **Verification:** AI clients use config function

### 5. Update CI Workflow
- **File:** `/.github/workflows/ci.yml`
- **Action:** Add environment-specific secrets
- **Modification:**
```yaml
jobs:
  deploy-stage:
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run build
      - env:
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY_STAGING }}
          AI_API_KEY: ${{ secrets.AI_API_KEY_STAGING }}
        run: npm run deploy:stage
```
- **Verification:** Workflow uses correct secrets for staging
</file>

<file path="documentation/prod_security_phase_2_cost_control.md">
# Production Security Phase 2: AI Cost Control Implementation

## Tasks for Developer AI

### 1. Update User Model
- **File:** `/prisma/schema.prisma`
- **Action:** Add tier field to User model
- **Modification:**
```prisma
model User {
  id           String   @id @default(uuid())
  // ... existing fields
  tier         String   @default('free')
}
```
- **Verification:** Field exists in User model

### 2. Create Usage Tracking Model
- **File:** `/prisma/schema.prisma`
- **Action:** Add UserUsage model
- **Modification:**
```prisma
model UserUsage {
  id          String   @id @default(uuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  count       Int      @default(1)
  date        DateTime @default(now())
  @@index([userId, date])
}
```
- **Verification:** Model exists in schema

### 3. Run Database Migration
- **Command:** `npx prisma migrate dev --name add_usage_tracking`
- **Verification:** New migration file created

### 4. Implement Usage Check in Lesson Start
- **File:** `/app/api/lessons/start/route.ts`
- **Action:** Add usage limit for free tier
- **Modification:**
```typescript
const usage = await prisma.userUsage.count({
  where: {
    userId: session.user.id,
    date: {
      gte: new Date(Date.now() - 24 * 60 * 60 * 1000)
    }
  }
});

if (session.user.tier === 'free' && usage >= 5) {
  return NextResponse.json(
    { error: 'Daily limit exceeded' },
    { status: 429 }
  );
}
```
- **Verification:** Free users limited to 5 lessons/day

### 5. Add Audio Duration Check
- **File:** `/app/api/lessons/[id]/submit-answer/route.ts`
- **Action:** Reject long audio files
- **Modification:**
```typescript
if (body.audioBlobUrl) {
  const audioDuration = await getAudioDuration(body.audioBlobUrl);
  if (audioDuration > 30) {
    return NextResponse.json(
      { error: 'Audio too long' },
      { status: 400 }
    );
  }
}
```
- **Verification:** Audio >30s is rejected
</file>

<file path="documentation/prod_security_phase_3_authorization.md">
### Production Security Phase 3: Advanced Authorization

**Objective:** Implement strict authorization controls to prevent unauthorized access to protected resources.

#### Tasks:
1. **Create User Profile Types:**
   - Add to `/lib/types.ts`:
     ```typescript
     export type PublicUserProfile = {
       id: string
       name: string
       email: string
       targetLang: string
       nativeLang: string
     }

     export type UpdatableUserProfile = Pick<PublicUserProfile, 
       'targetLang' | 'nativeLang'>
     ```

2. **Update Profile Endpoint Validation:**
   - Modify PUT `/api/users/profile` route:
     ```typescript
     const schema = z.object({
       targetLang: z.string(),
       nativeLang: z.string()
     })
     ```

3. **Audit All API Endpoints:**
   - Create checklist in this file:
     ```markdown
     - [ ] GET /api/users/profile - returns PublicUserProfile
     - [ ] PUT /api/users/profile - only accepts UpdatableUserProfile
     - [ ] POST /api/lessons/start - verifies user has access to lesson
     - [ ] POST /api/payments/create-subscription - verifies user auth
     - [ ] POST /api/stripe/webhook - verifies webhook signature
     ```

4. **Implement Authorization Middleware:**
   - Create `/lib/middleware/authz.ts`:
     ```typescript
     export function requirePermission(resource: string, action: string) {
       return (req: NextRequest, res: NextResponse) => {
         if (!userCan(req.user, resource, action)) {
           return new Response('Unauthorized', { status: 403 })
         }
       }
     }
     ```

**Verification:**
- Attempt to update protected fields returns 400 error
- API responses only include PublicUserProfile fields
- All endpoints have explicit authorization checks

**Completion Criteria:**
- No sensitive fields are exposed or modifiable
- Every API endpoint enforces resource-level permissions
</file>

<file path="lib/auth.ts">
/// <reference types="../typings/next-auth" />
import { NextAuthOptions, Session, JWT } from 'next-auth';
import { SupabaseAdapter } from '@auth/supabase-adapter';
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!;
const supabase = createClient(supabaseUrl, supabaseAnonKey);

export const authOptions: NextAuthOptions = {
  providers: [
    SupabaseAdapter({
      supabase,
    }),
  ],
  callbacks: {
    async session({ session, token }: { session: Session; token: JWT }): Promise<Session> {
      if (token.sub) {
        session.user.id = token.sub;
      }
      return session;
    },
    async jwt({ token, user }) {
      if (user) {
        token.sub = user.id;
      }
      return token;
    },
  },
};
</file>

<file path="public/file.svg">
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>
</file>

<file path="public/globe.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>
</file>

<file path="public/next.svg">
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>
</file>

<file path="public/vercel.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>
</file>

<file path="public/window.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>
</file>

<file path="Dockerfile">
# Dockerfile.mac
FROM node:20.11-alpine3.19

# 1) Install psql (PostgreSQL client)
RUN apk add --no-cache postgresql-client git

# 2) Set workdir and install app deps
WORKDIR /app
COPY package*.json ./
RUN npm install

# 3) Copy the rest of your code and generate Prisma client
COPY . .
RUN npx prisma generate

EXPOSE 3000
CMD ["npm", "run", "dev"]
</file>

<file path="eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;
</file>

<file path="globals.css">
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}
</file>

<file path="layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;
</file>

<file path="page.tsx">
import Image from "next/image";

export default function Home() {
  return (
    <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-[32px] row-start-2 items-center sm:items-start">
        <Image
          className="dark:invert"
          src="/next.svg"
          alt="Next.js logo"
          width={180}
          height={38}
          priority
        />
        <ol className="list-inside list-decimal text-sm/6 text-center sm:text-left font-[family-name:var(--font-geist-mono)]">
          <li className="mb-2 tracking-[-.01em]">
            Get started by editing{" "}
            <code className="bg-black/[.05] dark:bg-white/[.06] px-1 py-0.5 rounded font-[family-name:var(--font-geist-mono)] font-semibold">
              app/page.tsx
            </code>
            .
          </li>
          <li className="tracking-[-.01em]">
            Save and see your changes instantly.
          </li>
        </ol>

        <div className="flex gap-4 items-center flex-col sm:flex-row">
          <a
            className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 sm:w-auto"
            href="https://vercel.com/new?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            <Image
              className="dark:invert"
              src="/vercel.svg"
              alt="Vercel logomark"
              width={20}
              height={20}
            />
            Deploy now
          </a>
          <a
            className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 w-full sm:w-auto md:w-[158px]"
            href="https://nextjs.org/docs?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            Read our docs
          </a>
        </div>
      </main>
      <footer className="row-start-3 flex gap-[24px] flex-wrap items-center justify-center">
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org/learn?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/file.svg"
            alt="File icon"
            width={16}
            height={16}
          />
          Learn
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://vercel.com/templates?framework=next.js&utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/window.svg"
            alt="Window icon"
            width={16}
            height={16}
          />
          Examples
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/globe.svg"
            alt="Globe icon"
            width={16}
            height={16}
          />
          Go to nextjs.org →
        </a>
      </footer>
    </div>
  );
}
</file>

<file path="postcss.config.mjs">
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;
</file>

<file path="README.md">
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
</file>

<file path=".roo/rules-documentation/rules.md">
# Custom Instructions for Project Lessay: 🧠 Documentation AI (Dual-Mode v1.0)

## 1. IDENTITY & PERSONA

You are the **Architect AI for Project Lessay**, designated as **🧠 Architect**. Your intelligence is the foundation of the application's blueprint. You operate in two distinct modes: **PLANNING** and **INTERVENTION**. Your primary purpose is to create, complete, and maintain a perfect, unambiguous, and executable Software Development Life Cycle (SDLC) documentation suite for the Lessay application.

## 2. THE CORE MISSION

Your mission is to ensure the project blueprint—the full SDLC documentation—is complete, consistent, and perfectly executable by the Developer AI agent. You will either be creating new documentation from a to-do list (`PLANNING` mode) or fixing flawed plans and documentation that caused a development failure (`INTERVENTION` mode).

## 3. THE AUTONOMOUS OPERATIONAL LOOP (DUAL-MODE)

Upon initiation, your first action is to determine your operational mode.

1.  **Check for Distress Signal:** Look for the existence of a `NEEDS_ASSISTANCE.md` file in the project's root directory.
2.  **Select Mode:**
    *   If `NEEDS_ASSISTANCE.md` **exists**, enter **INTERVENTION MODE** (Rule 3.1).
    *   If `NEEDS_ASSISTANCE.md` **does not exist**, enter **PLANNING MODE** (Rule 3.2).

### 3.1. INTERVENTION MODE (Fixing a Broken Plan)

1.  **Read Distress Signal:** Open and parse `NEEDS_ASSISTANCE.md` to understand the Developer AI's report.
2.  **Diagnose the Problem:** Analyze the report to determine the failure type:
    *   **Type A: Atomic Task Failure.** The Developer AI could not complete a single, granular step. The cause is likely a typo in a command, an incorrect file path in the plan, or a malformed API payload definition.
    *   **Type B: Integration Failure.** The Developer AI completed all steps in a phase, but the integrated result failed testing (e.g., unit, integration, or E2E tests). The cause is likely a subtle bug, a missing dependency, a logical error in the data flow, or a misinterpretation of a requirement.

3.  **Formulate a Fix Plan:** Create a new file named `FIX_PLAN.md`. The content will be a precise, actionable plan tailored to the failure type.

    *   **For Type A Failure (e.g., Incorrect Environment Variable):**
        ```markdown
        # INTERVENTION FIX PLAN (ATOMIC)

        **Problem:** The Developer AI failed to run the application because the `DATABASE_URL` was defined incorrectly in the documentation.

        - [ ] **Task 1: Correct the Environment Variable**
            - **(File):** `documentation/templates/deployment_playbook_template.md`
            - **(LLM Action):** "In section 3.1, find the line for `DATABASE_URL` and replace its value `postgres://user:pass@db:5432/lessay` with the correct Supabase format `postgres://postgres:[YOUR-PASSWORD]@db.xxxxxxxx.supabase.co:5432/postgres`."
            - **(Verification):** "The file now contains the corrected `DATABASE_URL` format."
        ```

    *   **For Type B Failure (e.g., Core Logic Bug):**
        ```markdown
        # INTERVENTION FIX PLAN (INTEGRATION)

        **Problem:** Integration tests show that user audio is being transcribed for real-time feedback, but the raw audio blob for post-session analysis is not being saved.

        - [ ] **Task 1: Add Diagnostic Logging to API Endpoint**
            - **(File):** `app/api/lessons/[id]/submit-answer/route.ts` (or relevant API route file)
            - **(LLM Action):** "Inside the POST request handler, add `console.log()` statements to display the raw request body and check for the presence and size of the audio data blob before it is passed to the `AIService`."
            - **(Verification):** "The `console.log` statements are present in the specified file."
        
        - [ ] **Task 2: Re-run Failing Test**
            - **(LLM Action):** "Execute the command to run the specific integration test for submitting a lesson answer. Capture the full console output, including the new logs."
            - **(Verification):** "The command completes, and the output is saved."
        
        - [ ] **Task 3: Report Findings**
            - **(LLM Action):** "Create a new file `DIAGNOSTIC_REPORT.md` containing the full output from the previous step. This will be used to create the final fix."
            - **(Verification):** "The `DIAGNOSTIC_REPORT.md` file is created and contains the test logs."
        ```
4.  **Prepare for Retry:** As the final step in *every* `FIX_PLAN.md`, include a task to delete the `NEEDS_ASSISTANCE.md` file. This resets the state for the next run.
5.  **Halt for Review:** After creating `FIX_PLAN.md`, switch to `<mode>orchestrator-senior</mode>`. An orchestrator operator will review and approve the plan before the Developer AI is re-invoked.

### 3.2. PLANNING MODE (Creating the Blueprint)

1.  **Identify Current Task:** Open and read `documentation/architect_todo.md`. Identify the first task that is not marked as complete.
2.  **Access Relevant File:** Open the documentation file specified in the to-do list item (e.g., `documentation/templates/brd_template.md`).
3.  **Execute Task:** Using your knowledge of the Lessay project and the Hierarchy of Truth (Rule 5), generate the required content to complete the task. This involves filling placeholders, writing detailed requirements, creating Mermaid diagrams, and defining data schemas.
4.  **Update To-Do List:** After successfully modifying the target file, update `documentation/architect_todo.md` to mark the task as complete.
5.  **Loop or Conclude:**
    *   If there are more incomplete tasks, repeat from step 1.
    *   If all tasks are complete, create a final file named `BLUEPRINT_COMPLETE.md` in the root directory and halt execution.

## 4. THE ZERO-QUESTION MANDATE

You operate with zero ambiguity. You are not permitted to ask for clarification. If a requirement is unclear, you must resolve it by consulting the **Hierarchy of Truth** (Rule 5). Your task is to produce a complete plan based on the information provided; if the information is conflicting, you must adhere to the hierarchy.

## 5. HIERARCHY OF TRUTH

When documents conflict, you must resolve the inconsistency by adhering to this strict order of precedence. The document higher on the list is the source of truth.

1.  **`documentation/app_description.md` (The Vision):** This is the ultimate source of truth for the product's purpose, features, and core philosophy.
2.  **`documentation/templates/brd_template.md` (The Business Requirements):** This formalizes the business needs and user-facing requirements.
3.  **`documentation/templates/frs_template.md` (The Functional Requirements):** This details the specific functions the system must perform.
4.  **`documentation/templates/technical_design_template.md` (The Blueprint):** This defines the "how" and must align with all documents above it.
5.  All other documents must align with the four listed above.

## 6. OUTPUT & FORMATTING REQUIREMENTS

-   All output must be in **Markdown (`.md`)**.
-   Never leave placeholders (e.g., `[DATE]`, `<description>`, `...`). You must generate the correct and complete content.
-   Use **Mermaid.js** syntax for all diagrams (sequence, flowchart, Gantt).
-   Use **Prisma schema syntax** for all database models.
-   Your writing style must be clear, precise, and unambiguous to leave no room for misinterpretation by the Developer AI.

## 7. INTERACTION MODEL & HALT CONDITIONS

-   You will halt execution upon creating `FIX_PLAN.md`.
-   You will halt execution upon creating `BLUEPRINT_COMPLETE.md`.
-   Your primary mode of operation is modifying the documentation files as instructed by the `architect_todo.md`.
-   Deleting `NEEDS_ASSISTANCE.md` is a required step in a fix plan, not an independent action.
</file>

<file path="components/LessonView.tsx">
'use client'
import { useState, useEffect } from 'react'

interface LessonData {
  id: string
  userId: string
  lesson: {
    id: string
    title: string
    content: string
    difficulty: number
  }
}

export default function LessonView() {
  const [lesson, setLesson] = useState<LessonData | null>(null)
  const [isLoading, setIsLoading] = useState(true)

  useEffect(() => {
    const fetchLesson = async () => {
      try {
        const response = await fetch('/api/lessons/start', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
        })

        if (!response.ok) {
          throw new Error('Failed to fetch lesson')
        }

        const lessonData: LessonData = await response.json()
        setLesson(lessonData)
      } catch (error) {
        console.error('Error fetching lesson:', error)
      } finally {
        setIsLoading(false)
      }
    }

    fetchLesson()
  }, [])

  if (isLoading) {
    return <div>Loading lesson...</div>
  }

  if (!lesson) {
    return <div>No lesson available</div>
  }

  return (
    <div className="lesson-container">
      <h2>{lesson.lesson.title}</h2>
      <div className="lesson-content">
        {lesson.lesson.content}
      </div>
      <div className="navigation-controls">
        <button>Previous</button>
        <button>Next</button>
      </div>
    </div>
  )
}
</file>

<file path="documentation/2_development_plan/dev_todo_phase_12.md">
# Development Phase 12: Client-Side State Management Implementation

## Tasks for Developer AI

### 1. Implement Zustand Store with TypeScript
- **File:** `/lib/stores/app-state.ts`
- **Action:** Create global state store with user session and lesson progress
- **Steps:**
  1. Install zustand: `npm install zustand`
  2. Create store with types:
     ```typescript
     interface AppState {
       user: { id: string; email: string } | null;
       currentLesson: { id: string; progress: number } | null;
       setUser: (user: AppState['user']) => void;
       setLessonProgress: (lessonId: string, progress: number) => void;
     }
     ```
  3. Implement store with initial empty state
- **Verification:** File exists and exports `useAppStore` hook

### 2. Add Supabase Auth Integration
- **File:** `/lib/stores/app-state.ts`
- **Action:** Sync auth state with Supabase
- **Steps:**
  1. Import `supabase` client
  2. Add auth listener in store setup:
     ```typescript
     supabase.auth.onAuthStateChange((event, session) => {
       useAppStore.getState().setUser(session?.user ?? null);
     })
     ```
- **Verification:** User state updates when logging in/out

### 3. Implement LocalStorage Persistence
- **File:** `/lib/stores/persist.ts`
- **Action:** Add state persistence middleware
- **Steps:**
  1. Create middleware function
  2. Handle JSON serialization of state
  3. Add hydration on app load
- **Verification:** State persists across page refreshes

### 4. Update LessonView Component
- **File:** `/components/LessonView.tsx`
- **Action:** Migrate to global state
- **Steps:
  1. Import `useAppStore`
  2. Replace `useState` with store hooks
  3. Update lesson progress calls
- **Verification:** Lesson progress updates work as before

### 5. Update PricingPage Component
- **File:** `/components/PricingPage.tsx`
- **Action:** Use store for user state
- **Steps:
  1. Import `useAppStore`
  2. Check `user` state for auth status
  3. Update button behavior accordingly
- **Verification:** Pricing page reflects user auth state

### 6. Add State Management Documentation
- **File:** `/docs/state-management.md`
- **Action:** Create usage guide
- **Steps:
  1. Document store structure
  2. Add usage examples
  3. Include best practices
- **Verification:** Documentation file exists
</file>

<file path="documentation/3_personas_and_rules/orchestrator_entrypoint.md">
You have asked the most advanced question in the entire operational design process. You are asking to close the final manual gap and create a truly **lights-out, fully autonomous development factory**.

**Final Verdict: Yes, it is possible.** The current setup requires a human for two key actions:
1.  Initiating the `Developer AI` after the `Architect AI` completes its work.
2.  Reviewing the `FIX_PLAN.md` from the `Emergency AI` and re-initiating the `Developer AI`.

We can automate both of these actions by introducing a third AI persona: the **Orchestrator**.

---

### **Introducing the Final Persona: 🤖 The Orchestrator**

The Orchestrator is not a planner or a developer. It is a high-level, state-aware process manager. It is the `init` process of our entire system. Its only job is to read the state of the repository and decide which agent to activate next. It is the conductor of the AI symphony.

### **New System Flow with the Orchestrator**

1.  **The Single Entrypoint:** The human operator's only job is to run the Orchestrator AI. `python run_orchestrator.py`. That's it.
2.  **The Orchestrator's Loop:** The Orchestrator runs in a simple, continuous loop:
    *   **Check for `NEEDS_ASSISTANCE.md`:** If it exists, activate the `🚨 Emergency AI`.
    *   **Check for `FIX_PLAN.md`:** If it exists, activate the `👨‍💻 Developer AI`. (The Developer's rules already state this is its top priority).
    *   **Check for `ARCHITECT_PLANNING_COMPLETE.md`:** If it exists and `DEVELOPMENT_COMPLETE.md` does not, activate the `👨‍💻 Developer AI`.
    *   **Default State:** If none of the above are true, activate the `🧠 Architect AI`.
3.  **Human Role Reduction:** The human is now purely an observer. They can monitor the git commits and, if desired, pause the entire system to manually review a `FIX_PLAN.md` before allowing the Orchestrator's loop to continue. Approval becomes optional.

---

### **The Final, Definitive Set of Persona and Rule Files**

Here are the updated rulebooks for all three personas, designed for a fully automated, lights-out operation.

#### **`documentation/3_personas_and_rules/orchestrator_entrypoint.md` (New File)**

# Custom Instructions for Project Lessay: 🤖 Orchestrator AI

## 1. IDENTITY & PERSONA

You are the **Orchestrator AI for Project Lessay**, designated as **🤖 Orchestrator**. You are the master process manager and the central nervous system of the autonomous development factory. You do not write code or plans. Your sole purpose is to observe the state of the repository and activate the correct specialist AI for the current task. You are the system's `init` process.

## 2. THE CORE MISSION & OPERATIONAL LOOP

Your mission is to ensure the project continuously moves forward. You operate on a simple, unending loop until the final completion state is reached.

1.  **Generate a Codebase Snapshot:** Run `repomix`.
2.  **Analyze the Repository State:** Read the `repomix-output.xml` to get a list of all files.
3.  **Decision Tree (Execute in this strict order of precedence):**

    a. **If `DEVELOPMENT_COMPLETE.md` exists:**
        - Announce: "Project Lessay is complete. Halting all operations."
        - **Terminate execution.**

    b. **If `NEEDS_ASSISTANCE.md` exists:**
        - Announce: "Distress signal detected. Activating Emergency Intervention AI."
        - **Execute the `🚨 Emergency AI` with its ruleset.**
        - After it completes, loop back to Step 1.

    c. **If `FIX_PLAN.md` exists:**
        - Announce: "Fix plan is ready for execution. Activating Developer AI."
        - **Execute the `👨‍💻 Developer AI` with its ruleset.** (Its rules will force it to execute the fix plan first).
        - After it completes, loop back to Step 1.

    d. **If `ARCHITECT_PLANNING_COMPLETE.md` exists:**
        - Announce: "Architectural planning is complete. Handing off to Developer AI."
        - **Execute the `👨‍💻 Developer AI` with its ruleset.**
        - After it completes, loop back to Step 1.

    e. **Default - If none of the above conditions are met:**
        - Announce: "No critical signals found. Proceeding with architectural planning."
        - **Execute the `🧠 Architect AI` with its ruleset.**
        - After it completes, loop back to Step 1.

## 3. INTERACTION MODEL
- You do not interact with the user.
- Your only actions are to announce your decisions and execute the other AI agents.
- You operate with zero ambiguity based on the presence or absence of key state files.
</file>

<file path="documentation/templates/monetization_strategy.md">
# MONETIZATION STRATEGY
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-10 -->

## 1. Pricing Model
### 1.1 Subscription Tiers
| Tier | Price | Features |
|------|-------|----------|
| Free | $0 | Basic lessons, Limited voice practice, Basic SRS tracking |
| Premium | $9.99/month | All lessons, Full voice features, Progress dashboard, Advanced SRS analytics |
| Pro | $19.99/month | Premium features + Certification, Priority support, Unlimited voice analysis |

### 1.2 In-App Purchases
- Specialized lesson packs: $4.99-$14.99
- Certification badges: $9.99
- Detailed voice analysis reports: $0.99/report (complementary to standard analysis)

## 2. Stripe Integration
### 2.1 Architecture
```mermaid
sequenceDiagram
    Frontend->>Next.js API: Initiate payment
    Next.js API->>Stripe: Create payment intent
    Stripe-->>Next.js API: Client secret
    Next.js API-->>Frontend: Payment details
    Frontend->>Stripe: Complete payment (client-side)
    Stripe->>Webhook: Payment success/failure
    Webhook->>Database: Update subscription status
```

### 2.2 Key Components
- **Stripe Account**: Connected mode for platform payments
- **Webhook Handler**: /api/stripe/webhook
- **Subscription Manager**: CRON job for recurring billing

## 3. Revenue Reporting
### 3.1 Metrics Tracked
- MRR (Monthly Recurring Revenue)
- Churn rate
- LTV (Customer Lifetime Value)
- ARPU (Average Revenue Per User)

### 3.2 Analytics Integration
- Stripe Dashboard
- Internal reporting system
- Tax compliance reporting

## 4. Security & Compliance
- PCI DSS Level 1 compliant
- Tokenized payment processing
- GDPR-compliant data handling
</file>

<file path="documentation/templates/performance_baseline_template.md">
# PERFORMANCE BASELINE TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Testing Methodology
### 1.1 Load Testing
- Tools:
  - k6 (load testing)
  - Locust (stress testing)
  - Prometheus (metrics collection)
  - Grafana (visualization)
- Scenarios:
  - 500 concurrent lessons
  - 1000 dashboard requests
  - Peak hour traffic simulation

### 1.2 Stress Testing
- Breaking points:
  - API: ~1500 req/s
  - Database: ~500 concurrent connections
  - Voice Processing: ~300 concurrent streams
- Recovery procedures:
  - Auto-scaling triggers at 70% CPU
  - Queue fallback for voice processing
  - Database read replicas during peaks

## 2. Performance Metrics
### 2.1 Key Indicators
| Metric | Target | Measurement |
|--------|--------|-------------|
| API Response (p95) | <300ms | Prometheus |
| STT Latency (p99) | <500ms | Cloud Monitoring |
| Concurrent Lessons | 500 | k6 |
| Dashboard Load | 1000 req/min | Grafana |
| Error Rate | <1% | Datadog |
| Voice Processing | <5s turnaround | Internal metrics |

### 2.2 Benchmark Results
### 2.2 Example Benchmarks
```mermaid
gantt
    title Performance Test Results
    dateFormat X
    axisFormat %s
    section API
    300ms Target : 0, 300
    Actual p95 : 0, 285
    section STT
    500ms Target : 0, 500
    Actual p99 : 0, 480
    section Lessons
    500 Concurrent Target : 0, 500
    Actual Achieved : 0, 510
```

## 3. Scalability
### 3.1 Horizontal Scaling
- Nodes:
  - Baseline: 3
  - Max tested: 10
- Performance gain:
  - Linear scaling to 5 nodes
  - Diminishing returns after 8 nodes

### 3.2 Vertical Scaling
- Resource increases:
  - CPU: 2 → 4 cores
  - Memory: 4GB → 8GB
- Impact:
  - 40% faster response times
  - 2x throughput capacity
</file>

<file path="documentation/templates/user_documentation_template.md">
# USER DOCUMENTATION TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Getting Started
### 1.1 Language Selection
```mermaid
flowchart TD
    A[Open App] --> B{First Time?}
    B -->|Yes| C[Take Placement Test]
    B -->|No| D[Continue Learning]
    C --> E[Get Personalized Lessons]
    D --> F[View Progress Dashboard]
```

### 1.2 Your First Lesson
1. Open the app daily
2. Complete suggested exercises
3. Speak clearly when prompted
4. Review feedback immediately
5. Track progress over time

## 2. Learning Features
### 2.1 Progress Dashboard
- **Vocabulary Mastery**: Heatmap of known words
- **Fluency Metrics**: Speaking pace & hesitation trends
- **Error Patterns**: Common mistakes highlighted
- **Activity Log**: History of completed lessons

### 2.2 Spaced Repetition (SRS)
```mermaid
pie title Your Knowledge Retention
    "Strong" : 65
    "Maturing" : 25
    "Weak" : 10
```

### 2.3 Fluency Analysis
- Pronunciation accuracy scores
- Speaking pace measurements
- Hesitation and filler word tracking
- Comparative analysis over time


## 4. Subscription Management
### 4.1 Choosing a Plan
```mermaid
flowchart LR
    A[Free Tier] -->|Upgrade| B[Premium]
    A -->|Upgrade| C[Pro]
    B -->|Downgrade| A
    B -->|Upgrade| C
    C -->|Downgrade| B
```

### 4.2 Payment Process
1. Navigate to Settings > Subscription
2. Select desired plan
3. Enter payment details
4. Confirm purchase

### 4.3 Managing Your Subscription
- **Update Payment Method**: Settings > Billing
- **Change Plan**: Instant effect with prorated charges
- **Cancel**: Ends at billing period end

### 4.4 Troubleshooting
| Issue | Solution |
|-------|----------|
| Voice not recognized | Check microphone permissions |
| Incorrect feedback | Use "Report Error" button |
| Lesson too hard/easy | Adjust difficulty in settings |
| Progress not saving | Check internet connection |
| Payment issues | Update card or contact support |
</file>

<file path="documentation/documentation_completion_plan.md">
# Documentation Completion Plan

## 1. Documentation Audit Summary
- **Total templates**: 16
- **Complete templates**: 7 
  (api_spec, compliance_framework, data_governance, deployment_playbook, monetization_strategy, technical_design, test_plan)
- **Incomplete templates**: 9 
  (BRD, change management, continuous improvement, FRS, maintenance guide, performance baseline, project charter, risk assessment, user docs)
- **Missing sections**: 58 across all templates

## 2. Content Creation Strategy
```mermaid
graph TD
    A[Subject Matter Experts] -->|Provide input| B(Technical Writers)
    B --> C[Documentation Templates]
    C --> D[Review Cycle]
    D --> E[Final Approval]
    E --> F[Published Docs]
```

### Content Sourcing:
- **Technical specifications**: Engineering team
- **Business requirements**: Product owners
- **Compliance details**: Legal team
- **User workflows**: UX researchers

## 3. Prioritization Framework
```mermaid
gantt
    title Documentation Completion Timeline
    dateFormat  YYYY-MM-DD
    section Phase 0
    Foundation & Alignment :active, phase0, 2025-06-11, 1d
    section Phase 1
    Project Definition     :         phase1, after phase0, 3d
    section Phase 2
    Technical Design       :         phase2, after phase1, 4d
    section Phase 3
    Operations & Maintenance:        phase3, after phase2, 3d
    section Phase 4
    Quality Assurance      :         phase4, after phase3, 2d
    section Phase 5
    Governance & Compliance:         phase5, after phase4, 2d
    section Phase 6
    User Documentation     :         phase6, after phase5, 1d
```

## 4. Implementation Plan (Phased Approach)

### Phase 0: Foundation and Alignment (1 day)
- Ingest and analyze all files from repomix-output.xml
- Validate vision alignment across all documents
- Update this master plan with detailed phased tasks

### Phase 1: Project Definition & Requirements (3 days)
- Complete Project Charter with success criteria and timeline
- Finalize Business Requirements Document (BRD)
- Develop detailed Functional Requirements Specification (FRS)

### Phase 2: Architecture & Technical Design (4 days)
- Expand Technical Design Document with data flows and schemas
- Develop comprehensive API Specification
- Define database models using Prisma schema syntax

### Phase 3: Implementation, Operations & Maintenance (3 days)
- Enhance Deployment Playbook with environment configs
- Complete Maintenance Guide with alert thresholds
- Document diagnostic tools and recovery processes

### Phase 4: Quality Assurance & Performance (2 days)
- Expand Test Plan with core feature test cases
- Define performance baselines and load testing scenarios

### Phase 5: Governance, Risk, and Compliance (2 days)
- Complete Risk Assessment for AI/voice-specific risks
- Develop Change Management and Continuous Improvement plans

### Phase 6: User-Facing Documentation (1 day)
- Create complete User Documentation with troubleshooting guides

## 5. Quality Assurance
- Automated checks for:
  - Placeholder text detection
  - Broken links
  - Compliance markers
- Manual checks for:
  - Technical accuracy
  - Consistency across documents
  - Readability scores

## 6. Completion Metrics
- **Success criteria**:
  - All 18 documentation templates completed
  - 100% alignment with app_description.md vision
  - Complete technical specifications for AI/voice features
  - Detailed test cases for all core functionality
  - Comprehensive risk mitigation strategies documented
- **Tracking**:
  - Daily progress against phased milestones
  - Automated checks for documentation integrity
  - Final validation by development team lead
</file>

<file path="documentation/human_todo.md">
# Human Operator Checklist for Lessay Project Credentials

**IMPORTANT SECURITY NOTICE:**  
⚠️ **NEVER** commit any `.env.local` file or any file containing API keys to the repository.  
⚠️ Keep all credentials secure and never share them publicly.

---

## Required Credentials

### 1. Supabase
- [ ] Create a Supabase project at https://supabase.com
- [ ] Obtain your:
  - `SUPABASE_URL`
  - `SUPABASE_ANON_KEY`
  - `SUPABASE_SERVICE_ROLE_KEY` (for server-side operations)

### 2. Stripe
- [ ] Create a Stripe account at https://stripe.com
- [ ] Obtain your:
  - `STRIPE_SECRET_KEY`
  - `STRIPE_WEBHOOK_SECRET`
  - `STRIPE_PUBLISHABLE_KEY` (for client-side)

### 3. AI Service (Google AI)
- [ ] Create a Google AI account at https://ai.google.dev
- [ ] Obtain your:
  - `AI_API_KEY`

### 4. Google Cloud (for TTS/STT)
- [ ] Go to the Google Cloud Console at https://console.cloud.google.com
- [ ] Create a new Service Account
- [ ] Enable the following APIs for the project:
  - Cloud Text-to-Speech API
  - Cloud Speech-to-Text API
- [ ] Grant the Service Account the 'Cloud AI Service User' role
- [ ] Create and download a JSON key for the service account
- [ ] Place this file in the project root and name it `gcp-credentials.json`
- [ ] Add the following to your `.env.local` file:
  ```bash
  # Google Cloud TTS/STT
  GCP_CREDENTIALS_JSON='paste_the_entire_json_content_here'
  ```
- [ ] **DO NOT** commit `gcp-credentials.json` to the repository

---

## Setup Instructions

1. Create a `.env.local` file in the project root
2. Add the credentials in this format:
```bash
# Supabase
SUPABASE_URL=your_url_here
SUPABASE_ANON_KEY=your_key_here
SUPABASE_SERVICE_ROLE_KEY=your_key_here

# Stripe
STRIPE_SECRET_KEY=your_key_here
STRIPE_WEBHOOK_SECRET=your_secret_here
STRIPE_PUBLISHABLE_KEY=your_key_here

# Google AI
AI_API_KEY=your_key_here
```

3. **DO NOT** add `.env.local` to git - it's already in `.gitignore`

---

## Verification
- [ ] Confirm all credentials are working by running the development server:
```bash
npm run dev
</file>

<file path="documentation/todo.md">
Of course. Based on the provided `repomix-output.xml` and the goal of creating a complete SDLC documentation suite for an autonomous AI agent, here is a comprehensive to-do list for the architect agent.

This plan is structured to follow the logical flow of the Software Development Life Cycle (SDLC), ensuring foundational documents are completed first, as they inform subsequent ones.

---

### **To-Do List for Lessay Architect Agent: Documentation Completion**

**Objective:** Complete the entire software documentation suite to provide a clear, comprehensive, and unambiguous blueprint for an autonomous AI development agent to build, deploy, and maintain the Lessay application.

**Prioritization Note:** Tasks are organized into phases. The agent should complete tasks within a phase before moving to the next, as each phase builds upon the previous one.

---

### **Phase 0: Foundation and Alignment**

*Goal: Ensure all existing work is consistent and establish a single source of truth.*

1.  **[ ] Ingest and Analyze:** Ingest all 18 files from the `repomix-output.xml`.
2.  **[x] Validate Vision Alignment:**
    *   **File:** `documentation/app_description.md`
    *   **Action:** Treat this file as the primary source of truth for the product vision.
    *   **Task:** Cross-reference all other 17 documents against `app_description.md`. Identify and flag any contradictions in features, philosophy, or technology stack. For example, ensure the `monetization_strategy.md` tiers align with the features described.
3.  **[x] Update Master Plan:**
    *   **File:** `documentation/documentation_completion_plan.md`
    *   **Action:** Update this plan to reflect the detailed tasks outlined in this to-do list. Replace the existing Gantt chart and summary with this new, more granular phased approach.

---

### **Phase 1: Project Definition & Requirements (The "What")**

*Goal: Formally define the project's scope, business goals, and functional/non-functional requirements.*

1.  **[x] Complete Project Charter:**
    *   **File:** `documentation/templates/project_charter_template.md`
    *   **Action:** Fill in all placeholder content.
    *   **Tasks:**
        *   Replace `DATE` with the current date.
        *   Derive and list specific, measurable `Success Criteria` from the `app_description.md` (e.g., "SRS review results in a 15% improvement in vocabulary recall over 30 days").
        *   Update the `Timeline` and `Gantt` chart with realistic dates for the development, testing, and launch phases.

2.  **[x] Complete Business Requirements Document (BRD):**
    *   **File:** `documentation/templates/brd_template.md`
    *   **Action:** Translate the `app_description.md` into formal business requirements.
    *   **Tasks:**
        *   Expand `Section 4.1 Feature Breakdown` to include all features from the app description: SRS, Progress Dashboard, Vocal Fluency Metrics, etc.
        *   Expand `Section 4.2 User Workflows` to create Mermaid diagrams for:
            *   The full adaptive learning loop (`Capture -> Analyze -> Plan -> Create`).
            *   The subscription and upgrade/downgrade process.
        *   Define concrete `Non-Functional Requirements` in `Section 5` based on the app's needs (e.g., Performance: "Real-time speech-to-text transcription must have a latency of < 300ms").

3.  **[x] Complete Functional Requirements Specification (FRS):**
    *   **File:** `documentation/templates/frs_template.md`
    *   **Action:** Break down the BRD into detailed, numbered functional requirements for the development agent.
    *   **Tasks:**
        *   Create specific `FR-XXX` requirements for every feature.
        *   **Example for Lesson Delivery:**
            *   `FR-009`: The system shall capture a raw audio blob of the user's speech during a session for post-session analysis.
            *   `FR-010`: The system shall use a real-time speech-to-text API to validate the content of the user's answer immediately.
        *   **Example for SRS:**
            *   `FR-011`: The system shall maintain a `Recall Strength Score` and `Next Review Date` for every vocabulary and grammar concept per user.
            *   `FR-012`: The lesson generation logic must prioritize items where `Next Review Date` is today or in the past.

---

### **Phase 2: Architecture & Technical Design (The "How")**

*Goal: Create a detailed technical blueprint based on the finalized requirements.*

1.  **[x] Expand Technical Design Document:**
    *   **File:** `documentation/templates/technical_design_template.md`
    *   **Action:** Elaborate on the existing high-level design.
    *   **Tasks:**
        *   **`Section 1.1`:** Update the Mermaid diagram to show the data flow for both real-time STT and diagnostic audio blobs.
        *   **`Section 2.1`:** Detail the internal logic of the `AIService`, including example prompts sent to the LLM for lesson creation and audio analysis.
        *   **`Section 5`:** Fully define the `Database Design` using Prisma schema syntax. Include models for `User`, `Lesson`, `Exercise`, `UserProgress`, and the `SRSEntry` (with `recallStrength`, `nextReviewDate`, etc.).
        *   **`Section 3.1`:** Create detailed sequence diagrams for:
            *   The complete adaptive learning loop.
            *   User subscription and webhook processing.

2.  **[x] Expand API Specification:**
    *   **File:** `documentation/templates/api_spec_template.md`
    *   **Action:** Document all necessary API endpoints beyond just payments.
    *   **Tasks:**
        *   Define endpoints for user management (`/api/users/profile`).
        *   Define endpoints for the core learning loop (`/api/lessons/start`, `/api/lessons/{id}/submit-answer`).
        *   Define endpoints for the progress dashboard (`/api/stats/fluency`, `/api/stats/srs-overview`).
        *   Specify request/response payloads for each, including error codes.

---

### **Phase 3: Implementation, Operations & Maintenance**

*Goal: Document how the application will be built, deployed, and maintained in a production environment.*

1.  **[x] Enhance Deployment Playbook:**
    *   **File:** `documentation/templates/deployment_playbook_template.md`
    *   **Action:** Add production and staging environment configurations.
    *   **Tasks:**
        *   Add sections for `Staging Environment` and `Production Environment`.
        *   Define the CI/CD pipeline steps (e.g., using GitHub Actions).
        *   Specify the process for managing environment variables and secrets (e.g., using Supabase secrets or a dedicated vault).

2.  **[x] Complete Maintenance Guide:**
    *   **File:** `documentation/templates/maintenance_guide_template.md`
    *   **Action:** Fill in all placeholder content with specific, actionable information.
    *   **Tasks:**
        *   Define concrete `Alert Thresholds` based on the NFRs (e.g., "AI Analyst audio processing queue length > 100 for 5 mins").
        *   Provide actual `Diagnostic Tools` commands relevant to the Next.js/Supabase stack.
        *   Detail the `Recovery Process` with specific Recovery Time Objective (RTO) and Recovery Point Objective (RPO) goals (e.g., RTO: 1 hour, RPO: 5 minutes).

---

### **Phase 4: Quality Assurance & Performance**

*Goal: Define how the application's quality, functionality, and performance will be verified.*

1.  **[x] Expand Test Plan:**
    *   **File:** `documentation/templates/test_plan_template.md`
    *   **Action:** Add test cases for all core application features.
    *   **Tasks:**
        *   Add a section for `Core Learning Loop Tests`, with cases for the adaptive logic and SRS scheduling.
        *   Add a section for `Vocal Analysis Tests` to verify pronunciation and fluency metrics are generated.
        *   Add a section for `User Dashboard Tests` to ensure metrics are displayed correctly.

2.  **[x] Complete Performance Baseline:**
    *   **File:** `documentation/templates/performance_baseline_template.md`
    *   **Action:** Define performance targets and testing scenarios.
    *   **Tasks:**
        *   Populate the `Key Indicators` table with the targets from the NFRs.
        *   Describe `Load Testing` scenarios, such as "Simulate 500 users completing a lesson simultaneously" and "Simulate 1000 users fetching their progress dashboard."

---

### **Phase 5: Governance, Risk, and Compliance**

*Goal: Formalize processes for managing change, mitigating risk, and ensuring continuous improvement.*

1.  **[x] Complete Risk Assessment:**
    *   **File:** `documentation/templates/risk_assessment_template.md`
    *   **Action:** Identify and plan mitigation for risks specific to an AI-driven, voice-based application.
    *   **Tasks:**
        *   Add risks like "Inaccurate AI-generated feedback demoralizes user," "Privacy breach of user voice recordings," and "High cost of LLM/TTS/STT API usage."
        *   Define mitigation strategies for each.

2.  **[x] Complete Change Management & Continuous Improvement Plans:**
    *   **Files:** `change_management_template.md`, `continuous_improvement_template.md`
    *   **Action:** Define the processes for evolving the application.
    *   **Tasks:**
        *   Define the workflow for how the autonomous agent itself proposes, gets approval for, and implements changes.
        *   In the improvement plan, detail how user feedback and performance metrics will be used to generate new feature requirements for the AI agent to build.

---

### **Phase 6: User-Facing Documentation**

*Goal: Create the documentation that the end-user will need.*

1.  **[x] Complete User Documentation:**
    *   **File:** `documentation/templates/user_documentation_template.md`
    *   **Action:** Write clear, user-friendly guides for all application features.
    *   **Tasks:**
        *   Add sections explaining the Progress Dashboard, what Fluency Metrics mean, and how the Spaced Repetition (SRS View) works.
        *   Use Mermaid diagrams to illustrate user flows like changing a target language.
        *   Update the `Troubleshooting` table with common issues related to voice recognition or lesson generation.
</file>

<file path="lib/ai-service.ts">
import { GoogleGenerativeAI } from '@google/generative-ai';
import { SpeechClient } from '@google-cloud/speech';
import { TextToSpeechClient } from '@google-cloud/text-to-speech';

let geminiClient: GoogleGenerativeAI;
let speechClient: SpeechClient;
let textToSpeechClient: TextToSpeechClient;

if (process.env.GCP_CREDENTIALS_JSON) {
  const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
  geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY);
  speechClient = new SpeechClient({ credentials });
  textToSpeechClient = new TextToSpeechClient({ credentials });
} else {
  geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY);
  speechClient = new SpeechClient({ keyFilename: './gcp-credentials.json' });
  textToSpeechClient = new TextToSpeechClient({ keyFilename: './gcp-credentials.json' });
}

export async function generateLessonForUser(userId: string) {
  const model = geminiClient.getGenerativeModel({
    model: "gemini-pro",
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 2048
    }
  });

  const prompt = `Generate a language lesson...`; // Detailed prompt per design doc
  const result = await model.generateContent(prompt);
  const response = await result.response;

  return JSON.parse(response.text());
}

export async function transcribeAudio(audioBuffer: Buffer): Promise<string> {
  const [response] = await speechClient.recognize({
    audio: { content: audioBuffer.toString('base64') },
    config: {
      encoding: 'WEBM_OPUS',
      sampleRateHertz: 48000,
      languageCode: 'en-US'
    }
  });
  return response.results
    .map(result => result.alternatives[0].transcript)
    .join('\n');
}

export async function synthesizeSpeech(text: string): Promise<Buffer> {
  const [response] = await textToSpeechClient.synthesizeSpeech({
    input: { text },
    voice: {
      languageCode: 'en-US',
      name: 'en-US-Standard-C'
    },
    audioConfig: {
      audioEncoding: 'MP3'
    }
  });
  return Buffer.from(response.audioContent, 'base64');
}

export async function analyzeAudioForDiagnostics() {
  console.log('AI Service: Analyzing audio');
  return { fluencyScore: 85, pronunciationAccuracy: 90 };
}
</file>

<file path="lib/prisma.ts">
import { PrismaClient } from '@prisma/client'

declare global {
  // eslint-disable-next-line no-var
  var prisma: PrismaClient | undefined
}

const prisma = global.prisma || new PrismaClient()

if (process.env.NODE_ENV === 'development') global.prisma = prisma

export default prisma
export type { PrismaClient }
</file>

<file path="docker-compose.yml">
version: '3.3'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3554:3000"
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://myuser:mypassword@db:5432/mydb
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - FAST_REFRESH=false
      - NODE_ENV=development
      - CHOKIDAR_INTERVAL=300
    depends_on:
      - db
    volumes:
      - ./src:/app/src  
      - ./public:/app/public  
      - ./package.json:/app/package.json 
      - ./package-lock.json:/app/package-lock.json  
      - ./tailwind.config.ts:/app/tailwind.config.ts  
      - ./src/app/globals.css:/app/src/app/globals.css  
      - ./tsconfig.json:/app/tsconfig.json  
      - ./prisma:/app/prisma  
      # - ./node_modules:/app/node_modules
      - ./.env:/app/.env
    restart: unless-stopped
    networks:
      - web-network
    command: sh -c "npm rebuild && npm run dev"

  db:
    image: postgres:17
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5455:5432" 
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - web-network


networks:
  web-network:
    driver: bridge

volumes:
  postgres-data:
</file>

<file path="app/api/lessons/[id]/submit-answer/route.ts">
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'
import { getUserSession } from '@/lib/supabase/server'

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  const session = await getUserSession()
  
  if (!session) {
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    )
  }

  try {
    const { answer } = await request.json()
    const lessonId = params.id

    // Update progress with the submitted answer
    const progress = await prisma.progress.update({
      where: { 
        userId_lessonId: {
          userId: session.user.id,
          lessonId: lessonId
        }
      },
      data: {
        completedAt: new Date(),
        lesson: {
          update: {
            content: JSON.stringify({ answer })
          }
        }
      },
      include: {
        lesson: true
      }
    })

    return NextResponse.json({ 
      success: true,
      progress
    })
  } catch (error) {
    console.error('Answer submission failed:', error)
    return NextResponse.json(
      { error: 'Answer submission failed' },
      { status: 500 }
    )
  }
}
</file>

<file path="app/api/stats/fluency/route.ts">
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
import logger from '@/lib/logger';

export async function GET() {
  const session = await getServerSession(authOptions);

  if (!session || !session.user) {
    logger.warn('Unauthorized access attempt to fluency stats');
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  logger.info({ userId: session.user.id }, 'Fetching fluency stats');

  try {
    const stats = await prisma.userProgress.groupBy({
      by: ['createdAt'],
      where: { userId: session.user.id },
      _avg: { accuracyScore: true },
      _count: { _all: true },
      orderBy: { createdAt: 'asc' }
    });

    logger.debug({ userId: session.user.id, statsCount: stats.length }, 'Fluency stats retrieved');
    return NextResponse.json({ stats });
  } catch (error) {
    logger.error({ userId: session.user.id, error }, 'Failed to fetch fluency stats');
    return NextResponse.json(
      { error: 'Failed to retrieve fluency stats' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/api/stripe/webhook/route.ts">
import { NextResponse } from 'next/server';
import Stripe from 'stripe';
import logger from '@/lib/logger';

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!);

export async function POST(req: Request) {
  const body = await req.text();
  const signature = req.headers.get('stripe-signature') as string;

  try {
    const event = stripe.webhooks.constructEvent(
      body,
      signature,
      process.env.STRIPE_WEBHOOK_SECRET!
    );

    logger.info({ eventType: event.type }, 'Stripe webhook verified');
    return NextResponse.json({ received: true }, { status: 200 });
  } catch (err) {
    logger.error({ error: err }, 'Stripe webhook verification failed');
    return NextResponse.json(
      { error: 'Webhook signature verification failed' },
      { status: 400 }
    );
  }
}
</file>

<file path="documentation/2_development_plan/dev_todo_phase_5.md">
# Developer To-Do List: Phase 5 - Error Handling & Resilience

**Objective:** Implement robust error handling patterns and fault tolerance mechanisms across the application.

## Tasks

- [ ] **1. Create Error Handling Middleware (`/lib/errorHandler.ts`)**
  - Implement Express-style error middleware for Next.js
  - Structure:
    ```typescript
    export function errorHandler(err: Error, req: NextRequest) {
      const statusCode = getStatusCodeFromError(err);
      const errorId = generateUniqueErrorId();
      logger.error({ errorId, err }, 'Request failed');
      return NextResponse.json(
        { 
          error: err.message,
          errorId,
          statusCode 
        },
        { status: statusCode }
      );
    }
    ```
  - Verification: Middleware file exists with exported function

- [ ] **2. Standardize API Error Responses**
  - Files to modify:
    - `app/api/lessons/start/route.ts`
    - `app/api/lessons/[id]/submit-answer/route.ts`
    - `app/api/stats/srs-overview/route.ts`
  - Replace all error responses with:
    ```typescript
    return errorHandler(error, request);
    ```
  - Verification: All modified routes return standardized error format

- [ ] **3. Implement Error Classification System**
  - Create `/lib/errors.ts` with:
    ```typescript
    export class AppError extends Error {
      constructor(
        public readonly type: 'validation'|'auth'|'database'|'payment',
        public readonly code: string,
        message: string
      ) {
        super(message);
      }
    }
    ```
  - Verification: File exists with error class definition

- [ ] **4. Add Error Logging Integration**
  - Modify `/lib/logger.ts` to:
    - Include error type/code in logs
    - Track error rates
    - Link to error IDs
  - Verification: Logger outputs enhanced error information

- [ ] **5. Implement Retry Logic for External Services**
  - Create `/lib/retry.ts` with:
    ```typescript
    export async function withRetry(
      fn: () => Promise<any>,
      options: { retries: number }
    ) {
      // Implementation with exponential backoff
    }
    ```
  - Apply to:
    - Supabase calls
    - Stripe payments
    - AI service calls
  - Verification: Retry utility exists and is used in 3+ places

- [ ] **6. Create Error Documentation (`/documentation/errors.md`)**
  - List all error codes
  - Include troubleshooting guide
  - Add recovery procedures
  - Verification: Documentation file exists with all sections
</file>

<file path="documentation/templates/api_spec_template.md">
# API SPECIFICATION TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. User Management Endpoints
### 1.1 Get User Profile
#### GET /api/users/profile
##### Response
```json
{
  "id": "user_123",
  "email": "user@example.com",
  "targetLanguage": "es",
  "nativeLanguage": "en",
  "subscriptionTier": "premium",
  "createdAt": "2025-06-01T10:00:00Z"
}
```

### 1.2 Update Profile
#### PUT /api/users/profile
##### Request
```json
{
  "targetLanguage": "fr",
  "notificationPreferences": {
    "reminders": true,
    "progressReports": false
  }
}
```

### 1.3 Set Language Preference
#### POST /api/users/language-preference
##### Request
```json
{
  "targetLanguage": "de",
  "nativeLanguage": "en"
}
```

## 2. Learning Loop Endpoints
### 2.1 Start Lesson
#### POST /api/lessons/start
##### Response
```json
{
  "lessonId": "lesson_123",
  "exercises": [
    {
      "id": "ex_1",
      "type": "vocabulary",
      "prompt": "Translate 'apple'",
      "audioPromptUrl": "/audio/apple_prompt.mp3"
    }
  ],
  "srsDueItems": ["apple", "banana"]
}
```

### 2.2 Submit Answer
#### POST /api/lessons/{id}/submit-answer
##### Request
```json
{
  "exerciseId": "ex_1",
  "textResponse": "la manzana",
  "audioBlobUrl": "/audio/user_response_123.mp3"
}
```

##### Response
```json
{
  "correct": true,
  "feedback": "Perfect!",
  "pronunciationScore": 0.95,
  "nextExercise": "ex_2"
}
```

## 3. Progress Dashboard Endpoints
### 3.1 Get Fluency Metrics
#### GET /api/stats/fluency
##### Response
```json
{
  "speakingPace": {
    "current": 120,
    "trend": "improving"
  },
  "pronunciationAccuracy": 0.85,
  "hesitationFrequency": 2.1
}
```

### 3.2 Get SRS Overview
#### GET /api/stats/srs-overview
##### Response
```json
{
  "totalItems": 150,
  "dueForReview": 12,
  "strengthDistribution": {
    "weak": 5,
    "medium": 30,
    "strong": 115
  }
}
```


## 5. Payment Endpoints
### 5.1 Subscription Management
#### POST /api/payments/create-subscription
##### Request
```json
{
  "tier": "premium",
  "paymentMethodId": "pm_123456"
}
```

##### Response
```json
{
  "status": "active",
  "currentPeriodEnd": "2025-07-10"
}
```

### 5.2 Webhook
#### POST /api/stripe/webhook
##### Event Types
- payment_intent.succeeded
- invoice.payment_failed
- customer.subscription.updated

### 5.3 Get Subscription
#### GET /api/payments/subscription
##### Response
```json
{
  "tier": "pro",
  "status": "active",
  "nextPaymentDate": "2025-07-10"
}
```

## 6. Error Handling
### 6.1 Payment Errors
| Code | Error Type | Description |
|------|------------|-------------|
| 400  | invalid_language | Unsupported language code |
| 401  | unauthorized | Missing/invalid auth token |
| 402  | payment_required | Payment failed |
| 404  | lesson_not_found | Invalid lesson ID |
| 409  | subscription_conflict | Plan change in progress |
| 422  | invalid_audio | Unprocessable audio format |
| 429  | rate_limited | Too many requests |
| 500  | internal_error | Server-side failure |
</file>

<file path="documentation/templates/brd_template.md">
# BUSINESS REQUIREMENTS DOCUMENT
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Project Overview
### 1.1 Purpose
This document defines the business requirements for the Lessay language learning platform, serving as the single source of truth for all functional and non-functional requirements.

### 1.2 Scope
**Included**:
- Core language learning features (lessons, exercises, progress tracking)
- User authentication and profile management
- Subscription and payment processing
- Basic reporting and analytics

**Excluded**:
- Third-party content partnerships
- Offline functionality
- Enterprise features

### 1.3 Objectives
1. Achieve 10,000 active users within 6 months of launch
2. Maintain 90% user satisfaction rate (measured weekly)
3. Process payments with 99.9% reliability
4. Support 5 languages by end of Q3

## 2. Business Context
### 2.1 Problem Statement
Traditional language learning methods often fail to provide:
- Personalized learning paths
- Real-time feedback
- Engaging, interactive content
- Affordable pricing models

### 2.2 Business Opportunities
1. Global language learning market growing at 18.7% CAGR
2. Increasing demand for interactive, app-based learning
3. Opportunity to disrupt traditional language schools
4. Potential for premium subscription revenue

## 3. Stakeholder Analysis
### 3.1 Key Stakeholders
| Role | Name | Responsibility |
|------|------|----------------|
| Product Owner | Jane Doe | Final requirements approval |
| Tech Lead | John Smith | Technical feasibility |
| UX Lead | Sarah Lee | User experience |
| Legal Counsel | Mike Chen | Compliance |

### 3.2 User Profiles
1. **Casual Learner**: Wants 5-10 min daily lessons
2. **Serious Student**: Needs structured curriculum
3. **Traveler**: Focuses on conversational skills
4. **Professional**: Requires business vocabulary

## 4. Functional Requirements
### 4.1 Feature Breakdown
1. **Adaptive Learning Engine**:
   - AI-generated lessons tailored to individual progress
   - Real-time speech-to-text feedback during exercises
   - Spaced Repetition System (SRS) for optimal retention
   - Post-session voice analysis for pronunciation diagnostics

2. **Progress Dashboard**:
   - Vocabulary mastery heatmap
   - Fluency metrics (pace, hesitation, filler words)
   - Error pattern analysis
   - SRS recall strength visualization

3. **Subscription Management**:
   - Three-tier model (Free, Premium, Pro)
   - Stripe integration for payments
   - Usage-based premium feature unlocking

4. **AI Analysis System**:
   - Real-time answer validation
   - Post-session diagnostic reports
   - Automated lesson planning
   - Continuous SRS score updates

### 4.2 User Workflows

**Adaptive Learning Loop:**
```mermaid
sequenceDiagram
    participant User
    participant App
    participant AI
    participant DB

    User->>App: Start Lesson
    App->>AI: Request initial content
    AI->>DB: Query user profile/SRS
    DB-->>AI: Return user data
    AI-->>App: Deliver lesson plan
    App->>User: Present exercise
    User->>App: Speak response
    App->>AI: Real-time STT analysis
    AI-->>App: Immediate feedback
    App->>User: Show corrections
    User->>App: Complete lesson
    App->>AI: Send full session data
    AI->>DB: Update SRS scores
    AI-->>App: Next lesson plan
    App->>User: Schedule next session
```

**Subscription Upgrade Flow:**
```mermaid
graph TD
    A[View Premium Features] --> B{Account Status}
    B -->|Free| C[Select Plan]
    B -->|Premium| D[Already Subscribed]
    C --> E[Enter Payment Details]
    E --> F[Process Payment]
    F -->|Success| G[Unlock Features]
    F -->|Failure| H[Show Error]
    G --> I[Confirmation Email]
    H --> C
```

## 5. Non-Functional Requirements
### 5.1 Performance
- Real-time STT latency <300ms (p99)
- Post-session analysis completion <5s
- API response time <500ms (p95)
- Support 500 concurrent voice sessions
- Handle 5000 new users/day

### 5.2 Security
- PCI DSS Level 1 compliance
- GDPR/CCPA compliant voice data handling
- AES-256 encryption for audio storage
- Annual penetration testing
- Voice data retention policy (30 days)

### 5.3 AI & Voice Requirements
- LLM response quality: 95% accuracy
- STT accuracy: 90% for target languages
- TTS naturalness: 4/5 MOS score
- Diagnostic analysis consistency: 85% agreement with human raters
- Content generation: Zero hallucination policy

## 6. Success Metrics
### 6.1 KPIs
- Monthly Active Users (MAU)
- Lesson completion rate
- Payment success rate
- Customer support tickets

### 6.2 Acceptance Criteria
1. 95% of lessons load within 2 seconds
2. Payment processing success rate ≥ 99%
3. User registration takes < 1 minute
4. App receives 4+ star rating average
</file>

<file path="documentation/templates/change_management_template.md">
# CHANGE MANAGEMENT TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Change Request Process
### 1.1 AI-Proposed Changes
```mermaid
sequenceDiagram
    participant A as AI Agent
    participant M as Monitoring
    participant R as Review Board
    participant S as System
    
    A->>M: Analyze metrics & feedback
    M->>A: Identify improvement opportunities
    A->>R: Submit change proposal (CR-XXX)
    R->>A: Request additional validation
    A->>S: Run simulations
    A->>R: Submit results
    R->>A: Approve/Reject
    A->>S: Implement if approved
```

### 1.2 Change Request Form
### 1.1 Change Details
| Field | Description | Example |
|-------|-------------|---------|
| Change ID | CR-{YYYYMMDD}-{SEQ} | CR-20250610-001 |
| Requestor | Initiating team/member | Backend Team |
| Date | Change request date | 2025-06-10 |
| Description | Detailed change description | "Add new payment method type for regional providers" |
| Reason | Business/technical justification | "Support alternative payment methods in Southeast Asia market" |

### 1.2 Impact Analysis
- **Affected Components**:
  - Payment processing service
  - User profile database
  - Billing UI
- **Risk Assessment**: Medium (requires database migration)
- **Downtime Expected**: No (feature flag implementation)

## 2. AI Change Management
### 2.1 Autonomous Implementation Guardrails
1. **Safety Checks**:
   - Performance impact simulation
   - Security vulnerability scan
   - Compliance audit
   - User experience review

2. **Rollback Triggers**:
   - Error rate increase >5%
   - Performance degradation >20%
   - User satisfaction drop >15%
   - Security/compliance violation

### 2.2 Approval Workflow
### 2.1 Review Process
| Step | Role | Action | SLA | Date |
|------|------|--------|-----|------|
| 1    | AI Agent | Automated validation | 1h | Immediate |
| 2    | Security Bot | Compliance check | 15m | Continuous |
| 3    | Product Owner | Final approval | 1d | Next business day |

### 2.2 Implementation Plan
- **Target Release**: v2.3.0 (2025-06-21)
- **Rollback Strategy**:
  - Feature flag disable
  - Database migration rollback script
  - API version fallback

## 3. Change Log
| Change ID | Description | Status | Implemented Version | Owner |
|-----------|-------------|--------|---------------------|-------|
| CR-20250515-002 | Add voice recording feature | Completed | v2.2.0 | Frontend Team |
| CR-20250520-003 | Update Stripe API version | In Progress | v2.3.0 | Backend Team |
| CR-20250601-004 | New language content (Spanish) | Planned | v2.4.0 | Content Team |
</file>

<file path="documentation/templates/continuous_improvement_template.md">
# CONTINUOUS IMPROVEMENT PLAN TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. AI-Driven Improvement Cycle
### 1.1 Continuous Learning Process
```mermaid
graph TD
    A[User Interactions] --> B[Raw Metrics]
    B --> C[AI Analysis]
    C --> D[Pattern Detection]
    D --> E[Improvement Hypotheses]
    E --> F[Implementation]
    F --> A
```

### 1.2 Feedback Management
### 1.1 Collection Channels
- **Quantitative**:
  - Voice analysis trends
  - SRS effectiveness rates
  - Feature usage analytics
  - Error frequency heatmaps
  
- **Qualitative**:
  - Sentiment analysis of reviews
  - Support ticket clustering
  - User interview transcripts
  - Feature request patterns

### 1.2 Prioritization Framework
| Metric | Weight | AI Processing | Output |
|--------|--------|---------------|--------|
| User Satisfaction | 40% | Sentiment analysis | Feature adjustments |
| Business Impact | 30% | Revenue modeling | Monetization features |
| Technical Debt | 20% | Code quality scans | Refactoring tasks |
| Strategic Alignment | 10% | Roadmap analysis | Long-term investments |

## 2. Iteration Planning
### 2.1 Improvement Backlog
| ID | Description | Status | Target Release | Owner |
|----|-------------|--------|----------------|-------|
| CI-001 | Implement dark mode | Planned | v2.4 | Frontend Team |
| CI-002 | Add pronunciation analytics | In Progress | v2.3 | AI Team |
| CI-003 | Improve lesson loading speed | Backlog | v2.5 | Perf Team |

### 2.2 Retrospective Process
1. **Data Review** (30 mins):
   - Metrics comparison (before/after)
   - Key incidents analysis
2. **Discussion** (60 mins):
   - What went well?
   - What could be improved?
   - Action items
3. **Follow-up**:
   - Document decisions
   - Assign action items
   - Schedule check-ins

## 3. Technical Debt
### 3.1 Debt Inventory
| Area | Description | Severity | Remediation Plan |
|------|-------------|----------|------------------|
| API | Legacy authentication | High | Migrate to OAuth 2.0 |
| DB | Missing indexes | Medium | Add performance-critical indexes |
| UI | jQuery dependencies | Low | Rewrite in React |

### 3.2 Paydown Schedule
- **Q2 2025**: Address high-severity items
- **Q3 2025**: Complete medium-severity items
- **Q4 2025**: Review and prioritize remaining debt
- **Ongoing**: Allocate 20% sprint capacity to debt

## 4. Metrics & Reporting
### 4.1 Improvement Metrics
- Weekly velocity (story points)
- Bug escape rate (prod vs staging)
- Cycle time (commit to deploy)
- User satisfaction (CSAT)
- Feature adoption rate

### 4.2 Progress Dashboard
```mermaid
graph TD
    A[User Behavior] --> B[AI Analytics Engine]
    B --> C[Improvement Candidates]
    C --> D[Validation Simulations]
    D --> E[Approved Changes]
    E --> F[Autonomous Deployment]
    F --> A
```
</file>

<file path="documentation/templates/deployment_playbook_template.md">
# DEPLOYMENT PLAYBOOK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Local Development (Mac)
### 1.1 Docker Setup
```yaml
# docker-compose.mac.yml
version: '3.8'
services:
  postgres:
    image: postgres:17
    environment:
      POSTGRES_PASSWORD: lessay
    ports:
      - "5432:5432"
  
  app:
    build:
      context: .
      dockerfile: Dockerfile.mac
    ports:
      - "3000:3000"
    environment:
      MOCK_AUTH: "true"
```

### 1.2 Initial Setup
```bash
docker-compose -f docker-compose.mac.yml up -d
```

## 2. Staging Environment
### 2.1 Configuration
```yaml
# docker-compose.stage.yml
version: '3.8'
services:
  app:
    image: lessay-app:stage
    deploy:
      replicas: 2
    environment:
      NODE_ENV: staging
      DATABASE_URL: ${STAGE_DB_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
```

### 2.2 Deployment
```bash
docker stack deploy -c docker-compose.stage.yml lessay-stage
```

## 3. Production Environment
### 3.1 Configuration
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    image: lessay-app:prod
    deploy:
      replicas: 4
      resources:
        limits:
          cpus: '2'
          memory: 2G
    environment:
      NODE_ENV: production
      DATABASE_URL: ${PROD_DB_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    configs:
      - source: redis.conf
        target: /usr/local/etc/redis/redis.conf
```

### 3.2 Deployment
```bash
docker stack deploy -c docker-compose.prod.yml lessay-prod
```

## 4. CI/CD Pipeline
### 4.1 GitHub Actions Workflow
```yaml
name: Deploy Lessay
on:
  push:
    branches:
      - main
      - release/*

jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run build
      - run: npm test

  deploy-stage:
    needs: build-test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker-compose -f docker-compose.stage.yml up -d
      - run: npm run migrate:stage

  deploy-prod:
    needs: deploy-stage
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker-compose -f docker-compose.prod.yml up -d
      - run: npm run migrate:prod
```

## 5. Proxy Environment
### 2.1 Configuration
```yaml
# docker-compose.proxy.yml
version: '3.8'
services:
  reverse-proxy:
    image: nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
```

### 2.2 Deployment
```bash
docker-compose -f docker-compose.proxy.yml up -d
```

## 6. Secrets Management
### 6.1 Environment Variables
### 6.1.1 Required Variables
```env
### Supabase Secrets
```bash
supabase secrets set STRIPE_SECRET_KEY=sk_live_***
supabase secrets set AI_API_KEY=ai_***
```

### Google Cloud Credentials
For local development:
- Place `gcp-credentials.json` in project root
- Add to `.gitignore` to prevent accidental commits

For production environments:
```bash
# Store entire JSON content as a single environment variable
supabase secrets set GCP_CREDENTIALS_JSON='{"type": "service_account", ...}'
```

### 6.2 Environment Hierarchy
```env
# Order of precedence (highest to lowest)
1. Supabase secrets (production)
2. .env.production.local
3. .env.staging.local
4. .env.local
5. .env
```

### 6.3 Rotation Policy
- API keys: Every 90 days
- Database credentials: Every 180 days
- Certificates: Annually
- Google Cloud Service Account Keys: Every 365 days
</file>

<file path="documentation/templates/frs_template.md">
# FUNCTIONAL REQUIREMENTS SPECIFICATION
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Introduction
### 1.1 Purpose
This document specifies the functional requirements for the Lessay language learning platform, providing detailed specifications for development teams.

### 1.2 Scope
Covers core functionality including:
- User authentication and authorization
- Lesson delivery and progress tracking
- Subscription management
- Payment processing
- Basic reporting

Excludes:
- Content creation tools
- Marketing features
- Third-party integrations beyond payment processing

### 1.3 Definitions
- **LTI**: Learning Tools Interoperability
- **SRS**: Spaced Repetition System
- **STT**: Speech-to-Text
- **TTS**: Text-to-Speech
- **LLM**: Large Language Model
- **A/B Testing**: Feature experimentation
- **PCI DSS**: Payment Card Industry Data Security Standard

## 2. Overall Description
### 2.1 Product Perspective
Integrates with:
- Mobile devices for on-the-go learning
- Payment processors (Stripe)
- Email services for notifications
- Analytics platforms for usage tracking

### 2.2 User Characteristics
1. **Casual Learners**:
   - Need quick, engaging lessons
   - Prefer gamified elements
   - Limited time commitment

2. **Serious Students**:
   - Require structured curriculum
   - Want progress certifications
   - Need detailed feedback

3. **Educators**:
   - Require classroom tools
   - Need progress monitoring
   - Want assignment creation

## 3. System Features
### 3.1 Adaptive Lesson System
#### 3.1.1 Description
AI-driven lesson delivery with real-time feedback and post-session analysis.

#### 3.1.2 Functional Requirements
- FR-001: System shall generate personalized lesson plans using LLM analysis of user profile
- FR-002: Shall provide real-time STT feedback during exercises (latency <300ms)
- FR-003: Must capture raw audio blob for post-session analysis
- FR-004: Shall adapt difficulty based on performance history
- FR-009: System shall capture raw audio of user speech for diagnostics
- FR-010: Shall use real-time STT to validate answer content immediately

### 3.2 SRS Engine
#### 3.2.1 Description
Spaced Repetition System for optimal knowledge retention.

#### 3.2.2 Functional Requirements
- FR-011: System shall maintain Recall Strength Score per vocabulary/concept
- FR-012: Must track Next Review Date for each learned item
- FR-013: Lesson generation shall prioritize items due for review
- FR-014: Shall adjust SRS scores based on diagnostic analysis

### 3.3 Voice Analysis System
#### 3.3.1 Description
Real-time and post-session vocal fluency diagnostics.

#### 3.3.2 Functional Requirements
- FR-015: Shall measure speaking pace (words/minute)
- FR-016: Must track hesitation frequency and patterns
- FR-017: Shall identify pronunciation errors at phoneme level
- FR-018: Must compare current performance to historical baselines

### 3.4 Progress Dashboard
#### 3.4.1 Description
Comprehensive visualization of learning metrics.

#### 3.4.2 Functional Requirements
- FR-019: Shall display vocabulary mastery heatmap
- FR-020: Must show fluency metrics over time
- FR-021: Shall highlight recurring error patterns
- FR-022: Must visualize SRS recall strength distribution

## 4. External Interface Requirements
### 4.1 User Interfaces
- Responsive design for mobile/desktop
- Accessibility compliant (WCAG 2.1 AA)
- Consistent branding across screens
- Intuitive navigation structure

### 4.2 Hardware Interfaces
- Microphone for voice exercises
- Camera for AR translation features
- Touchscreen support for mobile
- Keyboard shortcuts for desktop

### 4.3 Software Interfaces
- Stripe API for payments
- Google/Facebook OAuth
- SendGrid for email
- Mixpanel for analytics

## 5. Other Requirements
### 5.1 Performance
- API response time < 500ms (p95)
- Support 100 concurrent lessons
- Handle 5000 requests/minute
- Database queries < 100ms

### 5.2 Safety
- Content moderation for user-generated content
- Age-appropriate material filtering
- Secure storage of personal data
- Compliance with COPPA for under-13 users
</file>

<file path="documentation/templates/maintenance_guide_template.md">
# MAINTENANCE GUIDE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Monitoring Configuration
### 1.1 Key Metrics
- API response times (p50, p95, p99)
- Error rates by service
- Database connection pool usage
- Payment transaction success rate
- Active user sessions
- Lesson completion rate

### 1.2 Alert Thresholds
- **Infrastructure**:
  - CPU Usage: >80% for 5m (warning), >90% for 5m (critical)
  - Memory Usage: >85% (warning), >95% (critical)
  - Disk Space: >75% used
  
- **API**:
  - Error Rate: >5% for 10m
  - Latency: >500ms p95
  - STT Response: >300ms p95
  
- **AI Services**:
  - Voice Queue: >100 pending for 5m
  - Analysis Time: >5s per request
  - LLM Degradation: >15% error rate
  - STT Accuracy: <85% confidence
  
- **Business Metrics**:
  - Lesson Start Failures: >10% for 15m
  - Payment Errors: >5% for 30m

## 2. Troubleshooting Procedures
### 2.1 Common Issues
| Symptom | Resolution | Escalation Path |
|---------|------------|-----------------|
| High API latency | Check database queries<br>Scale API instances | Senior Engineer |
| Payment failures | Verify Stripe API status<br>Check error logs | Payment Team |
| User login issues | Review auth service logs<br>Check IDP connectivity | Auth Team |

### 2.2 Diagnostic Tools
```bash
# Core System
journalctl -u lessay-api --since "5 minutes ago"
pg_stat_activity -x -c "SELECT * FROM pg_stat_activity"
curl -v https://api.lessay/health

# Voice Processing
curl -X POST https://api.lessay/v1/diagnostics/voice-queue
docker exec -it voice-worker lessay-cli check stt-latency

# AI Services
curl https://api.lessay/v1/llm/health | jq '.models[].status'
lessay-cli check analysis-backlog --threshold=50

# Storage Systems
aws s3api list-objects --bucket lessay-voice --query 'length(Contents)'
supabase status --service storage

## 3. Update Procedures
### 3.1 Patch Management
1. Review patch notes for breaking changes
2. Apply to staging environment first
3. Monitor for 24 hours
4. Deploy to production with canary rollout
5. Verify metrics post-deployment

### 3.2 Version Upgrades
1. **Preparation**:
   - Notify stakeholders of downtime window
   - Create database backup snapshot
   - Document rollback procedure

2. **Deployment**:
   - Drain traffic from old version
   - Deploy new version to 10% of nodes
   - Run migration scripts
   - Verify critical functionality

3. **Verification**:
   - Monitor metrics for 1 hour
   - Run smoke tests
   - Gradually roll out to 100%

## 4. Backup & Recovery
### 4.1 Backup Schedule
- **Database**: Hourly snapshots (retained 7 days) + Daily full backups (retained 30 days)
- **User Files**: Daily incremental (retained 14 days)
- **Configuration**: Versioned in Git + Weekly exports
- **Payment Data**: Real-time replication to DR site

### 4.2 Recovery Process
**Targets**:
- RTO (Recovery Time Objective): 1 hour
- RPO (Recovery Point Objective): 5 minutes

**Procedure**:
1. Declare incident and notify stakeholders
2. Identify last known good backup (within RPO window)
3. Restore critical systems in priority order:
   a. User database and auth
   b. Payment processing
   c. Voice processing pipeline
4. Verify data consistency checks:
   - Cross-check SRS scores
   - Validate voice analysis integrity
5. Gradually enable traffic (10% increments every 5m)
6. Monitor key health metrics:
   - API success rate
   - Voice processing latency
   - LLM response quality
7. Conduct post-mortem analysis within 24h
</file>

<file path="documentation/templates/project_charter_template.md">
# PROJECT CHARTER TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Project Overview
### 1.1 Vision Statement
To create an AI-powered language learning platform that listens, understands, and adapts to each learner through continuous voice analysis and Spaced Repetition (SRS), transforming every interaction into measurable progress toward fluency.

### 1.2 Objectives
- Launch with English, Spanish and French by Q3 2025
- Achieve 15% improvement in vocabulary recall (measured by SRS) within 30 days
- Maintain <300ms latency for real-time voice analysis
- Process 95% of payments through Stripe integration

### 1.3 Success Criteria
- 15% improvement in vocabulary recall over 30 days (SRS metric)
- 10% reduction in pronunciation errors per month (voice analysis)
- <300ms latency for real-time speech-to-text
- 90% user retention at 30 days

## 2. Scope
### 2.1 In Scope
- Adaptive lesson engine with SRS
- Real-time voice analysis pipeline
- Progress dashboard with fluency metrics
- Stripe payment integration
- AI-driven diagnostics system

### 2.2 Out of Scope
- Offline functionality
- Social features
- Classroom management tools
- Third-party content marketplace

## 3. Stakeholders
### 3.1 Key Stakeholders
| Role | Name | Responsibility |
|------|------|----------------|
| Product Owner | Jane Doe | Final requirements approval |
| Tech Lead | John Smith | Technical oversight |
| UX Lead | Sarah Lee | User experience |
| Marketing Lead | Alex Wong | Go-to-market strategy |

### 3.2 Steering Committee
Composed of:
- CTO (chair)
- VP Product
- Head of Engineering
- Finance Director
Meets bi-weekly to review progress and approve major changes

## 4. Timeline
### 4.1 Key Milestones
| Milestone | Date | Owner |
|-----------|------|-------|
| Requirements Finalized | 2025-06-25 | Jane Doe |
| Core Engine Complete | 2025-08-15 | John Smith |
| Voice Analysis Integrated | 2025-09-01 | John Smith |
| Beta Launch | 2025-09-15 | Sarah Lee |
| Full Release | 2025-10-01 | Alex Wong |

### 4.2 High-Level Schedule
```mermaid
gantt
    title Project Timeline
    dateFormat  YYYY-MM-DD
    section Phase 0
    Foundation       :active,  phase0, 2025-06-11, 5d
    section Phase 1
    Requirements     :         phase1, after phase0, 10d
    section Phase 2
    Technical Design :         phase2, after phase1, 15d
    section Phase 3
    Core Development :         phase3, after phase2, 45d
    Voice Integration:         voice, after phase3, 15d
    section Phase 4
    Testing & Launch :         phase4, after voice, 30d
```
</file>

<file path="documentation/templates/risk_assessment_template.md">
# RISK ASSESSMENT TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Risk Identification
### 1.1 Threat Sources
1. **External Threats**:
   - Hackers targeting voice data
   - Competitors scraping AI models
   - Malicious bots overloading APIs
   - Voice spoofing attacks
   - API cost exploitation

2. **Internal Threats**:
   - Accidental voice data leaks
   - Unauthorized access to AI models
   - Configuration errors in LLM prompts
   - Biased training data
   - Inadequate voice data retention

### 1.2 Vulnerabilities
1. **Technical**:
   - Unencrypted voice data storage
   - Lack of rate limiting on AI APIs
   - Single point of failure in voice processing
   - Inadequate bias testing
   - No LLM hallucination detection

2. **Process**:
   - Manual deployment procedures
   - Lack of disaster recovery testing
   - Incomplete audit trails

## 2. Risk Analysis
### 2.1 Risk Matrix
| Likelihood/Impact | Low | Medium | High |
|-------------------|-----|--------|------|
| **High**          | Voice spoofing |  Data scraping | Payment breach |
| **Medium**        | API cost overrun | Inaccurate AI feedback | Voice data leak |
| **Low**           | Minor UI bugs | LLM bias |      |

### 2.2 Risk Scoring
1. **Voice Data Breach**
   Likelihood: Medium
   Impact: Critical
   Score: 15 (Medium x Critical)
    
2. **Inaccurate AI Feedback**
   Likelihood: Medium
   Impact: High
   Score: 12
    
3. **API Cost Overrun**
   Likelihood: High
   Impact: High
   Score: 16
    
4. **LLM Bias**
   Likelihood: Medium
   Impact: High
   Score: 12
    
5. **Voice Spoofing**
   Likelihood: Low
   Impact: Critical
   Score: 9

## 3. Risk Mitigation
### 3.1 Mitigation Strategies
| Risk | Strategy | Owner | Timeline |
|------|----------|-------|----------|
| Voice Data Breach | AES-256 encryption + strict access controls | Security Team | Q3 2025 |
| Inaccurate AI Feedback | Human validation pipeline + confidence thresholds | AI Team | Q2 2025 |
| API Cost Overrun | Usage monitoring + budget alerts | Finance Team | Q2 2025 |
| LLM Bias | Diverse training data + regular audits | Ethics Board | Ongoing |
| Voice Spoofing | Liveness detection + voiceprint analysis | Auth Team | Q4 2025 |

### 3.2 Residual Risk
Accepted risks:
- Minor UI bugs (low impact)
- Temporary voice processing delays during peaks
- Model accuracy variance across languages
- Higher API costs during peak usage

## 4. Review Process
### 4.1 Monitoring
- Real-time payment fraud detection
- Weekly vulnerability scans
- Monthly penetration tests
- Quarterly compliance audits

### 4.2 Review Schedule
- **Monthly**: Operational risk review
- **Quarterly**: Full risk assessment
- **Annually**: Compliance certification
- **Ad-hoc**: After major incidents
</file>

<file path="documentation/templates/technical_design_template.md">
# TECHNICAL DESIGN DOCUMENT
<!-- Document Version: 1.2 -->
<!-- Last Updated: 2025-06-10 -->

## 1. Architecture Overview
### 1.1 System Context
```mermaid
graph TD
    A[Next.js Frontend] -->|API Routes| B[Next.js Backend]
    B --> C[Prisma ORM]
    B --> D[Supabase Auth]
    B --> E[Supabase Storage]
    B --> F[AIService]
    C --> G[Supabase PostgreSQL]
    F --> H[LLM Agent]
    F --> I[STT Service]
    F --> J[TTS Service]
    
    %% Real-time voice path
    A -->|WebSocket| K[Browser STT]
    K -->|Real-time text| B
    B -->|Analysis| F
    
    %% Diagnostic audio path
    A -->|Upload| E[Supabase Storage]
    E -->|Audio blob| F
    F -->|Store results| G
```

### 1.2 Key Features
- **Language Learning Core**:
  - Adaptive lesson generation
  - Progress tracking
  - Voice interaction handling
- **AI Integration**:
  - Autonomous development agent
  - Content personalization
  - Error correction

## 2. Component Design
### 2.1 Service Layer
- **AuthService**:
  - JWT verification
  - Session management
  - Mock auth implementation (`MOCK_AUTH=true`)
  
- **DataService**:
  ```mermaid
  flowchart LR
      A[API Route] --> B[DataService]
      B --> C[Prisma Client]
      C --> D[(PostgreSQL)]
      B --> E[Cache Layer]
  ```
  - Manages:
    - User profiles
    - Learning content
    - Progress data

- **AIService**:
  ```mermaid
  flowchart LR
      A[API Request] --> B{AIService}
      B --> C[Lesson Generation]
      B --> D[Voice Analysis]
      C --> E["Prompt:
      'Generate a lesson for {user} focusing on
      {weaknesses} using {SRS} schedule'"]
      D --> F["Analysis:
      - Pronunciation scoring
      - Hesitation detection
      - Fluency metrics"]
      E --> G[LLM Response]
      F --> H[Diagnostic Report]
  ```
  
  **Example Lesson Generation Payload**:
  ```json
  {
    "userId": "uuid",
    "targetLanguage": "es",
    "focusAreas": ["past_tense", "travel_vocab"],
    "srsDueItems": ["comer", "viajar"],
    "difficultyLevel": 3
  }
  ```
  
  **Voice Analysis Parameters**:
  ```prisma
  model VoiceAnalysis {
    id        String @id @default(uuid())
    userId    String
    lessonId  String
    metrics   Json // {pace: 120, accuracy: 0.85, ...}
    audioUrl  String
    createdAt DateTime @default(now())
  }
  ```

## 3. Data Flow
### 3.1 Adaptive Learning Loop
```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant B as Backend
    participant AI as AIService
    participant DB as Database
    
    U->>F: Start Lesson
    F->>B: POST /api/lessons/start
    B->>AI: Request lesson (with SRS due items)
    AI->>DB: Query user progress
    DB-->>AI: Return progress data
    AI-->>B: Generated lesson content
    B-->>F: Lesson data
    F->>U: Present exercise
    U->>F: Speak response
    F->>B: Stream audio to API
    B->>AI: Real-time STT analysis
    AI-->>B: Immediate feedback
    B-->>F: Corrections
    F->>U: Show results
    U->>F: Complete lesson
    F->>B: POST /api/lessons/{id}/complete
    B->>AI: Full session analysis
    AI->>DB: Update SRS scores
    AI-->>B: Next lesson plan
    B-->>F: Schedule recommendation
```

### 3.2 Subscription Webhook Flow
```mermaid
sequenceDiagram
    participant S as Stripe
    participant B as Backend
    participant DB as Database
    
    S->>B: POST /api/stripe/webhook
    B->>B: Verify signature
    alt payment_succeeded
        B->>DB: Update subscription status
    else payment_failed
        B->>DB: Flag account
    end
    B-->>S: 200 OK
```

## 4. Interface Specifications
### 4.1 AI Endpoints
| Method | Path | Description |
|--------|------|-------------|
| POST   | /api/ai/generate-lesson | Create personalized lesson |
| POST   | /api/ai/analyze-response | Evaluate user input |

## 5. Database Design
### 5.1 Complete Schema
```prisma
model User {
  id           String @id @default(uuid())
  email        String @unique
  password     String
  targetLang   String
  nativeLang   String
  progress     UserProgress[]
  srsEntries   SRSEntry[]
  lessons      Lesson[]
  createdAt    DateTime @default(now())
}

model Lesson {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  exercises   Exercise[]
  completedAt DateTime?
  analysis    VoiceAnalysis[]
}

model Exercise {
  id          String @id @default(uuid())
  type        String // 'vocabulary', 'grammar', etc.
  content     Json
  difficulty  Int
  language    String
  tags        String[]
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  lessonId    String
}

model UserProgress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  metric      String // 'vocabulary', 'grammar', etc.
  score       Float
  lastUpdated DateTime @default(now())
}

model SRSEntry {
  id             String @id @default(uuid())
  userId         String
  user           User @relation(fields: [userId], references: [id])
  item           String // word or grammar concept
  recallStrength Float @default(1.0)
  nextReview     DateTime @default(now())
  language       String
  @@index([userId, nextReview])
}

model VoiceAnalysis {
  id        String @id @default(uuid())
  userId    String
  user      User @relation(fields: [userId], references: [id])
  lessonId  String
  lesson    Lesson @relation(fields: [lessonId], references: [id])
  metrics   Json // {pace: 120, accuracy: 0.85, ...}
  audioUrl  String
  createdAt DateTime @default(now())
}
```

## 6. Non-Functional Considerations
### 6.1 AI Performance
- Model inference optimization
- Async task processing
- Rate limiting

### 6.2 Language Processing
- Multilingual support
- Voice data handling
- Real-time feedback
</file>

<file path="documentation/templates/test_plan_template.md">
# TEST PLAN TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Core Learning Loop Tests
### 1.1 Adaptive Lesson Generation
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| SRS-Driven Content | 1. User has 5 due items<br>2. Start new lesson | - Lesson contains 3-5 due items<br>- Mixed with new material |
| Difficulty Adjustment | 1. Fail 3 exercises<br>2. Next lesson | - Difficulty reduced by 1 level<br>- More review content |

### 1.2 Real-Time Feedback
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Correct Pronunciation | 1. Submit perfect audio<br>2. Get feedback | - Score ≥0.95<br>- Positive reinforcement |
| Grammar Error | 1. Submit incorrect tense<br>2. Get feedback | - Specific error highlighted<br>- Correction shown |

### 1.3 Post-Session Analysis
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Audio Processing | 1. Complete lesson<br>2. Wait 5m | - Diagnostic report generated<br>- SRS scores updated |
| Weakness Detection | 1. Make consistent errors<br>2. Review analysis | - Weakness pattern identified<br>- Next lesson focuses on area |

## 2. Vocal Analysis Tests
### 2.1 Pronunciation Accuracy
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Native Speaker | 1. Submit native audio<br>2. Check score | - Score ≥0.98<br>- No errors flagged |
| Common Mistake | 1. Submit "th" as "d"<br>2. Check feedback | - Error detected<br>- Specific correction |

### 2.2 Fluency Metrics
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Hesitation | 1. Submit audio with pauses<br>2. Check metrics | - Hesitation count correct<br>- Pace calculated |
| Filler Words | 1. Use "um" repeatedly<br>2. Check report | - Filler word count accurate<br>- Trend shown |

## 3. User Dashboard Tests
### 3.1 Progress Visualization
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| SRS Overview | 1. Complete 10 lessons<br>2. Check dashboard | - Due items count correct<br>- Strength distribution accurate |
| Error Patterns | 1. Make consistent errors<br>2. Check dashboard | - Top errors highlighted<br>- Frequency correct |

### 3.2 Metric Accuracy
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Fluency Trends | 1. Improve over week<br>2. Check graph | - Upward trend visible<br>- Data points correct |
| Vocabulary Growth | 1. Learn new words<br>2. Check stats | - Count matches lessons<br>- Retention rate shown |


## 5. Payment Flow Tests
### 5.1 Subscription Scenarios
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| New Premium Subscription | 1. Select Premium plan<br>2. Enter valid card<br>3. Submit | - Status: active<br>- Features unlocked |
| Payment Failure | 1. Use declined card<br>2. Attempt purchase | - Error message shown<br>- No access change |
| Plan Upgrade | 1. From Free to Pro<br>2. Confirm prorated charge | - Immediate upgrade<br>- Correct charge |

### 5.2 Webhook Tests
- Payment success → DB updated
- Payment failed → Retry logic
- Subscription canceled → Access revoked

## 6. Security Tests
### 6.1 Payment Data
- Card details never stored
- Tokenization verified
- PCI compliance checks
</file>

<file path="documentation/dev_todo_phase_2.md">
# Lessay Development Phase 2: Learning Loop Implementation

## Tasks for Developer AI

### 1. Implement Lesson Start Route (`/app/api/lessons/start/route.ts`)
- [x] **Add authentication check**
  - Import `getUserSession` from `@/lib/supabase-server`
  - At start of POST function, add:
    ```typescript
    const session = await getUserSession()
    if (!session) return new Response('Unauthorized', { status: 401 })
    ```
  - Verification: Route returns 401 for unauthenticated requests

- [x] **Implement lesson generation**
  - Call `AIService.generateLessonForUser(session.user.id)`
  - Store returned lesson data in Prisma:
    ```typescript
    const lesson = await prisma.lesson.create({
      data: {
        userId: session.user.id,
        content: generatedLesson.content
      }
    })
    ```
  - Verification: New lesson appears in database after API call

- [x] **Create exercise record**
  - Add exercise creation after lesson creation:
    ```typescript
    const exercise = await prisma.exercise.create({
      data: {
        lessonId: lesson.id,
        prompt: generatedLesson.exercise.prompt,
        correctAnswer: generatedLesson.exercise.correctAnswer
      }
    })
    ```
  - Verification: Exercise linked to lesson in database

### 2. Implement Answer Submission Route (`/app/api/lessons/[id]/submit-answer/route.ts`)
- [ ] **Add authentication check**
  - Same pattern as lesson start route
  - Verification: Route rejects unauthenticated requests

- [ ] **Implement answer validation**
  - Find exercise by ID from URL params
  - Compare `textResponse` to `exercise.correctAnswer`
  - Verification: API correctly identifies matching answers

- [ ] **Create progress record**
  - Add progress tracking:
    ```typescript
    await prisma.userProgress.create({
      data: {
        userId: session.user.id,
        exerciseId: exercise.id,
        submittedAnswer: textResponse,
        isCorrect: answerMatches
      }
    })
    ```
  - Verification: Progress records appear in database

### 3. Update Lesson View Component (`/components/LessonView.tsx`)
- [ ] **Add answer input UI**
  - Create controlled text input component
  - Add state management for answer text
  - Verification: Input field appears and updates properly

- [ ] **Implement submission logic**
  - Add submit button handler that:
    - Calls `/api/lessons/${lessonId}/submit-answer`
    - Disables during submission
    - Handles errors
  - Verification: Button works and shows loading state

- [ ] **Add feedback display**
  - Create section showing:
    - Correct/incorrect indicator
    - Correct answer
    - Explanation (if available)
  - Style with Tailwind classes
  - Verification: Feedback appears after submission
</file>

<file path="prisma/schema.prisma">
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

generator client {
  provider = "prisma-client-js"
}

model User {
  id           String @id @default(uuid())
  email        String @unique
  password     String
  targetLang   String
  nativeLang   String
  progress     UserProgress[]
  srsEntries   SRSEntry[]
  lessons      Lesson[]
  voiceAnalyses VoiceAnalysis[]
  progressRecords Progress[]
  createdAt    DateTime @default(now())
}

model Lesson {
  id          String @id @default(uuid())
  title       String
  content     String
  difficulty  Int
  userId      String
  user        User @relation(fields: [userId], references: [id])
  exercises   Exercise[]
  completedAt DateTime?
  analysis    VoiceAnalysis[]
  progress    Progress[]
}

model Exercise {
  id          String @id @default(uuid())
  type        String // 'vocabulary', 'grammar', etc.
  content     Json
  difficulty  Int
  language    String
  tags        String // comma-separated list of tags
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  lessonId    String
}

model UserProgress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  metric      String // 'vocabulary', 'grammar', etc.
  score       Float
  lastUpdated DateTime @default(now())
}

model Progress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  lessonId    String
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  completed   Boolean @default(false)
  score       Float?
  startedAt   DateTime @default(now())
  completedAt DateTime?
}

model SRSEntry {
  id             String @id @default(uuid())
  userId         String
  user           User @relation(fields: [userId], references: [id])
  item           String // word or grammar concept
  recallStrength Float @default(1.0)
  nextReview     DateTime @default(now())
  language       String
  @@index([userId, nextReview])
}

model VoiceAnalysis {
  id        String @id @default(uuid())
  userId    String
  user      User @relation(fields: [userId], references: [id])
  lessonId  String
  lesson    Lesson @relation(fields: [lessonId], references: [id])
  metrics   Json // {pace: 120, accuracy: 0.85, ...}
  audioUrl  String
  createdAt DateTime @default(now())
}
</file>

<file path="todos/master_development_plan.md">
# Master Development Plan

## Phase 1: Initial Development
- [ ] Complete dev_todo_phase_1.md tasks

## Phase 2: Transactional Integrity
- [x] Complete dev_todo_phase_2.md tasks

## Phase 3: Onboarding
- [x] Complete dev_todo_phase_3.md tasks

## Phase 4: Observability
- [x] Complete dev_todo_phase_4.md tasks

## Phase 5: Error Handling
- [ ] Complete dev_todo_phase_5.md tasks

## Phase 6: Security
- [ ] Complete dev_todo_phase_6.md tasks

## Phase 7: Performance
- [ ] Complete dev_todo_phase_7.md tasks

## Phase 8: Testing
- [ ] Complete dev_todo_phase_8.md tasks

## Phase 9: State Management
- [ ] Complete dev_todo_phase_9.md tasks

## Phase 10: Environments
- [ ] Complete dev_todo_phase_10.md tasks

## Phase 11: Cost Control
- [ ] Complete dev_todo_phase_11.md tasks

## Phase 12: Authorization
- [ ] Complete dev_todo_phase_12.md tasks
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

/app/generated/prisma
</file>

<file path="app/api/payments/create-subscription/route.ts">
import { NextResponse } from 'next/server';
import Stripe from 'stripe';
import logger from '@/lib/logger';

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY as string, {
  apiVersion: '2025-05-28.basil'
});

export async function POST(request: Request) {
  try {
    const { customerId, priceId } = await request.json();
    logger.info({ customerId, priceId }, 'Starting subscription creation');
    
    const subscription = await stripe.subscriptions.create({
      customer: customerId,
      items: [{ price: priceId }],
      payment_behavior: 'default_incomplete'
    });

    logger.info({ subscriptionId: subscription.id }, 'Subscription created successfully');
    return NextResponse.json({ subscription });
  } catch (error) {
    logger.error({ error }, 'Failed to create subscription');
    return NextResponse.json(
      { error: 'Subscription creation failed' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/api/users/profile/route.ts">
import { NextResponse } from 'next/server'
import { getUserSession } from '@/lib/supabase/server'
import prisma from '@/lib/prisma'
import logger from '@/lib/logger'

export async function GET() {
  const session = await getUserSession()
  
  if (!session) {
    logger.warn('Unauthorized profile access attempt');
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    )
  }

  logger.info({ userId: session.user.id }, 'Fetching user profile');

  const user = await prisma.user.findUnique({
    where: { id: session.user.id },
    select: {
      id: true,
      email: true,
      targetLang: true,
      nativeLang: true,
      createdAt: true
    }
  })

  if (!user) {
    logger.warn({ userId: session.user.id }, 'User profile not found');
    return NextResponse.json(
      { error: 'User not found' },
      { status: 404 }
    )
  }

  return NextResponse.json(user)
}

export async function PUT(request: Request) {
  const session = await getUserSession();
  
  if (!session) {
    logger.warn('Unauthorized profile update attempt');
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    );
  }

  logger.info({ userId: session.user.id }, 'Updating user profile');

  const body = await request.json();
  
  try {
    const updatedUser = await prisma.user.update({
      where: { id: session.user.id },
      data: {
        targetLang: body.targetLang,
        nativeLang: body.nativeLang
      },
      select: {
        id: true,
        email: true,
        targetLang: true,
        nativeLang: true,
        createdAt: true
      }
    });

    logger.debug({
      userId: session.user.id,
      updates: body
    }, 'Profile updated successfully');

    return NextResponse.json(updatedUser);
  } catch (error) {
    logger.error({
      userId: session.user.id,
      error,
      updateData: body
    }, 'Profile update failed');

    return NextResponse.json(
      { error: 'Profile update failed' },
      { status: 500 }
    );
  }
}
</file>

<file path="documentation/2_development_plan/dev_todo_phase_2.md">
# Development Phase 2: Lesson Functionality & Progress Tracking

## Tasks for Developer AI

### 1. Implement Lesson Schema
- [x] **File:** `/prisma/schema.prisma`
- [x] **Action:** Add Lesson and Progress models
- [x] **Steps:**
  1. Add Lesson model with fields: id, title, content, difficulty
  2. Add Progress model linking users to lessons
  3. Run `npx prisma migrate dev` to create migration
- [x] **Verification:** New models exist in schema and migration file created

### 2. Create Lesson API Endpoints
- [x] **File:** `/app/api/lessons/start/route.ts`
- [x] **Action:** Implement lesson initialization
- [x] **Steps:
  1. Create route handler for POST requests
  2. Validate user session
  3. Create new Progress record
- [x] **Verification:** Returns 401 when unauthenticated, lesson data when valid

### 3. Build Lesson Interface
- [x] **File:** `/components/LessonView.tsx`
- [x] **Action:** Create lesson presentation component
- [x] **Steps:**
  1. Fetch and display lesson content
  2. Add navigation controls
  3. Implement progress saving
- [x] **Verification:** Component renders lesson content correctly

### 4. Add Answer Submission
- [x] **File:** `/app/api/lessons/[id]/submit-answer/route.ts`
- [x] **Action:** Handle user answers
- [x] **Steps:
  1. Create dynamic route handler
  2. Validate and score user responses
  3. Update Progress record
- [x] **Verification:** POST requests update progress correctly

## Phase Completion Verification
1. All 4 task verifications pass
2. User can:
   - Start new lessons
   - View lesson content
   - Submit answers
   - Track progress
</file>

<file path="documentation/2_development_plan/dev_todo_phase_3.md">
# Development Phase 3: User Onboarding

## Tasks for Developer AI

### 1. Create Welcome Component
- [x] **File:** `/components/Welcome.tsx`
- [x] **Action:** Build onboarding interface for new users
- [x] **Steps:**
  1. Create component with greeting message
  2. Add quick start guide section
  3. Include progress tracker
- [x] **Verification:** Component renders correctly for new users

### 2. Implement Tutorial System
- [x] **File:** `/components/Tutorial.tsx`
- [x] **Action:** Create interactive tutorial
- [x] **Steps:
  1. Build step-by-step guide component
  2. Connect to lesson API
  3. Add navigation controls
- [x] **Verification:** Tutorial walks through app features

### 3. Set Up Onboarding Progress
- [x] **File:** `/app/api/onboarding/status/route.ts`
- [x] **Action:** Track user onboarding completion
- [x] **Steps:**
  1. Create API endpoint
  2. Store progress in database
  3. Add completion check
- [x] **Verification:** API returns correct onboarding status

### 4. Add Help Documentation
- [x] **File:** `/components/Help.tsx`
- [x] **Action:** Create in-app documentation
- [x] **Steps:
  1. Build help interface
  2. Add search functionality
  3. Link to external resources
- [x] **Verification:** Help content accessible throughout app

## Phase Completion Verification
1. All 4 task verifications pass
2. New users can:
   - Complete welcome tour
   - Access tutorials
   - View progress
   - Find help docs
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts", "node_modules/next-auth", "typings/**/*.d.ts"],
  "exclude": ["node_modules"]
}
</file>

<file path="documentation/2_development_plan/dev_todo_phase_4.md">
# Developer To-Do List: Phase 4 - Observability Implementation

**Objective:** Implement comprehensive logging, metrics, and monitoring infrastructure.

## Tasks

- [ ] **1. Enhance Logger Configuration (`/lib/logger.ts`)**
  - Add structured logging with Pino
  - Implement log levels (debug, info, warn, error)
  - Add request ID correlation
  - Verification: All API routes output structured JSON logs

- [ ] **2. Instrument Key Endpoints**
  - Files to modify:
    - `app/api/lessons/start/route.ts`
    - `app/api/lessons/[id]/submit-answer/route.ts` 
    - `app/api/stats/srs-overview/route.ts`
  - Add:
    - Response time metrics
    - Error rate tracking
    - Request volume counters
  - Verification: Endpoints log timing and success metrics

- [ ] **3. Implement Metrics Endpoint (`/app/api/metrics/route.ts`)**
  - Expose Prometheus-compatible metrics
  - Track:
    - API response times
    - Error rates
    - Active users
    - Lesson completion rates
  - Verification: `/api/metrics` returns valid Prometheus data

- [ ] **4. Create Monitoring Dashboard**
  - Install: `npm install @grafana/faro-web-sdk`
  - File: `/components/Monitoring.tsx`
  - Implement:
    - Error rate visualization
    - API latency heatmap
    - System health status
  - Verification: Dashboard renders with live data

- [ ] **5. Configure Alerting Rules**
  - Create file: `/config/alert-rules.yaml`
  - Define thresholds for:
    - High error rate (>5%)
    - Slow responses (>500ms p95)
    - Service downtime
  - Verification: Alert rules file exists with valid YAML

- [ ] **6. Update Documentation**
  - File: `/documentation/operations/observability.md`
  - Add:
    - Monitoring architecture overview
    - Alert response procedures
    - Dashboard usage guide
  - Verification: Documentation file exists with all sections
</file>

<file path=".roo/rules-emergency/rules.md">
## 1. IDENTITY & PERSONA

You are the **Emergency Intervention AI for Project Lessay**, designated as **🚨 Emergency**. You are an expert diagnostician. You do not write new feature code, nor do you execute any development or infrastructure commands. Your sole purpose is to analyze complex failures reported by the `👨‍💻 Developer AI` and to create a precise, surgical `FIX_PLAN.md` that will unblock the development process.

## 2. THE CORE MISSION & TRIGGER

Your entire operational loop is triggered by a single condition: the existence of a `NEEDS_ASSISTANCE.md` file in the project's root directory. If this file exists, you must activate. Your mission is to analyze the failure and produce a definitive fix plan.

## 3. THE INTERVENTION WORKFLOW

1.  **Acknowledge Emergency:** Announce: `Emergency protocol initiated. Analyzing distress signal.`
2.  **Read Distress Signal:** Open and parse the contents of `NEEDS_ASSISTANCE.md`.
3.  **Diagnose the Problem:** Analyze the error message and any provided `repomix-output.xml` data to determine the root cause (Atomic vs. Integration).
4.  **Formulate a Fix Plan:** Create a new file named `FIX_PLAN.md` containing atomic, verifiable tasks for the Developer AI.
5.  **Prepare for Resumption:** The **final task** in *every* `FIX_PLAN.md` must be the following:
    ```markdown
    - [ ] **Task N: Clean up and reset for autonomous handoff**
        - **LLM Prompt:** "Delete the file `NEEDS_ASSISTANCE.md` from the root directory."
        - **Verification:** The file `NEEDS_ASSISTANCE.md` no longer exists.
    ```
6.  **Handoff to Orchestrator:** After creating and saving `FIX_PLAN.md`, your mission is complete. Announce `Fix plan generated. Switching to Orchestrator mode to resume operations.` and then execute the final, definitive command: **`<mode>orchestrator-senior</mode>`**.

## 4. CRITICAL DIRECTIVES & CONSTRAINTS

*   **NO `attempt_completion`:** This tool is obsolete and forbidden.
*   **DIAGNOSE AND PLAN ONLY:** You do not implement fixes. Your only output is the `FIX_PLAN.md` file.
*   **IMMEDIATE HANDOFF:** Your process must conclude with the `<mode>orchestrator-senior</mode>` command. This is the only valid way to terminate your session. Halting for human review is not part of your autonomous protocol.
</file>

<file path="app/api/lessons/start/route.ts">
import { NextResponse } from 'next/server'
import { getUserSession } from '@/lib/supabase/server'
import prisma from '@/lib/prisma'

export async function POST() {
  const session = await getUserSession()
  
  if (!session) {
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    )
  }

  try {
    const progress = await prisma.progress.create({
      data: {
        userId: session.user.id,
        lesson: {
          create: {
            title: 'New Lesson',
            content: 'Lesson content',
            difficulty: 1
          }
        }
      },
      include: {
        lesson: true
      }
    })

    return NextResponse.json(progress)
  } catch (error) {
    console.error('Lesson creation failed:', error)
    return NextResponse.json(
      { error: 'Lesson creation failed' },
      { status: 500 }
    )
  }
}
</file>

<file path="app/api/stats/srs-overview/route.ts">
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';
import { getServerSession } from 'next-auth/next';
import { authOptions } from '@/lib/auth';
import logger from '@/lib/logger';

export async function GET() {
  const session = await getServerSession(authOptions);

  if (!session || !session.user) {
    logger.warn('Unauthorized access attempt to SRS overview');
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  logger.info({ userId: session.user.id }, 'Fetching SRS overview');

  try {
    const overview = await prisma.sRSEntry.groupBy({
      by: ['exerciseType'],
      where: { userId: session.user.id },
      _count: { status: true },
      _min: { nextReview: true },
      _max: { nextReview: true },
      _avg: { nextReview: true }
    });

    logger.debug({
      userId: session.user.id,
      entryCount: overview.length
    }, 'SRS overview retrieved successfully');

    return NextResponse.json({ overview });
  } catch (error) {
    logger.error({
      userId: session.user.id,
      error
    }, 'Failed to fetch SRS overview');
    
    return NextResponse.json(
      { error: 'Failed to retrieve SRS data' },
      { status: 500 }
    );
  }
}
</file>

<file path="documentation/2_development_plan/dev_todo_phase_1.md">
# Development Phase 1: Core Backend & User Authentication

## Tasks for Developer AI

### 1. Implement User Authentication ✅
- **File:** `/lib/supabase/server.ts`
- **Action:** Create server-side Supabase client utilities
- **Steps:**
  1. Create directory `lib/supabase`
  2. Create file `server.ts` with:
     - `supabaseServerClient` function using `createServerComponentClient`
     - `getUserSession` helper to fetch user session
- **Verification:** File exports both functions with proper TypeScript types

### 2. Create Profile GET Route ✅
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add authenticated profile retrieval
- **Steps:
  1. Import `getUserSession` from `@/lib/supabase/server`
  2. Add session check to GET function
  3. Query Prisma for user data
- **Verification:** Returns 401 when unauthenticated, profile data when valid

### 3. Implement Profile PUT Route ✅
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add profile update functionality
- **Steps:**
  1. Reuse auth check from GET route
  2. Add Prisma `user.update` call
  3. Return updated profile
- **Verification:** PUT requests update user data successfully

### 4. Create Auth UI Component ✅
- **File:** `/components/Auth.tsx`
- **Action:** Build sign-up/sign-in interface
- **Steps:**
  1. Create client-side Supabase client
  2. Add email/password fields
  3. Implement sign-up/sign-in buttons
- **Verification:** Component renders and allows user registration/login

### 5. Implement User Sync Endpoint ✅
- **File:** `/api/users/sync/route.ts`
- **Action:** Create public profile after auth sign-up
- **Steps:**
  1. Create new route file
  2. Listen for Supabase auth events
  3. Create corresponding Prisma user record
- **Verification:** New auth users get public profiles automatically

## Phase Completion Verification
1. All 5 task verifications pass
2. User can:
   - Register/login via UI
   - Access protected profile route
   - Update profile information
   - Have profile auto-created on sign-up
</file>

<file path=".roo/rules-developer/rules.md">
## 1. IDENTITY & PERSONA

You are the **Developer AI**, designated as **👨‍💻 Developer**. Your purpose is to execute a pre-defined architectural blueprint. You are a meticulous executor and a diligent verifier. You follow instructions literally. Your job is to either successfully complete every task in a plan or, upon failure, to trigger the correct help protocol **and immediately cease your own operations by switching modes.**

## 2. THE CORE MISSION

Your mission is to find and execute the tasks within the active plan file (e.g., `dev_todo_phase_*.md` or `FIX_PLAN.md`). You will complete all granular tasks sequentially.

## 3. THE AUTONOMOUS OPERATIONAL LOOP

Your operation follows a two-tiered loop. Adherence is mandatory.

**Tier 1: Phase Execution Loop (The Master Directive)**
1.  **Find Active Plan:** First, check for `FIX_PLAN.md`. If it exists, that is your **Active Plan**. If not, find the first incomplete task in `todos/master_development_plan.md` and use its corresponding file path as the **Active Plan**.
2.  **Check for Project Completion:** If no active plan can be found and the master plan is complete, create a file named `DEVELOPMENT_COMPLETE.md` and **halt all operations.**
3.  **Announce:** "Now executing plan: [Active Plan file path]".
4.  **Execute Phase:** Initiate the **Tier 2 Loop** for the **Active Plan** file.
5.  **Handle Success:** If the Tier 2 Loop completes successfully:
    *   If the plan was `FIX_PLAN.md`, it will have already deleted the relevant signal files.
    *   If it was a phase plan, mark the corresponding line in `todos/master_development_plan.md` as `[x]`.
    *   **In all success cases, handoff to the orchestrator** to re-evaluate the project state by executing the command: `<mode>orchestrator-senior</mode>`.
6.  **Handle Failure:** If the Tier 2 Loop signals failure at any point, your *only* action is to follow the **Failure & Escalation Protocol** (Rule 6).

**Tier 2: Atomic Task Loop (The Worker)**
1.  Within the **Active Plan**, identify the very first incomplete task (`[ ]`).
2.  **Execute & Verify:**
    a. Read the `LLM Prompt` or `Command` for the task and execute it.
    b. Perform the `(Verification)` check precisely as specified.
3.  **On Success:**
    a. Mark the task as `[x]` and save the **Active Plan** file.
    b. Execute the **Commit Protocol** (Rule 5).
    c. Loop back to Step 1 of this Tier 2 loop. If all tasks are complete, signal success to the Tier 1 loop.
4.  **On Failure:**
    a. If verification fails after 3 retries, immediately signal failure to the Tier 1 Loop. Do not attempt any further tasks.

## 5. THE COMMIT PROTOCOL

After each **successful and verified** atomic task, you must commit the change.
*   **Command:** `git add .`
*   **Command:** `git commit -m "feat: Complete task '[task title from plan]'"`.

## 6. FAILURE & ESCALATION PROTOCOL

If any task verification fails after 3 retries, you must stop all work and follow the appropriate protocol below. Your session ends after performing the final step.

### 6.1. Standard Task Failure (First-Time Error)

If the failing task is from a normal `dev_todo_phase_*.md` file:
1.  **Create Distress Signal (`NEEDS_ASSISTANCE.md`):** The file must contain the failing plan's path, the full task description, the action attempted, and the verbatim verification error.
2.  **Handoff to Orchestrator:** Announce "Standard task failed. Creating distress signal and handing off to orchestrator." and execute your final command: `<mode>orchestrator-senior</mode>`.

### 6.2. Fix Plan Failure (Strategic Escalation)

If the failing task is from a `FIX_PLAN.md` file, this indicates a deep strategic error that requires master-level review.
1.  **Announce Escalation:** "Tactical fix has failed. The problem is systemic. Escalating to Senior Architect for strategic review."
2.  **Gather Evidence:** Read the contents of the `NEEDS_ASSISTANCE.md` that triggered the fix and the contents of the failing `FIX_PLAN.md`.
3.  **Create Escalation Report (`NEEDS_ARCHITECTURAL_REVIEW.md`):**
    *   Create a new file with this name.
    *   In this file, write a clear report including:
        *   `## Original Problem:` (Paste the contents of `NEEDS_ASSISTANCE.md`).
        *   `## Failed Fix Attempt:` (Paste the contents of the `FIX_PLAN.md`).
        *   `## New Error:` (Provide the specific error that occurred when you tried the fix).
4.  **Clean Up State:** Delete the failed `FIX_PLAN.md` file and the original `NEEDS_ASSISTANCE.md` file.
5.  **Handoff to Leadership:** Execute your final command: `<mode>orchestrator-senior</mode>`.

## 7. CRITICAL DIRECTIVES
*   **NO `attempt_completion`:** This tool is forbidden. Your job is to execute a plan or signal failure. There is no other state.
*   **SWITCH MODE TO HALT:** Your operational turn ends **only** when you use the `<mode>...` command.
*   **DB COMMANDS IN DOCKER:** All database migrations or direct queries must happen inside the `app` service via `docker compose exec app ...`.
</file>

<file path="package.json">
{
  "name": "app",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "test": "echo 'No tests yet' && exit 0"
  },
  "dependencies": {
    "@auth/supabase-adapter": "^1.9.1",
    "@google-cloud/speech": "^7.1.0",
    "@google-cloud/text-to-speech": "^6.1.0",
    "@google/generative-ai": "^0.24.1",
    "@prisma/client": "^6.9.0",
    "@stripe/react-stripe-js": "^3.7.0",
    "@stripe/stripe-js": "^7.3.1",
    "@supabase/auth-helpers-nextjs": "^0.10.0",
    "@supabase/supabase-js": "^2.50.0",
    "@types/recharts": "^2.0.1",
    "@types/stripe": "^8.0.417",
    "next-auth": "^4.24.11",
    "pino": "^9.7.0",
    "pino-pretty": "^13.0.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "recharts": "^2.15.3",
    "stripe": "^18.2.1"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@tailwindcss/postcss": "^4",
    "@types/next-auth": "^3.15.0",
    "@types/node": "^20.19.0",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.3.3",
    "next": "^15.3.3",
    "prisma": "^6.9.0",
    "tailwindcss": "^4",
    "typescript": "^5"
  }
}
</file>

<file path="FIX_PLAN.md">
# INTERVENTION FIX PLAN (ATOMIC)

**Problem:** The Developer AI failed to create the error handling middleware file (`/lib/errorHandler.ts`).

- [ ] **Task 1: Create the error handling middleware file**
    - **(File):** `lib/errorHandler.ts`
    - **(LLM Prompt):** "Create a new file at `lib/errorHandler.ts` with the following content:"
    ```typescript
    import { NextResponse } from 'next/server'

    export function errorHandler(err: Error, req: NextRequest) {
      const statusCode = 500;
      const errorId = Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15);
      console.error({ errorId, err }, 'Request failed');
      return NextResponse.json(
        { 
          error: err.message,
          errorId,
          statusCode 
        },
        { status: statusCode }
      );
    }
    ```
    - **(Verification):** "The file `lib/errorHandler.ts` exists and contains the specified content."
    - **(Commit):** "git add lib/errorHandler.ts && git commit -m 'feat: Create error handling middleware'"

- [ ] **Task 2: Clean up and reset for autonomous handoff**
    - **LLM Prompt:** "Delete the file `NEEDS_ARCHITECTURAL_REVIEW.md` from the root directory."
    - **(Verification):** The file `NEEDS_ARCHITECTURAL_REVIEW.md` no longer exists.
    - **(Commit):** "git add NEEDS_ARCHITECTURAL_REVIEW.md && git commit -m 'feat: Delete NEEDS_ARCHITECTURAL_REVIEW.md'"
</file>

<file path="documentation/architect_master_todo.md">
# Developer Master Roadmap (0_to_prod)

- [x] documentation/2_development_plan/dev_todo_phase_1.md
- [x] documentation/2_development_plan/dev_todo_phase_2.md
- [x] documentation/2_development_plan/dev_todo_phase_3.md
- [x] documentation/2_development_plan/dev_todo_phase_4.md
- [ ] documentation/2_development_plan/dev_todo_phase_5.md
- [ ] documentation/2_development_plan/dev_todo_phase_6.md
- [ ] documentation/2_development_plan/dev_todo_phase_7.md
- [ ] documentation/2_development_plan/dev_todo_phase_8.md
- [ ] documentation/2_development_plan/dev_todo_phase_9.md
- [ ] documentation/2_development_plan/dev_todo_phase_10.md
- [ ] documentation/2_development_plan/dev_todo_phase_11.md
- [ ] documentation/2_development_plan/dev_todo_phase_12.md
- [ ] documentation/2_development_plan/dev_todo_phase_13.md
- [ ] documentation/2_development_plan/dev_todo_phase_14.md
- [ ] documentation/2_development_plan/dev_todo_phase_15.md
</file>

</files>
