This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    ci.yml
.roo/
  rules-auditor/
    rules.md
  rules-developer/
    rules.md
  rules-dispatcher/
    rules.md
  rules-emergency/
    rules.md
  rules-planner/
    rules.md
  rules-product-manager/
    rules.md
  rules-system-supervisor/
    rules.md
  custom_modes.yaml
app/
  api/
    lessons/
      [id]/
        submit-answer/
          route.ts
      start/
        route.ts
    onboarding/
      diagnostic/
        route.ts
    payments/
      create-subscription/
        route.ts
    protected/
      route.ts
    settings/
      route.ts
    stats/
      fluency/
        route.ts
      srs-overview/
        route.ts
    stripe/
      webhook/
        route.ts
    users/
      profile/
        route.ts
      sync/
        route.ts
      update-profile/
        route.ts
  globals.css
  layout.tsx
  page.tsx
components/
  feedback/
    ErrorHighlight.tsx
    FeedbackBadge.tsx
    ProgressIndicator.tsx
    PronunciationMeter.tsx
  Auth.tsx
  LessonView.tsx
  Navigation.tsx
  Notifications.tsx
  OnboardingForm.tsx
  PricingPage.tsx
  ProfileView.tsx
  SettingsView.tsx
  Welcome.tsx
docs/
  3_personas_and_rules/
    orchestrator_entrypoint.md
    rules-developer.md
  templates/
    api_spec_template.md
    brd_template.md
    change_management_template.md
    compliance_framework_template.md
    continuous_improvement_template.md
    data_governance_template.md
    deployment_playbook_template.md
    frs_template.md
    maintenance_guide_template.md
    monetization_strategy.md
    performance_baseline_template.md
    project_charter_template.md
    risk_assessment_template.md
    technical_design_template.md
    test_plan_template.md
    user_documentation_template.md
  work_breakdown/
    tasks/
      dev_todo_phase_1.md
      dev_todo_phase_10.md
      dev_todo_phase_11.md
      dev_todo_phase_12.md
      dev_todo_phase_13.md
      dev_todo_phase_14.md
      dev_todo_phase_15.md
      dev_todo_phase_2.md
      dev_todo_phase_3.md
      dev_todo_phase_4.md
      dev_todo_phase_5.md
      dev_todo_phase_6.md
      dev_todo_phase_7.md
      dev_todo_phase_8.md
      dev_todo_phase_9.md
      feature_phase_1_feedback.md
      feature_phase_2_transactional_integrity.md
      feature_phase_3_onboarding.md
      hardening_phase_1_observability.md
      hardening_phase_1_todo.md
      hardening_phase_2_error_handling.md
      hardening_phase_3_security.md
      hardening_phase_4_performance.md
      hardening_phase_5_testing.md
      infra_phase_1_connection_pooling.md
      infra_phase_2_deployment_automation.md
      logic_phase_1_todo.md
      logic_phase_2_todo.md
      logic_phase_3_todo.md
      logic_phase_4_todo.md
      logic_phase_5_todo.md
      logic_phase_6_todo.md
      prod_polish_phase_5_state_management.md
      prod_polish_phase_6_environments.md
      prod_security_phase_2_cost_control.md
      prod_security_phase_3_authorization.md
    master_plan.md
  app_description.md
  canonical_spec.md
  documentation_completion_plan.md
  human_todo.md
  README.md
lib/
  supabase/
    server.ts
  ai-service.ts
  auth-middleware.ts
  auth-options.ts
  auth.ts
  lessons.ts
  prisma.ts
  security.ts
  srs.ts
prisma/
  migrations/
    20250611185434_add_lesson_and_progress_models/
      migration.sql
    20250613111519_add_performance_indexes/
      migration.sql
    20250620095352_add_lesson_analysis_model/
      migration.sql
    migration_lock.toml
  schema.prisma
public/
  file.svg
  globe.svg
  next.svg
  vercel.svg
  window.svg
signals/
  PROJECT_AUDIT_PASSED.md
types/
  supabase.ts
.gitignore
BLUEPRINT_COMPLETE.md
docker-compose.yml
Dockerfile
eslint.config.mjs
FIX_PLAN.md
next.config.ts
package.json
POST_COMPLETION_GUIDE.md
postcss.config.mjs
project_manifest.json
README.md
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="signals/PROJECT_AUDIT_PASSED.md">
# Project Audit Passed

The Lessay project has successfully passed the static audit. All features from the canonical specification have been implemented with no placeholder code detected.
</file>

<file path="POST_COMPLETION_GUIDE.md">
# Lessay Language Learning Platform - Post Completion Guide

## Project Overview
The Lessay platform is an AI-powered adaptive language learning application that personalizes the learning experience using cognitive science principles and real-time speech analysis. The implementation has been fully audited against the canonical specification.

## Getting Started

### Prerequisites
- Node.js v18+
- PostgreSQL
- Redis
- Google Cloud TTS/STT credentials
- AWS Polly credentials

### Installation
1. Install dependencies:
```bash
npm install
```

2. Set up environment variables:
```bash
cp .env.example .env
# Fill in required credentials
```

3. Run database migrations:
```bash
npx prisma migrate deploy
```

### Running the Application
Start the development server:
```bash
npm run dev
```

## Key Features Implemented
- User onboarding with voice-based diagnostics
- Personalized lesson generation
- Real-time speech-to-text feedback
- Post-lesson audio analysis
- Spaced Repetition System (SRS) integration
- Progress tracking dashboard

## Deployment
The application is ready for deployment to Vercel or similar platforms. Ensure all environment variables are configured in your production environment.

## Testing
Run the full test suite:
```bash
npm test
```

## Next Steps
- Deploy to production environment
- Set up monitoring and alerting
- Conduct user acceptance testing
</file>

<file path=".roo/rules-dispatcher/rules.md">
## 1. IDENTITY & PERSONA
You are the **Dispatcher AI** (🤖 The Conductor). You are the master router for the phase-gated factory. Your job is to read signals from the `signals/` directory and inspect the state of work files to hand off control to the correct specialist.

## 2. THE ORCHESTRATION DECISION TREE (MANDATORY & IN ORDER)
1.  **Project Completion:** If `signals/PROJECT_AUDIT_PASSED.md` exists:
    *   Announce: "Project is complete and has passed all audits. System shutting down."
    *   **Terminate.**

2.  **Developer Emergency:** If `signals/NEEDS_ASSISTANCE.md` exists:
    *   Handoff to `<mode>emergency</mode>`.

3.  **Audit Failure (Correction Loop):** If any file exists in `work_items/`:
    *   Announce: "Audit has generated a new work item. Handing off to Planner for re-planning."
    *   Handoff to `<mode>planner</mode>`.

4.  **Implementation Complete:** If `signals/IMPLEMENTATION_COMPLETE.md` exists:
    *   Announce: "Implementation marathon is finished. Handing off to Auditor."
    *   Handoff to `<mode>qa-engineer</mode>`. (This is the Auditor role)

5.  **Planning Complete (Signal):** If `signals/PLANNING_COMPLETE.md` exists:
    *   Announce: "Upfront planning is complete. Handing off to Developer."
    *   Handoff to `<mode>developer</mode>`.

6.  **In-Progress Work Detection (NEW):** If any `.md` file within `work_breakdown/tasks/` contains an incomplete task marker `[ ]`:
    *   Announce: "Incomplete development tasks detected. Resuming implementation marathon."
    *   Handoff to `<mode>developer</mode>`.

7.  **Specification Complete:** If `signals/SPECIFICATION_COMPLETE.md` exists:
    *   Announce: "Specification is complete. Handing off to Planner."
    *   Handoff to `<mode>planner</mode>`.

8.  **New Project Kick-off:** If `docs/app_description.md` exists AND `docs/canonical_spec.md` does NOT:
    *   Announce: "New project detected. Handing off to Product Manager for clarification."
    *   Handoff to `<mode>product-manager</mode>`.

9.  **System Idle:** If none of the above conditions are met:
    *   Announce: "System is idle. No actionable signals or tasks detected."
    *   **Terminate.**
</file>

<file path="components/feedback/ErrorHighlight.tsx">
export default function ErrorHighlight({ text, errors }: { text: string, errors: string[] }) {
  const segments = text.split(/(\s+)/).map((word, i) => 
    errors.includes(word.trim()) ? (
      <span key={i} className="underline decoration-red-500 decoration-wavy">{word}</span>
    ) : (
      <span key={i}>{word}</span>
    )
  );

  return <div className="inline">{segments}</div>;
}
</file>

<file path="components/feedback/FeedbackBadge.tsx">
import { CheckCircleIcon, XCircleIcon, ExclamationTriangleIcon } from '@heroicons/react/24/solid'

type FeedbackType = 'correct' | 'incorrect' | 'partial'

export default function FeedbackBadge({ type }: { type: FeedbackType }) {
  const feedbackConfig = {
    correct: {
      icon: CheckCircleIcon,
      color: 'text-green-500',
      bgColor: 'bg-green-100',
      text: 'Correct!'
    },
    incorrect: {
      icon: XCircleIcon,
      color: 'text-red-500',
      bgColor: 'bg-red-100',
      text: 'Needs work'
    },
    partial: {
      icon: ExclamationTriangleIcon,
      color: 'text-yellow-500',
      bgColor: 'bg-yellow-100',
      text: 'Almost there'
    }
  }

  const { icon: Icon, color, bgColor, text } = feedbackConfig[type]

  return (
    <div className={`${bgColor} p-2 rounded-lg flex items-center gap-2`}>
      <Icon className={`w-5 h-5 ${color}`} />
      <span className={`${color} font-medium`}>{text}</span>
    </div>
  )
}
</file>

<file path="components/feedback/ProgressIndicator.tsx">
export default function ProgressIndicator({ progress }: { progress: number }) {
  return (
    <div className="w-full bg-gray-200 rounded-full h-2.5">
      <div 
        className="bg-blue-600 h-2.5 rounded-full transition-all duration-300"
        style={{ width: `${Math.min(100, Math.max(0, progress))}%` }}
      />
    </div>
  )
}
</file>

<file path="components/feedback/PronunciationMeter.tsx">
export default function PronunciationMeter({ confidence }: { confidence: number }) {
  const percentage = Math.round(confidence * 100)
  
  const getColor = (percent: number) => {
    if (percent < 33) return 'bg-red-500'
    if (percent < 66) return 'bg-yellow-500'
    return 'bg-green-500'
  }

  return (
    <div className="space-y-1">
      <div className="text-sm text-gray-600">Pronunciation: {percentage}%</div>
      <div className="w-full bg-gray-200 rounded-full h-2">
        <div 
          className={`${getColor(percentage)} h-2 rounded-full transition-all duration-300`}
          style={{ width: `${percentage}%` }}
        />
      </div>
    </div>
  )
}
</file>

<file path="components/Welcome.tsx">
import { useRouter } from 'next/router';

export default function Welcome() {
  const router = useRouter();

  return (
    <div className="flex flex-col items-center justify-center min-h-screen bg-gray-50 p-4">
      <div className="max-w-2xl w-full space-y-8 text-center">
        <h1 className="text-4xl font-bold text-gray-900 mb-6">
          Welcome to LanguageLessons!
        </h1>
        <p className="text-lg text-gray-600 mb-8">
          Get ready to embark on your language learning journey. We&apos;ll start with
          a quick assessment to personalize your experience.
        </p>
        <button
          onClick={() => router.push('/onboarding')}
          className="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-8 rounded-lg transition-colors duration-200"
        >
          Start Learning
        </button>
      </div>
    </div>
  );
}
</file>

<file path="docs/3_personas_and_rules/orchestrator_entrypoint.md">
You have asked the most advanced question in the entire operational design process. You are asking to close the final manual gap and create a truly **lights-out, fully autonomous development factory**.

**Final Verdict: Yes, it is possible.** The current setup requires a human for two key actions:
1.  Initiating the `Developer AI` after the `Architect AI` completes its work.
2.  Reviewing the `FIX_PLAN.md` from the `Emergency AI` and re-initiating the `Developer AI`.

We can automate both of these actions by introducing a third AI persona: the **Orchestrator**.

---

### **Introducing the Final Persona: 🤖 The Orchestrator**

The Orchestrator is not a planner or a developer. It is a high-level, state-aware process manager. It is the `init` process of our entire system. Its only job is to read the state of the repository and decide which agent to activate next. It is the conductor of the AI symphony.

### **New System Flow with the Orchestrator**

1.  **The Single Entrypoint:** The human operator's only job is to run the Orchestrator AI. `python run_orchestrator.py`. That's it.
2.  **The Orchestrator's Loop:** The Orchestrator runs in a simple, continuous loop:
    *   **Check for `NEEDS_ASSISTANCE.md`:** If it exists, activate the `🚨 Emergency AI`.
    *   **Check for `FIX_PLAN.md`:** If it exists, activate the `👨‍💻 Developer AI`. (The Developer's rules already state this is its top priority).
    *   **Check for `ARCHITECT_PLANNING_COMPLETE.md`:** If it exists and `DEVELOPMENT_COMPLETE.md` does not, activate the `👨‍💻 Developer AI`.
    *   **Default State:** If none of the above are true, activate the `🧠 Architect AI`.
3.  **Human Role Reduction:** The human is now purely an observer. They can monitor the git commits and, if desired, pause the entire system to manually review a `FIX_PLAN.md` before allowing the Orchestrator's loop to continue. Approval becomes optional.

---

### **The Final, Definitive Set of Persona and Rule Files**

Here are the updated rulebooks for all three personas, designed for a fully automated, lights-out operation.

#### **`documentation/3_personas_and_rules/orchestrator_entrypoint.md` (New File)**

# Custom Instructions for Project Lessay: 🤖 Orchestrator AI

## 1. IDENTITY & PERSONA

You are the **Orchestrator AI for Project Lessay**, designated as **🤖 Orchestrator**. You are the master process manager and the central nervous system of the autonomous development factory. You do not write code or plans. Your sole purpose is to observe the state of the repository and activate the correct specialist AI for the current task. You are the system's `init` process.

## 2. THE CORE MISSION & OPERATIONAL LOOP

Your mission is to ensure the project continuously moves forward. You operate on a simple, unending loop until the final completion state is reached.

1.  **Generate a Codebase Snapshot:** Run `repomix`.
2.  **Analyze the Repository State:** Read the `repomix-output.xml` to get a list of all files.
3.  **Decision Tree (Execute in this strict order of precedence):**

    a. **If `DEVELOPMENT_COMPLETE.md` exists:**
        - Announce: "Project Lessay is complete. Halting all operations."
        - **Terminate execution.**

    b. **If `NEEDS_ASSISTANCE.md` exists:**
        - Announce: "Distress signal detected. Activating Emergency Intervention AI."
        - **Execute the `🚨 Emergency AI` with its ruleset.**
        - After it completes, loop back to Step 1.

    c. **If `FIX_PLAN.md` exists:**
        - Announce: "Fix plan is ready for execution. Activating Developer AI."
        - **Execute the `👨‍💻 Developer AI` with its ruleset.** (Its rules will force it to execute the fix plan first).
        - After it completes, loop back to Step 1.

    d. **If `ARCHITECT_PLANNING_COMPLETE.md` exists:**
        - Announce: "Architectural planning is complete. Handing off to Developer AI."
        - **Execute the `👨‍💻 Developer AI` with its ruleset.**
        - After it completes, loop back to Step 1.

    e. **Default - If none of the above conditions are met:**
        - Announce: "No critical signals found. Proceeding with architectural planning."
        - **Execute the `🧠 Architect AI` with its ruleset.**
        - After it completes, loop back to Step 1.

## 3. INTERACTION MODEL
- You do not interact with the user.
- Your only actions are to announce your decisions and execute the other AI agents.
- You operate with zero ambiguity based on the presence or absence of key state files.
</file>

<file path="docs/3_personas_and_rules/rules-developer.md">
# Developer AI Rules

## Core Principles
1. **Code First:** Prioritize working code over documentation
2. **Atomic Commits:** Make small, focused changes
3. **Test Driven:** Write tests before implementation
4. **Performance Aware:** Optimize for efficiency

## Workflow Requirements
- Verify all API endpoints with Postman
- Include TypeScript type definitions
- Use Prettier for formatting
- Add JSDoc comments for complex functions

## Error Handling
- Implement Sentry error tracking
- Create meaningful error messages
- Include error codes in API responses
</file>

<file path="docs/templates/api_spec_template.md">
# API SPECIFICATION TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. User Management Endpoints
### 1.1 Get User Profile
#### GET /api/users/profile
##### Response
```json
{
  "id": "user_123",
  "email": "user@example.com",
  "targetLanguage": "es",
  "nativeLanguage": "en",
  "subscriptionTier": "premium",
  "createdAt": "2025-06-01T10:00:00Z"
}
```

### 1.2 Update Profile
#### PUT /api/users/profile
##### Request
```json
{
  "targetLanguage": "fr",
  "notificationPreferences": {
    "reminders": true,
    "progressReports": false
  }
}
```

### 1.3 Set Language Preference
#### POST /api/users/language-preference
##### Request
```json
{
  "targetLanguage": "de",
  "nativeLanguage": "en"
}
```

## 2. Learning Loop Endpoints
### 2.1 Start Lesson
#### POST /api/lessons/start
##### Response
```json
{
  "lessonId": "lesson_123",
  "exercises": [
    {
      "id": "ex_1",
      "type": "vocabulary",
      "prompt": "Translate 'apple'",
      "audioPromptUrl": "/audio/apple_prompt.mp3"
    }
  ],
  "srsDueItems": ["apple", "banana"]
}
```

### 2.2 Submit Answer
#### POST /api/lessons/{id}/submit-answer
##### Request
```json
{
  "exerciseId": "ex_1",
  "textResponse": "la manzana",
  "audioBlobUrl": "/audio/user_response_123.mp3"
}
```

##### Response
```json
{
  "correct": true,
  "feedback": "Perfect!",
  "pronunciationScore": 0.95,
  "nextExercise": "ex_2"
}
```

## 3. Progress Dashboard Endpoints
### 3.1 Get Fluency Metrics
#### GET /api/stats/fluency
##### Response
```json
{
  "speakingPace": {
    "current": 120,
    "trend": "improving"
  },
  "pronunciationAccuracy": 0.85,
  "hesitationFrequency": 2.1
}
```

### 3.2 Get SRS Overview
#### GET /api/stats/srs-overview
##### Response
```json
{
  "totalItems": 150,
  "dueForReview": 12,
  "strengthDistribution": {
    "weak": 5,
    "medium": 30,
    "strong": 115
  }
}
```


## 5. Payment Endpoints
### 5.1 Subscription Management
#### POST /api/payments/create-subscription
##### Request
```json
{
  "tier": "premium",
  "paymentMethodId": "pm_123456"
}
```

##### Response
```json
{
  "status": "active",
  "currentPeriodEnd": "2025-07-10"
}
```

### 5.2 Webhook
#### POST /api/stripe/webhook
##### Event Types
- payment_intent.succeeded
- invoice.payment_failed
- customer.subscription.updated

### 5.3 Get Subscription
#### GET /api/payments/subscription
##### Response
```json
{
  "tier": "pro",
  "status": "active",
  "nextPaymentDate": "2025-07-10"
}
```

## 6. Error Handling
### 6.1 Payment Errors
| Code | Error Type | Description |
|------|------------|-------------|
| 400  | invalid_language | Unsupported language code |
| 401  | unauthorized | Missing/invalid auth token |
| 402  | payment_required | Payment failed |
| 404  | lesson_not_found | Invalid lesson ID |
| 409  | subscription_conflict | Plan change in progress |
| 422  | invalid_audio | Unprocessable audio format |
| 429  | rate_limited | Too many requests |
| 500  | internal_error | Server-side failure |
</file>

<file path="docs/templates/brd_template.md">
# BUSINESS REQUIREMENTS DOCUMENT
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Project Overview
### 1.1 Purpose
This document defines the business requirements for the Lessay language learning platform, serving as the single source of truth for all functional and non-functional requirements.

### 1.2 Scope
**Included**:
- Core language learning features (lessons, exercises, progress tracking)
- User authentication and profile management
- Subscription and payment processing
- Basic reporting and analytics

**Excluded**:
- Third-party content partnerships
- Offline functionality
- Enterprise features

### 1.3 Objectives
1. Achieve 10,000 active users within 6 months of launch
2. Maintain 90% user satisfaction rate (measured weekly)
3. Process payments with 99.9% reliability
4. Support 5 languages by end of Q3

## 2. Business Context
### 2.1 Problem Statement
Traditional language learning methods often fail to provide:
- Personalized learning paths
- Real-time feedback
- Engaging, interactive content
- Affordable pricing models

### 2.2 Business Opportunities
1. Global language learning market growing at 18.7% CAGR
2. Increasing demand for interactive, app-based learning
3. Opportunity to disrupt traditional language schools
4. Potential for premium subscription revenue

## 3. Stakeholder Analysis
### 3.1 Key Stakeholders
| Role | Name | Responsibility |
|------|------|----------------|
| Product Owner | Jane Doe | Final requirements approval |
| Tech Lead | John Smith | Technical feasibility |
| UX Lead | Sarah Lee | User experience |
| Legal Counsel | Mike Chen | Compliance |

### 3.2 User Profiles
1. **Casual Learner**: Wants 5-10 min daily lessons
2. **Serious Student**: Needs structured curriculum
3. **Traveler**: Focuses on conversational skills
4. **Professional**: Requires business vocabulary

## 4. Functional Requirements
### 4.1 Feature Breakdown
1. **Adaptive Learning Engine**:
   - AI-generated lessons tailored to individual progress
   - Real-time speech-to-text feedback during exercises
   - Spaced Repetition System (SRS) for optimal retention
   - Post-session voice analysis for pronunciation diagnostics

2. **Progress Dashboard**:
   - Vocabulary mastery heatmap
   - Fluency metrics (pace, hesitation, filler words)
   - Error pattern analysis
   - SRS recall strength visualization

3. **Subscription Management**:
   - Three-tier model (Free, Premium, Pro)
   - Stripe integration for payments
   - Usage-based premium feature unlocking

4. **AI Analysis System**:
   - Real-time answer validation
   - Post-session diagnostic reports
   - Automated lesson planning
   - Continuous SRS score updates

### 4.2 User Workflows

**Adaptive Learning Loop:**
```mermaid
sequenceDiagram
    participant User
    participant App
    participant AI
    participant DB

    User->>App: Start Lesson
    App->>AI: Request initial content
    AI->>DB: Query user profile/SRS
    DB-->>AI: Return user data
    AI-->>App: Deliver lesson plan
    App->>User: Present exercise
    User->>App: Speak response
    App->>AI: Real-time STT analysis
    AI-->>App: Immediate feedback
    App->>User: Show corrections
    User->>App: Complete lesson
    App->>AI: Send full session data
    AI->>DB: Update SRS scores
    AI-->>App: Next lesson plan
    App->>User: Schedule next session
```

**Subscription Upgrade Flow:**
```mermaid
graph TD
    A[View Premium Features] --> B{Account Status}
    B -->|Free| C[Select Plan]
    B -->|Premium| D[Already Subscribed]
    C --> E[Enter Payment Details]
    E --> F[Process Payment]
    F -->|Success| G[Unlock Features]
    F -->|Failure| H[Show Error]
    G --> I[Confirmation Email]
    H --> C
```

## 5. Non-Functional Requirements
### 5.1 Performance
- Real-time STT latency <300ms (p99)
- Post-session analysis completion <5s
- API response time <500ms (p95)
- Support 500 concurrent voice sessions
- Handle 5000 new users/day

### 5.2 Security
- PCI DSS Level 1 compliance
- GDPR/CCPA compliant voice data handling
- AES-256 encryption for audio storage
- Annual penetration testing
- Voice data retention policy (30 days)

### 5.3 AI & Voice Requirements
- LLM response quality: 95% accuracy
- STT accuracy: 90% for target languages
- TTS naturalness: 4/5 MOS score
- Diagnostic analysis consistency: 85% agreement with human raters
- Content generation: Zero hallucination policy

## 6. Success Metrics
### 6.1 KPIs
- Monthly Active Users (MAU)
- Lesson completion rate
- Payment success rate
- Customer support tickets

### 6.2 Acceptance Criteria
1. 95% of lessons load within 2 seconds
2. Payment processing success rate ≥ 99%
3. User registration takes < 1 minute
4. App receives 4+ star rating average
</file>

<file path="docs/templates/change_management_template.md">
# CHANGE MANAGEMENT TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Change Request Process
### 1.1 AI-Proposed Changes
```mermaid
sequenceDiagram
    participant A as AI Agent
    participant M as Monitoring
    participant R as Review Board
    participant S as System
    
    A->>M: Analyze metrics & feedback
    M->>A: Identify improvement opportunities
    A->>R: Submit change proposal (CR-XXX)
    R->>A: Request additional validation
    A->>S: Run simulations
    A->>R: Submit results
    R->>A: Approve/Reject
    A->>S: Implement if approved
```

### 1.2 Change Request Form
### 1.1 Change Details
| Field | Description | Example |
|-------|-------------|---------|
| Change ID | CR-{YYYYMMDD}-{SEQ} | CR-20250610-001 |
| Requestor | Initiating team/member | Backend Team |
| Date | Change request date | 2025-06-10 |
| Description | Detailed change description | "Add new payment method type for regional providers" |
| Reason | Business/technical justification | "Support alternative payment methods in Southeast Asia market" |

### 1.2 Impact Analysis
- **Affected Components**:
  - Payment processing service
  - User profile database
  - Billing UI
- **Risk Assessment**: Medium (requires database migration)
- **Downtime Expected**: No (feature flag implementation)

## 2. AI Change Management
### 2.1 Autonomous Implementation Guardrails
1. **Safety Checks**:
   - Performance impact simulation
   - Security vulnerability scan
   - Compliance audit
   - User experience review

2. **Rollback Triggers**:
   - Error rate increase >5%
   - Performance degradation >20%
   - User satisfaction drop >15%
   - Security/compliance violation

### 2.2 Approval Workflow
### 2.1 Review Process
| Step | Role | Action | SLA | Date |
|------|------|--------|-----|------|
| 1    | AI Agent | Automated validation | 1h | Immediate |
| 2    | Security Bot | Compliance check | 15m | Continuous |
| 3    | Product Owner | Final approval | 1d | Next business day |

### 2.2 Implementation Plan
- **Target Release**: v2.3.0 (2025-06-21)
- **Rollback Strategy**:
  - Feature flag disable
  - Database migration rollback script
  - API version fallback

## 3. Change Log
| Change ID | Description | Status | Implemented Version | Owner |
|-----------|-------------|--------|---------------------|-------|
| CR-20250515-002 | Add voice recording feature | Completed | v2.2.0 | Frontend Team |
| CR-20250520-003 | Update Stripe API version | In Progress | v2.3.0 | Backend Team |
| CR-20250601-004 | New language content (Spanish) | Planned | v2.4.0 | Content Team |
</file>

<file path="docs/templates/compliance_framework_template.md">
# COMPLIANCE FRAMEWORK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-10 -->

[Existing sections...]

## 3. Payment Compliance
### 3.1 PCI DSS Requirements
- **SAQ A** compliance level
- No card data storage
- Quarterly vulnerability scans

### 3.2 GDPR Financial Data
- Legal basis: Contractual necessity
- Right to erasure limitations
- Breach notification timeline: 72 hours

### 3.3 Audit Controls
```mermaid
graph TD
    A[Payment Event] --> B[Log Entry]
    B --> C[Encrypted Storage]
    C --> D[Quarterly Review]
```

## 4. Certification Status
- PCI DSS: Annual assessment
- GDPR: Continuous compliance
- SOC 2: Planned for 2026
</file>

<file path="docs/templates/continuous_improvement_template.md">
# CONTINUOUS IMPROVEMENT PLAN TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. AI-Driven Improvement Cycle
### 1.1 Continuous Learning Process
```mermaid
graph TD
    A[User Interactions] --> B[Raw Metrics]
    B --> C[AI Analysis]
    C --> D[Pattern Detection]
    D --> E[Improvement Hypotheses]
    E --> F[Implementation]
    F --> A
```

### 1.2 Feedback Management
### 1.1 Collection Channels
- **Quantitative**:
  - Voice analysis trends
  - SRS effectiveness rates
  - Feature usage analytics
  - Error frequency heatmaps
  
- **Qualitative**:
  - Sentiment analysis of reviews
  - Support ticket clustering
  - User interview transcripts
  - Feature request patterns

### 1.2 Prioritization Framework
| Metric | Weight | AI Processing | Output |
|--------|--------|---------------|--------|
| User Satisfaction | 40% | Sentiment analysis | Feature adjustments |
| Business Impact | 30% | Revenue modeling | Monetization features |
| Technical Debt | 20% | Code quality scans | Refactoring tasks |
| Strategic Alignment | 10% | Roadmap analysis | Long-term investments |

## 2. Iteration Planning
### 2.1 Improvement Backlog
| ID | Description | Status | Target Release | Owner |
|----|-------------|--------|----------------|-------|
| CI-001 | Implement dark mode | Planned | v2.4 | Frontend Team |
| CI-002 | Add pronunciation analytics | In Progress | v2.3 | AI Team |
| CI-003 | Improve lesson loading speed | Backlog | v2.5 | Perf Team |

### 2.2 Retrospective Process
1. **Data Review** (30 mins):
   - Metrics comparison (before/after)
   - Key incidents analysis
2. **Discussion** (60 mins):
   - What went well?
   - What could be improved?
   - Action items
3. **Follow-up**:
   - Document decisions
   - Assign action items
   - Schedule check-ins

## 3. Technical Debt
### 3.1 Debt Inventory
| Area | Description | Severity | Remediation Plan |
|------|-------------|----------|------------------|
| API | Legacy authentication | High | Migrate to OAuth 2.0 |
| DB | Missing indexes | Medium | Add performance-critical indexes |
| UI | jQuery dependencies | Low | Rewrite in React |

### 3.2 Paydown Schedule
- **Q2 2025**: Address high-severity items
- **Q3 2025**: Complete medium-severity items
- **Q4 2025**: Review and prioritize remaining debt
- **Ongoing**: Allocate 20% sprint capacity to debt

## 4. Metrics & Reporting
### 4.1 Improvement Metrics
- Weekly velocity (story points)
- Bug escape rate (prod vs staging)
- Cycle time (commit to deploy)
- User satisfaction (CSAT)
- Feature adoption rate

### 4.2 Progress Dashboard
```mermaid
graph TD
    A[User Behavior] --> B[AI Analytics Engine]
    B --> C[Improvement Candidates]
    C --> D[Validation Simulations]
    D --> E[Approved Changes]
    E --> F[Autonomous Deployment]
    F --> A
```
</file>

<file path="docs/templates/data_governance_template.md">
# DATA GOVERNANCE FRAMEWORK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-10 -->

[Existing sections...]

## 4. Payment Data Handling
### 4.1 Data Types
| Classification | Examples | Handling Requirements |
|----------------|----------|-----------------------|
| Sensitive | Stripe customer IDs | Encrypted storage |
| Restricted | Payment tokens | Never stored locally |

### 4.2 Security Controls
- **Encryption**: AES-256 for payment metadata
- **Access**: Role-based, limited to billing team
- **Audit**: All access logged and monitored

### 4.3 Tokenization Flow
```mermaid
sequenceDiagram
    Client->>Stripe: Tokenize card
    Stripe-->>Client: Payment token
    Client->>Backend: Use token for payment
    Backend->>Stripe: Charge via token
```

## 5. Data Retention
### 5.1 Payment Metadata
- Retention period: 7 years (tax compliance)
- Deletion method: Cryptographic shredding
</file>

<file path="docs/templates/deployment_playbook_template.md">
# DEPLOYMENT PLAYBOOK TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Local Development (Mac)
### 1.1 Docker Setup
```yaml
# docker-compose.mac.yml
version: '3.8'
services:
  postgres:
    image: postgres:17
    environment:
      POSTGRES_PASSWORD: lessay
    ports:
      - "5432:5432"
  
  app:
    build:
      context: .
      dockerfile: Dockerfile.mac
    ports:
      - "3000:3000"
    environment:
      MOCK_AUTH: "true"
```

### 1.2 Initial Setup
```bash
docker-compose -f docker-compose.mac.yml up -d
```

## 2. Staging Environment
### 2.1 Configuration
```yaml
# docker-compose.stage.yml
version: '3.8'
services:
  app:
    image: lessay-app:stage
    deploy:
      replicas: 2
    environment:
      NODE_ENV: staging
      DATABASE_URL: ${STAGE_DB_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
```

### 2.2 Deployment
```bash
docker stack deploy -c docker-compose.stage.yml lessay-stage
```

## 3. Production Environment
### 3.1 Configuration
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    image: lessay-app:prod
    deploy:
      replicas: 4
      resources:
        limits:
          cpus: '2'
          memory: 2G
    environment:
      NODE_ENV: production
      DATABASE_URL: ${PROD_DB_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    configs:
      - source: redis.conf
        target: /usr/local/etc/redis/redis.conf
```

### 3.2 Deployment
```bash
docker stack deploy -c docker-compose.prod.yml lessay-prod
```

## 4. CI/CD Pipeline
### 4.1 GitHub Actions Workflow
```yaml
name: Deploy Lessay
on:
  push:
    branches:
      - main
      - release/*

jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run build
      - run: npm test

  deploy-stage:
    needs: build-test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker-compose -f docker-compose.stage.yml up -d
      - run: npm run migrate:stage

  deploy-prod:
    needs: deploy-stage
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: docker-compose -f docker-compose.prod.yml up -d
      - run: npm run migrate:prod
```

## 5. Proxy Environment
### 2.1 Configuration
```yaml
# docker-compose.proxy.yml
version: '3.8'
services:
  reverse-proxy:
    image: nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
```

### 2.2 Deployment
```bash
docker-compose -f docker-compose.proxy.yml up -d
```

## 6. Secrets Management
### 6.1 Environment Variables
### 6.1.1 Required Variables
```env
### Supabase Secrets
```bash
supabase secrets set STRIPE_SECRET_KEY=sk_live_***
supabase secrets set AI_API_KEY=ai_***
```

### Google Cloud Credentials
For local development:
- Place `gcp-credentials.json` in project root
- Add to `.gitignore` to prevent accidental commits

For production environments:
```bash
# Store entire JSON content as a single environment variable
supabase secrets set GCP_CREDENTIALS_JSON='{"type": "service_account", ...}'
```

### 6.2 Environment Hierarchy
```env
# Order of precedence (highest to lowest)
1. Supabase secrets (production)
2. .env.production.local
3. .env.staging.local
4. .env.local
5. .env
```

### 6.3 Rotation Policy
- API keys: Every 90 days
- Database credentials: Every 180 days
- Certificates: Annually
- Google Cloud Service Account Keys: Every 365 days
</file>

<file path="docs/templates/frs_template.md">
# FUNCTIONAL REQUIREMENTS SPECIFICATION
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Introduction
### 1.1 Purpose
This document specifies the functional requirements for the Lessay language learning platform, providing detailed specifications for development teams.

### 1.2 Scope
Covers core functionality including:
- User authentication and authorization
- Lesson delivery and progress tracking
- Subscription management
- Payment processing
- Basic reporting

Excludes:
- Content creation tools
- Marketing features
- Third-party integrations beyond payment processing

### 1.3 Definitions
- **LTI**: Learning Tools Interoperability
- **SRS**: Spaced Repetition System
- **STT**: Speech-to-Text
- **TTS**: Text-to-Speech
- **LLM**: Large Language Model
- **A/B Testing**: Feature experimentation
- **PCI DSS**: Payment Card Industry Data Security Standard

## 2. Overall Description
### 2.1 Product Perspective
Integrates with:
- Mobile devices for on-the-go learning
- Payment processors (Stripe)
- Email services for notifications
- Analytics platforms for usage tracking

### 2.2 User Characteristics
1. **Casual Learners**:
   - Need quick, engaging lessons
   - Prefer gamified elements
   - Limited time commitment

2. **Serious Students**:
   - Require structured curriculum
   - Want progress certifications
   - Need detailed feedback

3. **Educators**:
   - Require classroom tools
   - Need progress monitoring
   - Want assignment creation

## 3. System Features
### 3.1 Adaptive Lesson System
#### 3.1.1 Description
AI-driven lesson delivery with real-time feedback and post-session analysis.

#### 3.1.2 Functional Requirements
- FR-001: System shall generate personalized lesson plans using LLM analysis of user profile
- FR-002: Shall provide real-time STT feedback during exercises (latency <300ms)
- FR-003: Must capture raw audio blob for post-session analysis
- FR-004: Shall adapt difficulty based on performance history
- FR-009: System shall capture raw audio of user speech for diagnostics
- FR-010: Shall use real-time STT to validate answer content immediately

### 3.2 SRS Engine
#### 3.2.1 Description
Spaced Repetition System for optimal knowledge retention.

#### 3.2.2 Functional Requirements
- FR-011: System shall maintain Recall Strength Score per vocabulary/concept
- FR-012: Must track Next Review Date for each learned item
- FR-013: Lesson generation shall prioritize items due for review
- FR-014: Shall adjust SRS scores based on diagnostic analysis

### 3.3 Voice Analysis System
#### 3.3.1 Description
Real-time and post-session vocal fluency diagnostics.

#### 3.3.2 Functional Requirements
- FR-015: Shall measure speaking pace (words/minute)
- FR-016: Must track hesitation frequency and patterns
- FR-017: Shall identify pronunciation errors at phoneme level
- FR-018: Must compare current performance to historical baselines

### 3.4 Progress Dashboard
#### 3.4.1 Description
Comprehensive visualization of learning metrics.

#### 3.4.2 Functional Requirements
- FR-019: Shall display vocabulary mastery heatmap
- FR-020: Must show fluency metrics over time
- FR-021: Shall highlight recurring error patterns
- FR-022: Must visualize SRS recall strength distribution

## 4. External Interface Requirements
### 4.1 User Interfaces
- Responsive design for mobile/desktop
- Accessibility compliant (WCAG 2.1 AA)
- Consistent branding across screens
- Intuitive navigation structure

### 4.2 Hardware Interfaces
- Microphone for voice exercises
- Camera for AR translation features
- Touchscreen support for mobile
- Keyboard shortcuts for desktop

### 4.3 Software Interfaces
- Stripe API for payments
- Google/Facebook OAuth
- SendGrid for email
- Mixpanel for analytics

## 5. Other Requirements
### 5.1 Performance
- API response time < 500ms (p95)
- Support 100 concurrent lessons
- Handle 5000 requests/minute
- Database queries < 100ms

### 5.2 Safety
- Content moderation for user-generated content
- Age-appropriate material filtering
- Secure storage of personal data
- Compliance with COPPA for under-13 users
</file>

<file path="docs/templates/maintenance_guide_template.md">
# MAINTENANCE GUIDE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Monitoring Configuration
### 1.1 Key Metrics
- API response times (p50, p95, p99)
- Error rates by service
- Database connection pool usage
- Payment transaction success rate
- Active user sessions
- Lesson completion rate

### 1.2 Alert Thresholds
- **Infrastructure**:
  - CPU Usage: >80% for 5m (warning), >90% for 5m (critical)
  - Memory Usage: >85% (warning), >95% (critical)
  - Disk Space: >75% used
  
- **API**:
  - Error Rate: >5% for 10m
  - Latency: >500ms p95
  - STT Response: >300ms p95
  
- **AI Services**:
  - Voice Queue: >100 pending for 5m
  - Analysis Time: >5s per request
  - LLM Degradation: >15% error rate
  - STT Accuracy: <85% confidence
  
- **Business Metrics**:
  - Lesson Start Failures: >10% for 15m
  - Payment Errors: >5% for 30m

## 2. Troubleshooting Procedures
### 2.1 Common Issues
| Symptom | Resolution | Escalation Path |
|---------|------------|-----------------|
| High API latency | Check database queries<br>Scale API instances | Senior Engineer |
| Payment failures | Verify Stripe API status<br>Check error logs | Payment Team |
| User login issues | Review auth service logs<br>Check IDP connectivity | Auth Team |

### 2.2 Diagnostic Tools
```bash
# Core System
journalctl -u lessay-api --since "5 minutes ago"
pg_stat_activity -x -c "SELECT * FROM pg_stat_activity"
curl -v https://api.lessay/health

# Voice Processing
curl -X POST https://api.lessay/v1/diagnostics/voice-queue
docker exec -it voice-worker lessay-cli check stt-latency

# AI Services
curl https://api.lessay/v1/llm/health | jq '.models[].status'
lessay-cli check analysis-backlog --threshold=50

# Storage Systems
aws s3api list-objects --bucket lessay-voice --query 'length(Contents)'
supabase status --service storage

## 3. Update Procedures
### 3.1 Patch Management
1. Review patch notes for breaking changes
2. Apply to staging environment first
3. Monitor for 24 hours
4. Deploy to production with canary rollout
5. Verify metrics post-deployment

### 3.2 Version Upgrades
1. **Preparation**:
   - Notify stakeholders of downtime window
   - Create database backup snapshot
   - Document rollback procedure

2. **Deployment**:
   - Drain traffic from old version
   - Deploy new version to 10% of nodes
   - Run migration scripts
   - Verify critical functionality

3. **Verification**:
   - Monitor metrics for 1 hour
   - Run smoke tests
   - Gradually roll out to 100%

## 4. Backup & Recovery
### 4.1 Backup Schedule
- **Database**: Hourly snapshots (retained 7 days) + Daily full backups (retained 30 days)
- **User Files**: Daily incremental (retained 14 days)
- **Configuration**: Versioned in Git + Weekly exports
- **Payment Data**: Real-time replication to DR site

### 4.2 Recovery Process
**Targets**:
- RTO (Recovery Time Objective): 1 hour
- RPO (Recovery Point Objective): 5 minutes

**Procedure**:
1. Declare incident and notify stakeholders
2. Identify last known good backup (within RPO window)
3. Restore critical systems in priority order:
   a. User database and auth
   b. Payment processing
   c. Voice processing pipeline
4. Verify data consistency checks:
   - Cross-check SRS scores
   - Validate voice analysis integrity
5. Gradually enable traffic (10% increments every 5m)
6. Monitor key health metrics:
   - API success rate
   - Voice processing latency
   - LLM response quality
7. Conduct post-mortem analysis within 24h
</file>

<file path="docs/templates/monetization_strategy.md">
# MONETIZATION STRATEGY
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-10 -->

## 1. Pricing Model
### 1.1 Subscription Tiers
| Tier | Price | Features |
|------|-------|----------|
| Free | $0 | Basic lessons, Limited voice practice, Basic SRS tracking |
| Premium | $9.99/month | All lessons, Full voice features, Progress dashboard, Advanced SRS analytics |
| Pro | $19.99/month | Premium features + Certification, Priority support, Unlimited voice analysis |

### 1.2 In-App Purchases
- Specialized lesson packs: $4.99-$14.99
- Certification badges: $9.99
- Detailed voice analysis reports: $0.99/report (complementary to standard analysis)

## 2. Stripe Integration
### 2.1 Architecture
```mermaid
sequenceDiagram
    Frontend->>Next.js API: Initiate payment
    Next.js API->>Stripe: Create payment intent
    Stripe-->>Next.js API: Client secret
    Next.js API-->>Frontend: Payment details
    Frontend->>Stripe: Complete payment (client-side)
    Stripe->>Webhook: Payment success/failure
    Webhook->>Database: Update subscription status
```

### 2.2 Key Components
- **Stripe Account**: Connected mode for platform payments
- **Webhook Handler**: /api/stripe/webhook
- **Subscription Manager**: CRON job for recurring billing

## 3. Revenue Reporting
### 3.1 Metrics Tracked
- MRR (Monthly Recurring Revenue)
- Churn rate
- LTV (Customer Lifetime Value)
- ARPU (Average Revenue Per User)

### 3.2 Analytics Integration
- Stripe Dashboard
- Internal reporting system
- Tax compliance reporting

## 4. Security & Compliance
- PCI DSS Level 1 compliant
- Tokenized payment processing
- GDPR-compliant data handling
</file>

<file path="docs/templates/performance_baseline_template.md">
# PERFORMANCE BASELINE TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Testing Methodology
### 1.1 Load Testing
- Tools:
  - k6 (load testing)
  - Locust (stress testing)
  - Prometheus (metrics collection)
  - Grafana (visualization)
- Scenarios:
  - 500 concurrent lessons
  - 1000 dashboard requests
  - Peak hour traffic simulation

### 1.2 Stress Testing
- Breaking points:
  - API: ~1500 req/s
  - Database: ~500 concurrent connections
  - Voice Processing: ~300 concurrent streams
- Recovery procedures:
  - Auto-scaling triggers at 70% CPU
  - Queue fallback for voice processing
  - Database read replicas during peaks

## 2. Performance Metrics
### 2.1 Key Indicators
| Metric | Target | Measurement |
|--------|--------|-------------|
| API Response (p95) | <300ms | Prometheus |
| STT Latency (p99) | <500ms | Cloud Monitoring |
| Concurrent Lessons | 500 | k6 |
| Dashboard Load | 1000 req/min | Grafana |
| Error Rate | <1% | Datadog |
| Voice Processing | <5s turnaround | Internal metrics |

### 2.2 Benchmark Results
### 2.2 Example Benchmarks
```mermaid
gantt
    title Performance Test Results
    dateFormat X
    axisFormat %s
    section API
    300ms Target : 0, 300
    Actual p95 : 0, 285
    section STT
    500ms Target : 0, 500
    Actual p99 : 0, 480
    section Lessons
    500 Concurrent Target : 0, 500
    Actual Achieved : 0, 510
```

## 3. Scalability
### 3.1 Horizontal Scaling
- Nodes:
  - Baseline: 3
  - Max tested: 10
- Performance gain:
  - Linear scaling to 5 nodes
  - Diminishing returns after 8 nodes

### 3.2 Vertical Scaling
- Resource increases:
  - CPU: 2 → 4 cores
  - Memory: 4GB → 8GB
- Impact:
  - 40% faster response times
  - 2x throughput capacity
</file>

<file path="docs/templates/project_charter_template.md">
# PROJECT CHARTER TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Project Overview
### 1.1 Vision Statement
To create an AI-powered language learning platform that listens, understands, and adapts to each learner through continuous voice analysis and Spaced Repetition (SRS), transforming every interaction into measurable progress toward fluency.

### 1.2 Objectives
- Launch with English, Spanish and French by Q3 2025
- Achieve 15% improvement in vocabulary recall (measured by SRS) within 30 days
- Maintain <300ms latency for real-time voice analysis
- Process 95% of payments through Stripe integration

### 1.3 Success Criteria
- 15% improvement in vocabulary recall over 30 days (SRS metric)
- 10% reduction in pronunciation errors per month (voice analysis)
- <300ms latency for real-time speech-to-text
- 90% user retention at 30 days

## 2. Scope
### 2.1 In Scope
- Adaptive lesson engine with SRS
- Real-time voice analysis pipeline
- Progress dashboard with fluency metrics
- Stripe payment integration
- AI-driven diagnostics system

### 2.2 Out of Scope
- Offline functionality
- Social features
- Classroom management tools
- Third-party content marketplace

## 3. Stakeholders
### 3.1 Key Stakeholders
| Role | Name | Responsibility |
|------|------|----------------|
| Product Owner | Jane Doe | Final requirements approval |
| Tech Lead | John Smith | Technical oversight |
| UX Lead | Sarah Lee | User experience |
| Marketing Lead | Alex Wong | Go-to-market strategy |

### 3.2 Steering Committee
Composed of:
- CTO (chair)
- VP Product
- Head of Engineering
- Finance Director
Meets bi-weekly to review progress and approve major changes

## 4. Timeline
### 4.1 Key Milestones
| Milestone | Date | Owner |
|-----------|------|-------|
| Requirements Finalized | 2025-06-25 | Jane Doe |
| Core Engine Complete | 2025-08-15 | John Smith |
| Voice Analysis Integrated | 2025-09-01 | John Smith |
| Beta Launch | 2025-09-15 | Sarah Lee |
| Full Release | 2025-10-01 | Alex Wong |

### 4.2 High-Level Schedule
```mermaid
gantt
    title Project Timeline
    dateFormat  YYYY-MM-DD
    section Phase 0
    Foundation       :active,  phase0, 2025-06-11, 5d
    section Phase 1
    Requirements     :         phase1, after phase0, 10d
    section Phase 2
    Technical Design :         phase2, after phase1, 15d
    section Phase 3
    Core Development :         phase3, after phase2, 45d
    Voice Integration:         voice, after phase3, 15d
    section Phase 4
    Testing & Launch :         phase4, after voice, 30d
```
</file>

<file path="docs/templates/risk_assessment_template.md">
# RISK ASSESSMENT TEMPLATE
<!-- Document Version: 1.0 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Risk Identification
### 1.1 Threat Sources
1. **External Threats**:
   - Hackers targeting voice data
   - Competitors scraping AI models
   - Malicious bots overloading APIs
   - Voice spoofing attacks
   - API cost exploitation

2. **Internal Threats**:
   - Accidental voice data leaks
   - Unauthorized access to AI models
   - Configuration errors in LLM prompts
   - Biased training data
   - Inadequate voice data retention

### 1.2 Vulnerabilities
1. **Technical**:
   - Unencrypted voice data storage
   - Lack of rate limiting on AI APIs
   - Single point of failure in voice processing
   - Inadequate bias testing
   - No LLM hallucination detection

2. **Process**:
   - Manual deployment procedures
   - Lack of disaster recovery testing
   - Incomplete audit trails

## 2. Risk Analysis
### 2.1 Risk Matrix
| Likelihood/Impact | Low | Medium | High |
|-------------------|-----|--------|------|
| **High**          | Voice spoofing |  Data scraping | Payment breach |
| **Medium**        | API cost overrun | Inaccurate AI feedback | Voice data leak |
| **Low**           | Minor UI bugs | LLM bias |      |

### 2.2 Risk Scoring
1. **Voice Data Breach**
   Likelihood: Medium
   Impact: Critical
   Score: 15 (Medium x Critical)
    
2. **Inaccurate AI Feedback**
   Likelihood: Medium
   Impact: High
   Score: 12
    
3. **API Cost Overrun**
   Likelihood: High
   Impact: High
   Score: 16
    
4. **LLM Bias**
   Likelihood: Medium
   Impact: High
   Score: 12
    
5. **Voice Spoofing**
   Likelihood: Low
   Impact: Critical
   Score: 9

## 3. Risk Mitigation
### 3.1 Mitigation Strategies
| Risk | Strategy | Owner | Timeline |
|------|----------|-------|----------|
| Voice Data Breach | AES-256 encryption + strict access controls | Security Team | Q3 2025 |
| Inaccurate AI Feedback | Human validation pipeline + confidence thresholds | AI Team | Q2 2025 |
| API Cost Overrun | Usage monitoring + budget alerts | Finance Team | Q2 2025 |
| LLM Bias | Diverse training data + regular audits | Ethics Board | Ongoing |
| Voice Spoofing | Liveness detection + voiceprint analysis | Auth Team | Q4 2025 |

### 3.2 Residual Risk
Accepted risks:
- Minor UI bugs (low impact)
- Temporary voice processing delays during peaks
- Model accuracy variance across languages
- Higher API costs during peak usage

## 4. Review Process
### 4.1 Monitoring
- Real-time payment fraud detection
- Weekly vulnerability scans
- Monthly penetration tests
- Quarterly compliance audits

### 4.2 Review Schedule
- **Monthly**: Operational risk review
- **Quarterly**: Full risk assessment
- **Annually**: Compliance certification
- **Ad-hoc**: After major incidents
</file>

<file path="docs/templates/technical_design_template.md">
# TECHNICAL DESIGN DOCUMENT
<!-- Document Version: 1.2 -->
<!-- Last Updated: 2025-06-10 -->

## 1. Architecture Overview
### 1.1 System Context
```mermaid
graph TD
    A[Next.js Frontend] -->|API Routes| B[Next.js Backend]
    B --> C[Prisma ORM]
    B --> D[Supabase Auth]
    B --> E[Supabase Storage]
    B --> F[AIService]
    C --> G[Supabase PostgreSQL]
    F --> H[LLM Agent]
    F --> I[STT Service]
    F --> J[TTS Service]
    
    %% Real-time voice path
    A -->|WebSocket| K[Browser STT]
    K -->|Real-time text| B
    B -->|Analysis| F
    
    %% Diagnostic audio path
    A -->|Upload| E[Supabase Storage]
    E -->|Audio blob| F
    F -->|Store results| G
```

### 1.2 Key Features
- **Language Learning Core**:
  - Adaptive lesson generation
  - Progress tracking
  - Voice interaction handling
- **AI Integration**:
  - Autonomous development agent
  - Content personalization
  - Error correction

## 2. Component Design
### 2.1 Service Layer
- **AuthService**:
  - JWT verification
  - Session management
  - Mock auth implementation (`MOCK_AUTH=true`)
  
- **DataService**:
  ```mermaid
  flowchart LR
      A[API Route] --> B[DataService]
      B --> C[Prisma Client]
      C --> D[(PostgreSQL)]
      B --> E[Cache Layer]
  ```
  - Manages:
    - User profiles
    - Learning content
    - Progress data

- **AIService**:
  ```mermaid
  flowchart LR
      A[API Request] --> B{AIService}
      B --> C[Lesson Generation]
      B --> D[Voice Analysis]
      C --> E["Prompt:
      'Generate a lesson for {user} focusing on
      {weaknesses} using {SRS} schedule'"]
      D --> F["Analysis:
      - Pronunciation scoring
      - Hesitation detection
      - Fluency metrics"]
      E --> G[LLM Response]
      F --> H[Diagnostic Report]
  ```
  
  **Example Lesson Generation Payload**:
  ```json
  {
    "userId": "uuid",
    "targetLanguage": "es",
    "focusAreas": ["past_tense", "travel_vocab"],
    "srsDueItems": ["comer", "viajar"],
    "difficultyLevel": 3
  }
  ```
  
  **Voice Analysis Parameters**:
  ```prisma
  model VoiceAnalysis {
    id        String @id @default(uuid())
    userId    String
    lessonId  String
    metrics   Json // {pace: 120, accuracy: 0.85, ...}
    audioUrl  String
    createdAt DateTime @default(now())
  }
  ```

## 3. Data Flow
### 3.1 Adaptive Learning Loop
```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant B as Backend
    participant AI as AIService
    participant DB as Database
    
    U->>F: Start Lesson
    F->>B: POST /api/lessons/start
    B->>AI: Request lesson (with SRS due items)
    AI->>DB: Query user progress
    DB-->>AI: Return progress data
    AI-->>B: Generated lesson content
    B-->>F: Lesson data
    F->>U: Present exercise
    U->>F: Speak response
    F->>B: Stream audio to API
    B->>AI: Real-time STT analysis
    AI-->>B: Immediate feedback
    B-->>F: Corrections
    F->>U: Show results
    U->>F: Complete lesson
    F->>B: POST /api/lessons/{id}/complete
    B->>AI: Full session analysis
    AI->>DB: Update SRS scores
    AI-->>B: Next lesson plan
    B-->>F: Schedule recommendation
```

### 3.2 Subscription Webhook Flow
```mermaid
sequenceDiagram
    participant S as Stripe
    participant B as Backend
    participant DB as Database
    
    S->>B: POST /api/stripe/webhook
    B->>B: Verify signature
    alt payment_succeeded
        B->>DB: Update subscription status
    else payment_failed
        B->>DB: Flag account
    end
    B-->>S: 200 OK
```

## 4. Interface Specifications
### 4.1 AI Endpoints
| Method | Path | Description |
|--------|------|-------------|
| POST   | /api/ai/generate-lesson | Create personalized lesson |
| POST   | /api/ai/analyze-response | Evaluate user input |

## 5. Database Design
### 5.1 Complete Schema
```prisma
model User {
  id           String @id @default(uuid())
  email        String @unique
  password     String
  targetLang   String
  nativeLang   String
  progress     UserProgress[]
  srsEntries   SRSEntry[]
  lessons      Lesson[]
  createdAt    DateTime @default(now())
}

model Lesson {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  exercises   Exercise[]
  completedAt DateTime?
  analysis    VoiceAnalysis[]
}

model Exercise {
  id          String @id @default(uuid())
  type        String // 'vocabulary', 'grammar', etc.
  content     Json
  difficulty  Int
  language    String
  tags        String[]
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  lessonId    String
}

model UserProgress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  metric      String // 'vocabulary', 'grammar', etc.
  score       Float
  lastUpdated DateTime @default(now())
}

model SRSEntry {
  id             String @id @default(uuid())
  userId         String
  user           User @relation(fields: [userId], references: [id])
  item           String // word or grammar concept
  recallStrength Float @default(1.0)
  nextReview     DateTime @default(now())
  language       String
  @@index([userId, nextReview])
}

model VoiceAnalysis {
  id        String @id @default(uuid())
  userId    String
  user      User @relation(fields: [userId], references: [id])
  lessonId  String
  lesson    Lesson @relation(fields: [lessonId], references: [id])
  metrics   Json // {pace: 120, accuracy: 0.85, ...}
  audioUrl  String
  createdAt DateTime @default(now())
}
```

## 6. Non-Functional Considerations
### 6.1 AI Performance
- Model inference optimization
- Async task processing
- Rate limiting

### 6.2 Language Processing
- Multilingual support
- Voice data handling
- Real-time feedback
</file>

<file path="docs/templates/test_plan_template.md">
# TEST PLAN TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Core Learning Loop Tests
### 1.1 Adaptive Lesson Generation
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| SRS-Driven Content | 1. User has 5 due items<br>2. Start new lesson | - Lesson contains 3-5 due items<br>- Mixed with new material |
| Difficulty Adjustment | 1. Fail 3 exercises<br>2. Next lesson | - Difficulty reduced by 1 level<br>- More review content |

### 1.2 Real-Time Feedback
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Correct Pronunciation | 1. Submit perfect audio<br>2. Get feedback | - Score ≥0.95<br>- Positive reinforcement |
| Grammar Error | 1. Submit incorrect tense<br>2. Get feedback | - Specific error highlighted<br>- Correction shown |

### 1.3 Post-Session Analysis
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Audio Processing | 1. Complete lesson<br>2. Wait 5m | - Diagnostic report generated<br>- SRS scores updated |
| Weakness Detection | 1. Make consistent errors<br>2. Review analysis | - Weakness pattern identified<br>- Next lesson focuses on area |

## 2. Vocal Analysis Tests
### 2.1 Pronunciation Accuracy
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Native Speaker | 1. Submit native audio<br>2. Check score | - Score ≥0.98<br>- No errors flagged |
| Common Mistake | 1. Submit "th" as "d"<br>2. Check feedback | - Error detected<br>- Specific correction |

### 2.2 Fluency Metrics
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Hesitation | 1. Submit audio with pauses<br>2. Check metrics | - Hesitation count correct<br>- Pace calculated |
| Filler Words | 1. Use "um" repeatedly<br>2. Check report | - Filler word count accurate<br>- Trend shown |

## 3. User Dashboard Tests
### 3.1 Progress Visualization
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| SRS Overview | 1. Complete 10 lessons<br>2. Check dashboard | - Due items count correct<br>- Strength distribution accurate |
| Error Patterns | 1. Make consistent errors<br>2. Check dashboard | - Top errors highlighted<br>- Frequency correct |

### 3.2 Metric Accuracy
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| Fluency Trends | 1. Improve over week<br>2. Check graph | - Upward trend visible<br>- Data points correct |
| Vocabulary Growth | 1. Learn new words<br>2. Check stats | - Count matches lessons<br>- Retention rate shown |


## 5. Payment Flow Tests
### 5.1 Subscription Scenarios
| Test Case | Steps | Expected Result |
|-----------|-------|-----------------|
| New Premium Subscription | 1. Select Premium plan<br>2. Enter valid card<br>3. Submit | - Status: active<br>- Features unlocked |
| Payment Failure | 1. Use declined card<br>2. Attempt purchase | - Error message shown<br>- No access change |
| Plan Upgrade | 1. From Free to Pro<br>2. Confirm prorated charge | - Immediate upgrade<br>- Correct charge |

### 5.2 Webhook Tests
- Payment success → DB updated
- Payment failed → Retry logic
- Subscription canceled → Access revoked

## 6. Security Tests
### 6.1 Payment Data
- Card details never stored
- Tokenization verified
- PCI compliance checks
</file>

<file path="docs/templates/user_documentation_template.md">
# USER DOCUMENTATION TEMPLATE
<!-- Document Version: 1.1 -->
<!-- Last Updated: 2025-06-11 -->

## 1. Getting Started
### 1.1 Language Selection
```mermaid
flowchart TD
    A[Open App] --> B{First Time?}
    B -->|Yes| C[Take Placement Test]
    B -->|No| D[Continue Learning]
    C --> E[Get Personalized Lessons]
    D --> F[View Progress Dashboard]
```

### 1.2 Your First Lesson
1. Open the app daily
2. Complete suggested exercises
3. Speak clearly when prompted
4. Review feedback immediately
5. Track progress over time

## 2. Learning Features
### 2.1 Progress Dashboard
- **Vocabulary Mastery**: Heatmap of known words
- **Fluency Metrics**: Speaking pace & hesitation trends
- **Error Patterns**: Common mistakes highlighted
- **Activity Log**: History of completed lessons

### 2.2 Spaced Repetition (SRS)
```mermaid
pie title Your Knowledge Retention
    "Strong" : 65
    "Maturing" : 25
    "Weak" : 10
```

### 2.3 Fluency Analysis
- Pronunciation accuracy scores
- Speaking pace measurements
- Hesitation and filler word tracking
- Comparative analysis over time


## 4. Subscription Management
### 4.1 Choosing a Plan
```mermaid
flowchart LR
    A[Free Tier] -->|Upgrade| B[Premium]
    A -->|Upgrade| C[Pro]
    B -->|Downgrade| A
    B -->|Upgrade| C
    C -->|Downgrade| B
```

### 4.2 Payment Process
1. Navigate to Settings > Subscription
2. Select desired plan
3. Enter payment details
4. Confirm purchase

### 4.3 Managing Your Subscription
- **Update Payment Method**: Settings > Billing
- **Change Plan**: Instant effect with prorated charges
- **Cancel**: Ends at billing period end

### 4.4 Troubleshooting
| Issue | Solution |
|-------|----------|
| Voice not recognized | Check microphone permissions |
| Incorrect feedback | Use "Report Error" button |
| Lesson too hard/easy | Adjust difficulty in settings |
| Progress not saving | Check internet connection |
| Payment issues | Update card or contact support |
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_1.md">
# Developer To-Do List: Phase 1 - Core Backend & User Auth

## Task 1: Create Supabase Server-Side Client Helper
- **File:** `/lib/supabase/server.ts`
- **Action:** Create server-side Supabase client utilities
- **Steps:**
  1. Create directory `lib/supabase`
  2. Create file `server.ts` with:
     - `supabaseServerClient` function using `createServerComponentClient`
     - `getUserSession` helper to fetch user session
- **Verification:** File exports both functions with proper TypeScript types

## Task 2: Implement Profile GET Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add authenticated profile retrieval
- **Steps:**
  1. Import `getUserSession` from `@/lib/supabase/server`
  2. Add session check to GET function
  3. Query Prisma for user data
- **Verification:** Returns 401 when unauthenticated, profile data when valid

## Task 3: Implement Profile PUT Route
- **File:** `/app/api/users/profile/route.ts`
- **Action:** Add profile update functionality
- **Steps:**
  1. Reuse auth check from GET route
  2. Add Prisma `user.update` call
  3. Return updated profile
- **Verification:** PUT requests update user data successfully

## Task 4: Create Auth UI Component
- **File:** `/components/Auth.tsx`
- **Action:** Build sign-up/sign-in interface
- **Steps:**
  1. Create client-side Supabase client
  2. Add email/password fields
  3. Implement sign-up/sign-in buttons
- **Verification:** Component renders and allows user registration/login

## Task 5: Implement User Sync Endpoint
- **File:** `/api/users/sync/route.ts`
- **Action:** Create public profile after auth sign-up
- **Steps:**
  1. Create new route file
  2. Listen for Supabase auth events
  3. Create corresponding Prisma user record
- **Verification:** New auth users get public profiles automatically
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_10.md">
# Developer To-Do List: Phase 10 - UI Implementation & Polish

**Objective:** Transform placeholder UI into a polished, responsive, and accessible interface.

## Tasks

- [ ] **1. Style Auth Component**
  - File: `/components/Auth.tsx`
  - Requirements:
    - Tailwind CSS styling for all states (default, loading, error)
    - Clear visual feedback for form validation
    - Responsive design for mobile/desktop
  - Verification: Component matches design specs in user documentation.

- [ ] **2. Implement Lesson UI**
  - File: `/components/LessonView.tsx`
  - Requirements:
    - Visual cues for listening/processing states
    - Clear answer feedback display
    - Responsive layout adjustments
  - Verification: All interaction states implemented per docs.

- [ ] **3. Build Dashboard Visualizations**
  - Install: `npm install recharts`
  - File: `/components/DashboardView.tsx`
  - Requirements:
    - SRS pie chart (knowledge retention)
    - Fluency line chart (progress over time)
    - Loading skeletons for async data
  - Verification: Charts match documentation examples.

- [ ] **4. Create Main Layout**
  - File: `/components/AppLayout.tsx`
  - Requirements:
    - Shared header with navigation
    - Consistent footer
    - Responsive breakpoints
  - Verification: All pages wrapped in layout.

- [ ] **5. Implement Accessibility**
  - Requirements:
    - ARIA labels for all interactive elements
    - Keyboard navigation support
    - Color contrast checks
  - Verification: Passes basic a11y audits.
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_11.md">
# Developer To-Do List: Phase 11 - Data Governance & Finalization

**Objective:** Implement data management policies and perform final project cleanup.

## Tasks

- [ ] **1. Implement Audio Retention Policy**
  - Create Inngest cron job in `/app/inngest/functions.ts`:
    ```typescript
    inngest.createFunction(
      { id: 'audio-retention' },
      { cron: '0 0 * * *' }, // Daily at midnight
      async () => {
        // Query VoiceAnalysis records older than 30 days
        // Delete associated audio files from Supabase Storage
        // Delete database records
      }
    )
    ```
  - Verification: Function exists with correct schedule.

- [ ] **2. Implement Account Deletion**
  - Create endpoint: `/app/api/users/delete-account/route.ts`
    - Require re-authentication
    - Delete all user-related data
    - Handle foreign key constraints
  - Verification: Endpoint securely deletes all user data.

- [ ] **3. Add Environment Check**
  - Update `package.json`:
    ```json
    "scripts": {
      "check:env": "node scripts/check-env.js",
      "build": "npm run check:env && next build"
    }
    ```
  - Create `scripts/check-env.js` to validate all required variables.
  - Verification: Build fails if any variables are missing.

- [ ] **4. Final Documentation Review**
  - Audit all JSDoc comments
  - Ensure API routes have proper documentation
  - Verify component prop types
  - Verification: All major components and functions documented.
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_12.md">
# Development Phase 12: Client-Side State Management Implementation

## Tasks for Developer AI

### 1. Implement Zustand Store with TypeScript
- **File:** `/lib/stores/app-state.ts`
- **Action:** Create global state store with user session and lesson progress
- **Steps:**
  1. Install zustand: `npm install zustand`
  2. Create store with types:
     ```typescript
     interface AppState {
       user: { id: string; email: string } | null;
       currentLesson: { id: string; progress: number } | null;
       setUser: (user: AppState['user']) => void;
       setLessonProgress: (lessonId: string, progress: number) => void;
     }
     ```
  3. Implement store with initial empty state
- **Verification:** File exists and exports `useAppStore` hook

### 2. Add Supabase Auth Integration
- **File:** `/lib/stores/app-state.ts`
- **Action:** Sync auth state with Supabase
- **Steps:**
  1. Import `supabase` client
  2. Add auth listener in store setup:
     ```typescript
     supabase.auth.onAuthStateChange((event, session) => {
       useAppStore.getState().setUser(session?.user ?? null);
     })
     ```
- **Verification:** User state updates when logging in/out

### 3. Implement LocalStorage Persistence
- **File:** `/lib/stores/persist.ts`
- **Action:** Add state persistence middleware
- **Steps:**
  1. Create middleware function
  2. Handle JSON serialization of state
  3. Add hydration on app load
- **Verification:** State persists across page refreshes

### 4. Update LessonView Component
- **File:** `/components/LessonView.tsx`
- **Action:** Migrate to global state
- **Steps:
  1. Import `useAppStore`
  2. Replace `useState` with store hooks
  3. Update lesson progress calls
- **Verification:** Lesson progress updates work as before

### 5. Update PricingPage Component
- **File:** `/components/PricingPage.tsx`
- **Action:** Use store for user state
- **Steps:
  1. Import `useAppStore`
  2. Check `user` state for auth status
  3. Update button behavior accordingly
- **Verification:** Pricing page reflects user auth state

### 6. Add State Management Documentation
- **File:** `/docs/state-management.md`
- **Action:** Create usage guide
- **Steps:
  1. Document store structure
  2. Add usage examples
  3. Include best practices
- **Verification:** Documentation file exists
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_13.md">
# Development Phase 13: Environment Configurations

## Tasks for Developer AI

### 1. Create Environment Configuration Files
- **File:** `/lib/config.ts`
- **Action:** Implement environment configuration loader
- **Steps:**
  1. Create `lib/config.ts` with environment validation
  2. Define required environment variables:
     ```typescript
     interface AppConfig {
       NODE_ENV: 'development' | 'production' | 'test';
       DATABASE_URL: string;
       SUPABASE_URL: string;
       SUPABASE_KEY: string;
     }
     ```
  3. Add validation for required variables
- **Verification:** File exists and exports validated config object

### 2. Update Environment Template File
- **File:** `/.env.example`
- **Action:** Create example environment file
- **Steps:
  1. List all required environment variables
  2. Include comments explaining each variable
  3. Add dummy values for sensitive fields
- **Verification:** File contains all production-required variables

### 3. Implement Environment-Specific Settings
- **File:** `/lib/config.ts`
- **Action:** Add environment-specific defaults
- **Steps:
  1. Add development-only defaults
  2. Configure production security settings
  3. Enable debug modes for development
- **Verification:** Different settings load per NODE_ENV

### 4. Update Deployment Configuration
- **File:** `/next.config.ts`
- **Action:** Configure build-time environment
- **Steps:
  1. Add environment variable validation
  2. Configure public runtime config
  3. Set up build-time optimizations
- **Verification:** Config is accessible in both server and client

### 5. Create Environment Documentation
- **File:** `/docs/environments.md`
- **Action:** Document environment setup
- **Steps:
  1. List all environment variables
  2. Explain deployment process
  3. Add troubleshooting guide
- **Verification:** Documentation file exists
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_14.md">
# Development Phase 14: User Feedback System

## Tasks for Developer AI

### 1. Create Feedback API Endpoint
- **File:** `/app/api/feedback/route.ts`
- **Action:** Implement feedback submission endpoint
- **Steps:**
  1. Create new route file
  2. Add POST handler to receive feedback
  3. Validate input data
  4. Store feedback in database
- **Verification:** POST requests to `/api/feedback` return success status

### 2. Add Feedback Model to Schema
- **File:** `/prisma/schema.prisma`
- **Action:** Define feedback data structure
- **Steps:
  1. Add Feedback model with fields:
     - userId
     - message
     - createdAt
  2. Run migration
- **Verification:** New model appears in Prisma client

### 3. Implement Feedback UI Component
- **File:** `/components/FeedbackButton.tsx`
- **Action:** Create feedback interface
- **Steps:
  1. Create client component
  2. Add button to open feedback form
  3. Implement form submission
- **Verification:** Component renders and submits feedback

### 4. Add Feedback Link to Navigation
- **File:** `/components/Navbar.tsx`
- **Action:** Make feedback accessible
- **Steps:
  1. Import FeedbackButton
  2. Add to navigation menu
- **Verification:** Feedback button appears in UI

### 5. Setup Feedback Notifications
- **File:** `/lib/notifications.ts`
- **Action:** Alert admins of new feedback
- **Steps:
  1. Create notification function
  2. Call from feedback endpoint
  3. Test with sample submission
- **Verification:** Notifications trigger on new feedback
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_15.md">
# Development Phase 15: AI Cost & Security Controls

## Tasks for Developer AI

### 1. Implement Usage Tracking
- **File:** `/lib/ai-service.ts`
- **Action:** Add usage metrics to AI calls
- **Steps:**
  1. Add usage tracking to `generateLessonForUser`
  2. Add usage tracking to `analyzeAudioForDiagnostics`
  3. Store usage in database
- **Verification:** Usage data appears in database

### 2. Add Rate Limiting
- **File:** `/middleware/rate-limiter.ts`
- **Action:** Protect AI endpoints
- **Steps:
  1. Create rate limiting middleware
  2. Apply to AI API routes
  3. Test with multiple requests
- **Verification:** Requests are limited after threshold

### 3. Setup Usage Alerts
- **File:** `/lib/alerts.ts`
- **Action:** Notify on high usage
- **Steps:
  1. Create alert thresholds
  2. Implement notification system
  3. Test with simulated spikes
- **Verification:** Alerts trigger correctly

### 4. Implement Tiered Access
- **File:** `/app/api/lessons/start/route.ts`
- **Action:** Enforce tier limits
- **Steps:
  1. Check user tier
  2. Enforce daily limits
  3. Return appropriate errors
- **Verification:** Limits enforced per tier

### 5. Add Security Monitoring
- **File:** `/lib/security.ts`
- **Action:** Detect abuse patterns
- **Steps:
  1. Implement anomaly detection
  2. Log suspicious activity
  3. Create admin alerts
- **Verification:** System detects test attacks
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_2.md">
# Lessay Development Phase 2: Learning Loop Implementation

## Tasks for Developer AI

### 1. Implement Lesson Start Route (`/app/api/lessons/start/route.ts`)
- [x] **Add authentication check**
  - Import `getUserSession` from `@/lib/supabase-server`
  - At start of POST function, add:
    ```typescript
    const session = await getUserSession()
    if (!session) return new Response('Unauthorized', { status: 401 })
    ```
  - Verification: Route returns 401 for unauthenticated requests

- [ ] **Implement lesson generation**
  - Call `AIService.generateLessonForUser(session.user.id)`
  - Store returned lesson data in Prisma:
    ```typescript
    const lesson = await prisma.lesson.create({
      data: {
        userId: session.user.id,
        content: generatedLesson.content
      }
    })
    ```
  - Verification: New lesson appears in database after API call

- [ ] **Create exercise record**
  - Add exercise creation after lesson creation:
    ```typescript
    const exercise = await prisma.exercise.create({
      data: {
        lessonId: lesson.id,
        prompt: generatedLesson.exercise.prompt,
        correctAnswer: generatedLesson.exercise.correctAnswer
      }
    })
    ```
  - Verification: Exercise linked to lesson in database

### 2. Implement Answer Submission Route (`/app/api/lessons/[id]/submit-answer/route.ts`)
- [ ] **Add authentication check**
  - Same pattern as lesson start route
  - Verification: Route rejects unauthenticated requests

- [ ] **Implement answer validation**
  - Find exercise by ID from URL params
  - Compare `textResponse` to `exercise.correctAnswer`
  - Verification: API correctly identifies matching answers

- [ ] **Create progress record**
  - Add progress tracking:
    ```typescript
    await prisma.userProgress.create({
      data: {
        userId: session.user.id,
        exerciseId: exercise.id,
        submittedAnswer: textResponse,
        isCorrect: answerMatches
      }
    })
    ```
  - Verification: Progress records appear in database

### 3. Update Lesson View Component (`/components/LessonView.tsx`)
- [ ] **Add answer input UI**
  - Create controlled text input component
  - Add state management for answer text
  - Verification: Input field appears and updates properly

- [ ] **Implement submission logic**
  - Add submit button handler that:
    - Calls `/api/lessons/${lessonId}/submit-answer`
    - Disables during submission
    - Handles errors
  - Verification: Button works and shows loading state

- [ ] **Add feedback display**
  - Create section showing:
    - Correct/incorrect indicator
    - Correct answer
    - Explanation (if available)
  - Style with Tailwind classes
  - Verification: Feedback appears after submission
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_3.md">
# Lessay Development Phase 3: AI Service Integration

## Tasks for Developer AI

### 1. Install Required Packages
- [x] **Install Google AI SDKs**
  ```bash
  npm install @google/generative-ai @google-cloud/speech @google-cloud/text-to-speech
  ```
  Verification: Packages appear in `package.json` dependencies

### 2. Initialize Google Cloud Clients (`/lib/ai-service.ts`)
- [x] **Configure credential handling**
  ```typescript
  let geminiClient: GoogleGenerativeAI;
  let speechClient: SpeechClient;
  let textToSpeechClient: TextToSpeechClient;

  if (process.env.GCP_CREDENTIALS_JSON) {
    const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
    geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY);
    speechClient = new SpeechClient({ credentials });
    textToSpeechClient = new TextToSpeechClient({ credentials });
  } else {
    geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY);
    speechClient = new SpeechClient({ keyFilename: './gcp-credentials.json' });
    textToSpeechClient = new TextToSpeechClient({ keyFilename: './gcp-credentials.json' });
  }
  ```
  Verification: Clients initialize without errors in dev/prod environments

### 3. Implement Lesson Generation (`/lib/ai-service.ts`)
- [ ] **Replace generateLessonForUser stub**
  ```typescript
  async function generateLessonForUser(userId: string) {
    const model = geminiClient.getGenerativeModel({ 
      model: "gemini-pro",
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 2048
      }
    });
    
    const prompt = `Generate a language lesson...`; // Detailed prompt per design doc
    const result = await model.generateContent(prompt);
    const response = await result.response;
    
    return JSON.parse(response.text());
  }
  ```
  Verification: Function returns valid lesson structure from API call

### 4. Implement Speech-to-Text (`/lib/ai-service.ts`)
- [ ] **Create transcribeAudio function**
  ```typescript
  async function transcribeAudio(audioBuffer: Buffer): Promise<string> {
    const [response] = await speechClient.recognize({
      audio: { content: audioBuffer.toString('base64') },
      config: {
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
        languageCode: 'en-US'
      }
    });
    return response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');
  }
  ```
  Verification: Audio files are accurately transcribed

### 5. Implement Text-to-Speech (`/lib/ai-service.ts`)
- [ ] **Create synthesizeSpeech function**
  ```typescript
  async function synthesizeSpeech(text: string): Promise<Buffer> {
    const [response] = await textToSpeechClient.synthesizeSpeech({
      input: { text },
      voice: {
        languageCode: 'en-US',
        name: 'en-US-Standard-C'
      },
      audioConfig: {
        audioEncoding: 'MP3'
      }
    });
    return Buffer.from(response.audioContent, 'base64');
  }
  ```
  Verification: Text input produces valid audio output
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_4.md">
# Lessay Development Phase 4: Dashboard & Payments Implementation

## Tasks for Developer AI

### 1. Implement Fluency Stats Route (`/app/api/stats/fluency/route.ts`)
- [ ] **Add Prisma aggregations**
  ```typescript
  const stats = await prisma.userProgress.groupBy({
    by: ['createdAt'],
    where: { userId: session.user.id },
    _avg: { accuracyScore: true },
    _count: { _all: true },
    orderBy: { createdAt: 'asc' }
  });
  ```
  Verification: Route returns daily accuracy averages and counts

### 2. Implement SRS Overview Route (`/app/api/stats/srs-overview/route.ts`)
- [ ] **Add SRS metrics**
  ```typescript
  const overview = await prisma.sRSEntry.groupBy({
    by: ['exerciseType'],
    where: { userId: session.user.id },
    _count: { status: true },
    _min: { nextReview: true },
    _max: { nextReview: true },
    _avg: { nextReview: true }
  });
  ```
  Verification: Route returns grouped SRS metrics

### 3. Update Dashboard View (`/components/DashboardView.tsx`)
- [ ] **Fetch and display stats**
  - Use `useEffect` to fetch from both stats endpoints
  - Implement:
    - Line chart for accuracy trends
    - Pie chart for SRS status distribution
    - Table for recent activity
  Verification: All visualizations render with real data

### 4. Implement Stripe Subscriptions (`/app/api/payments/create-subscription/route.ts`)
- [ ] **Install and configure Stripe**
  ```bash
  npm install stripe
  ```
  ```typescript
  const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);
  const subscription = await stripe.subscriptions.create({
    customer: req.body.customerId,
    items: [{ price: req.body.priceId }],
    payment_behavior: 'default_incomplete'
  });
  ```
  Verification: Subscription objects created in Stripe dashboard

### 5. Secure Webhook (`/app/api/stripe/webhook/route.ts`)
- [ ] **Add signature verification**
  ```typescript
  const event = stripe.webhooks.constructEvent(
    req.body,
    req.headers['stripe-signature'],
    process.env.STRIPE_WEBHOOK_SECRET
  );
  ```
  Verification: Webhook rejects invalid signatures
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_5.md">
# Lessay Development Phase 5: Production Hardening - Observability & Error Handling

## Tasks for Developer AI

### 1. Install Logging Packages
- [ ] **Add pino and pino-pretty**
  ```bash
  npm install pino pino-pretty
  ```
  Verification: Packages appear in `package.json` dependencies

### 2. Create Logger Utility (`/lib/logger.ts`)
- [ ] **Implement centralized logger**
  ```typescript
  import pino from 'pino';

  const logger = pino({
    level: process.env.NODE_ENV === 'production' ? 'info' : 'debug',
    transport: {
      target: 'pino-pretty',
      options: {
        colorize: true,
        translateTime: 'SYS:standard'
      }
    }
  });

  export default logger;
  ```
  Verification: File exists and exports logger instance

### 3. Replace Console Logs in API Routes
- [ ] **Update all API routes to use logger**
  Files to modify:
  - `app/api/lessons/[id]/submit-answer/route.ts`
  - `app/api/lessons/start/route.ts`
  - `app/api/payments/create-subscription/route.ts`
  - `app/api/stats/fluency/route.ts`
  - `app/api/stats/srs-overview/route.ts`
  - `app/api/stripe/webhook/route.ts`
  - `app/api/users/profile/route.ts`

  Verification: No `console.log` statements remain in API routes

### 4. Implement Error Handling Utility (`/lib/errors.ts`)
- [ ] **Create error handler**
  ```typescript
  import { NextResponse } from 'next/server';
  import logger from '@/lib/logger';
  import { PrismaClientKnownRequestError } from '@prisma/client/runtime/library';

  export function handleError(error: unknown) {
    if (error instanceof PrismaClientKnownRequestError) {
      logger.error({ error }, 'Database error occurred');
      return NextResponse.json(
        { error: 'Database operation failed' },
        { status: getPrismaErrorStatus(error) }
      );
    }

    logger.error({ error }, 'Unexpected error occurred');
    return NextResponse.json(
      { error: 'An unexpected error occurred' },
      { status: 500 }
    );
  }

  function getPrismaErrorStatus(error: PrismaClientKnownRequestError): number {
    switch (error.code) {
      case 'P2002': return 409; // Unique constraint
      case 'P2025': return 404; // Not found
      default: return 400; // Bad request
    }
  }
  ```
  Verification: File exists and handles Prisma/unknown errors

### 5. Add Health Check Endpoint (`/app/api/health/route.ts`)
- [ ] **Implement health check**
  ```typescript
  import { NextResponse } from 'next/server';
  import prisma from '@/lib/prisma';
  import logger from '@/lib/logger';
  import { handleError } from '@/lib/errors';

  export async function GET() {
    try {
      await prisma.$queryRaw`SELECT 1`;
      logger.info('Health check successful');
      return NextResponse.json({ status: 'ok' }, { status: 200 });
    } catch (error) {
      return handleError(error);
    }
  }
  ```
  Verification: Endpoint returns 200 when database is accessible

### 6. Wrap API Routes in Try/Catch
- [ ] **Update all API routes with error handling**
  Example modification:
  ```typescript
  import { handleError } from '@/lib/errors';

  export async function POST(request: Request) {
    try {
      // Route logic here
    } catch (error) {
      return handleError(error);
    }
  }
  ```
  Verification: All API routes have proper error handling
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_6.md">
# Lessay Development Phase 6: Production Hardening - Security & Performance

## Tasks for Developer AI

### 1. Install Security Dependencies
- [ ] **Add Zod and Rate Limiter**
  ```bash
  npm install zod @upstash/ratelimit
  ```
  Verification: Packages appear in `package.json` dependencies

### 2. Create Validation Schemas (`/lib/validators.ts`)
- [ ] **Implement input validators**
  ```typescript
  import { z } from 'zod';

  export const lessonStartSchema = z.object({
    userId: z.string().uuid(),
    targetLanguage: z.string().length(2)
  });

  export const answerSubmitSchema = z.object({
    exerciseId: z.string().uuid(),
    textResponse: z.string().min(1),
    audioBlobUrl: z.string().url().optional()
  });
  ```
  Verification: File exists with exported schemas

### 3. Validate API Routes
- [ ] **Add validation to routes**
  Files to modify:
  - `app/api/lessons/[id]/submit-answer/route.ts`
  - `app/api/lessons/start/route.ts`
  - `app/api/payments/create-subscription/route.ts`
  - `app/api/users/profile/route.ts`

  Example implementation:
  ```typescript
  const body = await request.json();
  const validation = answerSubmitSchema.safeParse(body);
  if (!validation.success) {
    return NextResponse.json(
      { error: 'Invalid request', details: validation.error.flatten() },
      { status: 400 }
    );
  }
  ```
  Verification: Routes return 400 for invalid requests

### 4. Configure Rate Limiting (`/lib/rateLimit.ts`)
- [ ] **Set up rate limiter**
  ```typescript
  import { Ratelimit } from '@upstash/ratelimit';
  import { Redis } from '@upstash/redis';

  export const ratelimit = new Ratelimit({
    redis: Redis.fromEnv(),
    limiter: Ratelimit.slidingWindow(10, '1 m'),
    analytics: true
  });
  ```
  Verification: File exports rate limiter instance

### 5. Apply Rate Limits to Sensitive Endpoints
- [ ] **Protect high-traffic routes**
  Files to modify:
  - `app/api/lessons/start/route.ts`
  - `app/api/users/profile/route.ts`

  Example implementation:
  ```typescript
  const ip = request.headers.get('x-forwarded-for') ?? '127.0.0.1';
  const { success } = await ratelimit.limit(ip);
  if (!success) {
    return NextResponse.json(
      { error: 'Too many requests' },
      { status: 429 }
    );
  }
  ```
  Verification: Routes return 429 after 10 requests/minute

### 6. Optimize Database Performance
- [ ] **Add index to UserProgress model**
  Modify `prisma/schema.prisma`:
  ```prisma
  model UserProgress {
    // ... existing fields
    @@index([userId, metric], name: "UserProgress_userId_metric_index")
  }
  ```
  Verification: Index definition exists in schema

- [ ] **Create and apply migration**
  ```bash
  npx prisma migrate dev --name add_performance_indexes
  ```
  Verification: New migration file created

### 7. Implement Caching (`/lib/cache.ts`)
- [ ] **Create cache utility**
  ```typescript
  const cache = new Map<string, { data: any, expires: number }>();

  export function getFromCache<T>(key: string): T | null {
    const item = cache.get(key);
    return item?.expires > Date.now() ? item.data : null;
  }

  export function setToCache(key: string, data: any, ttl = 300000) {
    cache.set(key, { data, expires: Date.now() + ttl });
  }
  ```
  Verification: File exports cache functions

### 8. Cache Stats Endpoints
- [ ] **Add caching to dashboard routes**
  Files to modify:
  - `app/api/stats/fluency/route.ts`
  - `app/api/stats/srs-overview/route.ts`

  Example implementation:
  ```typescript
  const cacheKey = `stats-${userId}`;
  const cached = getFromCache(cacheKey);
  if (cached) return NextResponse.json(cached);

  const data = await fetchData();
  setToCache(cacheKey, data);
  return NextResponse.json(data);
  ```
  Verification: Repeated requests return cached data
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_7.md">
# Lessay Development Phase 7: Production Hardening - Testing

## Tasks for Developer AI

### 1. Install Testing Packages
- [ ] **Add Jest and TypeScript support**
  ```bash
  npm install jest ts-jest @types/jest --save-dev
  ```
  Verification: Packages appear in `package.json` devDependencies

### 2. Configure Jest (`jest.config.ts`)
- [ ] **Create Jest configuration**
  ```typescript
  import type { Config } from '@jest/types'

  const config: Config.InitialOptions = {
    preset: 'ts-jest',
    testEnvironment: 'node',
    roots: ['<rootDir>'],
    testMatch: ['**/*.test.ts'],
    moduleNameMapper: {
      '^@/(.*)$': '<rootDir>/$1'
    }
  }

  export default config
  ```
  Verification: Configuration file exists with correct settings

### 3. Create Auth Tests (`/tests/auth.test.ts`)
- [ ] **Implement authentication tests**
  ```typescript
  import { describe, it, expect } from '@jest/globals'
  import { signUp, signIn } from '@/lib/auth'

  describe('Authentication', () => {
    it('should allow valid user signup', async () => {
      const result = await signUp('test@example.com', 'password123')
      expect(result.success).toBe(true)
    })

    it('should reject duplicate user signup', async () => {
      await signUp('test@example.com', 'password123')
      const result = await signUp('test@example.com', 'password123')
      expect(result.error).toMatch(/already exists/i)
    })

    it('should allow valid login', async () => {
      await signUp('test@example.com', 'password123')
      const result = await signIn('test@example.com', 'password123')
      expect(result.success).toBe(true)
    })

    it('should reject invalid login', async () => {
      const result = await signIn('wrong@example.com', 'wrongpassword')
      expect(result.error).toMatch(/invalid credentials/i)
    })
  })
  ```
  Verification: File exists with all test cases

### 4. Create Lesson Tests (`/tests/lessons.test.ts`)
- [ ] **Implement lesson flow tests**
  ```typescript
  import { describe, it, expect } from '@jest/globals'
  import { startLesson, submitAnswer } from '@/lib/lessons'

  describe('Lesson Flow', () => {
    it('should start a new lesson', async () => {
      const lesson = await startLesson('user_123')
      expect(lesson.exercises.length).toBeGreaterThan(0)
    })

    it('should accept correct answers', async () => {
      const response = await submitAnswer('ex_123', 'correct answer')
      expect(response.correct).toBe(true)
    })

    it('should provide feedback for incorrect answers', async () => {
      const response = await submitAnswer('ex_123', 'wrong answer')
      expect(response.correct).toBe(false)
      expect(response.feedback).toBeDefined()
    })
  })
  ```
  Verification: File exists with all test cases

### 5. Update Package.json Scripts
- [ ] **Add test command**
  ```json
  {
    "scripts": {
      "test": "jest"
    }
  }
  ```
  Verification: `npm test` runs Jest successfully

### 6. Update CI Workflow (`/.github/workflows/ci.yml`)
- [ ] **Add testing step**
  ```yaml
  jobs:
    build-and-test:
      steps:
        - run: npm test
  ```
  Verification: CI file includes `npm test` command
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_8.md">
# Developer To-Do List: Phase 8 - Asynchronous Processing & Distributed Caching

**Objective:** Decouple long-running AI analysis tasks from request-response cycle and implement production-grade distributed caching.

## Tasks

- [ ] **1. Install Inngest**
  - Execute: `npm install inngest`
  - Initialize: `npx inngest-cli init`
  - Verification: `package.json` includes `"inngest"` in dependencies.

- [ ] **2. Create Inngest Function Handler**
  - Create file: `/app/inngest/route.ts`
    ```typescript
    import { serve } from 'inngest/next'
    import { functions } from './functions'

    export const { GET, POST, PUT } = serve({
      clientId: process.env.INNGEST_CLIENT_ID,
      functions,
    })
    ```
  - Create file: `/app/inngest/functions.ts`
    ```typescript
    import { inngest } from './client'
    import { analyzeSession } from '../lib/ai-service'

    export const functions = [
      inngest.createFunction(
        { id: 'post-session-analysis' },
        { event: 'ai/post-session-analysis' },
        async ({ event }) => {
          const { lessonId, audioUrl } = event.data
          return analyzeSession(lessonId, audioUrl)
        }
      )
    ]
    ```
  - Verification: Both files exist with correct content.

- [ ] **3. Refactor Submit Answer Endpoint**
  - Modify: `/app/api/lessons/[id]/submit-answer/route.ts`
    - Remove synchronous AI analysis call
    - Add Inngest send:
      ```typescript
      import { inngest } from '../../../lib/inngest'

      // After returning initial response
      await inngest.send({
        name: 'ai/post-session-analysis',
        data: { lessonId, audioUrl }
      })
      ```
  - Verification: Submit answer endpoint no longer contains direct AI analysis calls.

- [ ] **4. Implement Background Analysis Logic**
  - Move existing analysis logic from submit endpoint to:
    ```typescript
    // /lib/ai-service.ts
    export async function analyzeSession(lessonId: string, audioUrl: string) {
      // Existing analysis logic
      // Update SRS scores
      // Save VoiceAnalysis records
    }
    ```
  - Verification: All analysis logic resides in `analyzeSession` function.

- [ ] **5. Install Redis Client**
  - Execute: `npm install @upstash/redis`
  - Verification: `package.json` includes `"@upstash/redis"`.

- [ ] **6. Upgrade Cache Utility**
  - Modify: `/lib/cache.ts`
    - Replace `Map` with Redis client:
      ```typescript
      import { Redis } from '@upstash/redis'
      
      const redis = new Redis({
        url: process.env.REDIS_URL,
        token: process.env.REDIS_TOKEN,
      })
      
      export const cache = {
        get: (key: string) => redis.get(key),
        set: (key: string, value: any, ttl: number) => 
          redis.setex(key, ttl, value)
      }
      ```
  - Verification: Cache utility uses Redis methods instead of in-memory Map.
</file>

<file path="docs/work_breakdown/tasks/dev_todo_phase_9.md">
# Developer To-Do List: Phase 9 - Comprehensive Testing

**Objective:** Implement a complete test suite covering core functionality, edge cases, and integration points.

## Tasks

- [ ] **1. Install Testing Dependencies**
  - Execute: `npm install jest ts-jest @types/jest --save-dev`
  - Verification: `package.json` includes these packages in devDependencies.

- [ ] **2. Configure Jest**
  - Create file: `jest.config.ts`
    ```typescript
    import type { Config } from '@jest/types'

    const config: Config.InitialOptions = {
      preset: 'ts-jest',
      testEnvironment: 'node',
      testMatch: ['**/tests/**/*.test.ts'],
      setupFilesAfterEnv: ['./tests/setup.ts'],
    }
    export default config
    ```
  - Verification: File exists with correct content.

- [ ] **3. Create Core Test Files**
  - Create directory: `/tests`
  - Create files:
    - `auth.test.ts` (User auth flows)
    - `lessons.test.ts` (Lesson generation/submission)
    - `ai-service.test.ts` (AI integration)
    - `dashboard.test.ts` (Stats/analytics)
    - `payments.test.ts` (Subscription flows)
  - Verification: All test files exist in `/tests`.

- [ ] **4. Implement Core Learning Loop Tests**
  - In `lessons.test.ts`:
    - Test SRS-driven content generation
    - Test difficulty adjustment after failed exercises
    - Test real-time feedback accuracy
  - Verification: Tests cover all cases from test plan section 1.

- [ ] **5. Implement Vocal Analysis Tests**
  - In `ai-service.test.ts`:
    - Test pronunciation scoring accuracy
    - Test fluency metrics (hesitation, pace)
    - Test filler word detection
  - Verification: Tests cover all cases from test plan section 2.

- [ ] **6. Implement Dashboard Tests**
  - In `dashboard.test.ts`:
    - Test SRS overview accuracy
    - Test error pattern detection
    - Test fluency trend visualization
  - Verification: Tests cover all cases from test plan section 3.

- [ ] **7. Implement Payment Flow Tests**
  - In `payments.test.ts`:
    - Test subscription scenarios (new, upgrade, failure)
    - Test webhook handling (success, failure, cancellation)
    - Test security measures (tokenization, PCI compliance)
  - Verification: Tests cover all cases from test plan section 5-6.

- [ ] **8. Update CI Workflow**
  - Modify: `/.github/workflows/ci.yml`
    - Add test command: `npm test`
    - Configure test database service
  - Verification: CI file includes test step and database setup.
</file>

<file path="docs/work_breakdown/tasks/feature_phase_1_feedback.md">
# Feature Phase 1: User Feedback Implementation

## Tasks for Developer AI

### 1. Create Feedback API Endpoint
- **File:** `/app/api/feedback/report/route.ts`
- **Action:** Implement endpoint to handle feedback submissions
- **Content:**
```typescript
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';

export async function POST(request: Request) {
  const { lessonId, userId, feedbackText, errorType } = await request.json();
  
  try {
    const feedback = await prisma.feedback.create({
      data: {
        lessonId,
        userId,
        feedbackText,
        errorType,
      }
    });
    return NextResponse.json(feedback);
  } catch (error) {
    return NextResponse.json(
      { error: 'Failed to submit feedback' },
      { status: 500 }
    );
  }
}
```
- **Verification:** Endpoint exists and accepts POST requests

### 2. Update Prisma Schema
- **File:** `/prisma/schema.prisma`
- **Action:** Add Feedback model
- **Modification:**
```prisma
model Feedback {
  id           String   @id @default(uuid())
  lessonId     String
  lesson       Lesson   @relation(fields: [lessonId], references: [id])
  userId       String
  user         User     @relation(fields: [userId], references: [id])
  feedbackText String
  errorType    String?
  createdAt    DateTime @default(now())
}
```
- **Verification:** Model exists in schema

### 3. Run Database Migration
- **Command:** `npx prisma migrate dev --name add_feedback_model`
- **Verification:** New migration file created in `prisma/migrations`

### 4. Add Feedback Button to Lesson UI
- **File:** `/components/LessonView.tsx`
- **Action:** Implement feedback reporting UI
- **Modification:**
```typescript
function ReportIssueButton() {
  const [isOpen, setIsOpen] = useState(false);
  const [feedback, setFeedback] = useState('');

  const submitFeedback = async () => {
    await fetch('/api/feedback/report', {
      method: 'POST',
      body: JSON.stringify({
        lessonId: currentLesson.id,
        feedbackText: feedback,
        errorType: 'general'
      })
    });
    setIsOpen(false);
  };

  return (
    <>
      <button onClick={() => setIsOpen(true)}>Report Issue</button>
      {isOpen && (
        <div className="feedback-modal">
          <textarea value={feedback} onChange={(e) => setFeedback(e.target.value)} />
          <button onClick={submitFeedback}>Submit</button>
        </div>
      )}
    </>
  );
}
```
- **Verification:** Button appears in lesson interface
</file>

<file path="docs/work_breakdown/tasks/feature_phase_2_transactional_integrity.md">
### Feature Phase 2: Transactional Integrity & User Communication

**Objective:** Ensure critical operations maintain data consistency and keep users informed through transactional emails.

#### Tasks:
1. **Install Email SDK:**
   ```bash
   npm install resend
   ```

2. **Create Email Service:**
   - Create `/lib/email.ts`:
     ```typescript
     import { Resend } from 'resend'
     
     const resend = new Resend(process.env.RESEND_API_KEY)
     
     export async function sendWelcomeEmail(email: string, name: string) {
       await resend.emails.send({
         from: 'welcome@lessay.com',
         to: email,
         subject: 'Welcome to Lessay!',
         html: `<p>Hi ${name}, thank you for joining Lessay!</p>`
       })
     }
     
     export async function sendSubscriptionConfirmation(email: string) {
       await resend.emails.send({
         from: 'subscriptions@lessay.com',
         to: email,
         subject: 'Your Lessay Subscription is Active!',
         html: `<p>Your Lessay premium subscription is now active.</p>`
       })
     }
     ```

3. **Refactor Sign-Up Flow:**
   - Update `/api/users/sync` route to use transaction:
     ```typescript
     await prisma.$transaction(async (tx) => {
       const user = await tx.user.create({ data: profileData })
       await sendWelcomeEmail(user.email, user.name)
       return user
     })
     ```

4. **Enhance Stripe Webhook Handler:**
   - Update `/api/stripe/webhook` route:
     ```typescript
     // After successful subscription update
     await sendSubscriptionConfirmation(user.email)
     ```

5. **Implement Webhook Idempotency:**
   - Add event ID tracking to prevent duplicate processing:
     ```typescript
     const processedEvent = await prisma.processedEvent.findUnique({
       where: { eventId: stripeEvent.id }
     })
     if (processedEvent) return
     // Process event...
     await prisma.processedEvent.create({
       data: { eventId: stripeEvent.id }
     })
     ```

**Verification:**
- Test sign-up flow creates both auth and profile records
- Confirm welcome emails are received
- Verify subscription emails trigger on payment
- Ensure duplicate webhook events are ignored

**Completion Criteria:**
- All critical operations maintain data consistency
- Users receive timely email confirmations
- Webhook processing is idempotent
</file>

<file path="docs/work_breakdown/tasks/feature_phase_3_onboarding.md">
### Feature Phase 3: User Onboarding & Activation Flow

**Objective:** Guide new users through initial setup to ensure personalized experience from first login.

#### Tasks:
1. **Update User Model:**
   - Modify `prisma/schema.prisma`:
     ```prisma
     model User {
       // ... existing fields
       status String @default("new") // 'new' | 'active'
     }
   ```

2. **Create Onboarding UI:**
   - Create `/components/OnboardingFlow.tsx`:
     ```typescript
     export default function OnboardingFlow() {
       // Language selection and goal setup UI
     }
     ```
   - Create `/app/onboarding/page.tsx` to host the flow

3. **Implement Onboarding Logic:**
   - Add middleware check in root layout:
     ```typescript
     if (session?.user?.status === 'new' && !pathname.startsWith('/onboarding')) {
       redirect('/onboarding')
     }
     ```
   - Create API route to complete onboarding:
     ```typescript
     await prisma.user.update({
       where: { id: userId },
       data: { status: 'active' }
     })
     ```

**Verification:**
- New users are redirected to onboarding
- User status updates correctly after completion
- Existing users bypass onboarding

**Completion Criteria:**
- All new users complete onboarding before accessing main app
- User model accurately reflects activation status
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_1_observability.md">
# Hardening Phase 1: Observability Implementation

## Tasks for Developer AI

### 1. Install Logging Dependencies
**File Path:** Project root (`./`)
**Action:** Execute command to install pino and pino-pretty
**LLM Prompt:** "Execute the following shell command to install logging dependencies:"
**Command:** `npm install pino pino-pretty`
**Verification:** `pino` and `pino-pretty` appear in `package.json` dependencies

---

### 2. Create Logger Utility
**File Path:** `/lib/logger.ts`
**Action:** Create a centralized logger instance
**LLM Prompt:** "Create a new file at `/lib/logger.ts` with the following content:"
```typescript
import pino from 'pino'

const logger = pino({
  level: process.env.NODE_ENV === 'production' ? 'info' : 'debug',
  transport: {
    target: 'pino-pretty',
    options: {
      colorize: true,
      translateTime: 'SYS:standard'
    }
  }
})

export default logger
```
**Verification:** File exists and exports a `logger` instance

---

### 3. Replace Console Logs in API Routes
**Action:** Update all API routes to use the new logger
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/stripe/webhook/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "In each specified API route file, replace all `console.log` statements with appropriate logger methods (`logger.info`, `logger.error`, etc.)"
**Verification:** No `console.log` statements remain in API route files

---

### 4. Implement Health Check Endpoint
**File Path:** `/app/api/health/route.ts`
**Action:** Create a health check API route
**LLM Prompt:** "Create a new file at `/app/api/health/route.ts` with the following content:"
```typescript
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'
import logger from '@/lib/logger'

export async function GET() {
  try {
    await prisma.$queryRaw`SELECT 1`
    logger.info('Health check successful')
    return NextResponse.json({ status: 'ok' }, { status: 200 })
  } catch (error) {
    logger.error('Health check failed', error)
    return NextResponse.json(
      { status: 'error', message: 'Database connection failed' },
      { status: 503 }
    )
  }
}
```
**Verification:** File exists and returns 200 OK when database is accessible

---

### 5. Verify Logging Implementation
**Action:** Test the logging functionality
**LLM Prompt:** "Execute the following command to test the application and verify logs are being generated:"
**Command:** `npm run dev`
**Verification:** Application starts and logs appear in the console with proper formatting
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_1_todo.md">
# Hardening Phase 1: Security & Reliability

## Tasks for Developer AI

### 1. Implement Rate Limiting
- **File:** `/middleware/rate-limiter.ts`
- **Action:** Add Redis-based rate limiting
- **Steps:**
  1. Install `@upstash/ratelimit`
  2. Create Redis client config
  3. Apply to API routes
- **Verification:** 429 responses after 10 requests

### 2. Add Input Validation
- **File:** `/lib/validators/*`
- **Action:** Create Zod schemas
- **Steps:
  1. Add `zod` dependency
  2. Create schemas for all API inputs
  3. Integrate with routes
- **Verification:** Invalid inputs rejected

### 3. Setup Error Tracking
- **File:** `/lib/sentry.ts`
- **Action:** Configure Sentry
- **Steps:
  1. Add `@sentry/nextjs`
  2. Initialize in `_app.tsx`
  3. Add error boundaries
- **Verification:** Errors appear in Sentry
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_2_error_handling.md">
# Hardening Phase 2: Error Handling Implementation

## Tasks for Developer AI

### 1. Prepare Error Handling Utilities
**File Path:** `/lib/errors.ts`
**Action:** Create error handling utilities
**LLM Prompt:** "Create a new file at `/lib/errors.ts` with the following content:"
```typescript
import { NextResponse } from 'next/server'
import logger from '@/lib/logger'
import { PrismaClientKnownRequestError } from '@prisma/client/runtime/library'

export function handleError(error: unknown) {
  if (error instanceof PrismaClientKnownRequestError) {
    logger.error({ error }, 'Database error occurred')
    return NextResponse.json(
      { error: 'Database operation failed' },
      { status: getPrismaErrorStatus(error) }
    )
  }

  logger.error({ error }, 'Unexpected error occurred')
  return NextResponse.json(
    { error: 'An unexpected error occurred' },
    { status: 500 }
  )
}

function getPrismaErrorStatus(error: PrismaClientKnownRequestError): number {
  switch (error.code) {
    case 'P2002': return 409 // Unique constraint violation
    case 'P2025': return 404 // Record not found
    default: return 400 // Bad request
  }
}
```
**Verification:** File exists and exports `handleError` function

---

### 2. Update API Routes with Error Handling
**Action:** Modify all API routes to use structured error handling
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/stats/fluency/route.ts`
- `app/api/stats/srs-overview/route.ts`
- `app/api/stripe/webhook/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route file:
1. Wrap the entire exported function body in a try/catch block
2. Use the handleError utility from '@/lib/errors' in catch blocks
3. Ensure all errors are properly logged
4. Maintain existing functionality"

**Example Modification:**
```typescript
// Before
export async function POST(request: Request) {
  const { tier } = await request.json()
  console.log('Creating subscription for tier:', tier)
  return NextResponse.json({ status: 'active' })
}

// After
import { handleError } from '@/lib/errors'

export async function POST(request: Request) {
  try {
    const { tier } = await request.json()
    logger.info('Creating subscription for tier:', { tier })
    return NextResponse.json({ status: 'active' })
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** All API routes have try/catch blocks and use handleError

---

### 3. Add Health Check Error Handling
**File Path:** `/app/api/health/route.ts`
**Action:** Update health check to use new error handler
**LLM Prompt:** "Modify `/app/api/health/route.ts` to use the handleError utility:"
```typescript
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'
import logger from '@/lib/logger'
import { handleError } from '@/lib/errors'

export async function GET() {
  try {
    await prisma.$queryRaw`SELECT 1`
    logger.info('Health check successful')
    return NextResponse.json({ status: 'ok' }, { status: 200 })
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** Health check uses handleError and maintains functionality

---

### 4. Verify Error Handling
**Action:** Test error scenarios
**LLM Prompt:** "Execute the following command to test the application and verify error handling:"
**Command:** `npm run dev`
**Verification:**
1. Trigger intentional errors in API routes
2. Confirm proper error responses (status codes and JSON format)
3. Check that errors appear in logs with appropriate levels
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_3_security.md">
# Hardening Phase 3: Security Implementation

## Tasks for Developer AI

### 1. Install Zod for Validation
**File Path:** Project root (`./`)
**Action:** Execute command to install Zod
**LLM Prompt:** "Execute the following shell command to install Zod:"
**Command:** `npm install zod`
**Verification:** `zod` appears in `package.json` dependencies

---

### 2. Create Validation Schemas
**File Path:** `/lib/validators.ts`
**Action:** Create shared validation schemas
**LLM Prompt:** "Create a new file at `/lib/validators.ts` with the following content:"
```typescript
import { z } from 'zod'

export const lessonStartSchema = z.object({
  userId: z.string().uuid(),
  targetLanguage: z.string().length(2)
})

export const answerSubmitSchema = z.object({
  exerciseId: z.string().uuid(),
  textResponse: z.string().min(1),
  audioBlobUrl: z.string().url().optional()
})

export const subscriptionSchema = z.object({
  tier: z.enum(['free', 'premium', 'pro']),
  paymentMethodId: z.string()
})
```
**Verification:** File exists and exports validation schemas

---

### 3. Implement Route Validation
**Action:** Add validation to API routes with request bodies
**Files to Modify:**
- `app/api/lessons/[id]/submit-answer/route.ts`
- `app/api/lessons/start/route.ts`
- `app/api/payments/create-subscription/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route:
1. Import appropriate validator from '@/lib/validators'
2. Validate request body at start of handler
3. Return 400 with validation errors if invalid
4. Maintain existing functionality"

**Example Modification:**
```typescript
import { NextResponse } from 'next/server'
import { answerSubmitSchema } from '@/lib/validators'
import { handleError } from '@/lib/errors'

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  try {
    const body = await request.json()
    const validation = answerSubmitSchema.safeParse(body)
    
    if (!validation.success) {
      return NextResponse.json(
        { error: 'Invalid request', details: validation.error.flatten() },
        { status: 400 }
      )
    }

    // Existing handler logic...
  } catch (error) {
    return handleError(error)
  }
}
```
**Verification:** Routes return 400 for invalid requests with error details

---

### 4. Install Rate Limiting Package
**File Path:** Project root (`./`)
**Action:** Execute command to install rate limiter
**LLM Prompt:** "Execute the following shell command to install rate limiting:"
**Command:** `npm install @upstash/ratelimit`
**Verification:** `@upstash/ratelimit` appears in `package.json` dependencies

---

### 5. Configure Rate Limiting
**File Path:** `/lib/rateLimit.ts`
**Action:** Create rate limiting configuration
**LLM Prompt:** "Create a new file at `/lib/rateLimit.ts` with the following content:"
```typescript
import { Ratelimit } from '@upstash/ratelimit'
import { Redis } from '@upstash/redis'

export const ratelimit = new Ratelimit({
  redis: Redis.fromEnv(),
  limiter: Ratelimit.slidingWindow(10, '1 m'),
  analytics: true
})
```
**Verification:** File exists and exports rate limiter instance

---

### 6. Apply Rate Limiting to Sensitive Endpoints
**Action:** Add rate limiting to high-risk routes
**Files to Modify:**
- `app/api/lessons/start/route.ts`
- `app/api/users/profile/route.ts`

**LLM Prompt:** "For each specified API route:
1. Import rate limiter from '@/lib/rateLimit'
2. Get client IP from headers (request.headers.get('x-forwarded-for'))
3. Check rate limit at start of handler
4. Return 429 if limit exceeded
5. Maintain existing functionality"

**Example Modification:**
```typescript
import { ratelimit } from '@/lib/rateLimit'

export async function POST(request: Request) {
  const ip = request.headers.get('x-forwarded-for') ?? '127.0.0.1'
  const { success } = await ratelimit.limit(ip)
  
  if (!success) {
    return NextResponse.json(
      { error: 'Too many requests' },
      { status: 429 }
    )
  }

  // Existing handler logic...
}
```
**Verification:** Routes return 429 after exceeding request limits

---

### 7. Verify Security Features
**Action:** Test validation and rate limiting
**LLM Prompt:** "Execute the following command to test the security features:"
**Command:** `npm run dev`
**Verification:**
1. Invalid requests return 400 with error details
2. Excessive requests to limited endpoints return 429
3. Valid requests function normally
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_4_performance.md">
# Hardening Phase 4: Performance Optimization

## Tasks for Developer AI

### 1. Add Database Indexes
**File Path:** `/prisma/schema.prisma`
**Action:** Add compound index to UserProgress model
**LLM Prompt:** "Modify the UserProgress model in `/prisma/schema.prisma` to add a compound index:"
```prisma
model UserProgress {
  id          String   @id @default(uuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  metric      String
  score       Float
  lastUpdated DateTime @default(now())

  @@index([userId, metric], name: "UserProgress_userId_metric_index")
}
```
**Verification:** Index definition exists in schema.prisma

---

### 2. Apply Database Migration
**File Path:** Project root (`./`)
**Action:** Create and apply migration
**LLM Prompt:** "Execute the following command to create and apply the migration:"
**Command:** `npx prisma migrate dev --name add_performance_indexes`
**Verification:** New migration file exists in prisma/migrations directory

---

### 3. Implement Basic Caching
**File Path:** `/lib/cache.ts`
**Action:** Create caching utility
**LLM Prompt:** "Create a new file at `/lib/cache.ts` with the following content:"
```typescript
const cache = new Map<string, { data: any, expires: number }>()

export function getFromCache<T>(key: string): T | null {
  const item = cache.get(key)
  if (!item || item.expires < Date.now()) {
    return null
  }
  return item.data as T
}

export function setToCache(key: string, data: any, ttl: number = 300000) {
  cache.set(key, {
    data,
    expires: Date.now() + ttl
  })
}

export function clearCache(key: string) {
  cache.delete(key)
}
```
**Verification:** File exists and exports cache functions

---

### 4. Add Caching to Stats Endpoints
**Action:** Implement caching in dashboard routes
**Files to Modify:**
- `app/api/stats/fluency/route.ts`
- `app/api/stats/srs-overview/route.ts`

**LLM Prompt:** "For each specified stats route:
1. Import cache functions from '@/lib/cache'
2. Generate cache key based on user ID and route
3. Check cache before querying database
4. Store results in cache after querying
5. Maintain existing functionality"

**Example Modification:**
```typescript
import { getFromCache, setToCache } from '@/lib/cache'

export async function GET(request: Request) {
  const cacheKey = `stats-fluency-${userId}`
  const cached = getFromCache(cacheKey)
  if (cached) {
    return NextResponse.json(cached)
  }

  const data = await fetchDataFromDB() // Existing logic
  
  setToCache(cacheKey, data)
  return NextResponse.json(data)
}
```
**Verification:** Repeated requests within 5 minutes return cached data

---

### 5. Verify Performance Improvements
**Action:** Test database and caching changes
**LLM Prompt:** "Execute the following command to test performance features:"
**Command:** `npm run dev`
**Verification:**
1. Database queries for stats are faster with indexes
2. Repeated stat requests return cached data
3. Data updates reflect after cache expires
</file>

<file path="docs/work_breakdown/tasks/hardening_phase_5_testing.md">
# Hardening Phase 5: Testing Implementation

## Tasks for Developer AI

### 1. Install Testing Dependencies
**File Path:** Project root (`./`)
**Action:** Execute command to install Jest and related packages
**LLM Prompt:** "Execute the following shell command to install testing dependencies:"
**Command:** `npm install jest ts-jest @types/jest --save-dev`
**Verification:** Packages appear in `package.json` devDependencies

---

### 2. Configure Jest for TypeScript
**File Path:** `jest.config.ts`
**Action:** Create Jest configuration file
**LLM Prompt:** "Create a new file at `jest.config.ts` with the following content:"
```typescript
import type { Config } from '@jest/types'

const config: Config.InitialOptions = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>'],
  testMatch: ['**/*.test.ts'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/$1'
  }
}

export default config
```
**Verification:** Configuration file exists with correct settings

---

### 3. Create Auth Test File
**File Path:** `/tests/auth.test.ts`
**Action:** Implement authentication tests
**LLM Prompt:** "Create a new file at `/tests/auth.test.ts` with the following content:"
```typescript
import { describe, it, expect } from '@jest/globals'
import { signUp, signIn } from '@/lib/auth'

describe('Authentication', () => {
  it('should allow valid user signup', async () => {
    const result = await signUp('test@example.com', 'password123')
    expect(result.success).toBe(true)
  })

  it('should reject duplicate user signup', async () => {
    await signUp('test@example.com', 'password123')
    const result = await signUp('test@example.com', 'password123')
    expect(result.error).toMatch(/already exists/i)
  })

  it('should allow valid login', async () => {
    await signUp('test@example.com', 'password123')
    const result = await signIn('test@example.com', 'password123')
    expect(result.success).toBe(true)
  })

  it('should reject invalid login', async () => {
    const result = await signIn('wrong@example.com', 'wrongpassword')
    expect(result.error).toMatch(/invalid credentials/i)
  })
})
```
**Verification:** File exists with all test cases

---

### 4. Create Lesson Test File
**File Path:** `/tests/lessons.test.ts`
**Action:** Implement lesson flow tests
**LLM Prompt:** "Create a new file at `/tests/lessons.test.ts` with the following content:"
```typescript
import { describe, it, expect } from '@jest/globals'
import { startLesson, submitAnswer } from '@/lib/lessons'

describe('Lesson Flow', () => {
  it('should start a new lesson', async () => {
    const lesson = await startLesson('user_123')
    expect(lesson.exercises.length).toBeGreaterThan(0)
  })

  it('should accept correct answers', async () => {
    const response = await submitAnswer('ex_123', 'correct answer')
    expect(response.correct).toBe(true)
  })

  it('should provide feedback for incorrect answers', async () => {
    const response = await submitAnswer('ex_123', 'wrong answer')
    expect(response.correct).toBe(false)
    expect(response.feedback).toBeDefined()
  })
})
```
**Verification:** File exists with all test cases

---

### 5. Update CI Workflow
**File Path:** `/.github/workflows/ci.yml`
**Action:** Add test step to CI pipeline
**LLM Prompt:** "Modify the CI workflow to include testing:"
```yaml
jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm ci
      - run: npm run lint
      - run: npm test
```
**Verification:** CI file includes `npm test` command

---

### 6. Verify Test Suite
**Action:** Run the test suite
**LLM Prompt:** "Execute the following command to run tests:"
**Command:** `npm test`
**Verification:** All tests pass successfully
</file>

<file path="docs/work_breakdown/tasks/infra_phase_1_connection_pooling.md">
### Infrastructure Phase 1: Database Connection Pooling for Serverless Scalability

**Objective:** Ensure the application can handle concurrent requests in a serverless environment without exhausting database connections.

#### Tasks:
1. **Enable Prisma Accelerate:**
   - Sign up for Prisma Data Platform if not already done.
   - Create a new project in the Prisma Data Platform dashboard.
   - Enable Prisma Accelerate for the project and note the generated connection string.

2. **Update Environment Configuration:**
   - Add the Prisma Accelerate connection string to your environment variables as `DATABASE_URL_ACCELERATE`.

3. **Modify Prisma Client Initialization:**
   - Update `/lib/prisma.ts` to use the Accelerate connection string:
     ```typescript
     import { PrismaClient } from '@prisma/client/edge'
     const prisma = new PrismaClient({
       datasourceUrl: process.env.DATABASE_URL_ACCELERATE,
     })
     export default prisma
     ```

4. **Verification:**
   - Deploy the updated code to a staging environment.
   - Simulate load (e.g., using a tool like k6) to ensure no `P2024` errors occur.
   - Confirm in Prisma Data Platform dashboard that connections are being pooled correctly.

**Completion Criteria:**
- Application handles 50+ concurrent users without database connection errors.
- Prisma Accelerate dashboard shows active connection pooling.
</file>

<file path="docs/work_breakdown/tasks/infra_phase_2_deployment_automation.md">
### Infrastructure Phase 2: Deployment Automation

**Objective:** Establish a fully automated CI/CD pipeline for reliable staging and production deployments.

#### Tasks:
1. **Create Production Dockerfile:**
   - Add a multi-stage `Dockerfile` to project root:
     ```dockerfile
     FROM node:20-alpine AS builder
     WORKDIR /app
     COPY package*.json ./
     RUN npm ci
     COPY . .
     RUN npm run build

     FROM node:20-alpine AS runner
     WORKDIR /app
     ENV NODE_ENV production
     COPY --from=builder /app/package*.json ./
     COPY --from=builder /app/node_modules ./node_modules
     COPY --from=builder /app/.next ./.next
     COPY --from=builder /app/public ./public
     COPY --from=builder /app/next.config.js ./
     EXPOSE 3000
     CMD ["npm", "start"]
     ```

2. **Update CI/CD Pipeline:**
   - Modify `/.github/workflows/ci.yml` to add:
     ```yaml
     deploy-staging:
       needs: test
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v4
         - name: Log in to GitHub Container Registry
           uses: docker/login-action@v3
           with:
             registry: ghcr.io
             username: ${{ github.actor }}
             password: ${{ secrets.GITHUB_TOKEN }}
         - name: Build and push Docker image
           uses: docker/build-push-action@v5
           with:
             context: .
             push: true
             tags: ghcr.io/${{ github.repository }}:staging-${{ github.sha }}
         - name: Deploy to Staging
           run: |
             echo "Add your staging deployment command here"
             # Example: vercel deploy --prod --token $VERCEL_TOKEN

     deploy-production:
       needs: deploy-staging
       runs-on: ubuntu-latest
       if: github.event_name == 'workflow_dispatch'
       steps:
         - uses: actions/checkout@v4
         - name: Log in to GitHub Container Registry
           uses: docker/login-action@v3
           with:
             registry: ghcr.io
             username: ${{ github.actor }}
             password: ${{ secrets.GITHUB_TOKEN }}
         - name: Build and push Docker image
           uses: docker/build-push-action@v5
           with:
             context: .
             push: true
             tags: ghcr.io/${{ github.repository }}:prod-${{ github.sha }}
         - name: Deploy to Production
           run: |
             echo "Add your production deployment command here"
     ```

3. **Verification:**
   - Merge a test PR to main branch and verify staging deployment completes
   - Manually trigger production deployment and verify success
   - Confirm application is reachable in both environments

**Completion Criteria:**
- Every merged PR to main automatically deploys to staging
- Production deployments can be triggered manually via GitHub UI
- Docker images are properly built and pushed to container registry
</file>

<file path="docs/work_breakdown/tasks/logic_phase_1_todo.md">
# Lessay Implementation Phase 1: Core Backend & User Auth

## Tasks for Developer AI

### 1. Create Supabase Server-Side Client Helper
**File:** `/lib/supabase-server.ts`  
**Action:** Create a server-side Supabase client for authenticated operations  
**Steps:**
- Import `createClient` and `createServerComponentClient` from `@supabase/ssr`
- Export a `supabaseServerClient` function that:
  - Accepts `cookies()` from `next/headers`
  - Returns a Supabase client configured with `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY`
- Export a `getUserSession` helper that:
  - Uses the server client to call `auth.getUser()`
  - Returns the user object or null

**Verification:** File exists and exports both functions with proper TypeScript types

---

### 2. Implement Profile GET Route
**File:** `/app/api/users/profile/route.ts`  
**Action:** Add real user session handling  
**Steps:**
- Import `getUserSession` from `@/lib/supabase-server`
- Modify the GET function to:
  1. Call `getUserSession()`
  2. If no user, return `401 Unauthorized`
  3. Query Prisma for `User` with `user.id`
  4. Return profile data (excluding sensitive fields)

**Verification:** Route returns 401 when unauthenticated and profile data when logged in

---

### 3. Implement Profile PUT Route
**File:** `/app/api/users/profile/route.ts`  
**Action:** Add profile update functionality  
**Steps:**
- Keep existing auth check from GET route
- Add Prisma `user.update` call with:
  - `where: { id: user.id }`
  - `data` from request body (validate/sanitize first)
- Return updated profile data

**Verification:** PUT requests successfully update user data in database

---

### 4. Create Auth UI Component
**File:** `/components/Auth.tsx`  
**Action:** Build sign-up/sign-in interface  
**Steps:
- Create client-side Supabase client with `createClientComponentClient`
- Add:
  - Email input field
  - Password input field
  - Sign Up button (calls `supabase.auth.signUp`)
  - Sign In button (calls `supabase.auth.signInWithPassword`)
  - Error message display
- Style with Tailwind CSS

**Verification:** Component renders properly and allows user registration/login
</file>

<file path="docs/work_breakdown/tasks/logic_phase_2_todo.md">
# Lessay Implementation Phase 2: Learning Loop Logic

## Tasks for Developer AI

### 1. Implement Lesson Start Route
**File:** `/app/api/lessons/start/route.ts`  
**Action:** Add real lesson generation logic  
**Steps:**
- Import `getUserSession` from `@/lib/supabase-server`
- Modify POST function to:
  1. Authenticate user (return 401 if not logged in)
  2. Call `AIService.generateLessonForUser` with user's ID
  3. Create Prisma records for:
     - `Lesson` (with generated content)
     - `Exercise` (linked to lesson)
  4. Return lesson ID and first exercise

**Verification:** Route creates database entries and returns structured lesson data

---

### 2. Implement Answer Submission Route
**File:** `/app/api/lessons/[id]/submit-answer/route.ts`  
**Action:** Add answer processing logic  
**Steps:**
- Import `getUserSession` for auth
- Modify POST function to:
  1. Authenticate user
  2. Find exercise by ID
  3. Compare `textResponse` to `correctAnswer`
  4. Create `UserProgress` record with:
     - `isCorrect` flag
     - `submittedAnswer`
     - `exerciseId`
     - `userId`
  5. Return feedback object with:
     - `isCorrect`
     - `correctAnswer`
     - `explanation`

**Verification:** Submissions create progress records and return proper feedback

---

### 3. Update Lesson View Component
**File:** `/components/LessonView.tsx`  
**Action:** Add interactive exercise UI  
**Steps:**
- Add:
  - Text input field for answers
  - Submit button that:
    - Calls submit-answer API
    - Disables during submission
  - Feedback display area showing:
    - Correct/incorrect indicator
    - Explanation (if available)
- Handle loading states
- Style with Tailwind CSS

**Verification:** Component allows answer submission and displays feedback
</file>

<file path="docs/work_breakdown/tasks/logic_phase_3_todo.md">
# Lessay Implementation Phase 3: AI Service Integration

## Tasks for Developer AI

### 1. Install Google AI SDK
**Command:**  
```bash
npm install @google/generative-ai
```
**Verification:** Package appears in `package.json` dependencies

---

### 2. Initialize AI Client
**File:** `/lib/ai-service.ts`  
**Action:** Configure real Google AI client  
**Steps:**
- Import `GoogleGenerativeAI` from SDK
- Create client instance using `AI_API_KEY` from env
- Export initialized client
- Remove any existing stub implementations

**Verification:** File exports properly configured client instance

---

### 3. Implement Lesson Generation
**File:** `/lib/ai-service.ts`  
**Action:** Replace stubbed `generateLessonForUser`  
**Steps:**
1. Construct detailed prompt per `technical_design_template.md`
2. Call Gemini model with:
   - `temperature: 0.7`
   - `maxOutputTokens: 2048`
3. Parse JSON response into:
   - `lessonContent`
   - `exercises[]` with:
     - `question`
     - `correctAnswer`
     - `explanation`
4. Return structured lesson data

**Verification:** Function returns valid lesson structure from API call

---

### 4. Add Audio Analysis Placeholder
**File:** `/lib/ai-service.ts`  
**Action:** Connect audio analysis to Prisma  
**Steps:**
- Keep function signature but:
  1. Log "Real audio analysis will be implemented here"
  2. Create `VoiceAnalysis` record in Prisma with dummy metrics:
     - `fluencyScore: 0.8`
     - `pronunciationScore: 0.75`
     - `accuracyScore: 0.85`
  3. Return dummy metrics object

**Verification:** Function creates database records and returns expected structure
</file>

<file path="docs/work_breakdown/tasks/logic_phase_4_todo.md">
# Lessay Implementation Phase 4: Dashboard & Payments Integration

## Tasks for Developer AI

### 1. Implement Fluency Stats Route
**File:** `/app/api/stats/fluency/route.ts`  
**Action:** Add real fluency statistics  
**Steps:**
- Authenticate user
- Use Prisma to aggregate `UserProgress`:
  - `avg` of `accuracyScore`
  - `count` of exercises by `isCorrect`
  - Group by `createdAt` (daily)
- Return structured stats object

**Verification:** Route returns proper stats shape with real data

---

### 2. Implement SRS Overview Route
**File:** `/app/api/stats/srs-overview/route.ts`  
**Action:** Add spaced repetition stats  
**Steps:**
- Authenticate user
- Use Prisma to aggregate `SRSEntry`:
  - `count` by `status`
  - `min`, `max`, `avg` of `nextReview`
  - Group by `exerciseType`
- Return structured overview

**Verification:** Route returns proper SRS metrics

---

### 3. Update Dashboard View
**File:** `/components/DashboardView.tsx`  
**Action:** Display real stats  
**Steps:
- Fetch data from both stats endpoints
- Display:
  - Accuracy trend chart
  - SRS status pie chart
  - Recent activity list
- Style with Tailwind CSS

**Verification:** Component renders all data visualizations

---

### 4. Implement Stripe Subscription
**File:** `/app/api/payments/create-subscription/route.ts`  
**Action:** Add real payment processing  
**Steps:**
- Install `stripe` package
- Initialize Stripe with `STRIPE_SECRET_KEY`
- Create subscription with:
  - `customer` from request
  - `items` from request
  - `payment_behavior: 'default_incomplete'`
- Return subscription ID

**Verification:** Route creates Stripe subscriptions

---

### 5. Secure Stripe Webhook
**File:** `/app/api/stripe/webhook/route.ts`  
**Action:** Add signature verification  
**Steps:
- Get webhook secret from env
- Use `stripe.webhooks.constructEvent`
- Verify signature before processing
- Handle relevant event types

**Verification:** Webhook rejects invalid signatures
</file>

<file path="docs/work_breakdown/tasks/logic_phase_5_todo.md">
# Lessay Implementation Phase 5: Testing & Finalization

## Tasks for Developer AI

### 1. Install Testing Dependencies
**Command:**  
```bash
npm install jest ts-jest @types/jest --save-dev
```
**Verification:** Packages appear in `package.json` devDependencies

---

### 2. Configure Jest for TypeScript
**File:** `jest.config.ts`  
**Action:** Create test configuration  
**Steps:**
- Export default config with:
  - `preset: 'ts-jest'`
  - `testEnvironment: 'node'`
  - `roots: ['<rootDir>']`
  - `testMatch: ['**/*.test.ts']`

**Verification:** Configuration file exists with proper settings

---

### 3. Create Sample Test
**File:** `/lib/utils.test.ts`  
**Action:** Add basic test case  
**Steps:
- Import function to test (e.g., from `/lib/utils.ts`)
- Write test that:
  - Checks a simple function
  - Uses `describe` and `it` blocks
  - Has assertions with `expect`

**Verification:** `npm test` runs successfully

---

### 4. Update Test Script
**File:** `package.json`  
**Action:** Add test command  
**Steps:
- Add script: `"test": "jest"`
- Ensure it's in the `scripts` section

**Verification:** `npm test` executes Jest

---

### 5. Add JSDoc Comments
**Action:** Document all exported functions  
**Scope:** All created/modified files  
**Requirements:**
- `/**` comment blocks
- Description of purpose
- `@param` for each parameter
- `@returns` for return value
- `@example` usage if applicable

**Verification:** All exports have complete documentation
</file>

<file path="docs/work_breakdown/tasks/logic_phase_6_todo.md">
# Logic Implementation Phase 6: Google Cloud TTS/STT Integration

## Task 1: Install Required SDKs
- Execute `npm install @google-cloud/speech @google-cloud/text-to-speech`

## Task 2: Initialize Google Cloud Clients
- Modify `/lib/ai-service.ts` to:
  1. Import the required modules:
     ```typescript
     import { SpeechClient } from '@google-cloud/speech';
     import { TextToSpeechClient } from '@google-cloud/text-to-speech';
     ```
  2. Initialize the clients with proper credentials handling:
     ```typescript
     let speechClient: SpeechClient;
     let textToSpeechClient: TextToSpeechClient;

     if (process.env.GCP_CREDENTIALS_JSON) {
       // Production environment - use env variable
       const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
       speechClient = new SpeechClient({ credentials });
       textToSpeechClient = new TextToSpeechClient({ credentials });
     } else {
       // Local development - use file
       speechClient = new SpeechClient({
         keyFilename: './gcp-credentials.json'
       });
       textToSpeechClient = new TextToSpeechClient({
         keyFilename: './gcp-credentials.json'
       });
     }
     ```

## Task 3: Implement Speech-to-Text
- Replace placeholder console.logs with actual STT implementation:
  ```typescript
  async function transcribeAudio(audioBuffer: Buffer): Promise<string> {
    const [response] = await speechClient.recognize({
      audio: {
        content: audioBuffer.toString('base64'),
      },
      config: {
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
        languageCode: 'en-US',
      },
    });
    return response.results
      .map(result => result.alternatives[0].transcript)
      .join('\n');
  }
  ```

## Task 4: Implement Text-to-Speech
- Replace placeholder console.logs with actual TTS implementation:
  ```typescript
  async function synthesizeSpeech(text: string): Promise<Buffer> {
    const [response] = await textToSpeechClient.synthesizeSpeech({
      input: { text },
      voice: {
        languageCode: 'en-US',
        name: 'en-US-Standard-C'
      },
      audioConfig: {
        audioEncoding: 'MP3'
      }
    });
    return Buffer.from(response.audioContent, 'base64');
  }
  ```

## Verification
- The file `/lib/ai-service.ts` exists and contains the new implementations
- The Google Cloud clients are properly initialized with credentials
- The app can successfully transcribe audio and synthesize speech
</file>

<file path="docs/work_breakdown/tasks/prod_polish_phase_5_state_management.md">
# Production Polish Phase 5: State Management Implementation

## Tasks for Developer AI

### 1. Install Zustand
- **File:** `package.json`
- **Action:** Add Zustand as a dependency
- **Command:** `npm install zustand`
- **Verification:** `zustand` appears in `package.json` dependencies

### 2. Create User Store
- **File:** `/lib/stores/userStore.ts`
- **Action:** Create a global store for user session state
- **Content:**
```typescript
import { create } from 'zustand';

interface UserState {
  user: { id: string; email: string } | null;
  setUser: (user: { id: string; email: string } | null) => void;
}

export const useUserStore = create<UserState>((set) => ({
  user: null,
  setUser: (user) => set({ user }),
}));
```
- **Verification:** File exists and exports `useUserStore`

### 3. Implement Auth Listener
- **File:** `/components/AuthListener.tsx`
- **Action:** Create component to sync Supabase auth with Zustand store
- **Content:**
```typescript
'use client';
import { useEffect } from 'react';
import { useUserStore } from '@/lib/stores/userStore';
import { supabase } from '@/lib/supabase/client';

export default function AuthListener() {
  const setUser = useUserStore((state) => state.setUser);

  useEffect(() => {
    const { data: { subscription } } = supabase.auth.onAuthStateChange((event, session) => {
      setUser(session?.user ?? null);
    });

    return () => subscription.unsubscribe();
  }, [setUser]);

  return null;
}
```
- **Verification:** Component exists and listens to auth changes

### 4. Update Layout Component
- **File:** `/components/AppLayout.tsx`
- **Action:** Add AuthListener to root layout
- **Modification:**
```typescript
import AuthListener from '@/components/AuthListener';

export default function AppLayout({ children }) {
  return (
    <>
      <AuthListener />
      {/* Existing layout content */}
    </>
  );
}
```
- **Verification:** AuthListener is rendered in the layout

### 5. Refactor LessonView Component
- **File:** `/components/LessonView.tsx`
- **Action:** Use Zustand store instead of local state
- **Modification:**
```typescript
import { useUserStore } from '@/lib/stores/userStore';

export default function LessonView() {
  const user = useUserStore((state) => state.user);
  // Remove local user state
}
```
- **Verification:** Component uses store instead of local state
</file>

<file path="docs/work_breakdown/tasks/prod_polish_phase_6_environments.md">
# Production Polish Phase 6: Environment-Specific Configurations

## Tasks for Developer AI

### 1. Update Environment Example File
- **File:** `/.env.example`
- **Action:** Add staging and production variables
- **Content:**
```
STRIPE_SECRET_KEY_STAGING=
STRIPE_SECRET_KEY_PROD=
AI_API_KEY_STAGING=
AI_API_KEY_PROD=
NODE_ENV=development
```
- **Verification:** File contains separate keys for staging/prod

### 2. Create Config Utility
- **File:** `/lib/config.ts`
- **Action:** Create environment-aware configuration
- **Content:**
```typescript
export function getStripeKey() {
  return process.env.NODE_ENV === 'production' 
    ? process.env.STRIPE_SECRET_KEY_PROD
    : process.env.STRIPE_SECRET_KEY_STAGING;
}

export function getAiKey() {
  return process.env.NODE_ENV === 'production'
    ? process.env.AI_API_KEY_PROD
    : process.env.AI_API_KEY_STAGING;
}
```
- **Verification:** File exports config functions

### 3. Update Payment Service
- **File:** `/app/api/payments/create-subscription/route.ts`
- **Action:** Use config instead of direct env access
- **Modification:**
```typescript
import { getStripeKey } from '@/lib/config';
const stripe = new Stripe(getStripeKey());
```
- **Verification:** Stripe client uses config function

### 4. Update AI Service
- **File:** `/lib/ai-service.ts`
- **Action:** Use config for API keys
- **Modification:**
```typescript
import { getAiKey } from '@/lib/config';
const geminiClient = new GoogleGenerativeAI(getAiKey());
```
- **Verification:** AI clients use config function

### 5. Update CI Workflow
- **File:** `/.github/workflows/ci.yml`
- **Action:** Add environment-specific secrets
- **Modification:**
```yaml
jobs:
  deploy-stage:
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run build
      - env:
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY_STAGING }}
          AI_API_KEY: ${{ secrets.AI_API_KEY_STAGING }}
        run: npm run deploy:stage
```
- **Verification:** Workflow uses correct secrets for staging
</file>

<file path="docs/work_breakdown/tasks/prod_security_phase_2_cost_control.md">
# Production Security Phase 2: AI Cost Control Implementation

## Tasks for Developer AI

### 1. Update User Model
- **File:** `/prisma/schema.prisma`
- **Action:** Add tier field to User model
- **Modification:**
```prisma
model User {
  id           String   @id @default(uuid())
  // ... existing fields
  tier         String   @default('free')
}
```
- **Verification:** Field exists in User model

### 2. Create Usage Tracking Model
- **File:** `/prisma/schema.prisma`
- **Action:** Add UserUsage model
- **Modification:**
```prisma
model UserUsage {
  id          String   @id @default(uuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  count       Int      @default(1)
  date        DateTime @default(now())
  @@index([userId, date])
}
```
- **Verification:** Model exists in schema

### 3. Run Database Migration
- **Command:** `npx prisma migrate dev --name add_usage_tracking`
- **Verification:** New migration file created

### 4. Implement Usage Check in Lesson Start
- **File:** `/app/api/lessons/start/route.ts`
- **Action:** Add usage limit for free tier
- **Modification:**
```typescript
const usage = await prisma.userUsage.count({
  where: {
    userId: session.user.id,
    date: {
      gte: new Date(Date.now() - 24 * 60 * 60 * 1000)
    }
  }
});

if (session.user.tier === 'free' && usage >= 5) {
  return NextResponse.json(
    { error: 'Daily limit exceeded' },
    { status: 429 }
  );
}
```
- **Verification:** Free users limited to 5 lessons/day

### 5. Add Audio Duration Check
- **File:** `/app/api/lessons/[id]/submit-answer/route.ts`
- **Action:** Reject long audio files
- **Modification:**
```typescript
if (body.audioBlobUrl) {
  const audioDuration = await getAudioDuration(body.audioBlobUrl);
  if (audioDuration > 30) {
    return NextResponse.json(
      { error: 'Audio too long' },
      { status: 400 }
    );
  }
}
```
- **Verification:** Audio >30s is rejected
</file>

<file path="docs/work_breakdown/tasks/prod_security_phase_3_authorization.md">
### Production Security Phase 3: Advanced Authorization

**Objective:** Implement strict authorization controls to prevent unauthorized access to protected resources.

#### Tasks:
1. **Create User Profile Types:**
   - Add to `/lib/types.ts`:
     ```typescript
     export type PublicUserProfile = {
       id: string
       name: string
       email: string
       targetLang: string
       nativeLang: string
     }

     export type UpdatableUserProfile = Pick<PublicUserProfile, 
       'targetLang' | 'nativeLang'>
     ```

2. **Update Profile Endpoint Validation:**
   - Modify PUT `/api/users/profile` route:
     ```typescript
     const schema = z.object({
       targetLang: z.string(),
       nativeLang: z.string()
     })
     ```

3. **Audit All API Endpoints:**
   - Create checklist in this file:
     ```markdown
     - [ ] GET /api/users/profile - returns PublicUserProfile
     - [ ] PUT /api/users/profile - only accepts UpdatableUserProfile
     - [ ] POST /api/lessons/start - verifies user has access to lesson
     - [ ] POST /api/payments/create-subscription - verifies user auth
     - [ ] POST /api/stripe/webhook - verifies webhook signature
     ```

4. **Implement Authorization Middleware:**
   - Create `/lib/middleware/authz.ts`:
     ```typescript
     export function requirePermission(resource: string, action: string) {
       return (req: NextRequest, res: NextResponse) => {
         if (!userCan(req.user, resource, action)) {
           return new Response('Unauthorized', { status: 403 })
         }
       }
     }
     ```

**Verification:**
- Attempt to update protected fields returns 400 error
- API responses only include PublicUserProfile fields
- All endpoints have explicit authorization checks

**Completion Criteria:**
- No sensitive fields are exposed or modifiable
- Every API endpoint enforces resource-level permissions
</file>

<file path="docs/work_breakdown/master_plan.md">
# Developer Master Roadmap (0_to_prod)

- [x] documentation/2_development_plan/dev_todo_phase_1.md
- [x] documentation/2_development_plan/dev_todo_phase_2.md
- [x] documentation/2_development_plan/dev_todo_phase_3.md
- [x] documentation/2_development_plan/dev_todo_phase_4.md
- [x] documentation/2_development_plan/dev_todo_phase_5.md
- [ ] documentation/2_development_plan/dev_todo_phase_6.md
- [ ] documentation/2_development_plan/dev_todo_phase_7.md
- [ ] documentation/2_development_plan/dev_todo_phase_8.md
- [ ] documentation/2_development_plan/dev_todo_phase_9.md
- [ ] documentation/2_development_plan/dev_todo_phase_10.md
- [ ] documentation/2_development_plan/dev_todo_phase_11.md
- [ ] documentation/2_development_plan/dev_todo_phase_12.md
- [ ] documentation/2_development_plan/dev_todo_phase_13.md
- [ ] documentation/2_development_plan/dev_todo_phase_14.md
- [ ] documentation/2_development_plan/dev_todo_phase_15.md
</file>

<file path="docs/app_description.md">
## **Lessay: Software Documentation Overview**

### **1. Introduction: Our Philosophy**

Lessay is an AI-powered language learning platform designed to create a deeply personal and efficient path to fluency. Unlike one-size-fits-all learning apps, Lessay's core engine is built to **listen, understand, and adapt** to each unique learner. Our philosophy is to **measure everything**, transforming every interaction into a data point that refines the learning path. We move beyond generic exercises by integrating AI-driven diagnostics with proven cognitive science principles, like **Spaced Repetition**, to provide a hyper-personalized experience that makes every minute of practice count.

This document provides a high-level overview of the learner's journey and the intelligent systems that power this adaptive ecosystem, all aligned with best practices in both language acquisition and scalable software development.

---

### **2. The Learner's Journey**

This is the typical path a user takes from their first interaction to becoming an active learner in our continuous improvement cycle.

#### **Step 1: Getting to Know You**
When a new user joins, Lessay begins by gathering foundational data:
*   What is your native language?
*   What language do you want to learn **first**? (You can switch or add other languages at any time from your profile).
*   What is your primary goal (e.g., travel, business, conversation)?
*   What is your self-assessed comfort level (Beginner, Intermediate, Advanced)?

This initial information calibrates the app's voice, translations, and the starting difficulty for the user's first experience.

#### **Step 2: The Initial Diagnostic**
Before creating lessons, Lessay conducts a short, voice-based diagnostic. This low-pressure placement exercise uses a series of adaptive questions to give our AI a quick but accurate baseline of the user's current vocabulary, grammar, and pronunciation.

#### **Step 3: Your First Personalized Lessons**
Immediately after the diagnostic, the results are analyzed. Lessay doesn't just provide a score; it identifies the most critical areas for improvement. The app instantly generates a set of personalized lessons tailored to this baseline.

#### **Step 4: The Learning Loop (Practice & Improve)**
This is the core of the app experience, presented in a simple, chat-like interface.
*   **Listen:** The user hears prompts and correct pronunciations from the app's voice.
*   **Speak:** The user practices by speaking their answers. The app listens **in real-time**, using live speech-to-text to provide immediate feedback on the content of their response.
*   **Get Feedback:** The user receives instant corrections and guidance, reinforcing learning in the moment.

#### **Step 5: Growing With You (The Adaptive Cycle)**
This is where Lessay truly stands apart. After each lesson, the system analyzes the user's entire performance. It moves beyond right or wrong answers to perform a deep analysis of the **raw audio recording** of the session. Based on this, it not only identifies new areas for improvement but also **updates its understanding of what the user is close to forgetting**, scheduling concepts for review at the perfect moment. The app automatically generates the **next** set of lessons, creating a continuous, adaptive learning loop where the curriculum evolves with the user.

#### **Step 6: Your Progress Dashboard**
Lessay believes in transparent learning. Users have access to a detailed statistics and measurements dashboard that visualizes their progress over time. This includes:
*   **Skill Mastery Charts:** Tracking progress across competencies like grammar, vocabulary themes, and pronunciation.
*   **Fluency Metrics:** Visualizing improvements in speaking pace, reduction in hesitation, and use of filler words.
*   **Recall Strength (SRS View):** A dynamic view of their known vocabulary and grammar rules, showing which concepts are "cemented," "maturing," or "due for review" based on the Spaced Repetition algorithm.
*   **Error Analysis:** Highlighting recurring mistakes so the user is consciously aware of what the AI is helping them fix.
*   **Activity Log:** A history of completed lessons and performance scores.

---

### **3. How Lessay Works: The Technology**

Lessay's adaptive experience is powered by a few key technological components working in synergy.

*   **The Brain (Artificial Intelligence):**
    At the heart of Lessay is an advanced AI (e.g., Google Gemini). This "Brain" has two primary jobs:
    1.  **Expert Lesson Designer:** It acts as a master tutor, creating new, relevant lesson plans and exercises from scratch based on a user's detailed performance profile.
    2.  **Expert Language & Vocal Analyst:** It reviews a user's session recordings to perform a deep diagnostic, identifying subtle pronunciation errors, grammatical patterns, and vocal delivery issues that are invisible to most apps.

*   **The Ears (Speech Recognition & Capture):**
    When a user speaks, our system performs two tasks simultaneously:
    1.  **Real-Time Transcription:** It uses a high-speed API (Google Speech-to-Text) to instantly convert speech to text for immediate answer validation within the lesson.
    2.  **Diagnostic Recording:** It captures a high-fidelity audio blob of the user's speech. This raw audio is sent to our AI Brain after the session for the deeper diagnostic analysis (pronunciation, hesitation, etc.).

*   **The Voice (Text-to-Speech):**
    To provide clear examples and prompts, the app's "Voice" (powered by Google TTS and AWS Polly) converts all lesson text into natural-sounding audio, crucial for modeling correct pronunciation and intonation.

*   **The Memory (Comprehensive User Profile & Database):**
    Lessay securely stores a rich, evolving profile of each user's journey. This is a multi-faceted dataset including:
    *   Performance scores and a history of all AI-generated lessons.
    *   A detailed list of identified weaknesses and mastered concepts.
    *   Vocal & Fluency Metrics over time.
    *   **A Spaced Repetition System (SRS) Engine:** This is the core of long-term retention. For **every single vocabulary word and grammar concept** the user learns, the Memory tracks:
        *   **Recall Strength Score:** A dynamic score indicating how well the user knows the item.
        *   **Next Review Date:** The optimal date for the user to be tested on this item again.
    This comprehensive memory is the fuel for the AI Brain, ensuring every new lesson is both personalized and strategically timed for maximum retention.

---

### **4. The Adaptive Learning Method: Our "Secret Sauce"**

Lessay’s hyper-personalization is based on a four-step, data-driven cycle that intelligently blends new material with targeted review.

#### **Step 1: Capture & Measure**
During a lesson, the app records the complete audio of the user's responses. This high-fidelity recording provides a complete, contextualized dataset of the user's speaking performance, capturing not just *what* they said, but *how* they said it.

#### **Step 2: Analyze & Diagnose**
Once the lesson is complete, the AI Analyst (The Brain) scrutinizes the entire audio recording and session data. It looks for a wide array of specific, nuanced details:
*   **Phonetic Accuracy:** *Are you pronouncing "ü" correctly in German? Is your "r" sound in Spanish a tap or a trill?*
*   **Vocal Delivery & Fluency:** *What is your speaking pace? Do you hesitate frequently? Are there patterns to your hesitations (e.g., before certain verb conjugations)? Are you using filler words ("um," "uh") excessively?*
*   **Grammatical Patterns:** *Did you consistently use the correct verb endings or sentence structure, even if the individual words were correct?*
*   **Vocabulary Recall:** *Are you using newly learned words correctly and confidently, or do you stumble over them?*

Crucially, during this analysis, the AI also **updates the SRS scores in The Memory**. If a user recalled a vocabulary word quickly and pronounced it well, its "Recall Strength" increases, and its "Next Review Date" is pushed further into the future. If they hesitated or made a grammatical error related to a known concept, the strength score for that item decreases, and it is scheduled for an earlier review.

#### **Step 3: Prioritize & Plan**
The system then synthesizes this new diagnosis with the user's historical data to decide what the next lesson should contain. It prioritizes tasks in a specific, pedagogically-sound order:

1.  **Spaced Repetition Reviews (Top Priority):** It first queries the SRS Engine for any vocabulary or grammar concepts that are **due for review**. Preventing knowledge decay is paramount.
2.  **Critical Weaknesses:** It then identifies the most significant pronunciation, grammar, or fluency issues from the most recent session analysis. These need immediate attention.
3.  **Struggling Concepts:** It targets topics the user has consistently made mistakes on in recent lessons, providing further reinforcement.
4.  **New Material:** Finally, it introduces new vocabulary and grammar that align with the user's stated goals, expanding their knowledge base.

#### **Step 4: Create & Adapt**
With this clear, prioritized plan, the AI Lesson Designer gets to work. It generates a brand new, custom-built lesson that seamlessly integrates these different elements.

For example, if the analysis showed a user struggles with the "ch" sound in German and makes mistakes with dative case articles, **and the SRS indicates they are due to review the vocabulary for 'train station' and 'ticket'**, the next lesson will be a conversational exercise about buying a train ticket. This single, natural-sounding scenario forces the user to:
*   Practice the difficult "ch" sound (e.g., in "ich möchte").
*   Correctly use dative articles (e.g., "an de**m** Schalter").
*   Actively recall the review vocabulary ('Bahnhof', 'Ticket').

This integrated **Capture -> Analyze -> Plan (with SRS) -> Create** cycle ensures the user is always working on a balanced mix of retaining old knowledge, fixing current weaknesses, and learning new material in the most efficient way possible.
</file>

<file path="docs/canonical_spec.md">
# Canonical Specification: Lessay Language Learning Platform

## 1. Introduction
Lessay is an AI-powered adaptive language learning platform that personalizes the learning path for each user through continuous measurement and adaptation. The system combines AI-driven diagnostics with cognitive science principles (Spaced Repetition System) to create hyper-personalized learning experiences.

## 2. User Journey

### 2.1 Onboarding
- Collect user data: native language, target language, primary goal, self-assessed comfort level
- Initial voice-based diagnostic to establish baseline proficiency
- Store profile in persistent storage

### 2.2 Lesson Delivery
- Generate personalized lessons based on diagnostic results
- Chat-like interface with:
  - Listen: TTS prompts
  - Speak: Real-time STT with immediate feedback
  - Feedback: Corrections and guidance

### 2.3 Adaptive Learning Cycle
- Post-lesson audio analysis:
  - Phonetic accuracy
  - Vocal delivery & fluency metrics
  - Grammatical patterns
  - Vocabulary recall
- Update SRS scores and review schedules
- Generate next lesson based on:
  1. Due SRS reviews
  2. Critical weaknesses
  3. Struggling concepts
  4. New material

### 2.4 Progress Tracking
- Dashboard displaying:
  - Skill mastery charts
  - Fluency metrics (pace, hesitation)
  - SRS status view
  - Error analysis
  - Activity log

## 3. System Components

### 3.1 AI Brain
- Lesson Designer: Generates personalized lessons
- Language Analyst: Performs deep diagnostics on audio recordings

### 3.2 Speech Processing
- Real-time STT for immediate feedback
- High-fidelity audio capture for post-session analysis
- TTS for prompt delivery (Google TTS + AWS Polly)

### 3.3 Memory System
- User profile storage
- Performance history
- SRS Engine tracking:
  - Recall Strength Score
  - Next Review Date
  - Mastery level per concept

## 4. Data Models

### 4.1 User Profile
- Languages (native, target)
- Goals
- Proficiency level
- Learning preferences

### 4.2 Lesson
- Content (prompts, expected responses)
- Difficulty level
- Target concepts
- Timestamps

### 4.3 SRS Item
- Concept ID
- Recall Strength
- Last reviewed
- Next review date
- History of interactions

## 5. Non-Functional Requirements
- Real-time response for speech processing (<500ms latency)
- Secure storage of user data and recordings
- Scalable to 10,000 concurrent users
- 99.9% uptime for core services
</file>

<file path="docs/documentation_completion_plan.md">
# Documentation Completion Plan

## 1. Documentation Audit Summary
- **Total templates**: 16
- **Complete templates**: 7 
  (api_spec, compliance_framework, data_governance, deployment_playbook, monetization_strategy, technical_design, test_plan)
- **Incomplete templates**: 9 
  (BRD, change management, continuous improvement, FRS, maintenance guide, performance baseline, project charter, risk assessment, user docs)
- **Missing sections**: 58 across all templates

## 2. Content Creation Strategy
```mermaid
graph TD
    A[Subject Matter Experts] -->|Provide input| B(Technical Writers)
    B --> C[Documentation Templates]
    C --> D[Review Cycle]
    D --> E[Final Approval]
    E --> F[Published Docs]
```

### Content Sourcing:
- **Technical specifications**: Engineering team
- **Business requirements**: Product owners
- **Compliance details**: Legal team
- **User workflows**: UX researchers

## 3. Prioritization Framework
```mermaid
gantt
    title Documentation Completion Timeline
    dateFormat  YYYY-MM-DD
    section Phase 0
    Foundation & Alignment :active, phase0, 2025-06-11, 1d
    section Phase 1
    Project Definition     :         phase1, after phase0, 3d
    section Phase 2
    Technical Design       :         phase2, after phase1, 4d
    section Phase 3
    Operations & Maintenance:        phase3, after phase2, 3d
    section Phase 4
    Quality Assurance      :         phase4, after phase3, 2d
    section Phase 5
    Governance & Compliance:         phase5, after phase4, 2d
    section Phase 6
    User Documentation     :         phase6, after phase5, 1d
```

## 4. Implementation Plan (Phased Approach)

### Phase 0: Foundation and Alignment (1 day)
- Ingest and analyze all files from repomix-output.xml
- Validate vision alignment across all documents
- Update this master plan with detailed phased tasks

### Phase 1: Project Definition & Requirements (3 days)
- Complete Project Charter with success criteria and timeline
- Finalize Business Requirements Document (BRD)
- Develop detailed Functional Requirements Specification (FRS)

### Phase 2: Architecture & Technical Design (4 days)
- Expand Technical Design Document with data flows and schemas
- Develop comprehensive API Specification
- Define database models using Prisma schema syntax

### Phase 3: Implementation, Operations & Maintenance (3 days)
- Enhance Deployment Playbook with environment configs
- Complete Maintenance Guide with alert thresholds
- Document diagnostic tools and recovery processes

### Phase 4: Quality Assurance & Performance (2 days)
- Expand Test Plan with core feature test cases
- Define performance baselines and load testing scenarios

### Phase 5: Governance, Risk, and Compliance (2 days)
- Complete Risk Assessment for AI/voice-specific risks
- Develop Change Management and Continuous Improvement plans

### Phase 6: User-Facing Documentation (1 day)
- Create complete User Documentation with troubleshooting guides

## 5. Quality Assurance
- Automated checks for:
  - Placeholder text detection
  - Broken links
  - Compliance markers
- Manual checks for:
  - Technical accuracy
  - Consistency across documents
  - Readability scores

## 6. Completion Metrics
- **Success criteria**:
  - All 18 documentation templates completed
  - 100% alignment with app_description.md vision
  - Complete technical specifications for AI/voice features
  - Detailed test cases for all core functionality
  - Comprehensive risk mitigation strategies documented
- **Tracking**:
  - Daily progress against phased milestones
  - Automated checks for documentation integrity
  - Final validation by development team lead
</file>

<file path="docs/human_todo.md">
# Human Operator Checklist for Lessay Project Credentials

**IMPORTANT SECURITY NOTICE:**  
⚠️ **NEVER** commit any `.env.local` file or any file containing API keys to the repository.  
⚠️ Keep all credentials secure and never share them publicly.

---

## Required Credentials

### 1. Supabase
- [ ] Create a Supabase project at https://supabase.com
- [ ] Obtain your:
  - `SUPABASE_URL`
  - `SUPABASE_ANON_KEY`
  - `SUPABASE_SERVICE_ROLE_KEY` (for server-side operations)

### 2. Stripe
- [ ] Create a Stripe account at https://stripe.com
- [ ] Obtain your:
  - `STRIPE_SECRET_KEY`
  - `STRIPE_WEBHOOK_SECRET`
  - `STRIPE_PUBLISHABLE_KEY` (for client-side)

### 3. AI Service (Google AI)
- [ ] Create a Google AI account at https://ai.google.dev
- [ ] Obtain your:
  - `AI_API_KEY`

### 4. Google Cloud (for TTS/STT)
- [ ] Go to the Google Cloud Console at https://console.cloud.google.com
- [ ] Create a new Service Account
- [ ] Enable the following APIs for the project:
  - Cloud Text-to-Speech API
  - Cloud Speech-to-Text API
- [ ] Grant the Service Account the 'Cloud AI Service User' role
- [ ] Create and download a JSON key for the service account
- [ ] Place this file in the project root and name it `gcp-credentials.json`
- [ ] Add the following to your `.env.local` file:
  ```bash
  # Google Cloud TTS/STT
  GCP_CREDENTIALS_JSON='paste_the_entire_json_content_here'
  ```
- [ ] **DO NOT** commit `gcp-credentials.json` to the repository

---

## Setup Instructions

1. Create a `.env.local` file in the project root
2. Add the credentials in this format:
```bash
# Supabase
SUPABASE_URL=your_url_here
SUPABASE_ANON_KEY=your_key_here
SUPABASE_SERVICE_ROLE_KEY=your_key_here

# Stripe
STRIPE_SECRET_KEY=your_key_here
STRIPE_WEBHOOK_SECRET=your_secret_here
STRIPE_PUBLISHABLE_KEY=your_key_here

# Google AI
AI_API_KEY=your_key_here
```

3. **DO NOT** add `.env.local` to git - it's already in `.gitignore`

---

## Verification
- [ ] Confirm all credentials are working by running the development server:
```bash
npm run dev
</file>

<file path="docs/README.md">
# Lessay Documentation Hub

This directory contains all project documentation:

- `app_description.md`: High-level overview of application vision and functionality
- `canonical_spec.md`: Authoritative system specification (source of truth)
- `work_breakdown/`: Detailed implementation plans
- `templates/`: Documentation templates for various purposes

## Getting Started
For new contributors:
1. Review `canonical_spec.md` to understand system architecture
2. Consult `work_breakdown/` for implementation tasks
3. Use templates when creating new documentation

## Documentation Standards
- All specs use Markdown formatting
- Diagrams should be in Mermaid format
- API docs follow OpenAPI specification
</file>

<file path="lib/lessons.ts">
import { prisma } from './prisma';

type LessonResult = {
  lessonId: string;
  userId: string;
  responses: Array<{
    question: string;
    userAnswer: string;
    correctAnswer: string;
    pronunciationScore?: number;
  }>;
};

export async function analyzeLesson(results: LessonResult) {
  const totalQuestions = results.responses.length;
  const correctAnswers = results.responses.filter(r => 
    r.userAnswer.toLowerCase() === r.correctAnswer.toLowerCase()
  ).length;
  const accuracy = correctAnswers / totalQuestions;

  const pronunciationScores = results.responses
    .map(r => r.pronunciationScore)
    .filter((s): s is number => s !== undefined);
  const averagePronunciation = pronunciationScores.length > 0 
    ? pronunciationScores.reduce((a, b) => a + b, 0) / pronunciationScores.length
    : null;

  const weakPoints = results.responses
    .filter(r => r.userAnswer.toLowerCase() !== r.correctAnswer.toLowerCase())
    .map(r => r.question);

  const analysis = await prisma.lessonAnalysis.create({
    data: {
      lessonId: results.lessonId,
      userId: results.userId,
      accuracy,
      pronunciationScore: averagePronunciation,
      weakPoints: {
        set: weakPoints
      }
    }
  });

  return analysis;
}
</file>

<file path="lib/srs.ts">
import { prisma } from './prisma';

type ReviewOutcome = {
  ease: number;
  interval: number;
  nextReview: Date;
};

export async function calculateSrsScore(
  currentEase: number,
  currentInterval: number,
  performance: number
): Promise<ReviewOutcome> {
  let ease = currentEase;
  let interval = currentInterval;

  if (performance >= 0.9) {
    ease = Math.min(currentEase + 0.15, 2.5);
    interval = currentInterval * ease;
  } else if (performance >= 0.7) {
    ease = currentEase;
    interval = currentInterval * 1.5;
  } else {
    ease = Math.max(currentEase - 0.2, 1.3);
    interval = 1;
  }

  const nextReview = new Date();
  nextReview.setDate(nextReview.getDate() + Math.round(interval));

  return { ease, interval, nextReview };
}

export async function updateSrsEntry(
  entryId: string,
  performance: number
) {
  const entry = await prisma.sRSEntry.findUnique({
    where: { id: entryId }
  });

  if (!entry) return;

  const { ease, interval, nextReview } = await calculateSrsScore(
    entry.ease,
    entry.interval,
    performance
  );

  await prisma.sRSEntry.update({
    where: { id: entryId },
    data: {
      ease,
      interval,
      nextReview
    }
  });
}
</file>

<file path="prisma/migrations/20250620095352_add_lesson_analysis_model/migration.sql">
-- DropIndex
DROP INDEX "Lesson_userId_difficulty_idx";

-- DropIndex
DROP INDEX "Progress_userId_completedAt_idx";

-- CreateTable
CREATE TABLE "LessonAnalysis" (
    "id" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "accuracy" DOUBLE PRECISION NOT NULL,
    "pronunciationScore" DOUBLE PRECISION,
    "weakPoints" TEXT[],
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "LessonAnalysis_pkey" PRIMARY KEY ("id")
);

-- AddForeignKey
ALTER TABLE "LessonAnalysis" ADD CONSTRAINT "LessonAnalysis_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="project_manifest.json">
{
  "active_plan_file": "FIX_PLAN.md",
  "architectural_map": {
    "core_components": [
      "authentication",
      "lesson_management",
      "srs_system",
      "payment_processing",
      "analytics"
    ],
    "file_paths": [
      "app/",
      "lib/",
      "components/",
      "prisma/"
    ]
  }
}
</file>

<file path=".github/workflows/ci.yml">
name: CI

on:
  push:
    branches: [main]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm ci
      - run: npm run lint
</file>

<file path=".roo/rules-planner/rules.md">
## 1. IDENTITY & PERSONA
You are the **Planner AI** (🧠 The Master Planner). You are the master cartographer of the codebase. Your purpose is to create a complete, 100% coverage work breakdown structure before any implementation begins. You are obsessive about full coverage and leave no part of the specification unplanned.

## 2. THE CORE MISSION & TRIGGER
Your mission is to translate the `canonical_spec.md` into a full set of atomic implementation plans. You are triggered by the Dispatcher when the `signals/SPECIFICATION_COMPLETE.md` signal exists.

## 3. THE UPFRONT PLANNING WORKFLOW

### PHASE 1: DRAFTING THE PLAN
1.  **Acknowledge & Log:** "Specification received. Beginning 100% upfront project planning."
2.  **Create Directories:** Ensure `work_breakdown/tasks/` exists.
3.  **Consume Signal:** Delete `signals/SPECIFICATION_COMPLETE.md`.
4.  **Generate Full Work Breakdown:**
    *   Read `docs/canonical_spec.md` thoroughly.
    *   Create `work_breakdown/master_plan.md` with a high-level checklist of all features.
    *   For **every feature** in the master plan, create a corresponding detailed plan file in `work_breakdown/tasks/` (e.g., `plan-001-user-auth.md`). Each task within these files should still be tagged `(LOGIC)` or `(UI)`.

### PHASE 2: MANDATORY SELF-CORRECTION PROTOCOL
5.  **Final Sanity Check:** Before proceeding, you **must** halt and internally ask and answer the following questions. You cannot proceed until you can honestly answer "Yes" to all.
    *   "Is there a 1-to-1 mapping between every feature in `docs/canonical_spec.md` and the items in `work_breakdown/master_plan.md`?"
    *   "Does every single item in the master plan have a corresponding, detailed task file in the `work_breakdown/tasks/` directory?"
    *   "Have I accounted for all constraints and non-functional requirements mentioned in the spec within my task breakdowns?"
    *   "Can I guarantee that if the Developer completes every single task in these plan files, the resulting codebase will have 100% coverage of the specification?"
    *   If the answer to any of these is 'No' or 'I am unsure', you must return to Phase 1, correct the planning documents, and repeat this self-correction process.

### PHASE 3: ANNOUNCE & HANDOFF
6.  **Announce & Handoff (Post-Correction):**
    *   Announce: "Self-correction protocol passed. Full project plan is complete and verified to cover 100% of the specification. Handing off for implementation."
    *   Create the signal file `signals/PLANNING_COMPLETE.md`.
    *   Switch mode to `<mode>dispatcher</mode>`.
</file>

<file path=".roo/rules-system-supervisor/rules.md">
## 1. IDENTITY & PERSONA
You are the **System_Supervisor AI** (👑 Supervisor). You are the ultimate meta-agent that repairs the system's workflow logic. You operate by reading the `project_manifest.json` to find and analyze the system log.

## 2. THE CORE MISSION & TRIGGER
You are activated by the `Dispatcher` during an infinite loop. Your mission is to diagnose the flawed workflow by analyzing the log file and rewrite an agent's rules to correct it.

## 3. THE META-ANALYSIS & REPAIR WORKFLOW

1.  **Read the Manifest:** Read `project_manifest.json` to get the `log_file` path.
2.  **Ingest System State:**
    *   `echo '{"timestamp": "...", "agent": "System_Supervisor", "event": "action_start", "details": "Activated to resolve system-level failure."}' >> [log_file]`

3.  **Perform Root Cause Analysis on the *Workflow*:**
    *   **Analyze the Logs:** Read the `log_file` to trace the sequence of agent handoffs that led to the loop.
    *   **Analyze the Rules:** Read the `.roo/rules-*.md` files for the involved agents.
    *   **Identify & Log the Flaw:** Pinpoint the exact rule conflict causing the failure.
    *   `echo '{"timestamp": "...", "agent": "System_Supervisor", "event": "diagnosis", "details": "Identified logical flaw: [Concise description]"}' >> [log_file]`

4.  **Formulate a Rule-Based Solution:**
    *   Identify the target agent whose rules must be changed.
    *   Draft a new, corrected version of that agent's `rules.md` file.

5.  **Execute the System Refactor:**
    *   **Action:** Replace the content of `[path_to_agent_rules.md]` with the new ruleset.
    *   `echo '{"timestamp": "...", "agent": "System_Supervisor", "event": "action_complete", "details": "Applied fix by rewriting rules for agent: [Agent Name]."}' >> [log_file]`

6.  **Announce Fix & Handoff:**
    *   Announce: "System workflow repaired. I have updated the rules for the `[Agent Name]`. Retrying operation."
    *   Switch mode back to `<mode>dispatcher</mode>`.

## 4. CRITICAL DIRECTIVES
*   You only modify `.md` rule files.
*   Make the smallest, most targeted change possible.
*   You are forbidden from modifying your own `rules.md` file.
*   Explain your reasoning in your announcement and logs.
</file>

<file path="app/api/onboarding/diagnostic/route.ts">
import { NextResponse } from 'next/server';

import { speechClient, geminiClient } from '@/lib/ai-service';

interface SpeechRecognitionAlternative {
  transcript?: string;
  confidence?: number;
}

interface SpeechRecognitionResult {
  alternatives?: SpeechRecognitionAlternative[];
}

interface SpeechRecognitionResponse {
  results?: SpeechRecognitionResult[];
}

export async function POST(request: Request) {
  try {
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    
    if (!audioFile) {
      return NextResponse.json(
        { error: 'No audio file provided' },
        { status: 400 }
      );
    }

  
    const audioBuffer = Buffer.from(await audioFile.arrayBuffer());
    
    // Transcribe audio
    const [transcriptionResult] = await speechClient.recognize({
      audio: { content: audioBuffer },
      config: {
        encoding: 'WEBM_OPUS',
        sampleRateHertz: 48000,
        languageCode: 'en-US',
      },
    });

    const results = (transcriptionResult as SpeechRecognitionResponse).results || [];
    const transcription = results
      .flatMap(result => result.alternatives?.map(alt => alt.transcript) || [])
      .filter((t): t is string => Boolean(t))
      .join(' ');

    if (!transcription) {
      return NextResponse.json(
        { error: 'Could not transcribe audio' },
        { status: 400 }
      );
    }

    // Analyze with Gemini
    const model = geminiClient.getGenerativeModel({ model: 'gemini-pro' });
    const prompt = `Analyze this language diagnostic sample:\n\n${transcription}\n\nProvide feedback on pronunciation, grammar, and vocabulary usage.`;
    const result = await model.generateContent(prompt);
    const analysis = await result.response.text();

    return NextResponse.json({ transcription, analysis });
    
  } catch (error) {
    console.error('Diagnostic error:', error);
    return NextResponse.json(
      { error: 'Failed to process diagnostic' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/api/stats/fluency/route.ts">
import { NextResponse } from 'next/server';

export async function GET() {
  return NextResponse.json({ speakingPace: 125 });
}
</file>

<file path="app/api/stats/srs-overview/route.ts">
import { NextResponse } from 'next/server';

export async function GET() {
  return NextResponse.json({ totalItems: 150 });
}
</file>

<file path="app/api/users/update-profile/route.ts">
import { NextResponse } from 'next/server';
import prisma from '@/lib/prisma';

declare const prisma: {
  user: {
    update: (params: {
      where: { id: string };
      data: { nativeLang: string; targetLang: string };
    }) => Promise<void>;
  };
};

export async function POST(request: Request) {
  try {
    const { userId, nativeLang, targetLang } = await request.json();
    
    await prisma.user.update({
      where: { id: userId },
      data: {
        nativeLang,
        targetLang
      }
    });

    return NextResponse.json({ success: true });
  } catch (error) {
    console.error('Profile update error:', error);
    return NextResponse.json(
      { error: 'Failed to update profile' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/globals.css">
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}
</file>

<file path="app/layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}
</file>

<file path="app/page.tsx">
import Image from "next/image";

export default function Home() {
  return (
    <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-[32px] row-start-2 items-center sm:items-start">
        <Image
          className="dark:invert"
          src="/next.svg"
          alt="Next.js logo"
          width={180}
          height={38}
          priority
        />
        <ol className="list-inside list-decimal text-sm/6 text-center sm:text-left font-[family-name:var(--font-geist-mono)]">
          <li className="mb-2 tracking-[-.01em]">
            Get started by editing{" "}
            <code className="bg-black/[.05] dark:bg-white/[.06] px-1 py-0.5 rounded font-[family-name:var(--font-geist-mono)] font-semibold">
              app/page.tsx
            </code>
            .
          </li>
          <li className="tracking-[-.01em]">
            Save and see your changes instantly.
          </li>
        </ol>

        <div className="flex gap-4 items-center flex-col sm:flex-row">
          <a
            className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 sm:w-auto"
            href="https://vercel.com/new?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            <Image
              className="dark:invert"
              src="/vercel.svg"
              alt="Vercel logomark"
              width={20}
              height={20}
            />
            Deploy now
          </a>
          <a
            className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent font-medium text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 w-full sm:w-auto md:w-[158px]"
            href="https://nextjs.org/docs?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
            target="_blank"
            rel="noopener noreferrer"
          >
            Read our docs
          </a>
        </div>
      </main>
      <footer className="row-start-3 flex gap-[24px] flex-wrap items-center justify-center">
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org/learn?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/file.svg"
            alt="File icon"
            width={16}
            height={16}
          />
          Learn
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://vercel.com/templates?framework=next.js&utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/window.svg"
            alt="Window icon"
            width={16}
            height={16}
          />
          Examples
        </a>
        <a
          className="flex items-center gap-2 hover:underline hover:underline-offset-4"
          href="https://nextjs.org?utm_source=create-next-app&utm_medium=appdir-template-tw&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          <Image
            aria-hidden
            src="/globe.svg"
            alt="Globe icon"
            width={16}
            height={16}
          />
          Go to nextjs.org →
        </a>
      </footer>
    </div>
  );
}
</file>

<file path="prisma/migrations/20250613111519_add_performance_indexes/migration.sql">
-- CreateIndex
CREATE INDEX "Lesson_userId_difficulty_idx" ON "Lesson"("userId", "difficulty");

-- CreateIndex
CREATE INDEX "Progress_userId_completedAt_idx" ON "Progress"("userId", "completedAt");
</file>

<file path="public/file.svg">
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>
</file>

<file path="public/globe.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>
</file>

<file path="public/next.svg">
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>
</file>

<file path="public/vercel.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>
</file>

<file path="public/window.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>
</file>

<file path="Dockerfile">
# Dockerfile.mac
FROM node:20.11-alpine3.19

# 1) Install psql (PostgreSQL client)
RUN apk add --no-cache postgresql-client git

# 2) Set workdir and install app deps
WORKDIR /app
COPY package*.json ./
RUN npm install

# 3) Copy the rest of your code and generate Prisma client
COPY . .
RUN npx prisma generate

EXPOSE 3000
CMD ["npm", "run", "dev"]
</file>

<file path="eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;
</file>

<file path="postcss.config.mjs">
const config = {
  plugins: ["@tailwindcss/postcss"],
};

export default config;
</file>

<file path="README.md">
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
</file>

<file path=".roo/rules-product-manager/rules.md">
## 1. IDENTITY & PERSONA
You are the **Product Manager AI** (📈 The Clarifier). You are a meticulous interpreter of the user's vision. Your purpose is to eliminate all ambiguity by transforming a high-level description into a definitive, machine-readable specification. You do not proceed until you are certain of your interpretation's completeness.

## 2. THE CORE MISSION & TRIGGER
Your mission is to create the project's **source of truth**. You are triggered by the Dispatcher only when `docs/app_description.md` exists, but `docs/canonical_spec.md` does not.

## 3. THE CLARIFICATION WORKFLOW

### PHASE 1: DRAFTING THE SPECIFICATION
1.  **Acknowledge & Log:** "New project vision detected. I will create the canonical specification."
2.  **Create Directories:** Ensure `docs/` and `signals/` exist.
3.  **Read and Deconstruct the Vision:**
    *   Read the full contents of `docs/app_description.md`.
    *   Perform a semantic analysis to identify all features, user stories, requirements, and constraints.
4.  **Create Draft Specification:**
    *   Create `docs/canonical_spec.md`. This file must be a comprehensive, non-ambiguous document detailing the entire project. This is now the project's primary reference.
    *   Create a skeleton `docs/README.md`.

### PHASE 2: MANDATORY SELF-CORRECTION PROTOCOL
5.  **Final Sanity Check:** Before proceeding, you **must** halt and internally ask and answer the following questions. You cannot proceed until you can honestly answer "Yes" to all.
    *   "Have I captured every single feature, requirement, and constraint from `docs/app_description.md`?"
    *   "Is there any statement in my `canonical_spec.md` that could be considered ambiguous or open to misinterpretation by the Planner?"
    *   "Is this specification complete enough for a 100% upfront work breakdown, or are there still 'To Be Determined' sections?"
    *   "If I were the Planner, could I create a complete and exhaustive project plan from this document alone, without asking further questions?"
    *   If the answer to any of these is 'No' or 'I am unsure', you must return to Phase 1, refine `docs/canonical_spec.md`, and repeat this self-correction process.

### PHASE 3: FINALIZATION & HANDOFF
6.  **Announce & Handoff (Post-Correction):**
    *   Announce: "Self-correction protocol passed. Canonical specification is complete and verified. Handing off to the Planner for full-scale planning."
    *   Create the signal file `signals/SPECIFICATION_COMPLETE.md`.
    *   Switch mode to `<mode>dispatcher</mode>`.
</file>

<file path="app/api/protected/route.ts">
import { NextResponse } from 'next/server'
import { withAuthMiddleware } from '@/lib/auth-middleware'

async function handler() {
  return NextResponse.json({ message: 'Access granted to protected route' })
}

export const GET = withAuthMiddleware(handler)
</file>

<file path="app/api/settings/route.ts">
import { getServerSession } from 'next-auth';
import { NextResponse } from 'next/server';
import { authOptions } from '@/lib/auth-options';
import prisma from '@/lib/prisma';

export async function POST(req: Request) {
  const session = await getServerSession(authOptions);
  if (!session) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  try {
    const body = await req.json();
    
    // Update user in database
    await prisma.user.update({
      where: { id: session.user.id },
      data: {
        email: body.email,
        // Note: In a real application, we'd hash the password before saving
        ...(body.newPassword && { password: body.newPassword }),
        notificationPreferences: {
          update: {
            email: body.notifications
          }
        }
      }
    });

    return NextResponse.json({ success: true });
  } catch (error) {
    console.error('Error updating settings:', error);
    return NextResponse.json(
      { error: 'Failed to update settings' },
      { status: 500 }
    );
  }
}
</file>

<file path="app/api/users/sync/route.ts">
import { createClient } from '@supabase/supabase-js'
import { NextResponse } from 'next/server'
import prisma from '@/lib/prisma'

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
)

export async function POST() {
  const { data: { users }, error } = await supabase.auth.admin.listUsers()

  if (error) {
    return NextResponse.json(
      { error: 'Failed to fetch users' },
      { status: 500 }
    )
  }

  try {
    for (const user of users) {
      await prisma.user.upsert({
        where: { id: user.id },
        update: {
          email: user.email,
        },
        create: {
          id: user.id,
          email: user.email!,
          password: '', // Empty string since we don't store auth passwords
          targetLang: 'en', // Default target language
          nativeLang: 'en' // Default native language
        }
      })
    }

    return NextResponse.json({ success: true })
  } catch (error) {
    console.error('User sync failed:', error)
    return NextResponse.json(
      { error: 'User sync failed' },
      { status: 500 }
    )
  }
}
</file>

<file path="components/Auth.tsx">
import { createClientComponentClient } from '@supabase/auth-helpers-nextjs';
import { useState } from 'react';

export default function Auth() {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState('');
  const supabase = createClientComponentClient();

  const handleSignUp = async () => {
    setLoading(true);
    setError('');
    try {
      const { error } = await supabase.auth.signUp({
        email,
        password,
        options: { emailRedirectTo: `${location.origin}/auth/callback` },
      });
      if (error) throw error;
      alert('Check your email for the confirmation link!');
    } catch (error) {
      if (error instanceof Error) {
        setError(error.message);
      } else {
        setError('An unexpected error occurred');
      }
    } finally {
      setLoading(false);
    }
  };

  const handleSignIn = async () => {
    setLoading(true);
    setError('');
    try {
      const { error } = await supabase.auth.signInWithPassword({ email, password });
      if (error) throw error;
    } catch (error) {
      if (error instanceof Error) {
        setError(error.message);
      } else {
        setError('An unexpected error occurred');
      }
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="auth-container">
      <div className="form-group">
        <label>Email</label>
        <input
          type="email"
          value={email}
          onChange={(e) => setEmail(e.target.value)}
          disabled={loading}
        />
      </div>
      <div className="form-group">
        <label>Password</label>
        <input
          type="password"
          value={password}
          onChange={(e) => setPassword(e.target.value)}
          disabled={loading}
        />
      </div>
      {error && <div className="error-message">{error}</div>}
      <div className="button-group">
        <button onClick={handleSignUp} disabled={loading}>
          {loading ? 'Loading...' : 'Sign Up'}
        </button>
        <button onClick={handleSignIn} disabled={loading}>
          {loading ? 'Loading...' : 'Sign In'}
        </button>
      </div>
    </div>
  );
}
</file>

<file path="components/Navigation.tsx">
import Link from 'next/link'
import { getUserSession } from '@/lib/supabase/server'

export default async function Navigation() {
  const session = await getUserSession()
  
  return (
    <nav className="bg-gray-800 p-4">
      <div className="container mx-auto flex justify-between items-center">
        <div className="flex space-x-4">
          <Link href="/" className="text-white hover:text-gray-300">
            Home
          </Link>
        </div>
        <div className="flex space-x-4">
          {session ? (
            <Link href="/profile" className="text-white hover:text-gray-300">
              Profile
            </Link>
          ) : (
            <Link href="/login" className="text-white hover:text-gray-300">
              Login
            </Link>
          )}
        </div>
      </div>
    </nav>
  )
}
</file>

<file path="components/Notifications.tsx">
import { useState, useEffect } from 'react';
import { useSession } from 'next-auth/react';

interface Notification {
  id: string;
  message: string;
  type: 'lesson' | 'system' | 'achievement';
  read: boolean;
  createdAt: string;
  link?: string;
}

export default function Notifications() {
  const { data: session } = useSession();
  const [isOpen, setIsOpen] = useState(false);
  const [notifications, setNotifications] = useState<Notification[]>([]);
  const [unreadCount, setUnreadCount] = useState(0);

  useEffect(() => {
    if (!session?.user?.id) return;

    // Fetch initial notifications
    const fetchNotifications = async () => {
      try {
        const response = await fetch('/api/notifications');
        if (!response.ok) throw new Error('Failed to fetch notifications');
        const data: Notification[] = await response.json();
        setNotifications(data);
        setUnreadCount(data.filter(n => !n.read).length);
      } catch (error) {
        console.error('Error fetching notifications:', error);
      }
    };

    fetchNotifications();

    // Setup real-time updates (example using EventSource)
    const eventSource = new EventSource('/api/notifications/stream');
    
    eventSource.onmessage = (event) => {
      const newNotification: Notification = JSON.parse(event.data);
      setNotifications((prev: Notification[]) => [newNotification, ...prev]);
      setUnreadCount((prev: number) => prev + 1);
    };

    return () => {
      eventSource.close();
    };
  }, [session?.user?.id]);

  const markAsRead = async (id: string) => {
    try {
      await fetch(`/api/notifications/${id}/read`, { method: 'PUT' });
      setNotifications((prev: Notification[]) =>
        prev.map((n: Notification) => n.id === id ? { ...n, read: true } : n)
      );
      setUnreadCount((prev: number) => prev - 1);
    } catch (error) {
      console.error('Error marking notification as read:', error);
    }
  };

  const markAllAsRead = async () => {
    try {
      await fetch('/api/notifications/read-all', { method: 'PUT' });
      setNotifications((prev: Notification[]) => prev.map((n: Notification) => ({ ...n, read: true })));
      setUnreadCount(0);
    } catch (error) {
      console.error('Error marking all notifications as read:', error);
    }
  };

  return (
    <div className="relative">
      <button 
        onClick={() => setIsOpen(!isOpen)}
        className="p-2 hover:bg-gray-100 rounded-full relative"
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          className="h-6 w-6"
          fill="none"
          viewBox="0 0 24 24"
          stroke="currentColor"
        >
          <path
            strokeLinecap="round"
            strokeLinejoin="round"
            strokeWidth={2}
            d="M15 17h5l-1.405-1.405A2.032 2.032 0 0118 14.158V11a6.002 6.002 0 00-4-5.659V5a2 2 0 10-4 0v.341C7.67 6.165 6 8.388 6 11v3.159c0 .538-.214 1.055-.595 1.436L4 17h5m6 0v1a3 3 0 11-6 0v-1m6 0H9"
          />
        </svg>
        {unreadCount > 0 && (
          <span className="absolute top-0 right-0 bg-red-500 text-white rounded-full text-xs w-5 h-5 flex items-center justify-center">
            {unreadCount}
          </span>
        )}
      </button>

      {isOpen && (
        <div className="absolute right-0 mt-2 w-80 bg-white rounded-lg shadow-lg border">
          <div className="p-4 border-b flex justify-between items-center">
            <h3 className="font-semibold">Notifications</h3>
            <button
              onClick={markAllAsRead}
              className="text-blue-600 text-sm hover:underline"
              disabled={unreadCount === 0}
            >
              Mark all as read
            </button>
          </div>
          
          <div className="max-h-96 overflow-y-auto">
            {notifications.length === 0 ? (
              <p className="p-4 text-gray-500">No notifications</p>
            ) : (
              notifications.map((notification: Notification) => (
                <div
                  key={notification.id}
                  className={`p-4 border-b hover:bg-gray-50 cursor-pointer ${
                    !notification.read ? 'bg-blue-50' : ''
                  }`}
                  onClick={() => {
                    if (!notification.read) markAsRead(notification.id);
                    if (notification.link) window.location.href = notification.link;
                  }}
                >
                  <div className="flex justify-between items-start">
                    <span className="flex-1">{notification.message}</span>
                    {!notification.read && (
                      <span className="ml-2 w-2 h-2 bg-blue-500 rounded-full" />
                    )}
                  </div>
                  <p className="text-sm text-gray-500 mt-1">
                    {new Date(notification.createdAt).toLocaleDateString()}
                  </p>
                </div>
              ))
            )}
          </div>
        </div>
      )}
    </div>
  );
}
</file>

<file path="components/OnboardingForm.tsx">
import React, { useState, FormEvent, ChangeEvent } from 'react';

import { useRouter } from 'next/router';



const OnboardingForm = () => {
  const [nativeLang, setNativeLang] = useState<string>('');
  const [targetLang, setTargetLang] = useState<string>('');
  const [goal, setGoal] = useState<string>('');
  const [level, setLevel] = useState<string>('');
  const router = useRouter();


  const handleSubmit = async (e: FormEvent) => {
    e.preventDefault();
    
    try {
      const response = await fetch('/api/users/update-profile', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          userId: 'current-user-id', // TODO: Replace with actual user ID
          nativeLang,
          targetLang,
          goal,
          level
        }),
      });

      if (!response.ok) {
        throw new Error('Failed to save profile');
      }

      // Redirect to diagnostic after successful save
      router.push('/onboarding/diagnostic');
    } catch (error) {
      console.error('Profile save error:', error);
      // TODO: Show error message to user
    }
  };

  return (
    <div className="max-w-2xl mx-auto p-6">
      <div className="text-center mb-8">
        <h1 className="text-4xl font-bold text-blue-600 mb-4">
          Welcome to Lessay! 🌍
        </h1>
        <p className="text-lg text-gray-600">
          Let&apos;s create your personalized language learning journey
        </p>
      </div>
      
      <div className="bg-white rounded-lg shadow-md p-8">
        <div className="mb-6 text-center">
          <h2 className="text-2xl font-semibold mb-2">
            Get Started in 3 Simple Steps
          </h2>
          <p className="text-gray-500">
            1. Tell us about yourself<br/>
            2. Take a quick diagnostic<br/>
            3. Start your first lesson
          </p>
        </div>
        <form onSubmit={handleSubmit} className="space-y-6">
        <div className="space-y-6">
          <div>
            <label className="block text-sm font-medium text-gray-700 mb-1">
              Native Language
            </label>
            <input
              type="text"
              value={nativeLang}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setNativeLang(e.target.value)}
              className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"
              required
            />
          </div>
          
          <div>
            <label className="block text-sm font-medium text-gray-700 mb-1">
              Target Language
            </label>
            <input
              type="text"
              value={targetLang}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setTargetLang(e.target.value)}
              className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"
              required
            />
          </div>

          <div>
            <label className="block text-sm font-medium text-gray-700 mb-1">
              Primary Goal
            </label>
            <input
              type="text"
              value={goal}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setGoal(e.target.value)}
              className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"
              required
            />
          </div>

          <div>
            <label className="block text-sm font-medium text-gray-700 mb-1">
              Self-Assessed Level
            </label>
            <input
              type="text"
              value={level}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setLevel(e.target.value)}
              className="mt-1 block w-full rounded-md border-gray-300 shadow-sm focus:border-blue-500 focus:ring-blue-500"
              required
            />
          </div>

          <button
            type="submit"
            className="w-full flex justify-center py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-blue-600 hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500"
          >
            Start Diagnostic
          </button>
        </div>
        </form>
      </div>
    </div>
  
  );
};

export default OnboardingForm;
</file>

<file path="components/ProfileView.tsx">
import { useState, useEffect } from 'react'
import type { FC, FormEvent, ChangeEvent } from 'react'
import React from 'react'
import { useSupabase } from '@/lib/supabase/client'

interface UserProfile {
  id: string
  email: string
  avatarUrl?: string
  bio?: string
  targetLang: string
  nativeLang: string
  socialMediaLinks?: string[]
  createdAt: string
}

interface ProfileForm {
  targetLang: string
  nativeLang: string
  bio?: string
  socialMediaLinks?: string[]
}

export const ProfileView: FC = (): React.JSX.Element => {
  const supabase = useSupabase()
  const [userData, setUserData] = useState<UserProfile | null>(null)
  const [loading, setLoading] = useState(true)
  const [error, setError] = useState<string | null>(null)
  const [editMode, setEditMode] = useState(false)
  const [formData, setFormData] = useState<ProfileForm>({
    targetLang: '',
    nativeLang: '',
    bio: '',
    socialMediaLinks: []
  })

  useEffect(() => {
    const fetchProfile = async () => {
      try {
        const { error } = await supabase.auth.getUser()
        if (error) throw error
        
        const response = await fetch('/api/users/profile')
        if (!response.ok) throw new Error('Failed to fetch profile')
        
        const profile: UserProfile = await response.json()
        setUserData(profile)
        setFormData({
          targetLang: profile.targetLang,
          nativeLang: profile.nativeLang
        })
      } catch (err) {
        setError(err instanceof Error ? err.message : 'Unknown error occurred')
      } finally {
        setLoading(false)
      }
    }

    fetchProfile()
  }, [supabase.auth])

  const handleSubmit = async (e: FormEvent) => {
    e.preventDefault()
    try {
      const response = await fetch('/api/users/profile', {
        method: 'PUT',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(formData),
      })

      if (!response.ok) throw new Error('Update failed')
      
      const updatedProfile: UserProfile = await response.json()
      setUserData(updatedProfile)
      setEditMode(false)
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Update failed')
    }
  }

  if (loading) return <div>Loading...</div>
  if (error) return <div>Error: {error}</div>
  if (!userData) return <div>No profile data found</div>

  return (
    <div className="max-w-md mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">Profile</h1>
      
      {!editMode ? (
        <div>
          <div className="flex items-center gap-4 mb-4">
            {userData.avatarUrl ? (
              <img
                src={userData.avatarUrl}
                alt="Profile"
                className="w-20 h-20 rounded-full object-cover"
              />
            ) : (
              <div className="w-20 h-20 rounded-full bg-gray-200 flex items-center justify-center">
                <span className="text-gray-500">No photo</span>
              </div>
            )}
          </div>
          <p>Email: {userData.email}</p>
          <p>Target Language: {userData.targetLang}</p>
          <p>Native Language: {userData.nativeLang}</p>
          {userData.bio && <p className="mt-2 text-gray-600">{userData.bio}</p>}
          {userData.socialMediaLinks && userData.socialMediaLinks.length > 0 && (
            <div className="mt-2">
              <p className="font-medium">Social Media:</p>
              <ul className="list-disc pl-5">
                {userData.socialMediaLinks?.map((link: string, index: number) => (
                  <li key={index}>
                    <a href={link} target="_blank" rel="noopener noreferrer" className="text-blue-600 hover:underline">
                      {link}
                    </a>
                  </li>
                ))}
              </ul>
            </div>
          )}
          <button
            onClick={() => setEditMode(true)}
            className="mt-4 bg-blue-500 text-white px-4 py-2 rounded"
          >
            Edit Profile
          </button>
        </div>
      ) : (
        <form onSubmit={handleSubmit} className="space-y-4">
          <div>
            <label className="block">Target Language</label>
            <input
              type="text"
              value={formData.targetLang}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setFormData({...formData, targetLang: e.target.value})}
              className="w-full p-2 border rounded"
            />
          </div>
          
          <div>
            <label className="block">Native Language</label>
            <input
              type="text"
              value={formData.nativeLang}
              onChange={(e: ChangeEvent<HTMLInputElement>) => setFormData({...formData, nativeLang: e.target.value})}
              className="w-full p-2 border rounded"
            />
          </div>
          
          <div>
            <label className="block">Bio</label>
            <textarea
              value={formData.bio || ''}
              onChange={(e: ChangeEvent<HTMLTextAreaElement>) => setFormData({...formData, bio: e.target.value})}
              className="w-full p-2 border rounded h-32"
            />
          </div>

          <div>
            <label className="block">Social Media Links (one per line)</label>
            <textarea
              value={formData.socialMediaLinks?.join('\n') || ''}
              onChange={(e: ChangeEvent<HTMLTextAreaElement>) => setFormData({
                ...formData,
                socialMediaLinks: e.target.value.split('\n').filter((link: string) => link.trim())
              })}
              className="w-full p-2 border rounded h-32"
            />
          </div>

          <div>
            <label className="block">Profile Photo</label>
            <input
              type="file"
              accept="image/*"
              onChange={async (e: ChangeEvent<HTMLInputElement>) => {
                const file = e.target.files?.[0]
                if (file) {
                  const formData = new FormData()
                  formData.append('avatar', file)
                  try {
                    const response = await fetch('/api/users/profile/avatar', {
                      method: 'POST',
                      body: formData
                    })
                    if (!response.ok) throw new Error('Upload failed')
                    const { avatarUrl } = await response.json()
                    setUserData((prev: UserProfile | null) => prev ? {...prev, avatarUrl} : null)
                  } catch (err) {
                    setError(err instanceof Error ? err.message : 'Upload failed')
                  }
                }
              }}
              className="mt-1"
            />
          </div>

          <div className="flex gap-2">
            <button
              type="submit"
              className="bg-green-500 text-white px-4 py-2 rounded"
            >
              Save
            </button>
            <button
              type="button"
              onClick={() => setEditMode(false)}
              className="bg-gray-500 text-white px-4 py-2 rounded"
            >
              Cancel
            </button>
          </div>
        </form>
      )}
    </div>
  )
}
</file>

<file path="components/SettingsView.tsx">
import { useState } from 'react';
import type { ReactElement } from 'react';
import { useSession } from 'next-auth/react';

interface FormData {
  email: string;
  currentPassword: string;
  newPassword: string;
  theme: string;
  language: string;
  notifications: boolean;
  emailNotifications: boolean;
  pushNotifications: boolean;
}

export default function SettingsView(): ReactElement {
  const { data: session } = useSession();
  const [formData, setFormData] = useState<FormData>({
    email: session?.user?.email || '',
    currentPassword: '',
    newPassword: '',
    theme: 'light',
    language: 'en',
    notifications: true,
    emailNotifications: true,
    pushNotifications: true,
  });
  const [showSuccess, setShowSuccess] = useState(false);

  const handleSubmit = async (e: React.FormEvent<HTMLFormElement>) => {
    e.preventDefault();
    try {
      const response = await fetch('/api/settings', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(formData),
      });
      if (!response.ok) throw new Error('Update failed');
      setShowSuccess(true);
      setTimeout(() => setShowSuccess(false), 3000);
    } catch (error) {
      console.error('Error updating settings:', error);
    }
  };

  const handleInputChange = (e: React.ChangeEvent<HTMLInputElement | HTMLSelectElement>) => {
    const { name, value, type, checked } = e.target as HTMLInputElement;
    setFormData((prev: FormData) => ({
      ...prev,
      [name]: type === 'checkbox' ? checked : value
    }));
  };

  return (
    <div className="max-w-2xl mx-auto p-4">
      <h1 className="text-2xl font-bold mb-6">User Settings</h1>
      
      {showSuccess && (
        <div className="mb-4 p-3 bg-green-100 text-green-700 rounded">
          Settings saved successfully!
        </div>
      )}

      <form onSubmit={handleSubmit} className="space-y-6">
        <div className="space-y-4">
          <h2 className="text-lg font-semibold">Account Settings</h2>
          <div>
            <label className="block text-sm font-medium">Email</label>
            <input
              type="email"
              name="email"
              value={formData.email}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            />
          </div>
          
          <div>
            <label className="block text-sm font-medium">Current Password</label>
            <input
              type="password"
              name="currentPassword"
              value={formData.currentPassword}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            />
          </div>

          <div>
            <label className="block text-sm font-medium">New Password</label>
            <input
              type="password"
              name="newPassword"
              value={formData.newPassword}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            />
          </div>
        </div>

        <div className="space-y-4">
          <h2 className="text-lg font-semibold">Preferences</h2>
          <div>
            <label className="block text-sm font-medium">Theme</label>
            <select
              name="theme"
              value={formData.theme}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            >
              <option value="light">Light</option>
              <option value="dark">Dark</option>
              <option value="system">System Default</option>
            </select>
          </div>

          <div>
            <label className="block text-sm font-medium">Language</label>
            <select
              name="language"
              value={formData.language}
              onChange={handleInputChange}
              className="mt-1 block w-full rounded-md border p-2"
            >
              <option value="en">English</option>
              <option value="es">Spanish</option>
              <option value="fr">French</option>
              <option value="de">German</option>
            </select>
          </div>
        </div>

        <div className="space-y-4">
          <h2 className="text-lg font-semibold">Notifications</h2>
          <div className="flex flex-col space-y-2">
            <label className="flex items-center space-x-2">
              <input
                type="checkbox"
                name="notifications"
                checked={formData.notifications}
                onChange={handleInputChange}
                className="rounded"
              />
              <span>Enable all notifications</span>
            </label>
            
            <label className="flex items-center space-x-2 ml-4">
              <input
                type="checkbox"
                name="emailNotifications"
                checked={formData.emailNotifications}
                onChange={handleInputChange}
                className="rounded"
              />
              <span>Email notifications</span>
            </label>
            
            <label className="flex items-center space-x-2 ml-4">
              <input
                type="checkbox"
                name="pushNotifications"
                checked={formData.pushNotifications}
                onChange={handleInputChange}
                className="rounded"
              />
              <span>Push notifications</span>
            </label>
          </div>
        </div>

        <button
          type="submit"
          className="w-full px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700"
        >
          Save Changes
        </button>
      </form>
    </div>
  );
}
</file>

<file path="lib/supabase/server.ts">
import { createServerComponentClient } from '@supabase/auth-helpers-nextjs'
import { cookies } from 'next/headers'
import { Database } from '@/types/supabase'

export const supabaseServerClient = () => {
  const cookieStore = cookies()
  return createServerComponentClient<Database>({ cookies: () => cookieStore })
}

export const getUserSession = async () => {
  const supabase = supabaseServerClient()
  const { data: { session } } = await supabase.auth.getSession()
  return session
}
</file>

<file path="lib/auth-middleware.ts">
import type { NextRequest } from 'next/server'
import { NextResponse } from 'next/server'
import { supabaseServerClient } from '@/lib/supabase/server'
import { checkRateLimit, trackLoginAttempt } from '@/lib/security'

export async function requireAuth(
  req: NextRequest,
  handler: (req: NextRequest, userId: string) => Promise<NextResponse>
) {
  const ip = req.ip || req.headers.get('x-forwarded-for') || 'unknown'
  
  // Check rate limit
  const rateLimitResponse = checkRateLimit(ip)
  if (rateLimitResponse) {
    return rateLimitResponse
  }

  // Track login attempt
  const attempt = trackLoginAttempt(ip)
  if (!attempt.allowed) {
    return NextResponse.json(
      { error: attempt.message },
      { status: 429 }
    )
  }

  const supabase = supabaseServerClient()
  const { data: { user }, error } = await supabase.auth.getUser()

  if (error || !user) {
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    )
  }

  try {
    return await handler(req, user.id)
  } catch (err: unknown) {
    const error = err instanceof Error ? err : new Error('Unknown error')
    console.error('Auth middleware error:', error)
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}

export async function refreshSession() {
  const supabase = supabaseServerClient()
  const { data, error } = await supabase.auth.refreshSession()

  if (error) {
    throw error
  }

  return data
}

export async function withAuthMiddleware(handler: (req: NextRequest) => Promise<NextResponse>) {
  return async (req: NextRequest) => {
    const ip = req.ip || req.headers.get('x-forwarded-for') || 'unknown'
    
    // Check rate limit
    const rateLimitResponse = checkRateLimit(ip)
    if (rateLimitResponse) {
      return rateLimitResponse
    }

    const supabase = supabaseServerClient()
    const { data: { session }, error } = await supabase.auth.getSession()

    if (error || !session) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      )
    }

    // Check if access token is expired
    if (session.expires_at && session.expires_at * 1000 < Date.now()) {
      try {
        const newSession = await refreshSession()
        if (!newSession?.session) {
          return NextResponse.json(
            { error: 'Session expired' },
            { status: 401 }
          )
        }
      } catch (err: unknown) {
        console.error('Session refresh error:', err)
        return NextResponse.json(
          { error: 'Failed to refresh session' },
          { status: 401 }
        )
      }
    }

    return handler(req)
  }
}
</file>

<file path="lib/auth-options.ts">
import NextAuth, { type AuthOptions, type Session, type User } from 'next-auth';
import { PrismaAdapter } from '@next-auth/prisma-adapter';
import prisma from '@/lib/prisma';

export const authOptions: AuthOptions = {
  adapter: PrismaAdapter(prisma),
  providers: [
    // Configure authentication providers here
    // Example with GitHub:
    /*
    GitHubProvider({
      clientId: process.env.GITHUB_ID,
      clientSecret: process.env.GITHUB_SECRET,
    }),
    */
  ],
  callbacks: {
    async session({ session, user }: { session: Session; user: User }) {
      session.user.id = user.id;
      return session;
    }
  }
};

export default NextAuth(authOptions);
</file>

<file path="lib/auth.ts">
import {prisma} from '@/lib/prisma';
import { useRouter } from 'next/router';

export const  useAuth = () => {
  const router = useRouter();

  const startDiagnostic = () => {
    router.push('/onboarding/diagnostic');
  };

  const updateUserProfile = async (userId: string, profile: {
    nativeLang: string;
    targetLang: string;
    goal: string;
    level: string;
  }) => {
    await prisma.user.update({
      where: { id: userId },
      data: {
        nativeLang: profile.nativeLang,
        targetLang: profile.targetLang,
      }
    });
  };

  return { startDiagnostic, updateUserProfile };
};
</file>

<file path="lib/prisma.ts">
import { PrismaClient } from '@prisma/client'

const globalForPrisma = global as unknown as { prisma : PrismaClient }
export const prisma = globalForPrisma.prisma ||  new PrismaClient()
if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma
</file>

<file path="lib/security.ts">
import { NextResponse } from 'next/server';

// Rate limiting store
const rateLimitStore = new Map<string, { count: number, lastReset: number }>();
const RATE_LIMIT_WINDOW = 60 * 1000; // 1 minute
const MAX_REQUESTS_PER_WINDOW = 100;

// Login attempt tracking
const loginAttempts = new Map<string, { attempts: number, lastAttempt: number }>();
const MAX_LOGIN_ATTEMPTS = 5;
const LOGIN_ATTEMPT_WINDOW = 15 * 60 * 1000; // 15 minutes

export function checkRateLimit(ip: string): NextResponse | null {
  const now = Date.now();
  const entry = rateLimitStore.get(ip);

  if (entry) {
    if (now - entry.lastReset > RATE_LIMIT_WINDOW) {
      rateLimitStore.set(ip, { count: 1, lastReset: now });
    } else {
      if (entry.count >= MAX_REQUESTS_PER_WINDOW) {
        return NextResponse.json(
          { error: 'Too many requests' },
          { status: 429 }
        );
      }
      rateLimitStore.set(ip, { count: entry.count + 1, lastReset: entry.lastReset });
    }
  } else {
    rateLimitStore.set(ip, { count: 1, lastReset: now });
  }
  return null;
}

export function checkPasswordStrength(password: string): { valid: boolean, message?: string } {
  if (password.length < 8) {
    return { valid: false, message: 'Password must be at least 8 characters' };
  }
  if (!/[A-Z]/.test(password)) {
    return { valid: false, message: 'Password must contain at least one uppercase letter' };
  }
  if (!/[a-z]/.test(password)) {
    return { valid: false, message: 'Password must contain at least one lowercase letter' };
  }
  if (!/[0-9]/.test(password)) {
    return { valid: false, message: 'Password must contain at least one number' };
  }
  if (!/[^A-Za-z0-9]/.test(password)) {
    return { valid: false, message: 'Password must contain at least one special character' };
  }
  return { valid: true };
}

export function trackLoginAttempt(ip: string): { allowed: boolean, message?: string } {
  const now = Date.now();
  const entry = loginAttempts.get(ip);

  if (entry) {
    if (now - entry.lastAttempt > LOGIN_ATTEMPT_WINDOW) {
      loginAttempts.set(ip, { attempts: 1, lastAttempt: now });
    } else {
      if (entry.attempts >= MAX_LOGIN_ATTEMPTS) {
        return { allowed: false, message: 'Too many login attempts. Try again later.' };
      }
      loginAttempts.set(ip, { attempts: entry.attempts + 1, lastAttempt: now });
    }
  } else {
    loginAttempts.set(ip, { attempts: 1, lastAttempt: now });
  }
  return { allowed: true };
}
</file>

<file path="prisma/migrations/20250611185434_add_lesson_and_progress_models/migration.sql">
-- CreateTable
CREATE TABLE "User" (
    "id" TEXT NOT NULL,
    "email" TEXT NOT NULL,
    "password" TEXT NOT NULL,
    "targetLang" TEXT NOT NULL,
    "nativeLang" TEXT NOT NULL,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "User_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Lesson" (
    "id" TEXT NOT NULL,
    "title" TEXT NOT NULL,
    "content" TEXT NOT NULL,
    "difficulty" INTEGER NOT NULL,
    "userId" TEXT NOT NULL,
    "completedAt" TIMESTAMP(3),

    CONSTRAINT "Lesson_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Exercise" (
    "id" TEXT NOT NULL,
    "type" TEXT NOT NULL,
    "content" JSONB NOT NULL,
    "difficulty" INTEGER NOT NULL,
    "language" TEXT NOT NULL,
    "tags" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,

    CONSTRAINT "Exercise_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "UserProgress" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "metric" TEXT NOT NULL,
    "score" DOUBLE PRECISION NOT NULL,
    "lastUpdated" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "UserProgress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "Progress" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "completed" BOOLEAN NOT NULL DEFAULT false,
    "score" DOUBLE PRECISION,
    "startedAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "completedAt" TIMESTAMP(3),

    CONSTRAINT "Progress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "SRSEntry" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "item" TEXT NOT NULL,
    "recallStrength" DOUBLE PRECISION NOT NULL DEFAULT 1.0,
    "nextReview" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "language" TEXT NOT NULL,

    CONSTRAINT "SRSEntry_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "VoiceAnalysis" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "metrics" JSONB NOT NULL,
    "audioUrl" TEXT NOT NULL,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "VoiceAnalysis_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "User_email_key" ON "User"("email");

-- CreateIndex
CREATE INDEX "SRSEntry_userId_nextReview_idx" ON "SRSEntry"("userId", "nextReview");

-- AddForeignKey
ALTER TABLE "Lesson" ADD CONSTRAINT "Lesson_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Exercise" ADD CONSTRAINT "Exercise_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "UserProgress" ADD CONSTRAINT "UserProgress_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Progress" ADD CONSTRAINT "Progress_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "Progress" ADD CONSTRAINT "Progress_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "SRSEntry" ADD CONSTRAINT "SRSEntry_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "VoiceAnalysis" ADD CONSTRAINT "VoiceAnalysis_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "VoiceAnalysis" ADD CONSTRAINT "VoiceAnalysis_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "Lesson"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/migration_lock.toml">
# Please do not edit this file manually
# It should be added in your version-control system (e.g., Git)
provider = "postgresql"
</file>

<file path="types/supabase.ts">
export type Database = {
  public: {
    Tables: {
      users: {
        Row: {
          id: string
          email: string
          password: string
          targetLang: string
          nativeLang: string
          createdAt: Date
        }
      }
      lessons: {
        Row: {
          id: string
          userId: string
          completedAt: Date | null
        }
      }
      exercises: {
        Row: {
          id: string
          type: string
          content: any
          difficulty: number
          language: string
          tags: string
          lessonId: string
        }
      }
      user_progress: {
        Row: {
          id: string
          userId: string
          metric: string
          score: number
          lastUpdated: Date
        }
      }
      srs_entries: {
        Row: {
          id: string
          userId: string
          item: string
          recallStrength: number
          nextReview: Date
          language: string
        }
      }
      voice_analyses: {
        Row: {
          id: string
          userId: string
          lessonId: string
          metrics: any
          audioUrl: string
          createdAt: Date
        }
      }
    }
  }
}
</file>

<file path="BLUEPRINT_COMPLETE.md">
# Lessay Documentation Blueprint Complete

**Completion Date:** 2025-06-11  
**Architect AI:** Roo (Documentation Mode)

## Documentation Suite Overview
All SDLC documentation phases have been completed:

1. **Phase 0:** Foundation & Alignment
2. **Phase 1:** Project Definition & Requirements
3. **Phase 2:** Architecture & Technical Design
4. **Phase 3:** Implementation, Operations & Maintenance
5. **Phase 4:** Quality Assurance & Performance
6. **Phase 5:** Governance, Risk, and Compliance
7. **Phase 6:** User-Facing Documentation

## Key Documents Created
- Business Requirements Document (BRD)
- Functional Requirements Specification (FRS)
- Technical Design Document
- API Specification
- Deployment Playbook
- Maintenance Guide
- Test Plan
- Performance Baseline
- Risk Assessment
- Change Management Plan
- Continuous Improvement Plan
- User Documentation

## Next Steps
1. Review all documentation with development team
2. Begin implementation using the provided blueprints
3. Use the change management process for any modifications

**Signed,**  
🧠 Documentation AI  
Project Lessay
</file>

<file path="docker-compose.yml">
version: '3.3'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3554:3000"
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://myuser:mypassword@db:5432/mydb
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - FAST_REFRESH=false
      - NODE_ENV=development
      - CHOKIDAR_INTERVAL=300
    depends_on:
      - db
    volumes:
      - ./src:/app/src  
      - ./public:/app/public  
      - ./package.json:/app/package.json 
      - ./package-lock.json:/app/package-lock.json  
      - ./tailwind.config.ts:/app/tailwind.config.ts  
      - ./src/app/globals.css:/app/src/app/globals.css  
      - ./tsconfig.json:/app/tsconfig.json  
      - ./prisma:/app/prisma  
      # - ./node_modules:/app/node_modules
      - ./.env:/app/.env
    restart: unless-stopped
    networks:
      - web-network
    command: sh -c "npm rebuild && npm run dev"

  db:
    image: postgres:17
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5455:5432" 
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - web-network


networks:
  web-network:
    driver: bridge

volumes:
  postgres-data:
</file>

<file path=".roo/rules-auditor/rules.md">
## 1. IDENTITY & PERSONA
You are the **Auditor AI** (🔎 The Auditor). You are an unyielding, methodical, and obsessive gatekeeper of quality. You operate like a digital forensics expert, using `grep` on the `repomix-output.xml` context file to find evidence of compliance. You are **strictly forbidden** from simulating, assuming, or bypassing any step. You have **zero tolerance** for placeholder code, TODOs, or any form of incomplete implementation.

## 2. THE CORE MISSION & TRIGGER
Your mission is to perform a holistic, plan-driven audit of the project. You are triggered by the Dispatcher when the `signals/IMPLEMENTATION_COMPLETE.md` signal exists.

## 3. THE HOLISTIC AUDIT WORKFLOW

### PHASE 1: PREPARATION & PLANNING
1.  **Acknowledge & Setup:**
    *   Announce: "Implementation complete. Beginning STRICT static audit protocol."
    *   Consume `signals/IMPLEMENTATION_COMPLETE.md`.
    *   Create `audit/`.
    *   Execute `repomix` to generate `repomix-output.xml`.

2.  **Create Audit Plan:**
    *   Read `docs/canonical_spec.md`.
    *   Create `audit/audit_plan.md`. This plan **must** be a meticulous checklist covering every single feature, requirement, and constraint from the spec.
    *   Announce: "Comprehensive audit plan generated. Commencing `grep`-based verification. No assumptions will be made."

### PHASE 2: EXECUTION & FINDINGS
3.  **Execute Audit Plan (No Exceptions):**
    *   Initialize an empty internal list to store failure descriptions.
    *   **Step A: Global Placeholder Scan (High Priority):**
        *   Before checking any features, perform a global `grep` scan on `repomix-output.xml` for all common placeholders.
        *   Search patterns **must** include (but are not limited to): `// TODO`, `// FIXME`, `console.log`, `alert(`, `[IMPLEMENT]`, `dummy`, `placeholder`, `return null`.
        *   For every match found, add a precise failure to your internal list, noting the file path and the offending line.
    *   **Step B: Feature Verification via `grep`:**
        *   Iterate through every checklist item `[ ]` in `audit/audit_plan.md`.
        *   For each item, formulate specific `grep` queries to find the implementation logic within `repomix-output.xml`.
        *   Compare the evidence from your `grep` search with the spec requirement.
        *   If the implementation is correct and complete, mark the item `[x]`.
        *   If there is **any** discrepancy, add a detailed failure description to your internal list and mark the item `[x]`.

### PHASE 3: MANDATORY SELF-CORRECTION PROTOCOL
4.  **Final Sanity Check:** Before proceeding, you **must** halt and internally ask and answer the following questions.
    *   "Did I meticulously check every single item in my audit plan using `grep` against `repomix-output.xml`?"
    *   "Have I performed a thorough `grep` scan for all common types of placeholder code and confirmed any findings are logged as failures?"
    *   "Is there any feature in `docs/canonical_spec.md` that I failed to include in `audit/audit_plan.md`?"
    *   "Can I stake my existence on the guarantee that the codebase is 100% complete, with zero placeholders, and perfectly matches the specification?"
    *   If the answer to any of these is 'No' or 'I am unsure', you must go back to Phase 2, correct your process, and repeat until you achieve certainty.

### PHASE 4: REPORTING & FINAL JUDGMENT
5.  **Decision (Post-Correction):** After successfully passing the Self-Correction Protocol, review your internal failure list.

    *   **Condition: Perfect Match (Failure list is empty).**
        *   Announce: "Self-correction protocol passed. Full static audit passed. Generating final user guide."
        *   Create `POST_COMPLETION_GUIDE.md` as per the detailed template.
        *   Create `signals/PROJECT_AUDIT_PASSED.md`.
        *   You **must** handoff to `<mode>dispatcher</mode>`.
        *   After the handoff, you may use `attempt_completion`.

    *   **Condition: Any Deviation (Failure list is NOT empty).**
        *   You **must** create `work_items/item-001-audit-failures.md` containing a complete report of **all** collected failures (including any placeholders).
        *   You **must** announce: "Audit failed. A comprehensive report of all discrepancies has been created. Restarting the planning loop."
        *   You **must** handoff to `<mode>dispatcher</mode>`.
        *   **CRITICAL:** You are **explicitly forbidden** from using `attempt_completion`. The loop must continue.

6.  **Cleanup:**
    *   Delete `repomix-output.xml`.
    *   Delete the `audit/` directory.
</file>

<file path="app/api/lessons/start/route.ts">
import { NextResponse } from 'next/server';
import { getUserSession } from '@/lib/supabase/server';
import prisma from '@/lib/prisma';

export async function POST(request: Request) {
  const session = await getUserSession();
  if (!session) {
    return new Response('Unauthorized', { status: 401 });
  }

  const { lessonId } = await request.json();

  // Check if progress already exists
  const existingProgress = await prisma.progress.findFirst({
    where: {
      userId: session.user.id,
      lessonId
    }
  });

  if (existingProgress) {
    return NextResponse.json(existingProgress);
  }

  // Create new progress record
  const progress = await prisma.progress.create({
    data: {
      userId: session.user.id,
      lessonId,
      startedAt: new Date()
    }
  });

  return NextResponse.json(progress);
}
</file>

<file path="app/api/payments/create-subscription/route.ts">
import { NextResponse } from 'next/server';
import Stripe from 'stripe';

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: '2024-04-10'
});

export async function POST(request: Request) {
  try {
    const { tier } = await request.json();
    
    const session = await stripe.checkout.sessions.create({
      payment_method_types: ['card'],
      line_items: [{
        price: getStripePriceId(tier), // You'll need to implement this function
        quantity: 1,
      }],
      mode: 'subscription',
      success_url: `${process.env.NEXT_PUBLIC_SITE_URL}/payment/success?session_id={CHECKOUT_SESSION_ID}`,
      cancel_url: `${process.env.NEXT_PUBLIC_SITE_URL}/payment/cancel`,
    });

    return NextResponse.json({ sessionId: session.id });
  } catch (error) {
    console.error('Stripe error:', error);
    return NextResponse.json(
      { error: 'Failed to create subscription' },
      { status: 500 }
    );
  }
}

// Helper function to map tiers to Stripe price IDs
function getStripePriceId(tier: string): string {
  // Implement your tier to price ID mapping logic here
  switch(tier) {
    case 'premium':
      return 'price_premium_tier_id';
    case 'pro':
      return 'price_pro_tier_id';
    default:
      throw new Error('Invalid tier');
  }
}
</file>

<file path="app/api/stripe/webhook/route.ts">
import { NextResponse } from 'next/server';
import Stripe from 'stripe';
import prisma from '@/lib/prisma';

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: '2024-04-10'
});

export async function POST(request: Request) {
  const payload = await request.text();
  const sig = request.headers.get('stripe-signature');

  try {
    if (!sig) {
      throw new Error('Missing stripe signature');
    }

    const event = stripe.webhooks.constructEvent(
      payload,
      sig,
      process.env.STRIPE_WEBHOOK_SECRET!
    );

    switch (event.type) {
      case 'checkout.session.completed':
        const session = event.data.object as Stripe.Checkout.Session;
        await handleCheckoutSession(session);
        break;
      
      case 'invoice.payment_succeeded':
        const invoice = event.data.object as Stripe.Invoice;
        await handleInvoicePayment(invoice);
        break;

      default:
        console.log(`Unhandled event type: ${event.type}`);
    }

    return NextResponse.json({ received: true }, { status: 200 });
  } catch (err) {
    console.error('Webhook error:', err);
    return NextResponse.json(
      { error: 'Webhook handler failed' },
      { status: 400 }
    );
  }
}

async function handleCheckoutSession(session: Stripe.Checkout.Session) {
  if (!session.customer || typeof session.customer !== 'string') return;
  
  await prisma.user.update({
    where: { stripeCustomerId: session.customer },
    data: {
      subscriptionStatus: 'active',
      subscriptionId: session.subscription as string
    }
  });
}

async function handleInvoicePayment(invoice: Stripe.Invoice) {
  if (!invoice.customer || typeof invoice.customer !== 'string') return;

  await prisma.user.update({
    where: { stripeCustomerId: invoice.customer },
    data: {
      subscriptionCurrentPeriodEnd: new Date(invoice.period_end * 1000)
    }
  });
}
</file>

<file path="app/api/users/profile/route.ts">
import { NextResponse } from 'next/server'
import { getUserSession } from '@/lib/supabase/server'
import prisma from '@/lib/prisma'

export async function GET() {
  const session = await getUserSession()
  
  if (!session) {
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    )
  }

  const user = await prisma.user.findUnique({
    where: { id: session.user.id },
    select: {
      id: true,
      email: true,
      targetLang: true,
      nativeLang: true,
      createdAt: true
    }
  })

  if (!user) {
    return NextResponse.json(
      { error: 'User not found' },
      { status: 404 }
    )
  }

  return NextResponse.json(user)
}

export async function PUT(request: Request) {
  const session = await getUserSession();
  
  if (!session) {
    return NextResponse.json(
      { error: 'Unauthorized' },
      { status: 401 }
    );
  }

  const body = await request.json();
  
  try {
    const updatedUser = await prisma.user.update({
      where: { id: session.user.id },
      data: {
        targetLang: body.targetLang,
        nativeLang: body.nativeLang
      },
      select: {
        id: true,
        email: true,
        targetLang: true,
        nativeLang: true,
        createdAt: true
      }
    });

    return NextResponse.json(updatedUser);
  } catch (error) {
    console.error('Profile update failed:', error);
    return NextResponse.json(
      { error: 'Profile update failed' },
      { status: 500 }
    );
  }
}
</file>

<file path="components/PricingPage.tsx">
'use client';
import { useState } from 'react';
import { loadStripe } from '@stripe/stripe-js';

const stripePromise = loadStripe(process.env.NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY!);

export default function PricingPage() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const handleSubscribe = async (tier: string) => {
    try {
      setLoading(true);
      setError(null);
      
      const response = await fetch('/api/payments/create-subscription', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ tier }),
      });

      if (!response.ok) {
        throw new Error('Failed to create subscription');
      }

      const { sessionId } = await response.json();
      const stripe = await stripePromise;
      
      if (!stripe) {
        throw new Error('Stripe failed to initialize');
      }

      const { error } = await stripe.redirectToCheckout({ sessionId });
      
      if (error) {
        throw error;
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Something went wrong');
      setLoading(false);
    }
  };

  return (
    <div className="max-w-4xl mx-auto py-8 px-4">
      <h1 className="text-3xl font-bold text-center mb-8">Choose Your Plan</h1>
      
      {error && (
        <div className="bg-red-100 text-red-700 p-3 rounded mb-4">
          {error}
        </div>
      )}

      <div className="grid md:grid-cols-2 gap-6">
        <div className="border rounded-lg p-6 shadow-sm">
          <h2 className="text-xl font-semibold mb-4">Premium Plan</h2>
          <p className="text-gray-600 mb-4">$9.99/month</p>
          <ul className="mb-6">
            <li>✔ All basic features</li>
            <li>✔ Advanced analytics</li>
            <li>✔ Priority support</li>
          </ul>
          <button
            onClick={() => handleSubscribe('premium')}
            disabled={loading}
            className="w-full bg-blue-600 text-white py-2 px-4 rounded hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
          >
            {loading ? 'Processing...' : 'Subscribe'}
          </button>
        </div>

        <div className="border rounded-lg p-6 shadow-sm">
          <h2 className="text-xl font-semibold mb-4">Pro Plan</h2>
          <p className="text-gray-600 mb-4">$19.99/month</p>
          <ul className="mb-6">
            <li>✔ All premium features</li>
            <li>✔ Team management</li>
            <li>✔ 24/7 support</li>
          </ul>
          <button
            onClick={() => handleSubscribe('pro')}
            disabled={loading}
            className="w-full bg-blue-600 text-white py-2 px-4 rounded hover:bg-blue-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
          >
            {loading ? 'Processing...' : 'Subscribe'}
          </button>
        </div>
      </div>
    </div>
  );
}
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

/app/generated/prisma
</file>

<file path="app/api/lessons/[id]/submit-answer/route.ts">
import { NextResponse } from 'next/server'
import { supabaseServerClient } from '@/lib/supabase/server'
import prisma from '@/lib/prisma'

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  const supabase = supabaseServerClient()
  const { data: { user }, error } = await supabase.auth.getUser()

  if (error || !user) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
  }

  try {
    const { answer } = await request.json()
    const lessonId = params.id

    // Find the progress record first
    const existingProgress = await prisma.progress.findFirst({
      where: {
        userId: user.id,
        lessonId
      }
    })

    if (!existingProgress) {
      return NextResponse.json(
        { error: 'Progress record not found' },
        { status: 404 }
      )
    }

    // Update progress with the submitted answer
    const progress = await prisma.progress.update({
      where: {
        id: existingProgress.id
      },
      data: {
        score: 1, // Placeholder score, adjust as needed
        completedAt: new Date()
      }
    })

    // Simple answer validation - could be expanded with actual validation logic
    const isValid = answer.trim().length > 0

    return NextResponse.json({
      correct: isValid,
      progress
    })
  } catch (err) {
    console.error('Error submitting answer:', err)
    return NextResponse.json(
      { error: 'Failed to submit answer' },
      { status: 500 }
    )
  }
}
</file>

<file path="lib/ai-service.ts">
import { GoogleGenerativeAI } from '@google/generative-ai';
import { SpeechClient } from '@google-cloud/speech';
import { TextToSpeechClient } from '@google-cloud/text-to-speech';

// Client instances
export let geminiClient: GoogleGenerativeAI;
export let speechClient: SpeechClient;
export let textToSpeechClient: TextToSpeechClient;

// Initialize clients
if (process.env.GCP_CREDENTIALS_JSON) {
  const credentials = JSON.parse(process.env.GCP_CREDENTIALS_JSON);
  geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY || '');
  speechClient = new SpeechClient({ credentials });
  textToSpeechClient = new TextToSpeechClient({ credentials });
} else {
  geminiClient = new GoogleGenerativeAI(process.env.AI_API_KEY || '');
  speechClient = new SpeechClient({ 
    keyFilename: process.env.GCP_CREDENTIALS_PATH || './gcp-credentials.json'
  });
  textToSpeechClient = new TextToSpeechClient({ 
    keyFilename: process.env.GCP_CREDENTIALS_PATH || './gcp-credentials.json'
  });
}

// Type definitions for AI service responses
export interface LessonContent {
  title: string;
  vocabulary: string[];
  dialogue: string;
  exercises: string[];
}

export interface TranscriptionResult {
  text: string;
  confidence: number;
}

export interface AudioSynthesisResult {
  audioContent: Buffer;
  mimeType: string;
}

export interface StreamingTranscriptionResult {
  transcript: string;
  confidence: number;
  isFinal: boolean;
}

export async function* streamingSpeechToText(languageCode: string = 'en-US') {
  const recognizeStream = speechClient.streamingRecognize({
    config: {
      encoding: 'WEBM_OPUS',
      sampleRateHertz: 48000,
      languageCode: languageCode,
      model: 'default',
    },
    interimResults: true, // This is correctly placed at the root level
  });

  // Handle errors
  recognizeStream.on('error', (e) => {
    throw new Error(`Speech recognition error: ${e.message}`);
  });

  // Yield transcription results as they come in
  recognizeStream.on('data', (data) => {
    if (data.results[0]?.alternatives[0]) {
      const result = {
        transcript: data.results[0].alternatives[0].transcript,
        confidence: data.results[0].alternatives[0].confidence || 0,
        isFinal: data.results[0].isFinal,
      };
      recognizeStream.emit('result', result);
    }
  });

  try {
    yield* (recognizeStream as unknown) as AsyncGenerator<StreamingTranscriptionResult>;
  } finally {
    recognizeStream.destroy();
  }
}

export async function textToSpeech(text: string): Promise<AudioSynthesisResult> {
  const [response] = await textToSpeechClient.synthesizeSpeech({
    input: { text },
    voice: {
      languageCode: 'en-US',
      ssmlGender: 'NEUTRAL'
    },
    audioConfig: {
      audioEncoding: 'MP3'
    }
  });

  if (!response.audioContent) {
    throw new Error('No audio content received from TTS service');
  }

  return {
    audioContent: Buffer.from(response.audioContent),
    mimeType: 'audio/mpeg'
  };
}
</file>

<file path="prisma/schema.prisma">
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

generator client {
  provider = "prisma-client-js"
}

model User {
  id           String @id @default(uuid())
  email        String @unique
  password     String
  targetLang   String
  nativeLang   String
  progress     UserProgress[]
  srsEntries   SRSEntry[]
  lessons      Lesson[]
  voiceAnalyses VoiceAnalysis[]
  progressRecords Progress[]
  lessonAnalyses LessonAnalysis[]
  createdAt    DateTime @default(now())
}

model LessonAnalysis {
  id               String   @id @default(cuid())
  lessonId         String
  user             User     @relation(fields: [userId], references: [id])
  userId           String
  accuracy         Float
  pronunciationScore Float?
  weakPoints       String[]
  createdAt        DateTime @default(now())
}

model Lesson {
  id          String @id @default(uuid())
  title       String
  content     String
  difficulty  Int
  userId      String
  user        User @relation(fields: [userId], references: [id])
  exercises   Exercise[]
  completedAt DateTime?
  analysis    VoiceAnalysis[]
  progress    Progress[]
}

model Exercise {
  id          String @id @default(uuid())
  type        String // 'vocabulary', 'grammar', etc.
  content     Json
  difficulty  Int
  language    String
  tags        String // comma-separated list of tags
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  lessonId    String
}

model UserProgress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  metric      String // 'vocabulary', 'grammar', etc.
  score       Float
  lastUpdated DateTime @default(now())
}

model Progress {
  id          String @id @default(uuid())
  userId      String
  user        User @relation(fields: [userId], references: [id])
  lessonId    String
  lesson      Lesson @relation(fields: [lessonId], references: [id])
  completed   Boolean @default(false)
  score       Float?
  startedAt   DateTime @default(now())
  completedAt DateTime?
}

model SRSEntry {
  id             String @id @default(uuid())
  userId         String
  user           User @relation(fields: [userId], references: [id])
  item           String // word or grammar concept
  recallStrength Float @default(1.0)
  nextReview     DateTime @default(now())
  language       String
  @@index([userId, nextReview])
}

model VoiceAnalysis {
  id        String @id @default(uuid())
  userId    String
  user      User @relation(fields: [userId], references: [id])
  lessonId  String
  lesson    Lesson @relation(fields: [lessonId], references: [id])
  metrics   Json // {pace: 120, accuracy: 0.85, ...}
  audioUrl  String
  createdAt DateTime @default(now())
}
</file>

<file path=".roo/custom_modes.yaml">
customModes:
  - slug: product-manager
    name: Product Manager (The Clarifier)
    roleDefinition: >-
      You are the **Product Manager AI** (📈). Your sole purpose is to transform the user's initial, potentially vague `app_description.md` into a comprehensive and unambiguous `/docs/canonical_spec.md`. You are the source of project truth.
    groups: [read, edit, command, mcp]
    source: global

  - slug: planner
    name: Planner (The Master Planner)
    roleDefinition: >-
      You are the **Planner AI** (🧠). Triggered by a complete specification, you perform a single, upfront planning session to create a 100% complete work breakdown structure for the entire project, stored in `work_breakdown/`.
    groups: [read, edit, command, mcp]
    source: global

  - slug: developer
    name: Developer (The Marathon Runner)
    roleDefinition: >-
      You are the **Developer AI** (👨‍💻). You implement the full project plan by writing code. You operate in a **static-only** mode, meaning you cannot run tests, migrations, or servers, but you can use code generators like 'prisma generate'.
    groups: [read, edit, command, mcp]
    source: global

  - slug: auditor
    name: Auditor (The Gatekeeper)
    roleDefinition: >-
      You are the **Auditor AI** (🔎). You perform a **static-only** audit of the codebase against the spec. You do not run tests. If the audit passes, you generate the final `POST_COMPLETION_GUIDE.md` for the user.
    groups: [read, edit, command, mcp]
    source: global

  - slug: dispatcher
    name: Dispatcher (The Conductor)
    roleDefinition: >-
      You are the **Dispatcher AI** (🤖). You are the master router of the phase-gated factory. You read signals from the `signals/` directory and hand off control to the appropriate specialist for the next phase of work.
    groups: [read, edit, command, mcp]
    source: global

  - slug: emergency
    name: Emergency
    roleDefinition: >-
      You are the **Emergency AI** (🚨). You are a tactical fail-safe. You are triggered by a `NEEDS_ASSISTANCE.md` signal from the Developer. You diagnose the failure, create a `FIX_PLAN.md`, and hand back to the Dispatcher to restart the development phase.
    groups: [read, edit, command, browser, mcp]
    source: global

  - slug: system-supervisor
    name: System Supervisor (Meta-Agent)
    roleDefinition: >-
      You are the **System_Supervisor AI** (👑). You are the meta-agent that fixes the system itself. Triggered by the Dispatcher on infinite loops, you diagnose and rewrite the rules of failing agents to correct the system's logic.
    groups: [read, edit, command, browser, mcp]
    source: global
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ESNext",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noImplicitAny": true,
    "strictNullChecks": true,
    "strictFunctionTypes": true,
    "noImplicitThis": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "allowSyntheticDefaultImports": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts", "next.config.js", "src/config/performance.js"],
  "exclude": ["node_modules"]
}
</file>

<file path="components/LessonView.tsx">
'use client'

import React from 'react'
import { useState, useEffect, useRef } from 'react'
import { textToSpeech, streamingSpeechToText } from '@/lib/ai-service'
import PronunciationMeter from '@/components/feedback/PronunciationMeter'
import ProgressIndicator from '@/components/feedback/ProgressIndicator'

type Lesson = {
  id: string
  title: string
  content: string
  nextLessonId?: string
  prevLessonId?: string
}

export default function LessonView() {
  const [currentLesson, setCurrentLesson] = useState<Lesson | null>(null)
  const [messages, setMessages] = useState<Array<{
    text: string
    isUser: boolean
    confidence?: number
  }>>([])
  const [isRecording, setIsRecording] = useState(false)
  const [interimTranscript, setInterimTranscript] = useState('')
  
  const playAudio = async (audioBuffer: Buffer, mimeType: string) => {
    const blob = new Blob([audioBuffer], { type: mimeType })
    const url = URL.createObjectURL(blob)
    const audio = new Audio(url)
    await audio.play()
    URL.revokeObjectURL(url) // Clean up
  }

  const [newMessage, setNewMessage] = useState('')
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioStreamRef = useRef<MediaStream | null>(null)

  useEffect(() => {
    if (currentLesson?.id) {
      fetch(`/api/lessons/${currentLesson.id}`)
        .then(res => res.json())
        .then(data => setCurrentLesson(data))
    }
  }, [currentLesson?.id])

  const toggleRecording = async () => {
    if (isRecording) {
      stopRecording()
    } else {
      startRecording()
    }
  }

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      audioStreamRef.current = stream
      const mediaRecorder = new MediaRecorder(stream)
      mediaRecorderRef.current = mediaRecorder
      
      const audioChunks: Blob[] = []
      mediaRecorder.ondataavailable = (e) => {
        audioChunks.push(e.data)
      }

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' })
        const arrayBuffer = await audioBlob.arrayBuffer()
        Buffer.from(arrayBuffer) // Prepare for sending to backend
        // Here you would send the audioBuffer to your backend for processing
      }

      mediaRecorder.start()
      setIsRecording(true)

      // Start streaming to STT
      const sttStream = streamingSpeechToText()
      for await (const result of sttStream) {
        if (result.isFinal) {
          setMessages(prev => [...prev, {text: result.transcript, isUser: true}])
          setInterimTranscript('')
        } else {
          setInterimTranscript(result.transcript)
        }
      }
    } catch (error) {
      console.error('Error starting recording:', error)
      setIsRecording(false)
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current = null
    }
    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach((track: MediaStreamTrack) => track.stop())
      audioStreamRef.current = null
    }
    setIsRecording(false)
  }

  const startLesson = async () => {
    try {
      const response = await fetch('/api/lessons/start', {
        method: 'POST'
      })
      const data = await response.json()
      setCurrentLesson(data)
    } catch (error) {
      console.error('Failed to start lesson:', error)
    }
  }

  return (
    <div className="flex flex-col h-screen max-w-2xl mx-auto">
      <div className="p-4">
        <ProgressIndicator progress={33} /> {/* Temporary static value */}
      </div>
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {!currentLesson && (
          <button
            onClick={startLesson}
            className="bg-blue-600 text-white px-6 py-3 rounded-lg hover:bg-blue-700 transition-colors"
          >
            Start New Lesson
          </button>
        )}
        
        {messages.map((message, index) => (
          <div
            key={index}
            className={`flex ${message.isUser ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-xs lg:max-w-md p-4 rounded-lg ${
                message.isUser 
                  ? 'bg-blue-600 text-white' 
                  : 'bg-gray-100 text-gray-800'
              }`}
            >
              {message.text}
            </div>
            {message.isUser && message.confidence && (
              <PronunciationMeter confidence={message.confidence} />
            )}
          </div>
        ))}
      </div>

      <div className="border-t p-4">
        <form
          onSubmit={async (e) => {
            e.preventDefault();
            if (!newMessage.trim()) return;

            try {
              // Add user message
              setMessages(prev => [...prev, {text: newMessage, isUser: true}]);
              setNewMessage('');
              
              // Simulate bot response
              const botResponse = "Great! Let's practice that.";
              setMessages(prev => [...prev, {text: botResponse, isUser: false}]);
              
              // Convert bot response to speech
              const { audioContent, mimeType } = await textToSpeech(botResponse);
              await playAudio(audioContent, mimeType);
            } catch (error) {
              console.error('Error processing message:', error);
            }
          }}
          className="flex gap-2"
        >
          <input
            type="text"
            value={newMessage}
            onChange={(e) => setNewMessage(e.target.value)}
            placeholder="Type your answer..."
            className="flex-1 border rounded-lg px-4 py-2 focus:outline-none focus:ring-2 focus:ring-blue-500"
          />
          <button
            type="button"
            onClick={toggleRecording}
            className={`px-4 py-2 rounded-lg transition-colors ${
              isRecording
                ? 'bg-red-600 text-white hover:bg-red-700'
                : 'bg-gray-200 text-gray-700 hover:bg-gray-300'
            }`}
          >
            {isRecording ? '⏹ Stop' : '🎤 Record'}
          </button>
          <button
            type="submit"
            className="bg-blue-600 text-white px-6 py-2 rounded-lg hover:bg-blue-700 transition-colors"
          >
            Send
          </button>
          {interimTranscript && (
            <div className="absolute bottom-full mb-2 text-sm text-gray-500">
              {interimTranscript}
            </div>
          )}
        </form>
      </div>
    </div>
  )
}
</file>

<file path=".roo/rules-emergency/rules.md">
## 1. IDENTITY & PERSONA
You are the **Emergency Intervention AI** (🚨 Emergency). You are a manifest-driven diagnostician. You use the `architectural_map` and the `<codebase_search>` tool to rapidly pinpoint the source of an error.

## 2. THE CORE MISSION & TRIGGER
Triggered by a `needs_assistance` signal, your mission is to diagnose the failure, create a `FIX_PLAN.md`, and register it in the manifest.

## 3. THE INTERVENTION WORKFLOW

1.  **Read the Manifest:** Read `project_manifest.json` to get all file paths and the `architectural_map`.
2.  **Analyze Failure Signal:** Read the contents of the `needs_assistance` signal file to get the error message and context.
3.  **Diagnose with Codebase Search (Targeted):**
    *   First, try a direct query using the `<codebase_search>` tool:
        <codebase_search>
        <query>[verbatim error message from needs_assistance file]</query>
        </codebase_search>
    *   If that is inconclusive, read the developer's notes in the signal file to identify the architectural concept (e.g., "The error is in the user session logic").
    *   Look up the concept (e.g., "authentication") in the `architectural_map`.
    *   Run the high-quality query from the map using the `<codebase_search>` tool:
        <codebase_search>
        <query>[query from manifest's architectural_map]</query>
        </codebase_search>
4.  **Formulate and Register Fix Plan:**
    *   Create a `FIX_PLAN.md` with precise steps.
    *   Update the `active_plan_file` in `project_manifest.json` to point to `FIX_PLAN.md`.
5.  **Consume Distress Signal:**
    *   Delete the `needs_assistance` signal file.
    *   Log and announce the resolution.
6.  **Handoff:** Switch to `<mode>dispatcher</mode>`.
</file>

<file path="FIX_PLAN.md">
# Emergency Fix Plan: Missing Canonical Specification

## Problem Diagnosis
The system has encountered a critical failure due to the absence of the canonical specification document (`docs/canonical_spec.md`). This file is required for:
1. Architect planning
2. Developer implementation
3. Audit verification
4. Overall project coherence

## Fix Steps

### 1. Create Canonical Specification
- Create `docs/canonical_spec.md` with the following structure:
```markdown
# Canonical Specification: Lessay-Cline Application

## Overview
[Application purpose and high-level functionality]

## Core Components
1. User Authentication
2. Lesson Management
3. SRS (Spaced Repetition System)
4. Payment Processing
5. Analytics and Reporting

## Detailed Requirements
[Expand each component with specific functional requirements]

## Non-Functional Requirements
- Performance
- Security
- Scalability

## Data Models
[Database schema and relationships]

## API Specifications
[Endpoint definitions and payload structures]
```

### 2. Populate Specification Content
- Extract requirements from existing documentation:
  - `docs/app_description.md`
  - `docs/work_breakdown/master_plan.md`
  - `work_items/` audit reports
- Consult codebase implementation for implicit requirements

### 3. Validate Specification
- Review with all stakeholders
- Ensure complete coverage of:
  - Functional requirements
  - Business rules
  - Edge cases

### 4. Update System State
- Create `signals/SPECIFICATION_COMPLETE.md` to trigger Architect
- Remove emergency artifacts:
  - `work_items/audit_failure_missing_spec.md`
  - `NEEDS_ASSISTANCE.md` (if present)

## Implementation Notes
- This is a foundational document - invest adequate time in its creation
- Ensure all future development references this specification
- Establish change control process for specification updates
</file>

<file path="package.json">
{
  "name": "app",
  "version": "0.1.0",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "test": "echo 'No tests yet' && exit 0"
  },
  "dependencies": {
    "@google-cloud/speech": "^7.1.0",
    "@google-cloud/text-to-speech": "^6.1.0",
    "@google/generative-ai": "^0.24.1",
    "@heroicons/react": "^2.2.0",
    "@prisma/client": "^6.9.0",
    "@stripe/react-stripe-js": "^3.7.0",
    "@stripe/stripe-js": "^7.3.1",
    "@supabase/auth-helpers-nextjs": "^0.10.0",
    "@supabase/supabase-js": "^2.50.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "stripe": "^18.2.1"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@next-auth/prisma-adapter": "^1.0.7",
    "@tailwindcss/postcss": "^4",
    "@types/jsonwebtoken": "^9.0.9",
    "@types/next-auth": "^3.15.0",
    "@types/node": "^20.19.0",
    "@types/react": "^19.1.8",
    "@types/react-dom": "^19.1.6",
    "@types/ws": "^8.18.1",
    "eslint": "^9",
    "eslint-config-next": "15.3.3",
    "next": "^15.3.3",
    "prisma": "^6.9.0",
    "tailwindcss": "^4",
    "ts-node": "^10.9.2",
    "typescript": "^5.8.3"
  }
}
</file>

<file path=".roo/rules-developer/rules.md">
## 1. IDENTITY & PERSONA
You are the **Developer AI** (👨‍💻 The Resilient Runner). You are a highly efficient specialist who implements the project task by task. You are also self-aware: you monitor your own progress, recognize when you are stuck, and know when to ask for help instead of repeating a failing approach. Your work is purely static; you write code, you do not run it.

## 2. THE CORE MISSION & TRIGGER
Your mission is to execute all tasks outlined in the files under `work_breakdown/tasks/`. You are triggered by the Dispatcher when `signals/PLANNING_COMPLETE.md` exists, or when incomplete tasks are detected and the system hands control back to you.

## 3. EXECUTION CONSTRAINTS
*   **Static Generation Only:** You are **strictly forbidden** from executing runtime commands (e.g., `npm test`, `docker-compose up`).
*   **Permitted Commands:** You **are permitted** to run static code generation tools like `prisma generate`. You should consider a successful run of such tools as a "unit test" for your implementation.
*   **Environment Variables:** You **must** create `.env.example` and a placeholder `.env` file.

## 4. THE IMPLEMENTATION MARATHON (WITH SELF-CORRECTION)

1.  **Acknowledge & Set Up:**
    *   Announce: "Implementation marathon beginning. Adhering to static-only generation and self-correction protocols."
    *   If `signals/PLANNING_COMPLETE.md` exists, consume it.

2.  **The Outer Loop: Task Selection**
    *   This loop continues until **every task in every file** under `work_breakdown/tasks/` is marked complete `[x]`.
    *   **STEP 1: Find Next Task.**
        *   Scan all `.md` files in `work_breakdown/tasks/` for the first available incomplete task `[ ]`.
        *   If no incomplete tasks are found, proceed to Step 4 (Announce & Handoff).
        *   If a task is found, store its file path and description. Now, enter the Inner Loop.

3.  **The Inner Loop: Task Execution & Self-Questioning**
    *   Initialize an attempt counter for the current task: `attempts = 0`. Set `MAX_ATTEMPTS = 3`.
    *   **While `attempts < MAX_ATTEMPTS`:**
        *   **A. Self-Question (Before Attempt):**
            *   `attempts = attempts + 1`
            *   "This is attempt [attempts] for task: '[task description]'. My strategy is to [describe implementation plan]."
        *   **B. Execute:**
            *   Implement the code required to complete the task.
        *   **C. Self-Verify:**
            *   Run any relevant static analysis or generation commands (e.g., `prisma generate`).
            *   If the commands succeed and you believe the code fulfills the task, the attempt is successful. Break this inner loop and proceed to Step D.
            *   If the commands fail, the attempt has failed.
        *   **D. Self-Question (After Failure):**
            *   "Attempt [attempts] failed with error: [error message]. Is this a simple typo, or is my approach flawed? I will re-read the plan and try a different implementation strategy."
            *   (The loop will then repeat for the next attempt).
    *   **After the Inner Loop:**
        *   **If the attempt was successful:**
            *   Announce: "Task completed successfully."
            *   Commit the changes (`git add . && git commit -m "..."`).
            *   Update the plan file by marking the task `[x]`.
            *   **Return to the Outer Loop (Step 1)** to find the next task.
        *   **If `attempts` reached `MAX_ATTEMPTS` (you are stuck):**
            *   HALT the marathon.
            *   Go to the Failure Protocol (Step 5).

4.  **Announce & Handoff (Only when ALL tasks are complete):**
    *   Create `signals/IMPLEMENTATION_COMPLETE.md`.
    *   Announce: "Implementation marathon complete. All tasks in all plan files are finished. The codebase is ready for a holistic audit."
    *   Switch mode to `<mode>dispatcher</mode>`.

5.  **FAILURE PROTOCOL (When Stuck)**
    *   Announce: "I have failed to complete a task after [MAX_ATTEMPTS] attempts. I am stuck and require assistance."
    *   Create `signals/NEEDS_ASSISTANCE.md`. The content of this file **must** include:
        *   The task description that failed.
        *   The file path of the plan.
        *   A summary of the failed approaches.
        *   The final error message received.
    *   Hand off to the Dispatcher by switching to `<mode>dispatcher</mode>`.
    *   Do **not** create the `IMPLEMENTATION_COMPLETE.md` signal.
</file>

</files>
